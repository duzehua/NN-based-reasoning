{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "path_model = \"./checkpoint/\"\n",
    "batch_size = 512\n",
    "epochs = 15\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "# sampler = torch.utils.data.SubsetRandomSampler(indices=list(range(2000)))\n",
    "\n",
    "# download mnist dataset\n",
    "dataset_train = torchvision.datasets.MNIST(root='./data/',train=True,download=True,transform=transform)\n",
    "dataset_test = torchvision.datasets.MNIST(root='./data/',train=False,download=True,transform=transform)\n",
    "\n",
    "class_names = dataset_train.classes  # 获取数据集的分类信息 返回一个字典\n",
    "# load dataset\n",
    "data_train = dataloader(dataset=dataset_train,batch_size=batch_size,shuffle=False)\n",
    "data_test = dataloader(dataset=dataset_test,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "print(len(data_train))\n",
    "# for batch_idx,(data,target) in enumerate(data_test):\n",
    "#     print(\"id \",batch_idx, \"data shape\",data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()  # 切换到测试模式\n",
    "    test_correct_num = 0\n",
    "    with torch.no_grad():   # 不更新参数\n",
    "\n",
    "        for batch_idx,(data,target) in enumerate(data_test):\n",
    "            # data = data.to(device)\n",
    "            # target = target.to(device)\n",
    "            output, _ = net(data) # 正向传播得到预测值\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            test_correct_num += torch.sum(pred==target).item()\n",
    "            print(\"Test Epoch:{} [{}/{} ({:.0f}%)]\\t acc:{:.2f}\".format(epoch,batch_idx*batch_size,len(data_test.dataset),\n",
    "                                                 100. * batch_size*batch_idx/len(data_test.dataset),test_correct_num/len(data_test.dataset)))\n",
    "def train(epoch):\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(data_train):\n",
    "        # 清除grad累积值\n",
    "        optimizer.zero_grad()\n",
    "        # 读取dataloader中的数据，前半部分是tensor变量，后半部分是真实label\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward之后得到预测值\n",
    "        output, process_output_ = net(data)\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_layerout(epoch, batch_idx, process_output_)\n",
    "        # 计算loss\n",
    "        loss = cost_fun(output, target)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # 收集一组新的梯度，并使用optimizer.step()将其传播回每个网络参数\n",
    "        optimizer.step()\n",
    "        # 给出loss和acc\n",
    "        train_loss.append(loss)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        correct_num = torch.sum(pred == target).item()\n",
    "        train_acc.append(correct_num / batch_size)\n",
    "        print(\"Train Epoch:{}[{}/{} ({:.0f}%)]\\t Loss:{:.6f} acc:{:.2f}\".format(epoch, batch_idx * batch_size,\n",
    "               len(data_train.dataset),100. * batch_size * batch_idx / len(data_train.dataset), loss.item(),correct_num / batch_size))\n",
    "        \n",
    "        # MNIST一共60000个数据，batch_size为512，一共60000/512 = 118个batch\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_weight(epoch, batch_idx)\n",
    "\n",
    "def save_layerout(epoch, batch_idx, process_output_):\n",
    "\n",
    "    # TODO 将读取出来的参数进行保存，注意确认是否存在tensor与np之间的转换通道问题\n",
    "    '''\n",
    "    文件名共分8部分：\n",
    "    epoch filenums index                       number        channel   length  width  value_name\n",
    "    轮数   文件总数  序号(按参数在网络中的顺序)  变量中数据块个数 变量通道数  变量长   变量宽  变量名称\n",
    "    ''' \n",
    "    # TODO 根据需求改前缀字符串\n",
    "    # cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    cscfphn_str = '0' + '_' + str(len(process_output_)) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    # 将网络的过程结果进行保存\n",
    "    col_counter = 0\n",
    "\n",
    "    if (100 > len(process_output_) > 9):\n",
    "        cn_prex_flag = 1  # 层数个数达两位数\n",
    "    elif (1000 > len(process_output_) > 99):\n",
    "        cn_prex_flag = 2  # 层数个数达三位数\n",
    "    else: cn_prex_flag = 0  # 层数个数达一位数\n",
    "\n",
    "    for key in process_output_.keys():\n",
    "\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = process_output_[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # --\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            # TODO 根据需求改第一维的数值\n",
    "            if cvsl_idx == 0:  # 第一维个数改为1\n",
    "                pre_load_len_name = pre_load_len_name + '1' + '_'\n",
    "            else :\n",
    "                pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # --\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名，根据文件总数进行补‘0’，以使文件被顺序读取\n",
    "        if cn_prex_flag == 1:  # 层数个数达两位数\n",
    "            if 9 >= col_counter >= 0 :   # 小于两位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        elif cn_prex_flag == 2: # 层数个数达三位数\n",
    "            if 9 >= col_counter >= 0 :  # 小于三位数多添两个0\n",
    "                curt_csv_file_name = cscfphn_str + '00' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            elif 99 >= col_counter >= 10 :  # 小于三位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        else :\n",
    "            curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        \n",
    "        # 数据存储\n",
    "        if not os.path.isdir('layeroutput_data'):\n",
    "            os.mkdir('.\\layeroutput_data')\n",
    "        layer_output_result_path = '.\\layeroutput_data'\n",
    "        with open(layer_output_result_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\",\n",
    "                    newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            data = process_output_[key].reshape(-1)\n",
    "            data_np = data.detach().numpy()  # TODO 注意确认是否存在通道问题、此处摒弃梯度信息\n",
    "            writer.writerows([data_np])\n",
    "            # writer.writerows([data_curt] for data_curt in data_np)\n",
    "            csvfile.close()\n",
    "            # --\n",
    "        col_counter += 1\n",
    "\n",
    "def save_weight(epoch, batch_idx):\n",
    "    # 网络参数输出\n",
    "    parm = {}\n",
    "    for name, parameters in net.named_parameters():\n",
    "        # print('网络参数输出')\n",
    "        # print(name, ':', parameters.size())\n",
    "        parm[name] = parameters.detach().numpy()  # 将tensor变量转换为np格式\n",
    "\n",
    "    # TODO 将读取出来的参数进行保存，注意确认是否存在tensor与np之间的转换通道问题\n",
    "    '''\n",
    "    文件名共分8部分：\n",
    "    epoch filenums index                       number        channel   length  width  value_name\n",
    "    轮数   文件总数  序号(按参数在网络中的顺序)  变量中数据块个数 变量通道数  变量长   变量宽  变量名称\n",
    "    '''\n",
    "    \n",
    "    # TODO 根据需求改前缀字符串\n",
    "    # cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    cscfphn_str = '0' + '_' + str(len(parm)) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    \n",
    "    if (100 > len(parm) > 9):\n",
    "        cn_prex_flag = 1  # 层数个数达两位数\n",
    "    elif (1000 > len(parm) > 99):\n",
    "        cn_prex_flag = 2  # 层数个数达三位数\n",
    "    else: cn_prex_flag = 0  # 层数个数达一位数\n",
    "\n",
    "    col_counter = 0\n",
    "    for key in parm.keys():\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = parm[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # -- 定义有信息的前导尺寸\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # -- 将无信息的前导尺寸设置为缺省值\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名，根据文件总数进行补‘0’，以使文件被顺序读取\n",
    "        if cn_prex_flag == 1:  # 层数个数达两位数\n",
    "            if 9 >= col_counter >= 0 :   # 小于两位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        elif cn_prex_flag == 2: # 层数个数达三位数\n",
    "            if 9 >= col_counter >= 0 :  # 小于三位数多添两个0\n",
    "                curt_csv_file_name = cscfphn_str + '00' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            elif 99 >= col_counter >= 10 :  # 小于三位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        else :\n",
    "            curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        # 数据存储\n",
    "        # 创建文件对象\n",
    "        if not os.path.isdir('layer_para'):\n",
    "            os.mkdir('.\\layer_para')\n",
    "        if not os.path.isdir('layer_para\\\\bias'):\n",
    "            os.mkdir('.\\layer_para\\\\bias')\n",
    "        if not os.path.isdir('layer_para\\\\weight'):\n",
    "            os.mkdir('.\\layer_para\\\\weight')\n",
    "        layer_para_path = '.\\layer_para'\n",
    "        layer_bias_para_path = '.\\layer_para\\\\bias'\n",
    "        layer_weight_para_path = '.\\layer_para\\\\weight'\n",
    "        if('bias' in key):\n",
    "            with open(layer_bias_para_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "                writer = csv.writer(csvfile, delimiter=' ')\n",
    "                data = parm[key].reshape(-1)\n",
    "                # writer.writerows([data_curt] for data_curt in data)\n",
    "                writer.writerows([data])\n",
    "                csvfile.close()\n",
    "        else :\n",
    "            with open(layer_weight_para_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "                writer = csv.writer(csvfile, delimiter=' ')\n",
    "                data = parm[key].reshape(-1)\n",
    "                # writer.writerows([data_curt] for data_curt in data)\n",
    "                writer.writerows([data])\n",
    "                csvfile.close()            \n",
    "        # --\n",
    "        col_counter += 1 \n",
    "    \n",
    "def save_state():\n",
    "    print('===> Saving weights...')\n",
    "    state = {\n",
    "        'state': net.state_dict(),\n",
    "        'epoch': epoch  # 将epoch一并保存\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('./checkpoint')\n",
    "    torch.save(state, path_model + 'Epoch:' + str(epoch) + ' Loss:' + str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "def predict():\n",
    "    state_path = './checkpoint/model_14.pth' #  ***为指定加载的权重文件名称\n",
    "    print('===> Loading weights : ' + state_path)\n",
    "    weight_dict = torch.load(state_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "    # 从测试集中选取一个batch做预测\n",
    "    # pred_test = enumerate(data_test)\n",
    "    # batch_idx, (pred_data, pred_gt) = next(pred_test)\n",
    "    # output = net(pred_data)\n",
    "    # print(\"data: \", output.data)\n",
    "    # maxdata, pred = torch.max(output.data, 1) # 得到预测值,返回每一行的最大值，且返回索引\n",
    "    # print(\"maxdata: \", maxdata)\n",
    "    # print(\"ground truth: \",pred_gt)\n",
    "    # print(\"predict value: \",pred)\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    # 把tensor转成Image， 方便可视化\n",
    "    show = ToPILImage()\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "    net.eval()\n",
    "    for i in np.random.randint(0,20,size=10):\n",
    "        x, y = dataset_test[i][0], dataset_test[i][1]\n",
    "        # tensor格式数据可视化\n",
    "        show(x).show()\n",
    "        # 扩展张量维度为4维\n",
    "        x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=False).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "            predicted, actual = classes[torch.argmax(pred[0])], classes[y]\n",
    "            # 最终输出的预测值与真实值\n",
    "            print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "class LeNet(nn.Module): \t\t\t\t\t# 继承于nn.Module这个父类\n",
    "    def __init__(self):\t\t\t\t\t\t# 初始化网络结构\n",
    "        super(LeNet, self).__init__()    \t# 多继承需用到super函数\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),  # 输出为6*28*28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为6*14*14\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 输出为16*10*10\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为16*5*5\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # 正向传播过程\n",
    "        # x = self.block_1(x)\n",
    "        # x = x.view(-1,16*5*5)\n",
    "        # x = self.block_2(x)\n",
    "        block1_conv1_out = self.block_1[0](x)\n",
    "        block1_relu1_out = self.block_1[1](block1_conv1_out)\n",
    "        block1_maxpo1_out = self.block_1[2](block1_relu1_out)\n",
    "        block1_conv2_out = self.block_1[3](block1_maxpo1_out)\n",
    "        block1_relu2_out = self.block_1[4](block1_conv2_out)\n",
    "        block1_maxpo2_out = self.block_1[5](block1_relu2_out)\n",
    "\n",
    "        block1_flatten_out = block1_maxpo2_out.view(-1,16*5*5)\n",
    "\n",
    "        block2_fc1_out = self.block_2[0](block1_flatten_out)\n",
    "        block2_relu1_out = self.block_2[1](block2_fc1_out)\n",
    "        block2_fc2_out = self.block_2[2](block2_relu1_out)\n",
    "        block2_relu2_out = self.block_2[3](block2_fc2_out)\n",
    "        block2_fc3_out = self.block_2[4](block2_relu2_out)\n",
    "\n",
    "        softmax_output =  self.block_2[5](block2_fc3_out)\n",
    "\n",
    "        process_output = {'block1_conv1_out': block1_conv1_out,\n",
    "                          'block1_relu1_out': block1_relu1_out,\n",
    "                          'block1_maxpo1_out': block1_maxpo1_out,\n",
    "                          'block1_conv2_out': block1_conv2_out,\n",
    "                          'block1_relu2_out': block1_relu2_out,\n",
    "                          'block1_maxpo2_out': block1_maxpo2_out,\n",
    "                          'block1_flatten_out': block1_flatten_out,\n",
    "\n",
    "                          'block2_fc1_out': block2_fc1_out,\n",
    "                          'block2_relu1_out': block2_relu1_out,\n",
    "                          'block2_fc2_out': block2_fc2_out,\n",
    "                          'block2_relu2_out': block2_relu2_out,\n",
    "                          'block2_fc3_out': block2_fc3_out,\n",
    "                          'softmax_output': softmax_output\n",
    "                        }\n",
    "\n",
    "        return block2_fc3_out, process_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0[0/60000 (0%)]\t Loss:2.320146 acc:0.08\n",
      "Train Epoch:0[512/60000 (1%)]\t Loss:2.317503 acc:0.10\n",
      "Train Epoch:0[1024/60000 (2%)]\t Loss:2.311996 acc:0.10\n",
      "Train Epoch:0[1536/60000 (3%)]\t Loss:2.313923 acc:0.08\n",
      "Train Epoch:0[2048/60000 (3%)]\t Loss:2.317674 acc:0.10\n",
      "Train Epoch:0[2560/60000 (4%)]\t Loss:2.319223 acc:0.09\n",
      "Train Epoch:0[3072/60000 (5%)]\t Loss:2.316890 acc:0.08\n",
      "Train Epoch:0[3584/60000 (6%)]\t Loss:2.314215 acc:0.08\n",
      "Train Epoch:0[4096/60000 (7%)]\t Loss:2.320610 acc:0.08\n",
      "Train Epoch:0[4608/60000 (8%)]\t Loss:2.321168 acc:0.08\n",
      "Train Epoch:0[5120/60000 (9%)]\t Loss:2.318721 acc:0.08\n",
      "Train Epoch:0[5632/60000 (9%)]\t Loss:2.315048 acc:0.08\n",
      "Train Epoch:0[6144/60000 (10%)]\t Loss:2.308203 acc:0.10\n",
      "Train Epoch:0[6656/60000 (11%)]\t Loss:2.312018 acc:0.10\n",
      "Train Epoch:0[7168/60000 (12%)]\t Loss:2.311709 acc:0.09\n",
      "Train Epoch:0[7680/60000 (13%)]\t Loss:2.316766 acc:0.08\n",
      "Train Epoch:0[8192/60000 (14%)]\t Loss:2.316179 acc:0.06\n",
      "Train Epoch:0[8704/60000 (15%)]\t Loss:2.316101 acc:0.09\n",
      "Train Epoch:0[9216/60000 (15%)]\t Loss:2.311639 acc:0.09\n",
      "Train Epoch:0[9728/60000 (16%)]\t Loss:2.313223 acc:0.08\n",
      "Train Epoch:0[10240/60000 (17%)]\t Loss:2.311977 acc:0.10\n",
      "Train Epoch:0[10752/60000 (18%)]\t Loss:2.312916 acc:0.08\n",
      "Train Epoch:0[11264/60000 (19%)]\t Loss:2.312240 acc:0.10\n",
      "Train Epoch:0[11776/60000 (20%)]\t Loss:2.311283 acc:0.09\n",
      "Train Epoch:0[12288/60000 (20%)]\t Loss:2.312046 acc:0.09\n",
      "Train Epoch:0[12800/60000 (21%)]\t Loss:2.306555 acc:0.09\n",
      "Train Epoch:0[13312/60000 (22%)]\t Loss:2.304766 acc:0.10\n",
      "Train Epoch:0[13824/60000 (23%)]\t Loss:2.311886 acc:0.09\n",
      "Train Epoch:0[14336/60000 (24%)]\t Loss:2.309158 acc:0.09\n",
      "Train Epoch:0[14848/60000 (25%)]\t Loss:2.307410 acc:0.10\n",
      "Train Epoch:0[15360/60000 (26%)]\t Loss:2.309009 acc:0.10\n",
      "Train Epoch:0[15872/60000 (26%)]\t Loss:2.303653 acc:0.10\n",
      "Train Epoch:0[16384/60000 (27%)]\t Loss:2.304271 acc:0.09\n",
      "Train Epoch:0[16896/60000 (28%)]\t Loss:2.310651 acc:0.07\n",
      "Train Epoch:0[17408/60000 (29%)]\t Loss:2.310713 acc:0.09\n",
      "Train Epoch:0[17920/60000 (30%)]\t Loss:2.307826 acc:0.08\n",
      "Train Epoch:0[18432/60000 (31%)]\t Loss:2.310621 acc:0.08\n",
      "Train Epoch:0[18944/60000 (32%)]\t Loss:2.306438 acc:0.09\n",
      "Train Epoch:0[19456/60000 (32%)]\t Loss:2.305929 acc:0.11\n",
      "Train Epoch:0[19968/60000 (33%)]\t Loss:2.307921 acc:0.08\n",
      "Train Epoch:0[20480/60000 (34%)]\t Loss:2.306001 acc:0.08\n",
      "Train Epoch:0[20992/60000 (35%)]\t Loss:2.302204 acc:0.10\n",
      "Train Epoch:0[21504/60000 (36%)]\t Loss:2.306195 acc:0.09\n",
      "Train Epoch:0[22016/60000 (37%)]\t Loss:2.305880 acc:0.09\n",
      "Train Epoch:0[22528/60000 (38%)]\t Loss:2.307777 acc:0.10\n",
      "Train Epoch:0[23040/60000 (38%)]\t Loss:2.302632 acc:0.09\n",
      "Train Epoch:0[23552/60000 (39%)]\t Loss:2.299610 acc:0.11\n",
      "Train Epoch:0[24064/60000 (40%)]\t Loss:2.301581 acc:0.10\n",
      "Train Epoch:0[24576/60000 (41%)]\t Loss:2.307037 acc:0.08\n",
      "Train Epoch:0[25088/60000 (42%)]\t Loss:2.302643 acc:0.09\n",
      "Train Epoch:0[25600/60000 (43%)]\t Loss:2.305256 acc:0.09\n",
      "Train Epoch:0[26112/60000 (44%)]\t Loss:2.297012 acc:0.12\n",
      "Train Epoch:0[26624/60000 (44%)]\t Loss:2.297938 acc:0.10\n",
      "Train Epoch:0[27136/60000 (45%)]\t Loss:2.303869 acc:0.10\n",
      "Train Epoch:0[27648/60000 (46%)]\t Loss:2.302949 acc:0.08\n",
      "Train Epoch:0[28160/60000 (47%)]\t Loss:2.301067 acc:0.10\n",
      "Train Epoch:0[28672/60000 (48%)]\t Loss:2.298740 acc:0.09\n",
      "Train Epoch:0[29184/60000 (49%)]\t Loss:2.307881 acc:0.08\n",
      "Train Epoch:0[29696/60000 (49%)]\t Loss:2.303226 acc:0.09\n",
      "Train Epoch:0[30208/60000 (50%)]\t Loss:2.303471 acc:0.08\n",
      "Train Epoch:0[30720/60000 (51%)]\t Loss:2.301908 acc:0.08\n",
      "Train Epoch:0[31232/60000 (52%)]\t Loss:2.299399 acc:0.09\n",
      "Train Epoch:0[31744/60000 (53%)]\t Loss:2.295692 acc:0.10\n",
      "Train Epoch:0[32256/60000 (54%)]\t Loss:2.292628 acc:0.12\n",
      "Train Epoch:0[32768/60000 (55%)]\t Loss:2.300296 acc:0.08\n",
      "Train Epoch:0[33280/60000 (55%)]\t Loss:2.300448 acc:0.09\n",
      "Train Epoch:0[33792/60000 (56%)]\t Loss:2.303371 acc:0.08\n",
      "Train Epoch:0[34304/60000 (57%)]\t Loss:2.299853 acc:0.07\n",
      "Train Epoch:0[34816/60000 (58%)]\t Loss:2.293322 acc:0.10\n",
      "Train Epoch:0[35328/60000 (59%)]\t Loss:2.300278 acc:0.07\n",
      "Train Epoch:0[35840/60000 (60%)]\t Loss:2.298013 acc:0.09\n",
      "Train Epoch:0[36352/60000 (61%)]\t Loss:2.293610 acc:0.11\n",
      "Train Epoch:0[36864/60000 (61%)]\t Loss:2.291775 acc:0.09\n",
      "Train Epoch:0[37376/60000 (62%)]\t Loss:2.294815 acc:0.10\n",
      "Train Epoch:0[37888/60000 (63%)]\t Loss:2.302042 acc:0.08\n",
      "Train Epoch:0[38400/60000 (64%)]\t Loss:2.294103 acc:0.11\n",
      "Train Epoch:0[38912/60000 (65%)]\t Loss:2.298330 acc:0.07\n",
      "Train Epoch:0[39424/60000 (66%)]\t Loss:2.298635 acc:0.08\n",
      "Train Epoch:0[39936/60000 (67%)]\t Loss:2.298403 acc:0.10\n",
      "Train Epoch:0[40448/60000 (67%)]\t Loss:2.294164 acc:0.09\n",
      "Train Epoch:0[40960/60000 (68%)]\t Loss:2.297459 acc:0.09\n",
      "Train Epoch:0[41472/60000 (69%)]\t Loss:2.294866 acc:0.10\n",
      "Train Epoch:0[41984/60000 (70%)]\t Loss:2.297538 acc:0.08\n",
      "Train Epoch:0[42496/60000 (71%)]\t Loss:2.294149 acc:0.09\n",
      "Train Epoch:0[43008/60000 (72%)]\t Loss:2.292392 acc:0.09\n",
      "Train Epoch:0[43520/60000 (73%)]\t Loss:2.289202 acc:0.10\n",
      "Train Epoch:0[44032/60000 (73%)]\t Loss:2.296209 acc:0.06\n",
      "Train Epoch:0[44544/60000 (74%)]\t Loss:2.290629 acc:0.12\n",
      "Train Epoch:0[45056/60000 (75%)]\t Loss:2.292250 acc:0.10\n",
      "Train Epoch:0[45568/60000 (76%)]\t Loss:2.292104 acc:0.07\n",
      "Train Epoch:0[46080/60000 (77%)]\t Loss:2.292852 acc:0.07\n",
      "Train Epoch:0[46592/60000 (78%)]\t Loss:2.293173 acc:0.09\n",
      "Train Epoch:0[47104/60000 (79%)]\t Loss:2.294118 acc:0.09\n",
      "Train Epoch:0[47616/60000 (79%)]\t Loss:2.286004 acc:0.10\n",
      "Train Epoch:0[48128/60000 (80%)]\t Loss:2.292201 acc:0.08\n",
      "Train Epoch:0[48640/60000 (81%)]\t Loss:2.291313 acc:0.09\n",
      "Train Epoch:0[49152/60000 (82%)]\t Loss:2.289288 acc:0.09\n",
      "Train Epoch:0[49664/60000 (83%)]\t Loss:2.289719 acc:0.10\n",
      "Train Epoch:0[50176/60000 (84%)]\t Loss:2.289797 acc:0.10\n",
      "Train Epoch:0[50688/60000 (84%)]\t Loss:2.291013 acc:0.08\n",
      "Train Epoch:0[51200/60000 (85%)]\t Loss:2.287744 acc:0.10\n",
      "Train Epoch:0[51712/60000 (86%)]\t Loss:2.287371 acc:0.10\n",
      "Train Epoch:0[52224/60000 (87%)]\t Loss:2.289534 acc:0.07\n",
      "Train Epoch:0[52736/60000 (88%)]\t Loss:2.285802 acc:0.09\n",
      "Train Epoch:0[53248/60000 (89%)]\t Loss:2.285887 acc:0.10\n",
      "Train Epoch:0[53760/60000 (90%)]\t Loss:2.285391 acc:0.10\n",
      "Train Epoch:0[54272/60000 (90%)]\t Loss:2.286065 acc:0.09\n",
      "Train Epoch:0[54784/60000 (91%)]\t Loss:2.287061 acc:0.08\n",
      "Train Epoch:0[55296/60000 (92%)]\t Loss:2.282993 acc:0.10\n",
      "Train Epoch:0[55808/60000 (93%)]\t Loss:2.281596 acc:0.11\n",
      "Train Epoch:0[56320/60000 (94%)]\t Loss:2.291111 acc:0.09\n",
      "Train Epoch:0[56832/60000 (95%)]\t Loss:2.281065 acc:0.10\n",
      "Train Epoch:0[57344/60000 (96%)]\t Loss:2.287016 acc:0.07\n",
      "Train Epoch:0[57856/60000 (96%)]\t Loss:2.284621 acc:0.08\n",
      "Train Epoch:0[58368/60000 (97%)]\t Loss:2.279852 acc:0.10\n",
      "Train Epoch:0[58880/60000 (98%)]\t Loss:2.277342 acc:0.09\n",
      "Train Epoch:0[59392/60000 (99%)]\t Loss:2.280181 acc:0.09\n",
      "Train Epoch:0[59904/60000 (100%)]\t Loss:2.280004 acc:0.02\n",
      "===> Saving models...\n",
      "Test Epoch:0 [0/10000 (0%)]\t acc:0.00\n",
      "Test Epoch:0 [512/10000 (5%)]\t acc:0.01\n",
      "Test Epoch:0 [1024/10000 (10%)]\t acc:0.01\n",
      "Test Epoch:0 [1536/10000 (15%)]\t acc:0.02\n",
      "Test Epoch:0 [2048/10000 (20%)]\t acc:0.02\n",
      "Test Epoch:0 [2560/10000 (26%)]\t acc:0.03\n",
      "Test Epoch:0 [3072/10000 (31%)]\t acc:0.03\n",
      "Test Epoch:0 [3584/10000 (36%)]\t acc:0.04\n",
      "Test Epoch:0 [4096/10000 (41%)]\t acc:0.04\n",
      "Test Epoch:0 [4608/10000 (46%)]\t acc:0.05\n",
      "Test Epoch:0 [5120/10000 (51%)]\t acc:0.05\n",
      "Test Epoch:0 [5632/10000 (56%)]\t acc:0.05\n",
      "Test Epoch:0 [6144/10000 (61%)]\t acc:0.06\n",
      "Test Epoch:0 [6656/10000 (67%)]\t acc:0.06\n",
      "Test Epoch:0 [7168/10000 (72%)]\t acc:0.07\n",
      "Test Epoch:0 [7680/10000 (77%)]\t acc:0.07\n",
      "Test Epoch:0 [8192/10000 (82%)]\t acc:0.08\n",
      "Test Epoch:0 [8704/10000 (87%)]\t acc:0.08\n",
      "Test Epoch:0 [9216/10000 (92%)]\t acc:0.09\n",
      "Test Epoch:0 [9728/10000 (97%)]\t acc:0.09\n",
      "Train Epoch:1[0/60000 (0%)]\t Loss:2.281374 acc:0.08\n",
      "Train Epoch:1[512/60000 (1%)]\t Loss:2.283217 acc:0.10\n",
      "Train Epoch:1[1024/60000 (2%)]\t Loss:2.279937 acc:0.10\n",
      "Train Epoch:1[1536/60000 (3%)]\t Loss:2.278851 acc:0.08\n",
      "Train Epoch:1[2048/60000 (3%)]\t Loss:2.279909 acc:0.10\n",
      "Train Epoch:1[2560/60000 (4%)]\t Loss:2.279017 acc:0.09\n",
      "Train Epoch:1[3072/60000 (5%)]\t Loss:2.279647 acc:0.08\n",
      "Train Epoch:1[3584/60000 (6%)]\t Loss:2.276168 acc:0.09\n",
      "Train Epoch:1[4096/60000 (7%)]\t Loss:2.277941 acc:0.09\n",
      "Train Epoch:1[4608/60000 (8%)]\t Loss:2.280555 acc:0.08\n",
      "Train Epoch:1[5120/60000 (9%)]\t Loss:2.275865 acc:0.08\n",
      "Train Epoch:1[5632/60000 (9%)]\t Loss:2.274651 acc:0.09\n",
      "Train Epoch:1[6144/60000 (10%)]\t Loss:2.273086 acc:0.11\n",
      "Train Epoch:1[6656/60000 (11%)]\t Loss:2.275013 acc:0.12\n",
      "Train Epoch:1[7168/60000 (12%)]\t Loss:2.276159 acc:0.10\n",
      "Train Epoch:1[7680/60000 (13%)]\t Loss:2.272718 acc:0.09\n",
      "Train Epoch:1[8192/60000 (14%)]\t Loss:2.273934 acc:0.09\n",
      "Train Epoch:1[8704/60000 (15%)]\t Loss:2.274726 acc:0.09\n",
      "Train Epoch:1[9216/60000 (15%)]\t Loss:2.271116 acc:0.11\n",
      "Train Epoch:1[9728/60000 (16%)]\t Loss:2.269227 acc:0.10\n",
      "Train Epoch:1[10240/60000 (17%)]\t Loss:2.268311 acc:0.12\n",
      "Train Epoch:1[10752/60000 (18%)]\t Loss:2.270092 acc:0.09\n",
      "Train Epoch:1[11264/60000 (19%)]\t Loss:2.267445 acc:0.13\n",
      "Train Epoch:1[11776/60000 (20%)]\t Loss:2.272189 acc:0.13\n",
      "Train Epoch:1[12288/60000 (20%)]\t Loss:2.267601 acc:0.14\n",
      "Train Epoch:1[12800/60000 (21%)]\t Loss:2.266748 acc:0.15\n",
      "Train Epoch:1[13312/60000 (22%)]\t Loss:2.264622 acc:0.15\n",
      "Train Epoch:1[13824/60000 (23%)]\t Loss:2.268553 acc:0.13\n",
      "Train Epoch:1[14336/60000 (24%)]\t Loss:2.272811 acc:0.12\n",
      "Train Epoch:1[14848/60000 (25%)]\t Loss:2.261420 acc:0.17\n",
      "Train Epoch:1[15360/60000 (26%)]\t Loss:2.263201 acc:0.17\n",
      "Train Epoch:1[15872/60000 (26%)]\t Loss:2.258063 acc:0.17\n",
      "Train Epoch:1[16384/60000 (27%)]\t Loss:2.260457 acc:0.17\n",
      "Train Epoch:1[16896/60000 (28%)]\t Loss:2.262457 acc:0.14\n",
      "Train Epoch:1[17408/60000 (29%)]\t Loss:2.268168 acc:0.18\n",
      "Train Epoch:1[17920/60000 (30%)]\t Loss:2.258393 acc:0.20\n",
      "Train Epoch:1[18432/60000 (31%)]\t Loss:2.261543 acc:0.20\n",
      "Train Epoch:1[18944/60000 (32%)]\t Loss:2.257944 acc:0.21\n",
      "Train Epoch:1[19456/60000 (32%)]\t Loss:2.254094 acc:0.22\n",
      "Train Epoch:1[19968/60000 (33%)]\t Loss:2.260921 acc:0.16\n",
      "Train Epoch:1[20480/60000 (34%)]\t Loss:2.254288 acc:0.20\n",
      "Train Epoch:1[20992/60000 (35%)]\t Loss:2.249974 acc:0.27\n",
      "Train Epoch:1[21504/60000 (36%)]\t Loss:2.248207 acc:0.26\n",
      "Train Epoch:1[22016/60000 (37%)]\t Loss:2.259639 acc:0.21\n",
      "Train Epoch:1[22528/60000 (38%)]\t Loss:2.252640 acc:0.25\n",
      "Train Epoch:1[23040/60000 (38%)]\t Loss:2.249679 acc:0.26\n",
      "Train Epoch:1[23552/60000 (39%)]\t Loss:2.246534 acc:0.30\n",
      "Train Epoch:1[24064/60000 (40%)]\t Loss:2.247269 acc:0.27\n",
      "Train Epoch:1[24576/60000 (41%)]\t Loss:2.248402 acc:0.29\n",
      "Train Epoch:1[25088/60000 (42%)]\t Loss:2.246605 acc:0.27\n",
      "Train Epoch:1[25600/60000 (43%)]\t Loss:2.243354 acc:0.32\n",
      "Train Epoch:1[26112/60000 (44%)]\t Loss:2.240260 acc:0.33\n",
      "Train Epoch:1[26624/60000 (44%)]\t Loss:2.243662 acc:0.28\n",
      "Train Epoch:1[27136/60000 (45%)]\t Loss:2.246311 acc:0.28\n",
      "Train Epoch:1[27648/60000 (46%)]\t Loss:2.235440 acc:0.32\n",
      "Train Epoch:1[28160/60000 (47%)]\t Loss:2.235730 acc:0.31\n",
      "Train Epoch:1[28672/60000 (48%)]\t Loss:2.235797 acc:0.32\n",
      "Train Epoch:1[29184/60000 (49%)]\t Loss:2.233464 acc:0.33\n",
      "Train Epoch:1[29696/60000 (49%)]\t Loss:2.241901 acc:0.31\n",
      "Train Epoch:1[30208/60000 (50%)]\t Loss:2.238974 acc:0.31\n",
      "Train Epoch:1[30720/60000 (51%)]\t Loss:2.236509 acc:0.33\n",
      "Train Epoch:1[31232/60000 (52%)]\t Loss:2.235063 acc:0.34\n",
      "Train Epoch:1[31744/60000 (53%)]\t Loss:2.234316 acc:0.35\n",
      "Train Epoch:1[32256/60000 (54%)]\t Loss:2.232156 acc:0.32\n",
      "Train Epoch:1[32768/60000 (55%)]\t Loss:2.224641 acc:0.36\n",
      "Train Epoch:1[33280/60000 (55%)]\t Loss:2.224118 acc:0.37\n",
      "Train Epoch:1[33792/60000 (56%)]\t Loss:2.224896 acc:0.37\n",
      "Train Epoch:1[34304/60000 (57%)]\t Loss:2.223141 acc:0.33\n",
      "Train Epoch:1[34816/60000 (58%)]\t Loss:2.225318 acc:0.34\n",
      "Train Epoch:1[35328/60000 (59%)]\t Loss:2.210323 acc:0.38\n",
      "Train Epoch:1[35840/60000 (60%)]\t Loss:2.219114 acc:0.38\n",
      "Train Epoch:1[36352/60000 (61%)]\t Loss:2.205796 acc:0.41\n",
      "Train Epoch:1[36864/60000 (61%)]\t Loss:2.214065 acc:0.38\n",
      "Train Epoch:1[37376/60000 (62%)]\t Loss:2.209437 acc:0.39\n",
      "Train Epoch:1[37888/60000 (63%)]\t Loss:2.211697 acc:0.36\n",
      "Train Epoch:1[38400/60000 (64%)]\t Loss:2.193545 acc:0.43\n",
      "Train Epoch:1[38912/60000 (65%)]\t Loss:2.198041 acc:0.39\n",
      "Train Epoch:1[39424/60000 (66%)]\t Loss:2.199574 acc:0.37\n",
      "Train Epoch:1[39936/60000 (67%)]\t Loss:2.185960 acc:0.45\n",
      "Train Epoch:1[40448/60000 (67%)]\t Loss:2.189032 acc:0.42\n",
      "Train Epoch:1[40960/60000 (68%)]\t Loss:2.196368 acc:0.41\n",
      "Train Epoch:1[41472/60000 (69%)]\t Loss:2.196720 acc:0.40\n",
      "Train Epoch:1[41984/60000 (70%)]\t Loss:2.194476 acc:0.35\n",
      "Train Epoch:1[42496/60000 (71%)]\t Loss:2.180085 acc:0.41\n",
      "Train Epoch:1[43008/60000 (72%)]\t Loss:2.176499 acc:0.42\n",
      "Train Epoch:1[43520/60000 (73%)]\t Loss:2.181853 acc:0.40\n",
      "Train Epoch:1[44032/60000 (73%)]\t Loss:2.190391 acc:0.37\n",
      "Train Epoch:1[44544/60000 (74%)]\t Loss:2.169411 acc:0.44\n",
      "Train Epoch:1[45056/60000 (75%)]\t Loss:2.168924 acc:0.39\n",
      "Train Epoch:1[45568/60000 (76%)]\t Loss:2.178923 acc:0.38\n",
      "Train Epoch:1[46080/60000 (77%)]\t Loss:2.164081 acc:0.42\n",
      "Train Epoch:1[46592/60000 (78%)]\t Loss:2.155606 acc:0.42\n",
      "Train Epoch:1[47104/60000 (79%)]\t Loss:2.156384 acc:0.44\n",
      "Train Epoch:1[47616/60000 (79%)]\t Loss:2.145581 acc:0.44\n",
      "Train Epoch:1[48128/60000 (80%)]\t Loss:2.133016 acc:0.43\n",
      "Train Epoch:1[48640/60000 (81%)]\t Loss:2.157814 acc:0.38\n",
      "Train Epoch:1[49152/60000 (82%)]\t Loss:2.143393 acc:0.39\n",
      "Train Epoch:1[49664/60000 (83%)]\t Loss:2.152283 acc:0.39\n",
      "Train Epoch:1[50176/60000 (84%)]\t Loss:2.133066 acc:0.44\n",
      "Train Epoch:1[50688/60000 (84%)]\t Loss:2.134828 acc:0.42\n",
      "Train Epoch:1[51200/60000 (85%)]\t Loss:2.125230 acc:0.40\n",
      "Train Epoch:1[51712/60000 (86%)]\t Loss:2.122220 acc:0.41\n",
      "Train Epoch:1[52224/60000 (87%)]\t Loss:2.100309 acc:0.44\n",
      "Train Epoch:1[52736/60000 (88%)]\t Loss:2.114903 acc:0.42\n",
      "Train Epoch:1[53248/60000 (89%)]\t Loss:2.087456 acc:0.44\n",
      "Train Epoch:1[53760/60000 (90%)]\t Loss:2.097719 acc:0.42\n",
      "Train Epoch:1[54272/60000 (90%)]\t Loss:2.088901 acc:0.44\n",
      "Train Epoch:1[54784/60000 (91%)]\t Loss:2.075836 acc:0.44\n",
      "Train Epoch:1[55296/60000 (92%)]\t Loss:2.071716 acc:0.43\n",
      "Train Epoch:1[55808/60000 (93%)]\t Loss:2.074083 acc:0.41\n",
      "Train Epoch:1[56320/60000 (94%)]\t Loss:2.078389 acc:0.41\n",
      "Train Epoch:1[56832/60000 (95%)]\t Loss:2.050370 acc:0.43\n",
      "Train Epoch:1[57344/60000 (96%)]\t Loss:2.046071 acc:0.44\n",
      "Train Epoch:1[57856/60000 (96%)]\t Loss:2.041050 acc:0.47\n",
      "Train Epoch:1[58368/60000 (97%)]\t Loss:2.022105 acc:0.46\n",
      "Train Epoch:1[58880/60000 (98%)]\t Loss:1.988637 acc:0.45\n",
      "Train Epoch:1[59392/60000 (99%)]\t Loss:1.976168 acc:0.43\n",
      "Train Epoch:1[59904/60000 (100%)]\t Loss:2.052745 acc:0.09\n",
      "===> Saving models...\n",
      "Test Epoch:1 [0/10000 (0%)]\t acc:0.02\n",
      "Test Epoch:1 [512/10000 (5%)]\t acc:0.04\n",
      "Test Epoch:1 [1024/10000 (10%)]\t acc:0.07\n",
      "Test Epoch:1 [1536/10000 (15%)]\t acc:0.09\n",
      "Test Epoch:1 [2048/10000 (20%)]\t acc:0.11\n",
      "Test Epoch:1 [2560/10000 (26%)]\t acc:0.14\n",
      "Test Epoch:1 [3072/10000 (31%)]\t acc:0.16\n",
      "Test Epoch:1 [3584/10000 (36%)]\t acc:0.19\n",
      "Test Epoch:1 [4096/10000 (41%)]\t acc:0.21\n",
      "Test Epoch:1 [4608/10000 (46%)]\t acc:0.23\n",
      "Test Epoch:1 [5120/10000 (51%)]\t acc:0.26\n",
      "Test Epoch:1 [5632/10000 (56%)]\t acc:0.28\n",
      "Test Epoch:1 [6144/10000 (61%)]\t acc:0.30\n",
      "Test Epoch:1 [6656/10000 (67%)]\t acc:0.33\n",
      "Test Epoch:1 [7168/10000 (72%)]\t acc:0.35\n",
      "Test Epoch:1 [7680/10000 (77%)]\t acc:0.37\n",
      "Test Epoch:1 [8192/10000 (82%)]\t acc:0.39\n",
      "Test Epoch:1 [8704/10000 (87%)]\t acc:0.42\n",
      "Test Epoch:1 [9216/10000 (92%)]\t acc:0.44\n",
      "Test Epoch:1 [9728/10000 (97%)]\t acc:0.45\n",
      "Train Epoch:2[0/60000 (0%)]\t Loss:1.979471 acc:0.47\n",
      "Train Epoch:2[512/60000 (1%)]\t Loss:2.005213 acc:0.44\n",
      "Train Epoch:2[1024/60000 (2%)]\t Loss:1.996614 acc:0.46\n",
      "Train Epoch:2[1536/60000 (3%)]\t Loss:1.962859 acc:0.47\n",
      "Train Epoch:2[2048/60000 (3%)]\t Loss:1.950982 acc:0.47\n",
      "Train Epoch:2[2560/60000 (4%)]\t Loss:1.933399 acc:0.49\n",
      "Train Epoch:2[3072/60000 (5%)]\t Loss:1.956241 acc:0.45\n",
      "Train Epoch:2[3584/60000 (6%)]\t Loss:1.927998 acc:0.43\n",
      "Train Epoch:2[4096/60000 (7%)]\t Loss:1.888329 acc:0.51\n",
      "Train Epoch:2[4608/60000 (8%)]\t Loss:1.929971 acc:0.43\n",
      "Train Epoch:2[5120/60000 (9%)]\t Loss:1.861171 acc:0.51\n",
      "Train Epoch:2[5632/60000 (9%)]\t Loss:1.865469 acc:0.49\n",
      "Train Epoch:2[6144/60000 (10%)]\t Loss:1.850081 acc:0.53\n",
      "Train Epoch:2[6656/60000 (11%)]\t Loss:1.855871 acc:0.51\n",
      "Train Epoch:2[7168/60000 (12%)]\t Loss:1.895080 acc:0.48\n",
      "Train Epoch:2[7680/60000 (13%)]\t Loss:1.797874 acc:0.52\n",
      "Train Epoch:2[8192/60000 (14%)]\t Loss:1.816589 acc:0.50\n",
      "Train Epoch:2[8704/60000 (15%)]\t Loss:1.790866 acc:0.54\n",
      "Train Epoch:2[9216/60000 (15%)]\t Loss:1.788991 acc:0.57\n",
      "Train Epoch:2[9728/60000 (16%)]\t Loss:1.738992 acc:0.58\n",
      "Train Epoch:2[10240/60000 (17%)]\t Loss:1.702004 acc:0.55\n",
      "Train Epoch:2[10752/60000 (18%)]\t Loss:1.708838 acc:0.55\n",
      "Train Epoch:2[11264/60000 (19%)]\t Loss:1.706795 acc:0.57\n",
      "Train Epoch:2[11776/60000 (20%)]\t Loss:1.735338 acc:0.52\n",
      "Train Epoch:2[12288/60000 (20%)]\t Loss:1.712594 acc:0.54\n",
      "Train Epoch:2[12800/60000 (21%)]\t Loss:1.680902 acc:0.54\n",
      "Train Epoch:2[13312/60000 (22%)]\t Loss:1.637178 acc:0.57\n",
      "Train Epoch:2[13824/60000 (23%)]\t Loss:1.659009 acc:0.55\n",
      "Train Epoch:2[14336/60000 (24%)]\t Loss:1.731218 acc:0.50\n",
      "Train Epoch:2[14848/60000 (25%)]\t Loss:1.551728 acc:0.61\n",
      "Train Epoch:2[15360/60000 (26%)]\t Loss:1.570946 acc:0.57\n",
      "Train Epoch:2[15872/60000 (26%)]\t Loss:1.562724 acc:0.59\n",
      "Train Epoch:2[16384/60000 (27%)]\t Loss:1.533237 acc:0.62\n",
      "Train Epoch:2[16896/60000 (28%)]\t Loss:1.538764 acc:0.60\n",
      "Train Epoch:2[17408/60000 (29%)]\t Loss:1.582924 acc:0.57\n",
      "Train Epoch:2[17920/60000 (30%)]\t Loss:1.454833 acc:0.66\n",
      "Train Epoch:2[18432/60000 (31%)]\t Loss:1.472924 acc:0.65\n",
      "Train Epoch:2[18944/60000 (32%)]\t Loss:1.443934 acc:0.62\n",
      "Train Epoch:2[19456/60000 (32%)]\t Loss:1.353999 acc:0.64\n",
      "Train Epoch:2[19968/60000 (33%)]\t Loss:1.435170 acc:0.63\n",
      "Train Epoch:2[20480/60000 (34%)]\t Loss:1.355177 acc:0.65\n",
      "Train Epoch:2[20992/60000 (35%)]\t Loss:1.342397 acc:0.66\n",
      "Train Epoch:2[21504/60000 (36%)]\t Loss:1.247585 acc:0.74\n",
      "Train Epoch:2[22016/60000 (37%)]\t Loss:1.438460 acc:0.59\n",
      "Train Epoch:2[22528/60000 (38%)]\t Loss:1.276449 acc:0.68\n",
      "Train Epoch:2[23040/60000 (38%)]\t Loss:1.257779 acc:0.71\n",
      "Train Epoch:2[23552/60000 (39%)]\t Loss:1.240083 acc:0.71\n",
      "Train Epoch:2[24064/60000 (40%)]\t Loss:1.217741 acc:0.68\n",
      "Train Epoch:2[24576/60000 (41%)]\t Loss:1.224793 acc:0.68\n",
      "Train Epoch:2[25088/60000 (42%)]\t Loss:1.168492 acc:0.71\n",
      "Train Epoch:2[25600/60000 (43%)]\t Loss:1.110269 acc:0.76\n",
      "Train Epoch:2[26112/60000 (44%)]\t Loss:1.159512 acc:0.71\n",
      "Train Epoch:2[26624/60000 (44%)]\t Loss:1.181857 acc:0.71\n",
      "Train Epoch:2[27136/60000 (45%)]\t Loss:1.168998 acc:0.69\n",
      "Train Epoch:2[27648/60000 (46%)]\t Loss:0.998299 acc:0.77\n",
      "Train Epoch:2[28160/60000 (47%)]\t Loss:1.025588 acc:0.74\n",
      "Train Epoch:2[28672/60000 (48%)]\t Loss:1.036793 acc:0.70\n",
      "Train Epoch:2[29184/60000 (49%)]\t Loss:0.960756 acc:0.78\n",
      "Train Epoch:2[29696/60000 (49%)]\t Loss:1.201285 acc:0.66\n",
      "Train Epoch:2[30208/60000 (50%)]\t Loss:1.077074 acc:0.76\n",
      "Train Epoch:2[30720/60000 (51%)]\t Loss:0.986440 acc:0.73\n",
      "Train Epoch:2[31232/60000 (52%)]\t Loss:1.099712 acc:0.71\n",
      "Train Epoch:2[31744/60000 (53%)]\t Loss:1.013279 acc:0.73\n",
      "Train Epoch:2[32256/60000 (54%)]\t Loss:1.109447 acc:0.70\n",
      "Train Epoch:2[32768/60000 (55%)]\t Loss:0.939182 acc:0.76\n",
      "Train Epoch:2[33280/60000 (55%)]\t Loss:0.898053 acc:0.79\n",
      "Train Epoch:2[33792/60000 (56%)]\t Loss:0.759959 acc:0.81\n",
      "Train Epoch:2[34304/60000 (57%)]\t Loss:0.899691 acc:0.73\n",
      "Train Epoch:2[34816/60000 (58%)]\t Loss:0.886918 acc:0.75\n",
      "Train Epoch:2[35328/60000 (59%)]\t Loss:0.802579 acc:0.77\n",
      "Train Epoch:2[35840/60000 (60%)]\t Loss:0.779777 acc:0.79\n",
      "Train Epoch:2[36352/60000 (61%)]\t Loss:0.766521 acc:0.80\n",
      "Train Epoch:2[36864/60000 (61%)]\t Loss:0.814981 acc:0.76\n",
      "Train Epoch:2[37376/60000 (62%)]\t Loss:0.792046 acc:0.78\n",
      "Train Epoch:2[37888/60000 (63%)]\t Loss:0.784807 acc:0.78\n",
      "Train Epoch:2[38400/60000 (64%)]\t Loss:0.654698 acc:0.82\n",
      "Train Epoch:2[38912/60000 (65%)]\t Loss:0.689449 acc:0.81\n",
      "Train Epoch:2[39424/60000 (66%)]\t Loss:0.819073 acc:0.79\n",
      "Train Epoch:2[39936/60000 (67%)]\t Loss:0.651727 acc:0.82\n",
      "Train Epoch:2[40448/60000 (67%)]\t Loss:0.640506 acc:0.83\n",
      "Train Epoch:2[40960/60000 (68%)]\t Loss:0.803048 acc:0.78\n",
      "Train Epoch:2[41472/60000 (69%)]\t Loss:0.741920 acc:0.79\n",
      "Train Epoch:2[41984/60000 (70%)]\t Loss:0.833274 acc:0.72\n",
      "Train Epoch:2[42496/60000 (71%)]\t Loss:0.699223 acc:0.79\n",
      "Train Epoch:2[43008/60000 (72%)]\t Loss:0.630715 acc:0.81\n",
      "Train Epoch:2[43520/60000 (73%)]\t Loss:0.599606 acc:0.84\n",
      "Train Epoch:2[44032/60000 (73%)]\t Loss:0.744659 acc:0.77\n",
      "Train Epoch:2[44544/60000 (74%)]\t Loss:0.640550 acc:0.83\n",
      "Train Epoch:2[45056/60000 (75%)]\t Loss:0.631658 acc:0.82\n",
      "Train Epoch:2[45568/60000 (76%)]\t Loss:0.689489 acc:0.79\n",
      "Train Epoch:2[46080/60000 (77%)]\t Loss:0.640975 acc:0.79\n",
      "Train Epoch:2[46592/60000 (78%)]\t Loss:0.563695 acc:0.82\n",
      "Train Epoch:2[47104/60000 (79%)]\t Loss:0.636853 acc:0.80\n",
      "Train Epoch:2[47616/60000 (79%)]\t Loss:0.520370 acc:0.85\n",
      "Train Epoch:2[48128/60000 (80%)]\t Loss:0.512081 acc:0.84\n",
      "Train Epoch:2[48640/60000 (81%)]\t Loss:0.629168 acc:0.80\n",
      "Train Epoch:2[49152/60000 (82%)]\t Loss:0.680247 acc:0.77\n",
      "Train Epoch:2[49664/60000 (83%)]\t Loss:0.622180 acc:0.80\n",
      "Train Epoch:2[50176/60000 (84%)]\t Loss:0.666879 acc:0.82\n",
      "Train Epoch:2[50688/60000 (84%)]\t Loss:0.607324 acc:0.81\n",
      "Train Epoch:2[51200/60000 (85%)]\t Loss:0.541418 acc:0.82\n",
      "Train Epoch:2[51712/60000 (86%)]\t Loss:0.623848 acc:0.80\n",
      "Train Epoch:2[52224/60000 (87%)]\t Loss:0.493202 acc:0.84\n",
      "Train Epoch:2[52736/60000 (88%)]\t Loss:0.714466 acc:0.78\n",
      "Train Epoch:2[53248/60000 (89%)]\t Loss:0.474419 acc:0.83\n",
      "Train Epoch:2[53760/60000 (90%)]\t Loss:0.511316 acc:0.84\n",
      "Train Epoch:2[54272/60000 (90%)]\t Loss:0.482138 acc:0.84\n",
      "Train Epoch:2[54784/60000 (91%)]\t Loss:0.524438 acc:0.81\n",
      "Train Epoch:2[55296/60000 (92%)]\t Loss:0.488022 acc:0.85\n",
      "Train Epoch:2[55808/60000 (93%)]\t Loss:0.438742 acc:0.86\n",
      "Train Epoch:2[56320/60000 (94%)]\t Loss:0.484203 acc:0.84\n",
      "Train Epoch:2[56832/60000 (95%)]\t Loss:0.507249 acc:0.84\n",
      "Train Epoch:2[57344/60000 (96%)]\t Loss:0.518067 acc:0.85\n",
      "Train Epoch:2[57856/60000 (96%)]\t Loss:0.366548 acc:0.91\n",
      "Train Epoch:2[58368/60000 (97%)]\t Loss:0.366917 acc:0.90\n",
      "Train Epoch:2[58880/60000 (98%)]\t Loss:0.429872 acc:0.86\n",
      "Train Epoch:2[59392/60000 (99%)]\t Loss:0.344305 acc:0.91\n",
      "Train Epoch:2[59904/60000 (100%)]\t Loss:0.506528 acc:0.15\n",
      "===> Saving models...\n",
      "Test Epoch:2 [0/10000 (0%)]\t acc:0.04\n",
      "Test Epoch:2 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:2 [1024/10000 (10%)]\t acc:0.13\n",
      "Test Epoch:2 [1536/10000 (15%)]\t acc:0.17\n",
      "Test Epoch:2 [2048/10000 (20%)]\t acc:0.22\n",
      "Test Epoch:2 [2560/10000 (26%)]\t acc:0.26\n",
      "Test Epoch:2 [3072/10000 (31%)]\t acc:0.30\n",
      "Test Epoch:2 [3584/10000 (36%)]\t acc:0.35\n",
      "Test Epoch:2 [4096/10000 (41%)]\t acc:0.39\n",
      "Test Epoch:2 [4608/10000 (46%)]\t acc:0.43\n",
      "Test Epoch:2 [5120/10000 (51%)]\t acc:0.48\n",
      "Test Epoch:2 [5632/10000 (56%)]\t acc:0.52\n",
      "Test Epoch:2 [6144/10000 (61%)]\t acc:0.57\n",
      "Test Epoch:2 [6656/10000 (67%)]\t acc:0.61\n",
      "Test Epoch:2 [7168/10000 (72%)]\t acc:0.65\n",
      "Test Epoch:2 [7680/10000 (77%)]\t acc:0.70\n",
      "Test Epoch:2 [8192/10000 (82%)]\t acc:0.74\n",
      "Test Epoch:2 [8704/10000 (87%)]\t acc:0.78\n",
      "Test Epoch:2 [9216/10000 (92%)]\t acc:0.83\n",
      "Test Epoch:2 [9728/10000 (97%)]\t acc:0.85\n",
      "Train Epoch:3[0/60000 (0%)]\t Loss:0.486303 acc:0.86\n",
      "Train Epoch:3[512/60000 (1%)]\t Loss:0.551878 acc:0.82\n",
      "Train Epoch:3[1024/60000 (2%)]\t Loss:0.572446 acc:0.82\n",
      "Train Epoch:3[1536/60000 (3%)]\t Loss:0.396808 acc:0.89\n",
      "Train Epoch:3[2048/60000 (3%)]\t Loss:0.455155 acc:0.86\n",
      "Train Epoch:3[2560/60000 (4%)]\t Loss:0.455710 acc:0.84\n",
      "Train Epoch:3[3072/60000 (5%)]\t Loss:0.469475 acc:0.84\n",
      "Train Epoch:3[3584/60000 (6%)]\t Loss:0.477817 acc:0.83\n",
      "Train Epoch:3[4096/60000 (7%)]\t Loss:0.431531 acc:0.86\n",
      "Train Epoch:3[4608/60000 (8%)]\t Loss:0.497611 acc:0.85\n",
      "Train Epoch:3[5120/60000 (9%)]\t Loss:0.497079 acc:0.85\n",
      "Train Epoch:3[5632/60000 (9%)]\t Loss:0.432608 acc:0.87\n",
      "Train Epoch:3[6144/60000 (10%)]\t Loss:0.389939 acc:0.88\n",
      "Train Epoch:3[6656/60000 (11%)]\t Loss:0.499426 acc:0.83\n",
      "Train Epoch:3[7168/60000 (12%)]\t Loss:0.527357 acc:0.82\n",
      "Train Epoch:3[7680/60000 (13%)]\t Loss:0.478267 acc:0.86\n",
      "Train Epoch:3[8192/60000 (14%)]\t Loss:0.541284 acc:0.83\n",
      "Train Epoch:3[8704/60000 (15%)]\t Loss:0.562673 acc:0.83\n",
      "Train Epoch:3[9216/60000 (15%)]\t Loss:0.467218 acc:0.85\n",
      "Train Epoch:3[9728/60000 (16%)]\t Loss:0.447557 acc:0.86\n",
      "Train Epoch:3[10240/60000 (17%)]\t Loss:0.356281 acc:0.87\n",
      "Train Epoch:3[10752/60000 (18%)]\t Loss:0.433388 acc:0.87\n",
      "Train Epoch:3[11264/60000 (19%)]\t Loss:0.491182 acc:0.85\n",
      "Train Epoch:3[11776/60000 (20%)]\t Loss:0.417324 acc:0.86\n",
      "Train Epoch:3[12288/60000 (20%)]\t Loss:0.549640 acc:0.83\n",
      "Train Epoch:3[12800/60000 (21%)]\t Loss:0.501132 acc:0.85\n",
      "Train Epoch:3[13312/60000 (22%)]\t Loss:0.395283 acc:0.88\n",
      "Train Epoch:3[13824/60000 (23%)]\t Loss:0.529431 acc:0.83\n",
      "Train Epoch:3[14336/60000 (24%)]\t Loss:0.657757 acc:0.78\n",
      "Train Epoch:3[14848/60000 (25%)]\t Loss:0.395162 acc:0.89\n",
      "Train Epoch:3[15360/60000 (26%)]\t Loss:0.459070 acc:0.86\n",
      "Train Epoch:3[15872/60000 (26%)]\t Loss:0.466986 acc:0.86\n",
      "Train Epoch:3[16384/60000 (27%)]\t Loss:0.443846 acc:0.87\n",
      "Train Epoch:3[16896/60000 (28%)]\t Loss:0.476593 acc:0.85\n",
      "Train Epoch:3[17408/60000 (29%)]\t Loss:0.565570 acc:0.82\n",
      "Train Epoch:3[17920/60000 (30%)]\t Loss:0.351917 acc:0.90\n",
      "Train Epoch:3[18432/60000 (31%)]\t Loss:0.408076 acc:0.90\n",
      "Train Epoch:3[18944/60000 (32%)]\t Loss:0.418416 acc:0.87\n",
      "Train Epoch:3[19456/60000 (32%)]\t Loss:0.371695 acc:0.90\n",
      "Train Epoch:3[19968/60000 (33%)]\t Loss:0.468147 acc:0.86\n",
      "Train Epoch:3[20480/60000 (34%)]\t Loss:0.521118 acc:0.85\n",
      "Train Epoch:3[20992/60000 (35%)]\t Loss:0.387661 acc:0.88\n",
      "Train Epoch:3[21504/60000 (36%)]\t Loss:0.353925 acc:0.89\n",
      "Train Epoch:3[22016/60000 (37%)]\t Loss:0.438162 acc:0.86\n",
      "Train Epoch:3[22528/60000 (38%)]\t Loss:0.397981 acc:0.88\n",
      "Train Epoch:3[23040/60000 (38%)]\t Loss:0.364653 acc:0.89\n",
      "Train Epoch:3[23552/60000 (39%)]\t Loss:0.431278 acc:0.88\n",
      "Train Epoch:3[24064/60000 (40%)]\t Loss:0.454631 acc:0.85\n",
      "Train Epoch:3[24576/60000 (41%)]\t Loss:0.475269 acc:0.84\n",
      "Train Epoch:3[25088/60000 (42%)]\t Loss:0.376079 acc:0.89\n",
      "Train Epoch:3[25600/60000 (43%)]\t Loss:0.351413 acc:0.90\n",
      "Train Epoch:3[26112/60000 (44%)]\t Loss:0.460005 acc:0.87\n",
      "Train Epoch:3[26624/60000 (44%)]\t Loss:0.455208 acc:0.88\n",
      "Train Epoch:3[27136/60000 (45%)]\t Loss:0.457291 acc:0.87\n",
      "Train Epoch:3[27648/60000 (46%)]\t Loss:0.332707 acc:0.89\n",
      "Train Epoch:3[28160/60000 (47%)]\t Loss:0.409268 acc:0.88\n",
      "Train Epoch:3[28672/60000 (48%)]\t Loss:0.366464 acc:0.90\n",
      "Train Epoch:3[29184/60000 (49%)]\t Loss:0.388042 acc:0.89\n",
      "Train Epoch:3[29696/60000 (49%)]\t Loss:0.502579 acc:0.84\n",
      "Train Epoch:3[30208/60000 (50%)]\t Loss:0.421485 acc:0.89\n",
      "Train Epoch:3[30720/60000 (51%)]\t Loss:0.452733 acc:0.87\n",
      "Train Epoch:3[31232/60000 (52%)]\t Loss:0.532611 acc:0.83\n",
      "Train Epoch:3[31744/60000 (53%)]\t Loss:0.415908 acc:0.86\n",
      "Train Epoch:3[32256/60000 (54%)]\t Loss:0.506183 acc:0.85\n",
      "Train Epoch:3[32768/60000 (55%)]\t Loss:0.380638 acc:0.89\n",
      "Train Epoch:3[33280/60000 (55%)]\t Loss:0.405794 acc:0.89\n",
      "Train Epoch:3[33792/60000 (56%)]\t Loss:0.252329 acc:0.93\n",
      "Train Epoch:3[34304/60000 (57%)]\t Loss:0.411484 acc:0.86\n",
      "Train Epoch:3[34816/60000 (58%)]\t Loss:0.366458 acc:0.89\n",
      "Train Epoch:3[35328/60000 (59%)]\t Loss:0.331689 acc:0.90\n",
      "Train Epoch:3[35840/60000 (60%)]\t Loss:0.319523 acc:0.90\n",
      "Train Epoch:3[36352/60000 (61%)]\t Loss:0.344120 acc:0.89\n",
      "Train Epoch:3[36864/60000 (61%)]\t Loss:0.427654 acc:0.87\n",
      "Train Epoch:3[37376/60000 (62%)]\t Loss:0.426615 acc:0.88\n",
      "Train Epoch:3[37888/60000 (63%)]\t Loss:0.358719 acc:0.89\n",
      "Train Epoch:3[38400/60000 (64%)]\t Loss:0.313296 acc:0.91\n",
      "Train Epoch:3[38912/60000 (65%)]\t Loss:0.332455 acc:0.90\n",
      "Train Epoch:3[39424/60000 (66%)]\t Loss:0.476006 acc:0.86\n",
      "Train Epoch:3[39936/60000 (67%)]\t Loss:0.343495 acc:0.89\n",
      "Train Epoch:3[40448/60000 (67%)]\t Loss:0.317689 acc:0.91\n",
      "Train Epoch:3[40960/60000 (68%)]\t Loss:0.462395 acc:0.88\n",
      "Train Epoch:3[41472/60000 (69%)]\t Loss:0.370187 acc:0.89\n",
      "Train Epoch:3[41984/60000 (70%)]\t Loss:0.468743 acc:0.85\n",
      "Train Epoch:3[42496/60000 (71%)]\t Loss:0.435940 acc:0.87\n",
      "Train Epoch:3[43008/60000 (72%)]\t Loss:0.332419 acc:0.88\n",
      "Train Epoch:3[43520/60000 (73%)]\t Loss:0.347410 acc:0.90\n",
      "Train Epoch:3[44032/60000 (73%)]\t Loss:0.431340 acc:0.85\n",
      "Train Epoch:3[44544/60000 (74%)]\t Loss:0.357316 acc:0.89\n",
      "Train Epoch:3[45056/60000 (75%)]\t Loss:0.365664 acc:0.89\n",
      "Train Epoch:3[45568/60000 (76%)]\t Loss:0.403333 acc:0.87\n",
      "Train Epoch:3[46080/60000 (77%)]\t Loss:0.391294 acc:0.88\n",
      "Train Epoch:3[46592/60000 (78%)]\t Loss:0.310828 acc:0.88\n",
      "Train Epoch:3[47104/60000 (79%)]\t Loss:0.383259 acc:0.88\n",
      "Train Epoch:3[47616/60000 (79%)]\t Loss:0.324680 acc:0.89\n",
      "Train Epoch:3[48128/60000 (80%)]\t Loss:0.298924 acc:0.91\n",
      "Train Epoch:3[48640/60000 (81%)]\t Loss:0.395482 acc:0.88\n",
      "Train Epoch:3[49152/60000 (82%)]\t Loss:0.449820 acc:0.86\n",
      "Train Epoch:3[49664/60000 (83%)]\t Loss:0.404087 acc:0.87\n",
      "Train Epoch:3[50176/60000 (84%)]\t Loss:0.477542 acc:0.88\n",
      "Train Epoch:3[50688/60000 (84%)]\t Loss:0.356562 acc:0.88\n",
      "Train Epoch:3[51200/60000 (85%)]\t Loss:0.306949 acc:0.90\n",
      "Train Epoch:3[51712/60000 (86%)]\t Loss:0.414349 acc:0.87\n",
      "Train Epoch:3[52224/60000 (87%)]\t Loss:0.328130 acc:0.89\n",
      "Train Epoch:3[52736/60000 (88%)]\t Loss:0.494955 acc:0.86\n",
      "Train Epoch:3[53248/60000 (89%)]\t Loss:0.285647 acc:0.91\n",
      "Train Epoch:3[53760/60000 (90%)]\t Loss:0.325042 acc:0.92\n",
      "Train Epoch:3[54272/60000 (90%)]\t Loss:0.313871 acc:0.90\n",
      "Train Epoch:3[54784/60000 (91%)]\t Loss:0.349664 acc:0.89\n",
      "Train Epoch:3[55296/60000 (92%)]\t Loss:0.301593 acc:0.92\n",
      "Train Epoch:3[55808/60000 (93%)]\t Loss:0.270656 acc:0.92\n",
      "Train Epoch:3[56320/60000 (94%)]\t Loss:0.291957 acc:0.92\n",
      "Train Epoch:3[56832/60000 (95%)]\t Loss:0.318306 acc:0.89\n",
      "Train Epoch:3[57344/60000 (96%)]\t Loss:0.342650 acc:0.88\n",
      "Train Epoch:3[57856/60000 (96%)]\t Loss:0.212562 acc:0.94\n",
      "Train Epoch:3[58368/60000 (97%)]\t Loss:0.210997 acc:0.95\n",
      "Train Epoch:3[58880/60000 (98%)]\t Loss:0.261892 acc:0.92\n",
      "Train Epoch:3[59392/60000 (99%)]\t Loss:0.252977 acc:0.94\n",
      "Train Epoch:3[59904/60000 (100%)]\t Loss:0.386381 acc:0.16\n",
      "===> Saving models...\n",
      "Test Epoch:3 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:3 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:3 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:3 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:3 [2048/10000 (20%)]\t acc:0.23\n",
      "Test Epoch:3 [2560/10000 (26%)]\t acc:0.28\n",
      "Test Epoch:3 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:3 [3584/10000 (36%)]\t acc:0.37\n",
      "Test Epoch:3 [4096/10000 (41%)]\t acc:0.42\n",
      "Test Epoch:3 [4608/10000 (46%)]\t acc:0.46\n",
      "Test Epoch:3 [5120/10000 (51%)]\t acc:0.51\n",
      "Test Epoch:3 [5632/10000 (56%)]\t acc:0.56\n",
      "Test Epoch:3 [6144/10000 (61%)]\t acc:0.60\n",
      "Test Epoch:3 [6656/10000 (67%)]\t acc:0.65\n",
      "Test Epoch:3 [7168/10000 (72%)]\t acc:0.69\n",
      "Test Epoch:3 [7680/10000 (77%)]\t acc:0.74\n",
      "Test Epoch:3 [8192/10000 (82%)]\t acc:0.79\n",
      "Test Epoch:3 [8704/10000 (87%)]\t acc:0.83\n",
      "Test Epoch:3 [9216/10000 (92%)]\t acc:0.88\n",
      "Test Epoch:3 [9728/10000 (97%)]\t acc:0.90\n",
      "Train Epoch:4[0/60000 (0%)]\t Loss:0.322815 acc:0.91\n",
      "Train Epoch:4[512/60000 (1%)]\t Loss:0.372639 acc:0.87\n",
      "Train Epoch:4[1024/60000 (2%)]\t Loss:0.412281 acc:0.88\n",
      "Train Epoch:4[1536/60000 (3%)]\t Loss:0.270598 acc:0.93\n",
      "Train Epoch:4[2048/60000 (3%)]\t Loss:0.319848 acc:0.90\n",
      "Train Epoch:4[2560/60000 (4%)]\t Loss:0.314507 acc:0.90\n",
      "Train Epoch:4[3072/60000 (5%)]\t Loss:0.276938 acc:0.91\n",
      "Train Epoch:4[3584/60000 (6%)]\t Loss:0.301473 acc:0.91\n",
      "Train Epoch:4[4096/60000 (7%)]\t Loss:0.320252 acc:0.90\n",
      "Train Epoch:4[4608/60000 (8%)]\t Loss:0.363566 acc:0.89\n",
      "Train Epoch:4[5120/60000 (9%)]\t Loss:0.366570 acc:0.88\n",
      "Train Epoch:4[5632/60000 (9%)]\t Loss:0.306219 acc:0.91\n",
      "Train Epoch:4[6144/60000 (10%)]\t Loss:0.249300 acc:0.91\n",
      "Train Epoch:4[6656/60000 (11%)]\t Loss:0.369134 acc:0.88\n",
      "Train Epoch:4[7168/60000 (12%)]\t Loss:0.377042 acc:0.88\n",
      "Train Epoch:4[7680/60000 (13%)]\t Loss:0.343543 acc:0.90\n",
      "Train Epoch:4[8192/60000 (14%)]\t Loss:0.387159 acc:0.89\n",
      "Train Epoch:4[8704/60000 (15%)]\t Loss:0.472416 acc:0.86\n",
      "Train Epoch:4[9216/60000 (15%)]\t Loss:0.337447 acc:0.90\n",
      "Train Epoch:4[9728/60000 (16%)]\t Loss:0.333448 acc:0.91\n",
      "Train Epoch:4[10240/60000 (17%)]\t Loss:0.282395 acc:0.91\n",
      "Train Epoch:4[10752/60000 (18%)]\t Loss:0.331954 acc:0.92\n",
      "Train Epoch:4[11264/60000 (19%)]\t Loss:0.332248 acc:0.90\n",
      "Train Epoch:4[11776/60000 (20%)]\t Loss:0.285219 acc:0.91\n",
      "Train Epoch:4[12288/60000 (20%)]\t Loss:0.430069 acc:0.87\n",
      "Train Epoch:4[12800/60000 (21%)]\t Loss:0.364155 acc:0.88\n",
      "Train Epoch:4[13312/60000 (22%)]\t Loss:0.295648 acc:0.92\n",
      "Train Epoch:4[13824/60000 (23%)]\t Loss:0.413044 acc:0.87\n",
      "Train Epoch:4[14336/60000 (24%)]\t Loss:0.502711 acc:0.84\n",
      "Train Epoch:4[14848/60000 (25%)]\t Loss:0.282277 acc:0.91\n",
      "Train Epoch:4[15360/60000 (26%)]\t Loss:0.342200 acc:0.90\n",
      "Train Epoch:4[15872/60000 (26%)]\t Loss:0.318525 acc:0.90\n",
      "Train Epoch:4[16384/60000 (27%)]\t Loss:0.309860 acc:0.90\n",
      "Train Epoch:4[16896/60000 (28%)]\t Loss:0.345526 acc:0.90\n",
      "Train Epoch:4[17408/60000 (29%)]\t Loss:0.429908 acc:0.86\n",
      "Train Epoch:4[17920/60000 (30%)]\t Loss:0.266597 acc:0.93\n",
      "Train Epoch:4[18432/60000 (31%)]\t Loss:0.297463 acc:0.93\n",
      "Train Epoch:4[18944/60000 (32%)]\t Loss:0.295185 acc:0.91\n",
      "Train Epoch:4[19456/60000 (32%)]\t Loss:0.265891 acc:0.92\n",
      "Train Epoch:4[19968/60000 (33%)]\t Loss:0.328578 acc:0.90\n",
      "Train Epoch:4[20480/60000 (34%)]\t Loss:0.431404 acc:0.88\n",
      "Train Epoch:4[20992/60000 (35%)]\t Loss:0.292680 acc:0.91\n",
      "Train Epoch:4[21504/60000 (36%)]\t Loss:0.276400 acc:0.92\n",
      "Train Epoch:4[22016/60000 (37%)]\t Loss:0.297722 acc:0.90\n",
      "Train Epoch:4[22528/60000 (38%)]\t Loss:0.311938 acc:0.90\n",
      "Train Epoch:4[23040/60000 (38%)]\t Loss:0.253692 acc:0.91\n",
      "Train Epoch:4[23552/60000 (39%)]\t Loss:0.337955 acc:0.90\n",
      "Train Epoch:4[24064/60000 (40%)]\t Loss:0.333504 acc:0.90\n",
      "Train Epoch:4[24576/60000 (41%)]\t Loss:0.364715 acc:0.87\n",
      "Train Epoch:4[25088/60000 (42%)]\t Loss:0.279938 acc:0.92\n",
      "Train Epoch:4[25600/60000 (43%)]\t Loss:0.264679 acc:0.92\n",
      "Train Epoch:4[26112/60000 (44%)]\t Loss:0.364143 acc:0.89\n",
      "Train Epoch:4[26624/60000 (44%)]\t Loss:0.348677 acc:0.91\n",
      "Train Epoch:4[27136/60000 (45%)]\t Loss:0.353805 acc:0.90\n",
      "Train Epoch:4[27648/60000 (46%)]\t Loss:0.251779 acc:0.92\n",
      "Train Epoch:4[28160/60000 (47%)]\t Loss:0.327024 acc:0.89\n",
      "Train Epoch:4[28672/60000 (48%)]\t Loss:0.291825 acc:0.91\n",
      "Train Epoch:4[29184/60000 (49%)]\t Loss:0.287638 acc:0.91\n",
      "Train Epoch:4[29696/60000 (49%)]\t Loss:0.412001 acc:0.88\n",
      "Train Epoch:4[30208/60000 (50%)]\t Loss:0.318384 acc:0.90\n",
      "Train Epoch:4[30720/60000 (51%)]\t Loss:0.380390 acc:0.89\n",
      "Train Epoch:4[31232/60000 (52%)]\t Loss:0.434824 acc:0.86\n",
      "Train Epoch:4[31744/60000 (53%)]\t Loss:0.334101 acc:0.89\n",
      "Train Epoch:4[32256/60000 (54%)]\t Loss:0.390252 acc:0.86\n",
      "Train Epoch:4[32768/60000 (55%)]\t Loss:0.279773 acc:0.94\n",
      "Train Epoch:4[33280/60000 (55%)]\t Loss:0.312509 acc:0.91\n",
      "Train Epoch:4[33792/60000 (56%)]\t Loss:0.184063 acc:0.95\n",
      "Train Epoch:4[34304/60000 (57%)]\t Loss:0.333761 acc:0.88\n",
      "Train Epoch:4[34816/60000 (58%)]\t Loss:0.287612 acc:0.91\n",
      "Train Epoch:4[35328/60000 (59%)]\t Loss:0.265232 acc:0.92\n",
      "Train Epoch:4[35840/60000 (60%)]\t Loss:0.254495 acc:0.92\n",
      "Train Epoch:4[36352/60000 (61%)]\t Loss:0.295750 acc:0.91\n",
      "Train Epoch:4[36864/60000 (61%)]\t Loss:0.336730 acc:0.89\n",
      "Train Epoch:4[37376/60000 (62%)]\t Loss:0.346734 acc:0.90\n",
      "Train Epoch:4[37888/60000 (63%)]\t Loss:0.269152 acc:0.91\n",
      "Train Epoch:4[38400/60000 (64%)]\t Loss:0.234204 acc:0.92\n",
      "Train Epoch:4[38912/60000 (65%)]\t Loss:0.274944 acc:0.91\n",
      "Train Epoch:4[39424/60000 (66%)]\t Loss:0.365403 acc:0.88\n",
      "Train Epoch:4[39936/60000 (67%)]\t Loss:0.299638 acc:0.90\n",
      "Train Epoch:4[40448/60000 (67%)]\t Loss:0.250524 acc:0.93\n",
      "Train Epoch:4[40960/60000 (68%)]\t Loss:0.392748 acc:0.89\n",
      "Train Epoch:4[41472/60000 (69%)]\t Loss:0.275977 acc:0.91\n",
      "Train Epoch:4[41984/60000 (70%)]\t Loss:0.386911 acc:0.87\n",
      "Train Epoch:4[42496/60000 (71%)]\t Loss:0.349971 acc:0.90\n",
      "Train Epoch:4[43008/60000 (72%)]\t Loss:0.260899 acc:0.92\n",
      "Train Epoch:4[43520/60000 (73%)]\t Loss:0.275703 acc:0.92\n",
      "Train Epoch:4[44032/60000 (73%)]\t Loss:0.337096 acc:0.89\n",
      "Train Epoch:4[44544/60000 (74%)]\t Loss:0.282447 acc:0.91\n",
      "Train Epoch:4[45056/60000 (75%)]\t Loss:0.295410 acc:0.92\n",
      "Train Epoch:4[45568/60000 (76%)]\t Loss:0.334855 acc:0.89\n",
      "Train Epoch:4[46080/60000 (77%)]\t Loss:0.333391 acc:0.89\n",
      "Train Epoch:4[46592/60000 (78%)]\t Loss:0.235077 acc:0.93\n",
      "Train Epoch:4[47104/60000 (79%)]\t Loss:0.313077 acc:0.91\n",
      "Train Epoch:4[47616/60000 (79%)]\t Loss:0.265835 acc:0.91\n",
      "Train Epoch:4[48128/60000 (80%)]\t Loss:0.224362 acc:0.93\n",
      "Train Epoch:4[48640/60000 (81%)]\t Loss:0.327589 acc:0.89\n",
      "Train Epoch:4[49152/60000 (82%)]\t Loss:0.368121 acc:0.88\n",
      "Train Epoch:4[49664/60000 (83%)]\t Loss:0.311780 acc:0.90\n",
      "Train Epoch:4[50176/60000 (84%)]\t Loss:0.398000 acc:0.90\n",
      "Train Epoch:4[50688/60000 (84%)]\t Loss:0.291233 acc:0.89\n",
      "Train Epoch:4[51200/60000 (85%)]\t Loss:0.255223 acc:0.91\n",
      "Train Epoch:4[51712/60000 (86%)]\t Loss:0.344246 acc:0.89\n",
      "Train Epoch:4[52224/60000 (87%)]\t Loss:0.263160 acc:0.91\n",
      "Train Epoch:4[52736/60000 (88%)]\t Loss:0.394185 acc:0.87\n",
      "Train Epoch:4[53248/60000 (89%)]\t Loss:0.228802 acc:0.92\n",
      "Train Epoch:4[53760/60000 (90%)]\t Loss:0.281075 acc:0.92\n",
      "Train Epoch:4[54272/60000 (90%)]\t Loss:0.243939 acc:0.93\n",
      "Train Epoch:4[54784/60000 (91%)]\t Loss:0.286651 acc:0.91\n",
      "Train Epoch:4[55296/60000 (92%)]\t Loss:0.251328 acc:0.93\n",
      "Train Epoch:4[55808/60000 (93%)]\t Loss:0.209272 acc:0.94\n",
      "Train Epoch:4[56320/60000 (94%)]\t Loss:0.244416 acc:0.94\n",
      "Train Epoch:4[56832/60000 (95%)]\t Loss:0.236185 acc:0.93\n",
      "Train Epoch:4[57344/60000 (96%)]\t Loss:0.287175 acc:0.89\n",
      "Train Epoch:4[57856/60000 (96%)]\t Loss:0.169346 acc:0.94\n",
      "Train Epoch:4[58368/60000 (97%)]\t Loss:0.164173 acc:0.95\n",
      "Train Epoch:4[58880/60000 (98%)]\t Loss:0.201210 acc:0.95\n",
      "Train Epoch:4[59392/60000 (99%)]\t Loss:0.220118 acc:0.96\n",
      "Train Epoch:4[59904/60000 (100%)]\t Loss:0.340405 acc:0.17\n",
      "===> Saving models...\n",
      "Test Epoch:4 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:4 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:4 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:4 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:4 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:4 [2560/10000 (26%)]\t acc:0.28\n",
      "Test Epoch:4 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:4 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:4 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:4 [4608/10000 (46%)]\t acc:0.47\n",
      "Test Epoch:4 [5120/10000 (51%)]\t acc:0.52\n",
      "Test Epoch:4 [5632/10000 (56%)]\t acc:0.57\n",
      "Test Epoch:4 [6144/10000 (61%)]\t acc:0.61\n",
      "Test Epoch:4 [6656/10000 (67%)]\t acc:0.66\n",
      "Test Epoch:4 [7168/10000 (72%)]\t acc:0.71\n",
      "Test Epoch:4 [7680/10000 (77%)]\t acc:0.76\n",
      "Test Epoch:4 [8192/10000 (82%)]\t acc:0.80\n",
      "Test Epoch:4 [8704/10000 (87%)]\t acc:0.85\n",
      "Test Epoch:4 [9216/10000 (92%)]\t acc:0.90\n",
      "Test Epoch:4 [9728/10000 (97%)]\t acc:0.92\n",
      "Train Epoch:5[0/60000 (0%)]\t Loss:0.269422 acc:0.92\n",
      "Train Epoch:5[512/60000 (1%)]\t Loss:0.301746 acc:0.91\n",
      "Train Epoch:5[1024/60000 (2%)]\t Loss:0.337677 acc:0.89\n",
      "Train Epoch:5[1536/60000 (3%)]\t Loss:0.211395 acc:0.94\n",
      "Train Epoch:5[2048/60000 (3%)]\t Loss:0.258263 acc:0.92\n",
      "Train Epoch:5[2560/60000 (4%)]\t Loss:0.266851 acc:0.92\n",
      "Train Epoch:5[3072/60000 (5%)]\t Loss:0.212717 acc:0.94\n",
      "Train Epoch:5[3584/60000 (6%)]\t Loss:0.234722 acc:0.93\n",
      "Train Epoch:5[4096/60000 (7%)]\t Loss:0.252178 acc:0.92\n",
      "Train Epoch:5[4608/60000 (8%)]\t Loss:0.292031 acc:0.92\n",
      "Train Epoch:5[5120/60000 (9%)]\t Loss:0.291474 acc:0.92\n",
      "Train Epoch:5[5632/60000 (9%)]\t Loss:0.250067 acc:0.93\n",
      "Train Epoch:5[6144/60000 (10%)]\t Loss:0.189347 acc:0.94\n",
      "Train Epoch:5[6656/60000 (11%)]\t Loss:0.311608 acc:0.91\n",
      "Train Epoch:5[7168/60000 (12%)]\t Loss:0.314226 acc:0.90\n",
      "Train Epoch:5[7680/60000 (13%)]\t Loss:0.293130 acc:0.92\n",
      "Train Epoch:5[8192/60000 (14%)]\t Loss:0.318028 acc:0.90\n",
      "Train Epoch:5[8704/60000 (15%)]\t Loss:0.404086 acc:0.89\n",
      "Train Epoch:5[9216/60000 (15%)]\t Loss:0.279476 acc:0.92\n",
      "Train Epoch:5[9728/60000 (16%)]\t Loss:0.259978 acc:0.93\n",
      "Train Epoch:5[10240/60000 (17%)]\t Loss:0.232113 acc:0.93\n",
      "Train Epoch:5[10752/60000 (18%)]\t Loss:0.258687 acc:0.94\n",
      "Train Epoch:5[11264/60000 (19%)]\t Loss:0.261734 acc:0.92\n",
      "Train Epoch:5[11776/60000 (20%)]\t Loss:0.222129 acc:0.93\n",
      "Train Epoch:5[12288/60000 (20%)]\t Loss:0.375342 acc:0.90\n",
      "Train Epoch:5[12800/60000 (21%)]\t Loss:0.291420 acc:0.91\n",
      "Train Epoch:5[13312/60000 (22%)]\t Loss:0.242865 acc:0.94\n",
      "Train Epoch:5[13824/60000 (23%)]\t Loss:0.332331 acc:0.89\n",
      "Train Epoch:5[14336/60000 (24%)]\t Loss:0.401998 acc:0.87\n",
      "Train Epoch:5[14848/60000 (25%)]\t Loss:0.230208 acc:0.92\n",
      "Train Epoch:5[15360/60000 (26%)]\t Loss:0.303565 acc:0.90\n",
      "Train Epoch:5[15872/60000 (26%)]\t Loss:0.255966 acc:0.91\n",
      "Train Epoch:5[16384/60000 (27%)]\t Loss:0.258808 acc:0.91\n",
      "Train Epoch:5[16896/60000 (28%)]\t Loss:0.260085 acc:0.92\n",
      "Train Epoch:5[17408/60000 (29%)]\t Loss:0.333114 acc:0.89\n",
      "Train Epoch:5[17920/60000 (30%)]\t Loss:0.220179 acc:0.94\n",
      "Train Epoch:5[18432/60000 (31%)]\t Loss:0.234994 acc:0.94\n",
      "Train Epoch:5[18944/60000 (32%)]\t Loss:0.246937 acc:0.92\n",
      "Train Epoch:5[19456/60000 (32%)]\t Loss:0.230999 acc:0.93\n",
      "Train Epoch:5[19968/60000 (33%)]\t Loss:0.268128 acc:0.92\n",
      "Train Epoch:5[20480/60000 (34%)]\t Loss:0.380888 acc:0.90\n",
      "Train Epoch:5[20992/60000 (35%)]\t Loss:0.235691 acc:0.94\n",
      "Train Epoch:5[21504/60000 (36%)]\t Loss:0.234183 acc:0.94\n",
      "Train Epoch:5[22016/60000 (37%)]\t Loss:0.243187 acc:0.92\n",
      "Train Epoch:5[22528/60000 (38%)]\t Loss:0.268917 acc:0.91\n",
      "Train Epoch:5[23040/60000 (38%)]\t Loss:0.203263 acc:0.93\n",
      "Train Epoch:5[23552/60000 (39%)]\t Loss:0.286685 acc:0.92\n",
      "Train Epoch:5[24064/60000 (40%)]\t Loss:0.274886 acc:0.91\n",
      "Train Epoch:5[24576/60000 (41%)]\t Loss:0.308976 acc:0.89\n",
      "Train Epoch:5[25088/60000 (42%)]\t Loss:0.240829 acc:0.93\n",
      "Train Epoch:5[25600/60000 (43%)]\t Loss:0.226092 acc:0.93\n",
      "Train Epoch:5[26112/60000 (44%)]\t Loss:0.315872 acc:0.91\n",
      "Train Epoch:5[26624/60000 (44%)]\t Loss:0.287777 acc:0.93\n",
      "Train Epoch:5[27136/60000 (45%)]\t Loss:0.296076 acc:0.91\n",
      "Train Epoch:5[27648/60000 (46%)]\t Loss:0.203213 acc:0.94\n",
      "Train Epoch:5[28160/60000 (47%)]\t Loss:0.284189 acc:0.91\n",
      "Train Epoch:5[28672/60000 (48%)]\t Loss:0.244124 acc:0.93\n",
      "Train Epoch:5[29184/60000 (49%)]\t Loss:0.234019 acc:0.92\n",
      "Train Epoch:5[29696/60000 (49%)]\t Loss:0.353185 acc:0.89\n",
      "Train Epoch:5[30208/60000 (50%)]\t Loss:0.267442 acc:0.92\n",
      "Train Epoch:5[30720/60000 (51%)]\t Loss:0.336037 acc:0.91\n",
      "Train Epoch:5[31232/60000 (52%)]\t Loss:0.378014 acc:0.88\n",
      "Train Epoch:5[31744/60000 (53%)]\t Loss:0.271607 acc:0.90\n",
      "Train Epoch:5[32256/60000 (54%)]\t Loss:0.332230 acc:0.89\n",
      "Train Epoch:5[32768/60000 (55%)]\t Loss:0.225238 acc:0.95\n",
      "Train Epoch:5[33280/60000 (55%)]\t Loss:0.260133 acc:0.92\n",
      "Train Epoch:5[33792/60000 (56%)]\t Loss:0.146567 acc:0.96\n",
      "Train Epoch:5[34304/60000 (57%)]\t Loss:0.283345 acc:0.91\n",
      "Train Epoch:5[34816/60000 (58%)]\t Loss:0.250833 acc:0.92\n",
      "Train Epoch:5[35328/60000 (59%)]\t Loss:0.222034 acc:0.94\n",
      "Train Epoch:5[35840/60000 (60%)]\t Loss:0.210086 acc:0.94\n",
      "Train Epoch:5[36352/60000 (61%)]\t Loss:0.247399 acc:0.92\n",
      "Train Epoch:5[36864/60000 (61%)]\t Loss:0.289989 acc:0.91\n",
      "Train Epoch:5[37376/60000 (62%)]\t Loss:0.303378 acc:0.92\n",
      "Train Epoch:5[37888/60000 (63%)]\t Loss:0.230667 acc:0.93\n",
      "Train Epoch:5[38400/60000 (64%)]\t Loss:0.190755 acc:0.94\n",
      "Train Epoch:5[38912/60000 (65%)]\t Loss:0.240401 acc:0.93\n",
      "Train Epoch:5[39424/60000 (66%)]\t Loss:0.297641 acc:0.92\n",
      "Train Epoch:5[39936/60000 (67%)]\t Loss:0.245131 acc:0.91\n",
      "Train Epoch:5[40448/60000 (67%)]\t Loss:0.199607 acc:0.94\n",
      "Train Epoch:5[40960/60000 (68%)]\t Loss:0.338916 acc:0.91\n",
      "Train Epoch:5[41472/60000 (69%)]\t Loss:0.235707 acc:0.92\n",
      "Train Epoch:5[41984/60000 (70%)]\t Loss:0.324701 acc:0.90\n",
      "Train Epoch:5[42496/60000 (71%)]\t Loss:0.302561 acc:0.92\n",
      "Train Epoch:5[43008/60000 (72%)]\t Loss:0.222941 acc:0.93\n",
      "Train Epoch:5[43520/60000 (73%)]\t Loss:0.238858 acc:0.93\n",
      "Train Epoch:5[44032/60000 (73%)]\t Loss:0.268183 acc:0.92\n",
      "Train Epoch:5[44544/60000 (74%)]\t Loss:0.240953 acc:0.92\n",
      "Train Epoch:5[45056/60000 (75%)]\t Loss:0.245485 acc:0.93\n",
      "Train Epoch:5[45568/60000 (76%)]\t Loss:0.278982 acc:0.91\n",
      "Train Epoch:5[46080/60000 (77%)]\t Loss:0.296212 acc:0.91\n",
      "Train Epoch:5[46592/60000 (78%)]\t Loss:0.199400 acc:0.94\n",
      "Train Epoch:5[47104/60000 (79%)]\t Loss:0.277544 acc:0.91\n",
      "Train Epoch:5[47616/60000 (79%)]\t Loss:0.224074 acc:0.92\n",
      "Train Epoch:5[48128/60000 (80%)]\t Loss:0.187563 acc:0.93\n",
      "Train Epoch:5[48640/60000 (81%)]\t Loss:0.290296 acc:0.91\n",
      "Train Epoch:5[49152/60000 (82%)]\t Loss:0.320776 acc:0.89\n",
      "Train Epoch:5[49664/60000 (83%)]\t Loss:0.242594 acc:0.93\n",
      "Train Epoch:5[50176/60000 (84%)]\t Loss:0.339769 acc:0.92\n",
      "Train Epoch:5[50688/60000 (84%)]\t Loss:0.249826 acc:0.90\n",
      "Train Epoch:5[51200/60000 (85%)]\t Loss:0.219035 acc:0.93\n",
      "Train Epoch:5[51712/60000 (86%)]\t Loss:0.305055 acc:0.89\n",
      "Train Epoch:5[52224/60000 (87%)]\t Loss:0.221617 acc:0.93\n",
      "Train Epoch:5[52736/60000 (88%)]\t Loss:0.333251 acc:0.89\n",
      "Train Epoch:5[53248/60000 (89%)]\t Loss:0.189737 acc:0.94\n",
      "Train Epoch:5[53760/60000 (90%)]\t Loss:0.245964 acc:0.93\n",
      "Train Epoch:5[54272/60000 (90%)]\t Loss:0.200176 acc:0.94\n",
      "Train Epoch:5[54784/60000 (91%)]\t Loss:0.251413 acc:0.93\n",
      "Train Epoch:5[55296/60000 (92%)]\t Loss:0.225180 acc:0.93\n",
      "Train Epoch:5[55808/60000 (93%)]\t Loss:0.184060 acc:0.94\n",
      "Train Epoch:5[56320/60000 (94%)]\t Loss:0.220940 acc:0.93\n",
      "Train Epoch:5[56832/60000 (95%)]\t Loss:0.184965 acc:0.95\n",
      "Train Epoch:5[57344/60000 (96%)]\t Loss:0.248391 acc:0.91\n",
      "Train Epoch:5[57856/60000 (96%)]\t Loss:0.143671 acc:0.95\n",
      "Train Epoch:5[58368/60000 (97%)]\t Loss:0.129740 acc:0.96\n",
      "Train Epoch:5[58880/60000 (98%)]\t Loss:0.158400 acc:0.95\n",
      "Train Epoch:5[59392/60000 (99%)]\t Loss:0.196187 acc:0.97\n",
      "Train Epoch:5[59904/60000 (100%)]\t Loss:0.308058 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:5 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:5 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:5 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:5 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:5 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:5 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:5 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:5 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:5 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:5 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:5 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:5 [5632/10000 (56%)]\t acc:0.57\n",
      "Test Epoch:5 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:5 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:5 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:5 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:5 [8192/10000 (82%)]\t acc:0.81\n",
      "Test Epoch:5 [8704/10000 (87%)]\t acc:0.86\n",
      "Test Epoch:5 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:5 [9728/10000 (97%)]\t acc:0.93\n",
      "Train Epoch:6[0/60000 (0%)]\t Loss:0.242442 acc:0.93\n",
      "Train Epoch:6[512/60000 (1%)]\t Loss:0.269029 acc:0.92\n",
      "Train Epoch:6[1024/60000 (2%)]\t Loss:0.297427 acc:0.92\n",
      "Train Epoch:6[1536/60000 (3%)]\t Loss:0.170476 acc:0.95\n",
      "Train Epoch:6[2048/60000 (3%)]\t Loss:0.206671 acc:0.94\n",
      "Train Epoch:6[2560/60000 (4%)]\t Loss:0.221871 acc:0.93\n",
      "Train Epoch:6[3072/60000 (5%)]\t Loss:0.171610 acc:0.94\n",
      "Train Epoch:6[3584/60000 (6%)]\t Loss:0.196657 acc:0.94\n",
      "Train Epoch:6[4096/60000 (7%)]\t Loss:0.215779 acc:0.93\n",
      "Train Epoch:6[4608/60000 (8%)]\t Loss:0.253016 acc:0.93\n",
      "Train Epoch:6[5120/60000 (9%)]\t Loss:0.245475 acc:0.94\n",
      "Train Epoch:6[5632/60000 (9%)]\t Loss:0.212454 acc:0.93\n",
      "Train Epoch:6[6144/60000 (10%)]\t Loss:0.158415 acc:0.95\n",
      "Train Epoch:6[6656/60000 (11%)]\t Loss:0.269150 acc:0.93\n",
      "Train Epoch:6[7168/60000 (12%)]\t Loss:0.264408 acc:0.93\n",
      "Train Epoch:6[7680/60000 (13%)]\t Loss:0.260194 acc:0.92\n",
      "Train Epoch:6[8192/60000 (14%)]\t Loss:0.276432 acc:0.91\n",
      "Train Epoch:6[8704/60000 (15%)]\t Loss:0.359657 acc:0.90\n",
      "Train Epoch:6[9216/60000 (15%)]\t Loss:0.246387 acc:0.93\n",
      "Train Epoch:6[9728/60000 (16%)]\t Loss:0.229090 acc:0.94\n",
      "Train Epoch:6[10240/60000 (17%)]\t Loss:0.206400 acc:0.93\n",
      "Train Epoch:6[10752/60000 (18%)]\t Loss:0.216267 acc:0.96\n",
      "Train Epoch:6[11264/60000 (19%)]\t Loss:0.218973 acc:0.94\n",
      "Train Epoch:6[11776/60000 (20%)]\t Loss:0.179759 acc:0.94\n",
      "Train Epoch:6[12288/60000 (20%)]\t Loss:0.327582 acc:0.91\n",
      "Train Epoch:6[12800/60000 (21%)]\t Loss:0.250406 acc:0.92\n",
      "Train Epoch:6[13312/60000 (22%)]\t Loss:0.215781 acc:0.94\n",
      "Train Epoch:6[13824/60000 (23%)]\t Loss:0.288329 acc:0.90\n",
      "Train Epoch:6[14336/60000 (24%)]\t Loss:0.347124 acc:0.88\n",
      "Train Epoch:6[14848/60000 (25%)]\t Loss:0.192176 acc:0.93\n",
      "Train Epoch:6[15360/60000 (26%)]\t Loss:0.277078 acc:0.92\n",
      "Train Epoch:6[15872/60000 (26%)]\t Loss:0.215160 acc:0.93\n",
      "Train Epoch:6[16384/60000 (27%)]\t Loss:0.224453 acc:0.93\n",
      "Train Epoch:6[16896/60000 (28%)]\t Loss:0.215837 acc:0.93\n",
      "Train Epoch:6[17408/60000 (29%)]\t Loss:0.285162 acc:0.90\n",
      "Train Epoch:6[17920/60000 (30%)]\t Loss:0.198951 acc:0.95\n",
      "Train Epoch:6[18432/60000 (31%)]\t Loss:0.196429 acc:0.95\n",
      "Train Epoch:6[18944/60000 (32%)]\t Loss:0.211731 acc:0.93\n",
      "Train Epoch:6[19456/60000 (32%)]\t Loss:0.202944 acc:0.93\n",
      "Train Epoch:6[19968/60000 (33%)]\t Loss:0.230847 acc:0.93\n",
      "Train Epoch:6[20480/60000 (34%)]\t Loss:0.345385 acc:0.91\n",
      "Train Epoch:6[20992/60000 (35%)]\t Loss:0.204329 acc:0.95\n",
      "Train Epoch:6[21504/60000 (36%)]\t Loss:0.202111 acc:0.94\n",
      "Train Epoch:6[22016/60000 (37%)]\t Loss:0.212657 acc:0.93\n",
      "Train Epoch:6[22528/60000 (38%)]\t Loss:0.237514 acc:0.92\n",
      "Train Epoch:6[23040/60000 (38%)]\t Loss:0.172092 acc:0.95\n",
      "Train Epoch:6[23552/60000 (39%)]\t Loss:0.248628 acc:0.93\n",
      "Train Epoch:6[24064/60000 (40%)]\t Loss:0.234079 acc:0.92\n",
      "Train Epoch:6[24576/60000 (41%)]\t Loss:0.269453 acc:0.91\n",
      "Train Epoch:6[25088/60000 (42%)]\t Loss:0.216914 acc:0.93\n",
      "Train Epoch:6[25600/60000 (43%)]\t Loss:0.199678 acc:0.94\n",
      "Train Epoch:6[26112/60000 (44%)]\t Loss:0.276193 acc:0.93\n",
      "Train Epoch:6[26624/60000 (44%)]\t Loss:0.246361 acc:0.93\n",
      "Train Epoch:6[27136/60000 (45%)]\t Loss:0.258267 acc:0.93\n",
      "Train Epoch:6[27648/60000 (46%)]\t Loss:0.167309 acc:0.95\n",
      "Train Epoch:6[28160/60000 (47%)]\t Loss:0.253253 acc:0.92\n",
      "Train Epoch:6[28672/60000 (48%)]\t Loss:0.206228 acc:0.93\n",
      "Train Epoch:6[29184/60000 (49%)]\t Loss:0.192094 acc:0.94\n",
      "Train Epoch:6[29696/60000 (49%)]\t Loss:0.306958 acc:0.90\n",
      "Train Epoch:6[30208/60000 (50%)]\t Loss:0.226600 acc:0.93\n",
      "Train Epoch:6[30720/60000 (51%)]\t Loss:0.297272 acc:0.92\n",
      "Train Epoch:6[31232/60000 (52%)]\t Loss:0.338214 acc:0.90\n",
      "Train Epoch:6[31744/60000 (53%)]\t Loss:0.229047 acc:0.92\n",
      "Train Epoch:6[32256/60000 (54%)]\t Loss:0.288823 acc:0.91\n",
      "Train Epoch:6[32768/60000 (55%)]\t Loss:0.185360 acc:0.96\n",
      "Train Epoch:6[33280/60000 (55%)]\t Loss:0.221185 acc:0.93\n",
      "Train Epoch:6[33792/60000 (56%)]\t Loss:0.120665 acc:0.97\n",
      "Train Epoch:6[34304/60000 (57%)]\t Loss:0.247397 acc:0.93\n",
      "Train Epoch:6[34816/60000 (58%)]\t Loss:0.225142 acc:0.93\n",
      "Train Epoch:6[35328/60000 (59%)]\t Loss:0.191640 acc:0.94\n",
      "Train Epoch:6[35840/60000 (60%)]\t Loss:0.184316 acc:0.95\n",
      "Train Epoch:6[36352/60000 (61%)]\t Loss:0.207158 acc:0.93\n",
      "Train Epoch:6[36864/60000 (61%)]\t Loss:0.253930 acc:0.92\n",
      "Train Epoch:6[37376/60000 (62%)]\t Loss:0.265812 acc:0.93\n",
      "Train Epoch:6[37888/60000 (63%)]\t Loss:0.199860 acc:0.94\n",
      "Train Epoch:6[38400/60000 (64%)]\t Loss:0.165240 acc:0.96\n",
      "Train Epoch:6[38912/60000 (65%)]\t Loss:0.214406 acc:0.94\n",
      "Train Epoch:6[39424/60000 (66%)]\t Loss:0.239808 acc:0.93\n",
      "Train Epoch:6[39936/60000 (67%)]\t Loss:0.208393 acc:0.93\n",
      "Train Epoch:6[40448/60000 (67%)]\t Loss:0.167274 acc:0.95\n",
      "Train Epoch:6[40960/60000 (68%)]\t Loss:0.306743 acc:0.91\n",
      "Train Epoch:6[41472/60000 (69%)]\t Loss:0.209465 acc:0.92\n",
      "Train Epoch:6[41984/60000 (70%)]\t Loss:0.273621 acc:0.92\n",
      "Train Epoch:6[42496/60000 (71%)]\t Loss:0.268625 acc:0.92\n",
      "Train Epoch:6[43008/60000 (72%)]\t Loss:0.191111 acc:0.93\n",
      "Train Epoch:6[43520/60000 (73%)]\t Loss:0.211134 acc:0.94\n",
      "Train Epoch:6[44032/60000 (73%)]\t Loss:0.230191 acc:0.93\n",
      "Train Epoch:6[44544/60000 (74%)]\t Loss:0.210943 acc:0.92\n",
      "Train Epoch:6[45056/60000 (75%)]\t Loss:0.215622 acc:0.94\n",
      "Train Epoch:6[45568/60000 (76%)]\t Loss:0.241095 acc:0.92\n",
      "Train Epoch:6[46080/60000 (77%)]\t Loss:0.265790 acc:0.92\n",
      "Train Epoch:6[46592/60000 (78%)]\t Loss:0.176827 acc:0.95\n",
      "Train Epoch:6[47104/60000 (79%)]\t Loss:0.250387 acc:0.91\n",
      "Train Epoch:6[47616/60000 (79%)]\t Loss:0.197955 acc:0.94\n",
      "Train Epoch:6[48128/60000 (80%)]\t Loss:0.166269 acc:0.95\n",
      "Train Epoch:6[48640/60000 (81%)]\t Loss:0.260986 acc:0.93\n",
      "Train Epoch:6[49152/60000 (82%)]\t Loss:0.292016 acc:0.89\n",
      "Train Epoch:6[49664/60000 (83%)]\t Loss:0.202327 acc:0.94\n",
      "Train Epoch:6[50176/60000 (84%)]\t Loss:0.301170 acc:0.93\n",
      "Train Epoch:6[50688/60000 (84%)]\t Loss:0.211423 acc:0.92\n",
      "Train Epoch:6[51200/60000 (85%)]\t Loss:0.185162 acc:0.94\n",
      "Train Epoch:6[51712/60000 (86%)]\t Loss:0.268521 acc:0.92\n",
      "Train Epoch:6[52224/60000 (87%)]\t Loss:0.190198 acc:0.94\n",
      "Train Epoch:6[52736/60000 (88%)]\t Loss:0.293830 acc:0.91\n",
      "Train Epoch:6[53248/60000 (89%)]\t Loss:0.165961 acc:0.95\n",
      "Train Epoch:6[53760/60000 (90%)]\t Loss:0.220034 acc:0.93\n",
      "Train Epoch:6[54272/60000 (90%)]\t Loss:0.173826 acc:0.96\n",
      "Train Epoch:6[54784/60000 (91%)]\t Loss:0.223949 acc:0.93\n",
      "Train Epoch:6[55296/60000 (92%)]\t Loss:0.207445 acc:0.94\n",
      "Train Epoch:6[55808/60000 (93%)]\t Loss:0.164512 acc:0.95\n",
      "Train Epoch:6[56320/60000 (94%)]\t Loss:0.200049 acc:0.94\n",
      "Train Epoch:6[56832/60000 (95%)]\t Loss:0.157124 acc:0.95\n",
      "Train Epoch:6[57344/60000 (96%)]\t Loss:0.217689 acc:0.93\n",
      "Train Epoch:6[57856/60000 (96%)]\t Loss:0.124276 acc:0.96\n",
      "Train Epoch:6[58368/60000 (97%)]\t Loss:0.107413 acc:0.97\n",
      "Train Epoch:6[58880/60000 (98%)]\t Loss:0.122417 acc:0.96\n",
      "Train Epoch:6[59392/60000 (99%)]\t Loss:0.179809 acc:0.97\n",
      "Train Epoch:6[59904/60000 (100%)]\t Loss:0.271048 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:6 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:6 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:6 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:6 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:6 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:6 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:6 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:6 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:6 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:6 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:6 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:6 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:6 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:6 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:6 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:6 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:6 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:6 [8704/10000 (87%)]\t acc:0.86\n",
      "Test Epoch:6 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:6 [9728/10000 (97%)]\t acc:0.94\n",
      "Train Epoch:7[0/60000 (0%)]\t Loss:0.214780 acc:0.94\n",
      "Train Epoch:7[512/60000 (1%)]\t Loss:0.239457 acc:0.93\n",
      "Train Epoch:7[1024/60000 (2%)]\t Loss:0.270358 acc:0.92\n",
      "Train Epoch:7[1536/60000 (3%)]\t Loss:0.146338 acc:0.96\n",
      "Train Epoch:7[2048/60000 (3%)]\t Loss:0.173744 acc:0.95\n",
      "Train Epoch:7[2560/60000 (4%)]\t Loss:0.193232 acc:0.94\n",
      "Train Epoch:7[3072/60000 (5%)]\t Loss:0.146682 acc:0.95\n",
      "Train Epoch:7[3584/60000 (6%)]\t Loss:0.169085 acc:0.94\n",
      "Train Epoch:7[4096/60000 (7%)]\t Loss:0.187580 acc:0.94\n",
      "Train Epoch:7[4608/60000 (8%)]\t Loss:0.227298 acc:0.94\n",
      "Train Epoch:7[5120/60000 (9%)]\t Loss:0.215542 acc:0.95\n",
      "Train Epoch:7[5632/60000 (9%)]\t Loss:0.188239 acc:0.94\n",
      "Train Epoch:7[6144/60000 (10%)]\t Loss:0.142183 acc:0.96\n",
      "Train Epoch:7[6656/60000 (11%)]\t Loss:0.241479 acc:0.94\n",
      "Train Epoch:7[7168/60000 (12%)]\t Loss:0.232581 acc:0.94\n",
      "Train Epoch:7[7680/60000 (13%)]\t Loss:0.236587 acc:0.93\n",
      "Train Epoch:7[8192/60000 (14%)]\t Loss:0.248317 acc:0.92\n",
      "Train Epoch:7[8704/60000 (15%)]\t Loss:0.325265 acc:0.91\n",
      "Train Epoch:7[9216/60000 (15%)]\t Loss:0.223939 acc:0.94\n",
      "Train Epoch:7[9728/60000 (16%)]\t Loss:0.211409 acc:0.94\n",
      "Train Epoch:7[10240/60000 (17%)]\t Loss:0.188922 acc:0.94\n",
      "Train Epoch:7[10752/60000 (18%)]\t Loss:0.192702 acc:0.96\n",
      "Train Epoch:7[11264/60000 (19%)]\t Loss:0.190841 acc:0.94\n",
      "Train Epoch:7[11776/60000 (20%)]\t Loss:0.150924 acc:0.95\n",
      "Train Epoch:7[12288/60000 (20%)]\t Loss:0.289589 acc:0.92\n",
      "Train Epoch:7[12800/60000 (21%)]\t Loss:0.220209 acc:0.93\n",
      "Train Epoch:7[13312/60000 (22%)]\t Loss:0.195530 acc:0.96\n",
      "Train Epoch:7[13824/60000 (23%)]\t Loss:0.254810 acc:0.92\n",
      "Train Epoch:7[14336/60000 (24%)]\t Loss:0.305262 acc:0.89\n",
      "Train Epoch:7[14848/60000 (25%)]\t Loss:0.163159 acc:0.94\n",
      "Train Epoch:7[15360/60000 (26%)]\t Loss:0.254021 acc:0.92\n",
      "Train Epoch:7[15872/60000 (26%)]\t Loss:0.185266 acc:0.94\n",
      "Train Epoch:7[16384/60000 (27%)]\t Loss:0.198467 acc:0.94\n",
      "Train Epoch:7[16896/60000 (28%)]\t Loss:0.188388 acc:0.94\n",
      "Train Epoch:7[17408/60000 (29%)]\t Loss:0.250399 acc:0.91\n",
      "Train Epoch:7[17920/60000 (30%)]\t Loss:0.182618 acc:0.96\n",
      "Train Epoch:7[18432/60000 (31%)]\t Loss:0.170701 acc:0.96\n",
      "Train Epoch:7[18944/60000 (32%)]\t Loss:0.185968 acc:0.93\n",
      "Train Epoch:7[19456/60000 (32%)]\t Loss:0.180616 acc:0.94\n",
      "Train Epoch:7[19968/60000 (33%)]\t Loss:0.203786 acc:0.94\n",
      "Train Epoch:7[20480/60000 (34%)]\t Loss:0.320333 acc:0.92\n",
      "Train Epoch:7[20992/60000 (35%)]\t Loss:0.182466 acc:0.95\n",
      "Train Epoch:7[21504/60000 (36%)]\t Loss:0.180728 acc:0.95\n",
      "Train Epoch:7[22016/60000 (37%)]\t Loss:0.193024 acc:0.94\n",
      "Train Epoch:7[22528/60000 (38%)]\t Loss:0.221128 acc:0.93\n",
      "Train Epoch:7[23040/60000 (38%)]\t Loss:0.146290 acc:0.95\n",
      "Train Epoch:7[23552/60000 (39%)]\t Loss:0.221693 acc:0.94\n",
      "Train Epoch:7[24064/60000 (40%)]\t Loss:0.199673 acc:0.93\n",
      "Train Epoch:7[24576/60000 (41%)]\t Loss:0.239177 acc:0.91\n",
      "Train Epoch:7[25088/60000 (42%)]\t Loss:0.201709 acc:0.94\n",
      "Train Epoch:7[25600/60000 (43%)]\t Loss:0.181960 acc:0.95\n",
      "Train Epoch:7[26112/60000 (44%)]\t Loss:0.246999 acc:0.94\n",
      "Train Epoch:7[26624/60000 (44%)]\t Loss:0.216754 acc:0.95\n",
      "Train Epoch:7[27136/60000 (45%)]\t Loss:0.230876 acc:0.94\n",
      "Train Epoch:7[27648/60000 (46%)]\t Loss:0.142398 acc:0.96\n",
      "Train Epoch:7[28160/60000 (47%)]\t Loss:0.229301 acc:0.93\n",
      "Train Epoch:7[28672/60000 (48%)]\t Loss:0.177327 acc:0.94\n",
      "Train Epoch:7[29184/60000 (49%)]\t Loss:0.164565 acc:0.95\n",
      "Train Epoch:7[29696/60000 (49%)]\t Loss:0.273165 acc:0.92\n",
      "Train Epoch:7[30208/60000 (50%)]\t Loss:0.192925 acc:0.95\n",
      "Train Epoch:7[30720/60000 (51%)]\t Loss:0.262053 acc:0.92\n",
      "Train Epoch:7[31232/60000 (52%)]\t Loss:0.306230 acc:0.91\n",
      "Train Epoch:7[31744/60000 (53%)]\t Loss:0.197153 acc:0.94\n",
      "Train Epoch:7[32256/60000 (54%)]\t Loss:0.253419 acc:0.93\n",
      "Train Epoch:7[32768/60000 (55%)]\t Loss:0.162153 acc:0.96\n",
      "Train Epoch:7[33280/60000 (55%)]\t Loss:0.196935 acc:0.93\n",
      "Train Epoch:7[33792/60000 (56%)]\t Loss:0.101583 acc:0.98\n",
      "Train Epoch:7[34304/60000 (57%)]\t Loss:0.220824 acc:0.94\n",
      "Train Epoch:7[34816/60000 (58%)]\t Loss:0.203221 acc:0.94\n",
      "Train Epoch:7[35328/60000 (59%)]\t Loss:0.168215 acc:0.94\n",
      "Train Epoch:7[35840/60000 (60%)]\t Loss:0.166925 acc:0.95\n",
      "Train Epoch:7[36352/60000 (61%)]\t Loss:0.179572 acc:0.94\n",
      "Train Epoch:7[36864/60000 (61%)]\t Loss:0.226808 acc:0.93\n",
      "Train Epoch:7[37376/60000 (62%)]\t Loss:0.240013 acc:0.93\n",
      "Train Epoch:7[37888/60000 (63%)]\t Loss:0.173703 acc:0.94\n",
      "Train Epoch:7[38400/60000 (64%)]\t Loss:0.145708 acc:0.97\n",
      "Train Epoch:7[38912/60000 (65%)]\t Loss:0.196547 acc:0.94\n",
      "Train Epoch:7[39424/60000 (66%)]\t Loss:0.204617 acc:0.95\n",
      "Train Epoch:7[39936/60000 (67%)]\t Loss:0.180033 acc:0.95\n",
      "Train Epoch:7[40448/60000 (67%)]\t Loss:0.146662 acc:0.95\n",
      "Train Epoch:7[40960/60000 (68%)]\t Loss:0.281029 acc:0.92\n",
      "Train Epoch:7[41472/60000 (69%)]\t Loss:0.190091 acc:0.93\n",
      "Train Epoch:7[41984/60000 (70%)]\t Loss:0.242756 acc:0.92\n",
      "Train Epoch:7[42496/60000 (71%)]\t Loss:0.243247 acc:0.94\n",
      "Train Epoch:7[43008/60000 (72%)]\t Loss:0.173421 acc:0.95\n",
      "Train Epoch:7[43520/60000 (73%)]\t Loss:0.188082 acc:0.95\n",
      "Train Epoch:7[44032/60000 (73%)]\t Loss:0.203493 acc:0.94\n",
      "Train Epoch:7[44544/60000 (74%)]\t Loss:0.183602 acc:0.93\n",
      "Train Epoch:7[45056/60000 (75%)]\t Loss:0.193610 acc:0.94\n",
      "Train Epoch:7[45568/60000 (76%)]\t Loss:0.215078 acc:0.93\n",
      "Train Epoch:7[46080/60000 (77%)]\t Loss:0.244582 acc:0.93\n",
      "Train Epoch:7[46592/60000 (78%)]\t Loss:0.161575 acc:0.95\n",
      "Train Epoch:7[47104/60000 (79%)]\t Loss:0.232469 acc:0.93\n",
      "Train Epoch:7[47616/60000 (79%)]\t Loss:0.175116 acc:0.95\n",
      "Train Epoch:7[48128/60000 (80%)]\t Loss:0.149592 acc:0.95\n",
      "Train Epoch:7[48640/60000 (81%)]\t Loss:0.240991 acc:0.93\n",
      "Train Epoch:7[49152/60000 (82%)]\t Loss:0.272540 acc:0.90\n",
      "Train Epoch:7[49664/60000 (83%)]\t Loss:0.177375 acc:0.95\n",
      "Train Epoch:7[50176/60000 (84%)]\t Loss:0.273621 acc:0.93\n",
      "Train Epoch:7[50688/60000 (84%)]\t Loss:0.183337 acc:0.93\n",
      "Train Epoch:7[51200/60000 (85%)]\t Loss:0.159934 acc:0.95\n",
      "Train Epoch:7[51712/60000 (86%)]\t Loss:0.241486 acc:0.92\n",
      "Train Epoch:7[52224/60000 (87%)]\t Loss:0.166163 acc:0.96\n",
      "Train Epoch:7[52736/60000 (88%)]\t Loss:0.264875 acc:0.92\n",
      "Train Epoch:7[53248/60000 (89%)]\t Loss:0.144482 acc:0.95\n",
      "Train Epoch:7[53760/60000 (90%)]\t Loss:0.197932 acc:0.94\n",
      "Train Epoch:7[54272/60000 (90%)]\t Loss:0.154888 acc:0.96\n",
      "Train Epoch:7[54784/60000 (91%)]\t Loss:0.200919 acc:0.94\n",
      "Train Epoch:7[55296/60000 (92%)]\t Loss:0.193185 acc:0.94\n",
      "Train Epoch:7[55808/60000 (93%)]\t Loss:0.149246 acc:0.95\n",
      "Train Epoch:7[56320/60000 (94%)]\t Loss:0.183780 acc:0.95\n",
      "Train Epoch:7[56832/60000 (95%)]\t Loss:0.139984 acc:0.95\n",
      "Train Epoch:7[57344/60000 (96%)]\t Loss:0.194363 acc:0.95\n",
      "Train Epoch:7[57856/60000 (96%)]\t Loss:0.112063 acc:0.96\n",
      "Train Epoch:7[58368/60000 (97%)]\t Loss:0.093185 acc:0.97\n",
      "Train Epoch:7[58880/60000 (98%)]\t Loss:0.101741 acc:0.96\n",
      "Train Epoch:7[59392/60000 (99%)]\t Loss:0.169688 acc:0.97\n",
      "Train Epoch:7[59904/60000 (100%)]\t Loss:0.251782 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:7 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:7 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:7 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:7 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:7 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:7 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:7 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:7 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:7 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:7 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:7 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:7 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:7 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:7 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:7 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:7 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:7 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:7 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:7 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:7 [9728/10000 (97%)]\t acc:0.94\n",
      "Train Epoch:8[0/60000 (0%)]\t Loss:0.190970 acc:0.94\n",
      "Train Epoch:8[512/60000 (1%)]\t Loss:0.214174 acc:0.94\n",
      "Train Epoch:8[1024/60000 (2%)]\t Loss:0.251209 acc:0.92\n",
      "Train Epoch:8[1536/60000 (3%)]\t Loss:0.127865 acc:0.96\n",
      "Train Epoch:8[2048/60000 (3%)]\t Loss:0.152060 acc:0.95\n",
      "Train Epoch:8[2560/60000 (4%)]\t Loss:0.176285 acc:0.95\n",
      "Train Epoch:8[3072/60000 (5%)]\t Loss:0.129067 acc:0.96\n",
      "Train Epoch:8[3584/60000 (6%)]\t Loss:0.148836 acc:0.95\n",
      "Train Epoch:8[4096/60000 (7%)]\t Loss:0.168192 acc:0.95\n",
      "Train Epoch:8[4608/60000 (8%)]\t Loss:0.209365 acc:0.94\n",
      "Train Epoch:8[5120/60000 (9%)]\t Loss:0.195387 acc:0.95\n",
      "Train Epoch:8[5632/60000 (9%)]\t Loss:0.171107 acc:0.94\n",
      "Train Epoch:8[6144/60000 (10%)]\t Loss:0.132090 acc:0.96\n",
      "Train Epoch:8[6656/60000 (11%)]\t Loss:0.219555 acc:0.95\n",
      "Train Epoch:8[7168/60000 (12%)]\t Loss:0.206331 acc:0.95\n",
      "Train Epoch:8[7680/60000 (13%)]\t Loss:0.218096 acc:0.94\n",
      "Train Epoch:8[8192/60000 (14%)]\t Loss:0.226943 acc:0.92\n",
      "Train Epoch:8[8704/60000 (15%)]\t Loss:0.294271 acc:0.91\n",
      "Train Epoch:8[9216/60000 (15%)]\t Loss:0.206776 acc:0.94\n",
      "Train Epoch:8[9728/60000 (16%)]\t Loss:0.196825 acc:0.95\n",
      "Train Epoch:8[10240/60000 (17%)]\t Loss:0.177481 acc:0.94\n",
      "Train Epoch:8[10752/60000 (18%)]\t Loss:0.178379 acc:0.96\n",
      "Train Epoch:8[11264/60000 (19%)]\t Loss:0.167416 acc:0.95\n",
      "Train Epoch:8[11776/60000 (20%)]\t Loss:0.132099 acc:0.96\n",
      "Train Epoch:8[12288/60000 (20%)]\t Loss:0.259072 acc:0.94\n",
      "Train Epoch:8[12800/60000 (21%)]\t Loss:0.196298 acc:0.94\n",
      "Train Epoch:8[13312/60000 (22%)]\t Loss:0.178433 acc:0.95\n",
      "Train Epoch:8[13824/60000 (23%)]\t Loss:0.232638 acc:0.92\n",
      "Train Epoch:8[14336/60000 (24%)]\t Loss:0.274537 acc:0.90\n",
      "Train Epoch:8[14848/60000 (25%)]\t Loss:0.141258 acc:0.96\n",
      "Train Epoch:8[15360/60000 (26%)]\t Loss:0.234103 acc:0.92\n",
      "Train Epoch:8[15872/60000 (26%)]\t Loss:0.167269 acc:0.95\n",
      "Train Epoch:8[16384/60000 (27%)]\t Loss:0.181111 acc:0.94\n",
      "Train Epoch:8[16896/60000 (28%)]\t Loss:0.165669 acc:0.95\n",
      "Train Epoch:8[17408/60000 (29%)]\t Loss:0.222658 acc:0.92\n",
      "Train Epoch:8[17920/60000 (30%)]\t Loss:0.167819 acc:0.96\n",
      "Train Epoch:8[18432/60000 (31%)]\t Loss:0.150586 acc:0.96\n",
      "Train Epoch:8[18944/60000 (32%)]\t Loss:0.168254 acc:0.94\n",
      "Train Epoch:8[19456/60000 (32%)]\t Loss:0.164015 acc:0.95\n",
      "Train Epoch:8[19968/60000 (33%)]\t Loss:0.186125 acc:0.94\n",
      "Train Epoch:8[20480/60000 (34%)]\t Loss:0.301903 acc:0.92\n",
      "Train Epoch:8[20992/60000 (35%)]\t Loss:0.166052 acc:0.96\n",
      "Train Epoch:8[21504/60000 (36%)]\t Loss:0.165831 acc:0.95\n",
      "Train Epoch:8[22016/60000 (37%)]\t Loss:0.181540 acc:0.94\n",
      "Train Epoch:8[22528/60000 (38%)]\t Loss:0.211554 acc:0.94\n",
      "Train Epoch:8[23040/60000 (38%)]\t Loss:0.125250 acc:0.96\n",
      "Train Epoch:8[23552/60000 (39%)]\t Loss:0.202940 acc:0.94\n",
      "Train Epoch:8[24064/60000 (40%)]\t Loss:0.171292 acc:0.94\n",
      "Train Epoch:8[24576/60000 (41%)]\t Loss:0.212702 acc:0.93\n",
      "Train Epoch:8[25088/60000 (42%)]\t Loss:0.186693 acc:0.94\n",
      "Train Epoch:8[25600/60000 (43%)]\t Loss:0.168517 acc:0.95\n",
      "Train Epoch:8[26112/60000 (44%)]\t Loss:0.226510 acc:0.94\n",
      "Train Epoch:8[26624/60000 (44%)]\t Loss:0.195441 acc:0.95\n",
      "Train Epoch:8[27136/60000 (45%)]\t Loss:0.209587 acc:0.94\n",
      "Train Epoch:8[27648/60000 (46%)]\t Loss:0.127045 acc:0.97\n",
      "Train Epoch:8[28160/60000 (47%)]\t Loss:0.209536 acc:0.94\n",
      "Train Epoch:8[28672/60000 (48%)]\t Loss:0.155610 acc:0.96\n",
      "Train Epoch:8[29184/60000 (49%)]\t Loss:0.147908 acc:0.95\n",
      "Train Epoch:8[29696/60000 (49%)]\t Loss:0.247086 acc:0.93\n",
      "Train Epoch:8[30208/60000 (50%)]\t Loss:0.166898 acc:0.96\n",
      "Train Epoch:8[30720/60000 (51%)]\t Loss:0.235550 acc:0.93\n",
      "Train Epoch:8[31232/60000 (52%)]\t Loss:0.281234 acc:0.92\n",
      "Train Epoch:8[31744/60000 (53%)]\t Loss:0.172764 acc:0.95\n",
      "Train Epoch:8[32256/60000 (54%)]\t Loss:0.226479 acc:0.93\n",
      "Train Epoch:8[32768/60000 (55%)]\t Loss:0.144940 acc:0.96\n",
      "Train Epoch:8[33280/60000 (55%)]\t Loss:0.179655 acc:0.95\n",
      "Train Epoch:8[33792/60000 (56%)]\t Loss:0.089012 acc:0.98\n",
      "Train Epoch:8[34304/60000 (57%)]\t Loss:0.201603 acc:0.95\n",
      "Train Epoch:8[34816/60000 (58%)]\t Loss:0.183208 acc:0.95\n",
      "Train Epoch:8[35328/60000 (59%)]\t Loss:0.150875 acc:0.96\n",
      "Train Epoch:8[35840/60000 (60%)]\t Loss:0.151695 acc:0.96\n",
      "Train Epoch:8[36352/60000 (61%)]\t Loss:0.162951 acc:0.95\n",
      "Train Epoch:8[36864/60000 (61%)]\t Loss:0.209321 acc:0.94\n",
      "Train Epoch:8[37376/60000 (62%)]\t Loss:0.222386 acc:0.94\n",
      "Train Epoch:8[37888/60000 (63%)]\t Loss:0.153596 acc:0.95\n",
      "Train Epoch:8[38400/60000 (64%)]\t Loss:0.131891 acc:0.97\n",
      "Train Epoch:8[38912/60000 (65%)]\t Loss:0.182320 acc:0.95\n",
      "Train Epoch:8[39424/60000 (66%)]\t Loss:0.179442 acc:0.96\n",
      "Train Epoch:8[39936/60000 (67%)]\t Loss:0.159644 acc:0.95\n",
      "Train Epoch:8[40448/60000 (67%)]\t Loss:0.132520 acc:0.96\n",
      "Train Epoch:8[40960/60000 (68%)]\t Loss:0.258171 acc:0.93\n",
      "Train Epoch:8[41472/60000 (69%)]\t Loss:0.170833 acc:0.94\n",
      "Train Epoch:8[41984/60000 (70%)]\t Loss:0.220526 acc:0.93\n",
      "Train Epoch:8[42496/60000 (71%)]\t Loss:0.222370 acc:0.94\n",
      "Train Epoch:8[43008/60000 (72%)]\t Loss:0.159772 acc:0.95\n",
      "Train Epoch:8[43520/60000 (73%)]\t Loss:0.170266 acc:0.95\n",
      "Train Epoch:8[44032/60000 (73%)]\t Loss:0.183125 acc:0.94\n",
      "Train Epoch:8[44544/60000 (74%)]\t Loss:0.162590 acc:0.94\n",
      "Train Epoch:8[45056/60000 (75%)]\t Loss:0.175633 acc:0.95\n",
      "Train Epoch:8[45568/60000 (76%)]\t Loss:0.195898 acc:0.93\n",
      "Train Epoch:8[46080/60000 (77%)]\t Loss:0.228947 acc:0.93\n",
      "Train Epoch:8[46592/60000 (78%)]\t Loss:0.151885 acc:0.95\n",
      "Train Epoch:8[47104/60000 (79%)]\t Loss:0.220189 acc:0.93\n",
      "Train Epoch:8[47616/60000 (79%)]\t Loss:0.158052 acc:0.96\n",
      "Train Epoch:8[48128/60000 (80%)]\t Loss:0.135687 acc:0.96\n",
      "Train Epoch:8[48640/60000 (81%)]\t Loss:0.224607 acc:0.93\n",
      "Train Epoch:8[49152/60000 (82%)]\t Loss:0.252691 acc:0.90\n",
      "Train Epoch:8[49664/60000 (83%)]\t Loss:0.158472 acc:0.95\n",
      "Train Epoch:8[50176/60000 (84%)]\t Loss:0.250588 acc:0.93\n",
      "Train Epoch:8[50688/60000 (84%)]\t Loss:0.162110 acc:0.95\n",
      "Train Epoch:8[51200/60000 (85%)]\t Loss:0.142718 acc:0.95\n",
      "Train Epoch:8[51712/60000 (86%)]\t Loss:0.220437 acc:0.93\n",
      "Train Epoch:8[52224/60000 (87%)]\t Loss:0.147450 acc:0.96\n",
      "Train Epoch:8[52736/60000 (88%)]\t Loss:0.245825 acc:0.93\n",
      "Train Epoch:8[53248/60000 (89%)]\t Loss:0.126611 acc:0.96\n",
      "Train Epoch:8[53760/60000 (90%)]\t Loss:0.183622 acc:0.95\n",
      "Train Epoch:8[54272/60000 (90%)]\t Loss:0.140571 acc:0.97\n",
      "Train Epoch:8[54784/60000 (91%)]\t Loss:0.182821 acc:0.95\n",
      "Train Epoch:8[55296/60000 (92%)]\t Loss:0.179999 acc:0.95\n",
      "Train Epoch:8[55808/60000 (93%)]\t Loss:0.138636 acc:0.95\n",
      "Train Epoch:8[56320/60000 (94%)]\t Loss:0.167669 acc:0.95\n",
      "Train Epoch:8[56832/60000 (95%)]\t Loss:0.125288 acc:0.96\n",
      "Train Epoch:8[57344/60000 (96%)]\t Loss:0.174969 acc:0.95\n",
      "Train Epoch:8[57856/60000 (96%)]\t Loss:0.100796 acc:0.96\n",
      "Train Epoch:8[58368/60000 (97%)]\t Loss:0.082681 acc:0.98\n",
      "Train Epoch:8[58880/60000 (98%)]\t Loss:0.086591 acc:0.97\n",
      "Train Epoch:8[59392/60000 (99%)]\t Loss:0.164253 acc:0.97\n",
      "Train Epoch:8[59904/60000 (100%)]\t Loss:0.239085 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:8 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:8 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:8 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:8 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:8 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:8 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:8 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:8 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:8 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:8 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:8 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:8 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:8 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:8 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:8 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:8 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:8 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:8 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:8 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:8 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:9[0/60000 (0%)]\t Loss:0.173317 acc:0.95\n",
      "Train Epoch:9[512/60000 (1%)]\t Loss:0.191745 acc:0.95\n",
      "Train Epoch:9[1024/60000 (2%)]\t Loss:0.232612 acc:0.92\n",
      "Train Epoch:9[1536/60000 (3%)]\t Loss:0.112859 acc:0.97\n",
      "Train Epoch:9[2048/60000 (3%)]\t Loss:0.133018 acc:0.96\n",
      "Train Epoch:9[2560/60000 (4%)]\t Loss:0.161303 acc:0.96\n",
      "Train Epoch:9[3072/60000 (5%)]\t Loss:0.114893 acc:0.96\n",
      "Train Epoch:9[3584/60000 (6%)]\t Loss:0.133537 acc:0.96\n",
      "Train Epoch:9[4096/60000 (7%)]\t Loss:0.152869 acc:0.96\n",
      "Train Epoch:9[4608/60000 (8%)]\t Loss:0.191491 acc:0.95\n",
      "Train Epoch:9[5120/60000 (9%)]\t Loss:0.178821 acc:0.96\n",
      "Train Epoch:9[5632/60000 (9%)]\t Loss:0.155389 acc:0.95\n",
      "Train Epoch:9[6144/60000 (10%)]\t Loss:0.127064 acc:0.96\n",
      "Train Epoch:9[6656/60000 (11%)]\t Loss:0.205407 acc:0.96\n",
      "Train Epoch:9[7168/60000 (12%)]\t Loss:0.184808 acc:0.95\n",
      "Train Epoch:9[7680/60000 (13%)]\t Loss:0.198996 acc:0.94\n",
      "Train Epoch:9[8192/60000 (14%)]\t Loss:0.208229 acc:0.93\n",
      "Train Epoch:9[8704/60000 (15%)]\t Loss:0.265834 acc:0.92\n",
      "Train Epoch:9[9216/60000 (15%)]\t Loss:0.192521 acc:0.94\n",
      "Train Epoch:9[9728/60000 (16%)]\t Loss:0.184823 acc:0.95\n",
      "Train Epoch:9[10240/60000 (17%)]\t Loss:0.167101 acc:0.95\n",
      "Train Epoch:9[10752/60000 (18%)]\t Loss:0.166117 acc:0.96\n",
      "Train Epoch:9[11264/60000 (19%)]\t Loss:0.149254 acc:0.96\n",
      "Train Epoch:9[11776/60000 (20%)]\t Loss:0.116721 acc:0.96\n",
      "Train Epoch:9[12288/60000 (20%)]\t Loss:0.240988 acc:0.94\n",
      "Train Epoch:9[12800/60000 (21%)]\t Loss:0.176204 acc:0.95\n",
      "Train Epoch:9[13312/60000 (22%)]\t Loss:0.164627 acc:0.96\n",
      "Train Epoch:9[13824/60000 (23%)]\t Loss:0.213947 acc:0.93\n",
      "Train Epoch:9[14336/60000 (24%)]\t Loss:0.250840 acc:0.90\n",
      "Train Epoch:9[14848/60000 (25%)]\t Loss:0.125804 acc:0.96\n",
      "Train Epoch:9[15360/60000 (26%)]\t Loss:0.217354 acc:0.93\n",
      "Train Epoch:9[15872/60000 (26%)]\t Loss:0.153855 acc:0.95\n",
      "Train Epoch:9[16384/60000 (27%)]\t Loss:0.165948 acc:0.95\n",
      "Train Epoch:9[16896/60000 (28%)]\t Loss:0.149775 acc:0.95\n",
      "Train Epoch:9[17408/60000 (29%)]\t Loss:0.203435 acc:0.93\n",
      "Train Epoch:9[17920/60000 (30%)]\t Loss:0.153887 acc:0.96\n",
      "Train Epoch:9[18432/60000 (31%)]\t Loss:0.131747 acc:0.97\n",
      "Train Epoch:9[18944/60000 (32%)]\t Loss:0.154224 acc:0.95\n",
      "Train Epoch:9[19456/60000 (32%)]\t Loss:0.148807 acc:0.95\n",
      "Train Epoch:9[19968/60000 (33%)]\t Loss:0.170771 acc:0.95\n",
      "Train Epoch:9[20480/60000 (34%)]\t Loss:0.284110 acc:0.93\n",
      "Train Epoch:9[20992/60000 (35%)]\t Loss:0.152990 acc:0.96\n",
      "Train Epoch:9[21504/60000 (36%)]\t Loss:0.157009 acc:0.95\n",
      "Train Epoch:9[22016/60000 (37%)]\t Loss:0.173917 acc:0.94\n",
      "Train Epoch:9[22528/60000 (38%)]\t Loss:0.206576 acc:0.94\n",
      "Train Epoch:9[23040/60000 (38%)]\t Loss:0.110978 acc:0.96\n",
      "Train Epoch:9[23552/60000 (39%)]\t Loss:0.186845 acc:0.95\n",
      "Train Epoch:9[24064/60000 (40%)]\t Loss:0.149275 acc:0.95\n",
      "Train Epoch:9[24576/60000 (41%)]\t Loss:0.192385 acc:0.93\n",
      "Train Epoch:9[25088/60000 (42%)]\t Loss:0.173899 acc:0.94\n",
      "Train Epoch:9[25600/60000 (43%)]\t Loss:0.158908 acc:0.96\n",
      "Train Epoch:9[26112/60000 (44%)]\t Loss:0.210809 acc:0.94\n",
      "Train Epoch:9[26624/60000 (44%)]\t Loss:0.178048 acc:0.96\n",
      "Train Epoch:9[27136/60000 (45%)]\t Loss:0.192595 acc:0.94\n",
      "Train Epoch:9[27648/60000 (46%)]\t Loss:0.116917 acc:0.97\n",
      "Train Epoch:9[28160/60000 (47%)]\t Loss:0.195038 acc:0.94\n",
      "Train Epoch:9[28672/60000 (48%)]\t Loss:0.139626 acc:0.96\n",
      "Train Epoch:9[29184/60000 (49%)]\t Loss:0.136268 acc:0.96\n",
      "Train Epoch:9[29696/60000 (49%)]\t Loss:0.226179 acc:0.93\n",
      "Train Epoch:9[30208/60000 (50%)]\t Loss:0.145080 acc:0.96\n",
      "Train Epoch:9[30720/60000 (51%)]\t Loss:0.212374 acc:0.93\n",
      "Train Epoch:9[31232/60000 (52%)]\t Loss:0.260174 acc:0.93\n",
      "Train Epoch:9[31744/60000 (53%)]\t Loss:0.154354 acc:0.95\n",
      "Train Epoch:9[32256/60000 (54%)]\t Loss:0.209063 acc:0.95\n",
      "Train Epoch:9[32768/60000 (55%)]\t Loss:0.130283 acc:0.96\n",
      "Train Epoch:9[33280/60000 (55%)]\t Loss:0.165330 acc:0.95\n",
      "Train Epoch:9[33792/60000 (56%)]\t Loss:0.079202 acc:0.98\n",
      "Train Epoch:9[34304/60000 (57%)]\t Loss:0.189237 acc:0.95\n",
      "Train Epoch:9[34816/60000 (58%)]\t Loss:0.165798 acc:0.95\n",
      "Train Epoch:9[35328/60000 (59%)]\t Loss:0.137772 acc:0.97\n",
      "Train Epoch:9[35840/60000 (60%)]\t Loss:0.139711 acc:0.96\n",
      "Train Epoch:9[36352/60000 (61%)]\t Loss:0.151181 acc:0.95\n",
      "Train Epoch:9[36864/60000 (61%)]\t Loss:0.196201 acc:0.94\n",
      "Train Epoch:9[37376/60000 (62%)]\t Loss:0.208778 acc:0.94\n",
      "Train Epoch:9[37888/60000 (63%)]\t Loss:0.138211 acc:0.96\n",
      "Train Epoch:9[38400/60000 (64%)]\t Loss:0.123117 acc:0.97\n",
      "Train Epoch:9[38912/60000 (65%)]\t Loss:0.174189 acc:0.95\n",
      "Train Epoch:9[39424/60000 (66%)]\t Loss:0.164797 acc:0.96\n",
      "Train Epoch:9[39936/60000 (67%)]\t Loss:0.145234 acc:0.96\n",
      "Train Epoch:9[40448/60000 (67%)]\t Loss:0.121420 acc:0.96\n",
      "Train Epoch:9[40960/60000 (68%)]\t Loss:0.240288 acc:0.94\n",
      "Train Epoch:9[41472/60000 (69%)]\t Loss:0.154387 acc:0.95\n",
      "Train Epoch:9[41984/60000 (70%)]\t Loss:0.200603 acc:0.93\n",
      "Train Epoch:9[42496/60000 (71%)]\t Loss:0.207425 acc:0.94\n",
      "Train Epoch:9[43008/60000 (72%)]\t Loss:0.148597 acc:0.95\n",
      "Train Epoch:9[43520/60000 (73%)]\t Loss:0.157623 acc:0.95\n",
      "Train Epoch:9[44032/60000 (73%)]\t Loss:0.168277 acc:0.94\n",
      "Train Epoch:9[44544/60000 (74%)]\t Loss:0.148250 acc:0.94\n",
      "Train Epoch:9[45056/60000 (75%)]\t Loss:0.164983 acc:0.95\n",
      "Train Epoch:9[45568/60000 (76%)]\t Loss:0.183121 acc:0.94\n",
      "Train Epoch:9[46080/60000 (77%)]\t Loss:0.217760 acc:0.94\n",
      "Train Epoch:9[46592/60000 (78%)]\t Loss:0.146542 acc:0.97\n",
      "Train Epoch:9[47104/60000 (79%)]\t Loss:0.209042 acc:0.93\n",
      "Train Epoch:9[47616/60000 (79%)]\t Loss:0.145735 acc:0.96\n",
      "Train Epoch:9[48128/60000 (80%)]\t Loss:0.127187 acc:0.96\n",
      "Train Epoch:9[48640/60000 (81%)]\t Loss:0.208160 acc:0.94\n",
      "Train Epoch:9[49152/60000 (82%)]\t Loss:0.239633 acc:0.91\n",
      "Train Epoch:9[49664/60000 (83%)]\t Loss:0.145854 acc:0.96\n",
      "Train Epoch:9[50176/60000 (84%)]\t Loss:0.233014 acc:0.93\n",
      "Train Epoch:9[50688/60000 (84%)]\t Loss:0.145635 acc:0.96\n",
      "Train Epoch:9[51200/60000 (85%)]\t Loss:0.130318 acc:0.96\n",
      "Train Epoch:9[51712/60000 (86%)]\t Loss:0.203885 acc:0.94\n",
      "Train Epoch:9[52224/60000 (87%)]\t Loss:0.132594 acc:0.96\n",
      "Train Epoch:9[52736/60000 (88%)]\t Loss:0.234956 acc:0.93\n",
      "Train Epoch:9[53248/60000 (89%)]\t Loss:0.112847 acc:0.96\n",
      "Train Epoch:9[53760/60000 (90%)]\t Loss:0.173600 acc:0.95\n",
      "Train Epoch:9[54272/60000 (90%)]\t Loss:0.132044 acc:0.96\n",
      "Train Epoch:9[54784/60000 (91%)]\t Loss:0.169492 acc:0.95\n",
      "Train Epoch:9[55296/60000 (92%)]\t Loss:0.168043 acc:0.96\n",
      "Train Epoch:9[55808/60000 (93%)]\t Loss:0.129995 acc:0.95\n",
      "Train Epoch:9[56320/60000 (94%)]\t Loss:0.152289 acc:0.96\n",
      "Train Epoch:9[56832/60000 (95%)]\t Loss:0.112397 acc:0.96\n",
      "Train Epoch:9[57344/60000 (96%)]\t Loss:0.156012 acc:0.96\n",
      "Train Epoch:9[57856/60000 (96%)]\t Loss:0.089981 acc:0.96\n",
      "Train Epoch:9[58368/60000 (97%)]\t Loss:0.074260 acc:0.98\n",
      "Train Epoch:9[58880/60000 (98%)]\t Loss:0.076922 acc:0.97\n",
      "Train Epoch:9[59392/60000 (99%)]\t Loss:0.160696 acc:0.97\n",
      "Train Epoch:9[59904/60000 (100%)]\t Loss:0.232599 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:9 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:9 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:9 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:9 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:9 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:9 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:9 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:9 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:9 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:9 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:9 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:9 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:9 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:9 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:9 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:9 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:9 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:9 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:9 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:9 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:10[0/60000 (0%)]\t Loss:0.160156 acc:0.96\n",
      "Train Epoch:10[512/60000 (1%)]\t Loss:0.174649 acc:0.95\n",
      "Train Epoch:10[1024/60000 (2%)]\t Loss:0.216157 acc:0.93\n",
      "Train Epoch:10[1536/60000 (3%)]\t Loss:0.101089 acc:0.97\n",
      "Train Epoch:10[2048/60000 (3%)]\t Loss:0.117528 acc:0.96\n",
      "Train Epoch:10[2560/60000 (4%)]\t Loss:0.148079 acc:0.96\n",
      "Train Epoch:10[3072/60000 (5%)]\t Loss:0.105439 acc:0.97\n",
      "Train Epoch:10[3584/60000 (6%)]\t Loss:0.123337 acc:0.96\n",
      "Train Epoch:10[4096/60000 (7%)]\t Loss:0.142543 acc:0.96\n",
      "Train Epoch:10[4608/60000 (8%)]\t Loss:0.179110 acc:0.95\n",
      "Train Epoch:10[5120/60000 (9%)]\t Loss:0.165929 acc:0.96\n",
      "Train Epoch:10[5632/60000 (9%)]\t Loss:0.142278 acc:0.95\n",
      "Train Epoch:10[6144/60000 (10%)]\t Loss:0.122569 acc:0.96\n",
      "Train Epoch:10[6656/60000 (11%)]\t Loss:0.194779 acc:0.95\n",
      "Train Epoch:10[7168/60000 (12%)]\t Loss:0.168563 acc:0.95\n",
      "Train Epoch:10[7680/60000 (13%)]\t Loss:0.182412 acc:0.95\n",
      "Train Epoch:10[8192/60000 (14%)]\t Loss:0.192325 acc:0.94\n",
      "Train Epoch:10[8704/60000 (15%)]\t Loss:0.244697 acc:0.93\n",
      "Train Epoch:10[9216/60000 (15%)]\t Loss:0.181343 acc:0.95\n",
      "Train Epoch:10[9728/60000 (16%)]\t Loss:0.176887 acc:0.95\n",
      "Train Epoch:10[10240/60000 (17%)]\t Loss:0.159854 acc:0.95\n",
      "Train Epoch:10[10752/60000 (18%)]\t Loss:0.159556 acc:0.96\n",
      "Train Epoch:10[11264/60000 (19%)]\t Loss:0.135613 acc:0.96\n",
      "Train Epoch:10[11776/60000 (20%)]\t Loss:0.106336 acc:0.98\n",
      "Train Epoch:10[12288/60000 (20%)]\t Loss:0.223174 acc:0.94\n",
      "Train Epoch:10[12800/60000 (21%)]\t Loss:0.159782 acc:0.95\n",
      "Train Epoch:10[13312/60000 (22%)]\t Loss:0.152554 acc:0.96\n",
      "Train Epoch:10[13824/60000 (23%)]\t Loss:0.199041 acc:0.93\n",
      "Train Epoch:10[14336/60000 (24%)]\t Loss:0.232461 acc:0.90\n",
      "Train Epoch:10[14848/60000 (25%)]\t Loss:0.115937 acc:0.96\n",
      "Train Epoch:10[15360/60000 (26%)]\t Loss:0.202182 acc:0.94\n",
      "Train Epoch:10[15872/60000 (26%)]\t Loss:0.144081 acc:0.95\n",
      "Train Epoch:10[16384/60000 (27%)]\t Loss:0.154777 acc:0.95\n",
      "Train Epoch:10[16896/60000 (28%)]\t Loss:0.136744 acc:0.96\n",
      "Train Epoch:10[17408/60000 (29%)]\t Loss:0.187316 acc:0.94\n",
      "Train Epoch:10[17920/60000 (30%)]\t Loss:0.141927 acc:0.96\n",
      "Train Epoch:10[18432/60000 (31%)]\t Loss:0.118092 acc:0.97\n",
      "Train Epoch:10[18944/60000 (32%)]\t Loss:0.144827 acc:0.95\n",
      "Train Epoch:10[19456/60000 (32%)]\t Loss:0.137368 acc:0.95\n",
      "Train Epoch:10[19968/60000 (33%)]\t Loss:0.157880 acc:0.96\n",
      "Train Epoch:10[20480/60000 (34%)]\t Loss:0.269632 acc:0.93\n",
      "Train Epoch:10[20992/60000 (35%)]\t Loss:0.141639 acc:0.96\n",
      "Train Epoch:10[21504/60000 (36%)]\t Loss:0.147896 acc:0.96\n",
      "Train Epoch:10[22016/60000 (37%)]\t Loss:0.167600 acc:0.94\n",
      "Train Epoch:10[22528/60000 (38%)]\t Loss:0.201928 acc:0.94\n",
      "Train Epoch:10[23040/60000 (38%)]\t Loss:0.100801 acc:0.96\n",
      "Train Epoch:10[23552/60000 (39%)]\t Loss:0.173478 acc:0.95\n",
      "Train Epoch:10[24064/60000 (40%)]\t Loss:0.132154 acc:0.95\n",
      "Train Epoch:10[24576/60000 (41%)]\t Loss:0.176380 acc:0.94\n",
      "Train Epoch:10[25088/60000 (42%)]\t Loss:0.161427 acc:0.94\n",
      "Train Epoch:10[25600/60000 (43%)]\t Loss:0.150534 acc:0.95\n",
      "Train Epoch:10[26112/60000 (44%)]\t Loss:0.198809 acc:0.95\n",
      "Train Epoch:10[26624/60000 (44%)]\t Loss:0.163752 acc:0.96\n",
      "Train Epoch:10[27136/60000 (45%)]\t Loss:0.177768 acc:0.95\n",
      "Train Epoch:10[27648/60000 (46%)]\t Loss:0.107718 acc:0.97\n",
      "Train Epoch:10[28160/60000 (47%)]\t Loss:0.180936 acc:0.95\n",
      "Train Epoch:10[28672/60000 (48%)]\t Loss:0.126283 acc:0.97\n",
      "Train Epoch:10[29184/60000 (49%)]\t Loss:0.127041 acc:0.96\n",
      "Train Epoch:10[29696/60000 (49%)]\t Loss:0.206271 acc:0.93\n",
      "Train Epoch:10[30208/60000 (50%)]\t Loss:0.131182 acc:0.96\n",
      "Train Epoch:10[30720/60000 (51%)]\t Loss:0.195066 acc:0.93\n",
      "Train Epoch:10[31232/60000 (52%)]\t Loss:0.240263 acc:0.93\n",
      "Train Epoch:10[31744/60000 (53%)]\t Loss:0.140241 acc:0.96\n",
      "Train Epoch:10[32256/60000 (54%)]\t Loss:0.192006 acc:0.95\n",
      "Train Epoch:10[32768/60000 (55%)]\t Loss:0.116762 acc:0.97\n",
      "Train Epoch:10[33280/60000 (55%)]\t Loss:0.153518 acc:0.95\n",
      "Train Epoch:10[33792/60000 (56%)]\t Loss:0.070216 acc:0.99\n",
      "Train Epoch:10[34304/60000 (57%)]\t Loss:0.180355 acc:0.95\n",
      "Train Epoch:10[34816/60000 (58%)]\t Loss:0.149999 acc:0.95\n",
      "Train Epoch:10[35328/60000 (59%)]\t Loss:0.128053 acc:0.97\n",
      "Train Epoch:10[35840/60000 (60%)]\t Loss:0.130165 acc:0.96\n",
      "Train Epoch:10[36352/60000 (61%)]\t Loss:0.140504 acc:0.95\n",
      "Train Epoch:10[36864/60000 (61%)]\t Loss:0.183622 acc:0.94\n",
      "Train Epoch:10[37376/60000 (62%)]\t Loss:0.194404 acc:0.94\n",
      "Train Epoch:10[37888/60000 (63%)]\t Loss:0.124956 acc:0.96\n",
      "Train Epoch:10[38400/60000 (64%)]\t Loss:0.117052 acc:0.97\n",
      "Train Epoch:10[38912/60000 (65%)]\t Loss:0.166964 acc:0.95\n",
      "Train Epoch:10[39424/60000 (66%)]\t Loss:0.153255 acc:0.96\n",
      "Train Epoch:10[39936/60000 (67%)]\t Loss:0.134494 acc:0.96\n",
      "Train Epoch:10[40448/60000 (67%)]\t Loss:0.112686 acc:0.97\n",
      "Train Epoch:10[40960/60000 (68%)]\t Loss:0.223738 acc:0.94\n",
      "Train Epoch:10[41472/60000 (69%)]\t Loss:0.139467 acc:0.95\n",
      "Train Epoch:10[41984/60000 (70%)]\t Loss:0.181518 acc:0.94\n",
      "Train Epoch:10[42496/60000 (71%)]\t Loss:0.195056 acc:0.95\n",
      "Train Epoch:10[43008/60000 (72%)]\t Loss:0.136565 acc:0.96\n",
      "Train Epoch:10[43520/60000 (73%)]\t Loss:0.147399 acc:0.95\n",
      "Train Epoch:10[44032/60000 (73%)]\t Loss:0.156666 acc:0.95\n",
      "Train Epoch:10[44544/60000 (74%)]\t Loss:0.137222 acc:0.94\n",
      "Train Epoch:10[45056/60000 (75%)]\t Loss:0.156322 acc:0.95\n",
      "Train Epoch:10[45568/60000 (76%)]\t Loss:0.174922 acc:0.94\n",
      "Train Epoch:10[46080/60000 (77%)]\t Loss:0.207289 acc:0.94\n",
      "Train Epoch:10[46592/60000 (78%)]\t Loss:0.144763 acc:0.97\n",
      "Train Epoch:10[47104/60000 (79%)]\t Loss:0.197025 acc:0.93\n",
      "Train Epoch:10[47616/60000 (79%)]\t Loss:0.136672 acc:0.96\n",
      "Train Epoch:10[48128/60000 (80%)]\t Loss:0.117723 acc:0.96\n",
      "Train Epoch:10[48640/60000 (81%)]\t Loss:0.193239 acc:0.95\n",
      "Train Epoch:10[49152/60000 (82%)]\t Loss:0.224812 acc:0.91\n",
      "Train Epoch:10[49664/60000 (83%)]\t Loss:0.136552 acc:0.96\n",
      "Train Epoch:10[50176/60000 (84%)]\t Loss:0.216669 acc:0.93\n",
      "Train Epoch:10[50688/60000 (84%)]\t Loss:0.131452 acc:0.96\n",
      "Train Epoch:10[51200/60000 (85%)]\t Loss:0.120197 acc:0.96\n",
      "Train Epoch:10[51712/60000 (86%)]\t Loss:0.188950 acc:0.94\n",
      "Train Epoch:10[52224/60000 (87%)]\t Loss:0.119392 acc:0.97\n",
      "Train Epoch:10[52736/60000 (88%)]\t Loss:0.225366 acc:0.93\n",
      "Train Epoch:10[53248/60000 (89%)]\t Loss:0.100454 acc:0.97\n",
      "Train Epoch:10[53760/60000 (90%)]\t Loss:0.166734 acc:0.95\n",
      "Train Epoch:10[54272/60000 (90%)]\t Loss:0.126625 acc:0.97\n",
      "Train Epoch:10[54784/60000 (91%)]\t Loss:0.159447 acc:0.95\n",
      "Train Epoch:10[55296/60000 (92%)]\t Loss:0.157349 acc:0.96\n",
      "Train Epoch:10[55808/60000 (93%)]\t Loss:0.121303 acc:0.96\n",
      "Train Epoch:10[56320/60000 (94%)]\t Loss:0.137826 acc:0.97\n",
      "Train Epoch:10[56832/60000 (95%)]\t Loss:0.101149 acc:0.97\n",
      "Train Epoch:10[57344/60000 (96%)]\t Loss:0.140146 acc:0.96\n",
      "Train Epoch:10[57856/60000 (96%)]\t Loss:0.079914 acc:0.97\n",
      "Train Epoch:10[58368/60000 (97%)]\t Loss:0.068451 acc:0.98\n",
      "Train Epoch:10[58880/60000 (98%)]\t Loss:0.072077 acc:0.98\n",
      "Train Epoch:10[59392/60000 (99%)]\t Loss:0.155468 acc:0.97\n",
      "Train Epoch:10[59904/60000 (100%)]\t Loss:0.233521 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:10 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:10 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:10 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:10 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:10 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:10 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:10 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:10 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:10 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:10 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:10 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:10 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:10 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:10 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:10 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:10 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:10 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:10 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:10 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:10 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:11[0/60000 (0%)]\t Loss:0.150862 acc:0.96\n",
      "Train Epoch:11[512/60000 (1%)]\t Loss:0.161802 acc:0.96\n",
      "Train Epoch:11[1024/60000 (2%)]\t Loss:0.205962 acc:0.94\n",
      "Train Epoch:11[1536/60000 (3%)]\t Loss:0.093646 acc:0.97\n",
      "Train Epoch:11[2048/60000 (3%)]\t Loss:0.106766 acc:0.97\n",
      "Train Epoch:11[2560/60000 (4%)]\t Loss:0.136342 acc:0.96\n",
      "Train Epoch:11[3072/60000 (5%)]\t Loss:0.096747 acc:0.97\n",
      "Train Epoch:11[3584/60000 (6%)]\t Loss:0.115120 acc:0.96\n",
      "Train Epoch:11[4096/60000 (7%)]\t Loss:0.135252 acc:0.96\n",
      "Train Epoch:11[4608/60000 (8%)]\t Loss:0.167787 acc:0.95\n",
      "Train Epoch:11[5120/60000 (9%)]\t Loss:0.156272 acc:0.96\n",
      "Train Epoch:11[5632/60000 (9%)]\t Loss:0.132544 acc:0.95\n",
      "Train Epoch:11[6144/60000 (10%)]\t Loss:0.119895 acc:0.97\n",
      "Train Epoch:11[6656/60000 (11%)]\t Loss:0.184526 acc:0.96\n",
      "Train Epoch:11[7168/60000 (12%)]\t Loss:0.157426 acc:0.95\n",
      "Train Epoch:11[7680/60000 (13%)]\t Loss:0.166628 acc:0.95\n",
      "Train Epoch:11[8192/60000 (14%)]\t Loss:0.177401 acc:0.94\n",
      "Train Epoch:11[8704/60000 (15%)]\t Loss:0.228522 acc:0.93\n",
      "Train Epoch:11[9216/60000 (15%)]\t Loss:0.170583 acc:0.95\n",
      "Train Epoch:11[9728/60000 (16%)]\t Loss:0.168377 acc:0.95\n",
      "Train Epoch:11[10240/60000 (17%)]\t Loss:0.153187 acc:0.96\n",
      "Train Epoch:11[10752/60000 (18%)]\t Loss:0.152043 acc:0.97\n",
      "Train Epoch:11[11264/60000 (19%)]\t Loss:0.125108 acc:0.96\n",
      "Train Epoch:11[11776/60000 (20%)]\t Loss:0.100184 acc:0.98\n",
      "Train Epoch:11[12288/60000 (20%)]\t Loss:0.210789 acc:0.94\n",
      "Train Epoch:11[12800/60000 (21%)]\t Loss:0.145887 acc:0.96\n",
      "Train Epoch:11[13312/60000 (22%)]\t Loss:0.138443 acc:0.96\n",
      "Train Epoch:11[13824/60000 (23%)]\t Loss:0.181704 acc:0.94\n",
      "Train Epoch:11[14336/60000 (24%)]\t Loss:0.210651 acc:0.91\n",
      "Train Epoch:11[14848/60000 (25%)]\t Loss:0.108786 acc:0.96\n",
      "Train Epoch:11[15360/60000 (26%)]\t Loss:0.189782 acc:0.94\n",
      "Train Epoch:11[15872/60000 (26%)]\t Loss:0.135717 acc:0.95\n",
      "Train Epoch:11[16384/60000 (27%)]\t Loss:0.147376 acc:0.95\n",
      "Train Epoch:11[16896/60000 (28%)]\t Loss:0.124775 acc:0.97\n",
      "Train Epoch:11[17408/60000 (29%)]\t Loss:0.168121 acc:0.95\n",
      "Train Epoch:11[17920/60000 (30%)]\t Loss:0.132260 acc:0.96\n",
      "Train Epoch:11[18432/60000 (31%)]\t Loss:0.106119 acc:0.97\n",
      "Train Epoch:11[18944/60000 (32%)]\t Loss:0.137158 acc:0.95\n",
      "Train Epoch:11[19456/60000 (32%)]\t Loss:0.128719 acc:0.95\n",
      "Train Epoch:11[19968/60000 (33%)]\t Loss:0.147181 acc:0.96\n",
      "Train Epoch:11[20480/60000 (34%)]\t Loss:0.256798 acc:0.93\n",
      "Train Epoch:11[20992/60000 (35%)]\t Loss:0.130937 acc:0.96\n",
      "Train Epoch:11[21504/60000 (36%)]\t Loss:0.134982 acc:0.96\n",
      "Train Epoch:11[22016/60000 (37%)]\t Loss:0.159592 acc:0.94\n",
      "Train Epoch:11[22528/60000 (38%)]\t Loss:0.195786 acc:0.94\n",
      "Train Epoch:11[23040/60000 (38%)]\t Loss:0.093863 acc:0.97\n",
      "Train Epoch:11[23552/60000 (39%)]\t Loss:0.162277 acc:0.95\n",
      "Train Epoch:11[24064/60000 (40%)]\t Loss:0.116985 acc:0.95\n",
      "Train Epoch:11[24576/60000 (41%)]\t Loss:0.158979 acc:0.96\n",
      "Train Epoch:11[25088/60000 (42%)]\t Loss:0.146718 acc:0.95\n",
      "Train Epoch:11[25600/60000 (43%)]\t Loss:0.142402 acc:0.96\n",
      "Train Epoch:11[26112/60000 (44%)]\t Loss:0.188899 acc:0.95\n",
      "Train Epoch:11[26624/60000 (44%)]\t Loss:0.153563 acc:0.96\n",
      "Train Epoch:11[27136/60000 (45%)]\t Loss:0.167643 acc:0.95\n",
      "Train Epoch:11[27648/60000 (46%)]\t Loss:0.102115 acc:0.98\n",
      "Train Epoch:11[28160/60000 (47%)]\t Loss:0.170387 acc:0.95\n",
      "Train Epoch:11[28672/60000 (48%)]\t Loss:0.115668 acc:0.97\n",
      "Train Epoch:11[29184/60000 (49%)]\t Loss:0.116608 acc:0.96\n",
      "Train Epoch:11[29696/60000 (49%)]\t Loss:0.185664 acc:0.94\n",
      "Train Epoch:11[30208/60000 (50%)]\t Loss:0.120916 acc:0.97\n",
      "Train Epoch:11[30720/60000 (51%)]\t Loss:0.180052 acc:0.93\n",
      "Train Epoch:11[31232/60000 (52%)]\t Loss:0.223901 acc:0.94\n",
      "Train Epoch:11[31744/60000 (53%)]\t Loss:0.132105 acc:0.96\n",
      "Train Epoch:11[32256/60000 (54%)]\t Loss:0.178903 acc:0.95\n",
      "Train Epoch:11[32768/60000 (55%)]\t Loss:0.106813 acc:0.97\n",
      "Train Epoch:11[33280/60000 (55%)]\t Loss:0.142348 acc:0.96\n",
      "Train Epoch:11[33792/60000 (56%)]\t Loss:0.062354 acc:0.99\n",
      "Train Epoch:11[34304/60000 (57%)]\t Loss:0.171724 acc:0.96\n",
      "Train Epoch:11[34816/60000 (58%)]\t Loss:0.136973 acc:0.96\n",
      "Train Epoch:11[35328/60000 (59%)]\t Loss:0.121141 acc:0.97\n",
      "Train Epoch:11[35840/60000 (60%)]\t Loss:0.123620 acc:0.96\n",
      "Train Epoch:11[36352/60000 (61%)]\t Loss:0.129954 acc:0.95\n",
      "Train Epoch:11[36864/60000 (61%)]\t Loss:0.172757 acc:0.95\n",
      "Train Epoch:11[37376/60000 (62%)]\t Loss:0.178758 acc:0.94\n",
      "Train Epoch:11[37888/60000 (63%)]\t Loss:0.113833 acc:0.97\n",
      "Train Epoch:11[38400/60000 (64%)]\t Loss:0.111272 acc:0.97\n",
      "Train Epoch:11[38912/60000 (65%)]\t Loss:0.160689 acc:0.96\n",
      "Train Epoch:11[39424/60000 (66%)]\t Loss:0.142779 acc:0.96\n",
      "Train Epoch:11[39936/60000 (67%)]\t Loss:0.124610 acc:0.96\n",
      "Train Epoch:11[40448/60000 (67%)]\t Loss:0.104218 acc:0.97\n",
      "Train Epoch:11[40960/60000 (68%)]\t Loss:0.207274 acc:0.94\n",
      "Train Epoch:11[41472/60000 (69%)]\t Loss:0.128465 acc:0.95\n",
      "Train Epoch:11[41984/60000 (70%)]\t Loss:0.165181 acc:0.96\n",
      "Train Epoch:11[42496/60000 (71%)]\t Loss:0.184196 acc:0.95\n",
      "Train Epoch:11[43008/60000 (72%)]\t Loss:0.128041 acc:0.97\n",
      "Train Epoch:11[43520/60000 (73%)]\t Loss:0.138707 acc:0.96\n",
      "Train Epoch:11[44032/60000 (73%)]\t Loss:0.145214 acc:0.95\n",
      "Train Epoch:11[44544/60000 (74%)]\t Loss:0.125669 acc:0.95\n",
      "Train Epoch:11[45056/60000 (75%)]\t Loss:0.145341 acc:0.95\n",
      "Train Epoch:11[45568/60000 (76%)]\t Loss:0.165904 acc:0.94\n",
      "Train Epoch:11[46080/60000 (77%)]\t Loss:0.196223 acc:0.94\n",
      "Train Epoch:11[46592/60000 (78%)]\t Loss:0.142904 acc:0.96\n",
      "Train Epoch:11[47104/60000 (79%)]\t Loss:0.185388 acc:0.94\n",
      "Train Epoch:11[47616/60000 (79%)]\t Loss:0.130123 acc:0.96\n",
      "Train Epoch:11[48128/60000 (80%)]\t Loss:0.109040 acc:0.96\n",
      "Train Epoch:11[48640/60000 (81%)]\t Loss:0.180011 acc:0.95\n",
      "Train Epoch:11[49152/60000 (82%)]\t Loss:0.208391 acc:0.92\n",
      "Train Epoch:11[49664/60000 (83%)]\t Loss:0.129241 acc:0.96\n",
      "Train Epoch:11[50176/60000 (84%)]\t Loss:0.201950 acc:0.94\n",
      "Train Epoch:11[50688/60000 (84%)]\t Loss:0.118553 acc:0.97\n",
      "Train Epoch:11[51200/60000 (85%)]\t Loss:0.110642 acc:0.96\n",
      "Train Epoch:11[51712/60000 (86%)]\t Loss:0.174965 acc:0.95\n",
      "Train Epoch:11[52224/60000 (87%)]\t Loss:0.106800 acc:0.97\n",
      "Train Epoch:11[52736/60000 (88%)]\t Loss:0.209396 acc:0.94\n",
      "Train Epoch:11[53248/60000 (89%)]\t Loss:0.091053 acc:0.97\n",
      "Train Epoch:11[53760/60000 (90%)]\t Loss:0.160140 acc:0.96\n",
      "Train Epoch:11[54272/60000 (90%)]\t Loss:0.122825 acc:0.97\n",
      "Train Epoch:11[54784/60000 (91%)]\t Loss:0.152409 acc:0.95\n",
      "Train Epoch:11[55296/60000 (92%)]\t Loss:0.146513 acc:0.97\n",
      "Train Epoch:11[55808/60000 (93%)]\t Loss:0.113235 acc:0.96\n",
      "Train Epoch:11[56320/60000 (94%)]\t Loss:0.123059 acc:0.97\n",
      "Train Epoch:11[56832/60000 (95%)]\t Loss:0.091828 acc:0.97\n",
      "Train Epoch:11[57344/60000 (96%)]\t Loss:0.128273 acc:0.96\n",
      "Train Epoch:11[57856/60000 (96%)]\t Loss:0.070746 acc:0.98\n",
      "Train Epoch:11[58368/60000 (97%)]\t Loss:0.062807 acc:0.98\n",
      "Train Epoch:11[58880/60000 (98%)]\t Loss:0.067946 acc:0.98\n",
      "Train Epoch:11[59392/60000 (99%)]\t Loss:0.150925 acc:0.97\n",
      "Train Epoch:11[59904/60000 (100%)]\t Loss:0.236677 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:11 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:11 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:11 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:11 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:11 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:11 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:11 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:11 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:11 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:11 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:11 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:11 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:11 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:11 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:11 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:11 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:11 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:11 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:11 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:11 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:12[0/60000 (0%)]\t Loss:0.143126 acc:0.96\n",
      "Train Epoch:12[512/60000 (1%)]\t Loss:0.149707 acc:0.96\n",
      "Train Epoch:12[1024/60000 (2%)]\t Loss:0.196590 acc:0.94\n",
      "Train Epoch:12[1536/60000 (3%)]\t Loss:0.087358 acc:0.98\n",
      "Train Epoch:12[2048/60000 (3%)]\t Loss:0.099370 acc:0.97\n",
      "Train Epoch:12[2560/60000 (4%)]\t Loss:0.125421 acc:0.97\n",
      "Train Epoch:12[3072/60000 (5%)]\t Loss:0.089764 acc:0.97\n",
      "Train Epoch:12[3584/60000 (6%)]\t Loss:0.107608 acc:0.96\n",
      "Train Epoch:12[4096/60000 (7%)]\t Loss:0.128755 acc:0.96\n",
      "Train Epoch:12[4608/60000 (8%)]\t Loss:0.154904 acc:0.96\n",
      "Train Epoch:12[5120/60000 (9%)]\t Loss:0.147243 acc:0.96\n",
      "Train Epoch:12[5632/60000 (9%)]\t Loss:0.127458 acc:0.96\n",
      "Train Epoch:12[6144/60000 (10%)]\t Loss:0.117962 acc:0.97\n",
      "Train Epoch:12[6656/60000 (11%)]\t Loss:0.176567 acc:0.95\n",
      "Train Epoch:12[7168/60000 (12%)]\t Loss:0.151166 acc:0.95\n",
      "Train Epoch:12[7680/60000 (13%)]\t Loss:0.154335 acc:0.95\n",
      "Train Epoch:12[8192/60000 (14%)]\t Loss:0.162644 acc:0.95\n",
      "Train Epoch:12[8704/60000 (15%)]\t Loss:0.214474 acc:0.94\n",
      "Train Epoch:12[9216/60000 (15%)]\t Loss:0.158593 acc:0.96\n",
      "Train Epoch:12[9728/60000 (16%)]\t Loss:0.154371 acc:0.95\n",
      "Train Epoch:12[10240/60000 (17%)]\t Loss:0.143778 acc:0.96\n",
      "Train Epoch:12[10752/60000 (18%)]\t Loss:0.141355 acc:0.97\n",
      "Train Epoch:12[11264/60000 (19%)]\t Loss:0.114240 acc:0.96\n",
      "Train Epoch:12[11776/60000 (20%)]\t Loss:0.090670 acc:0.98\n",
      "Train Epoch:12[12288/60000 (20%)]\t Loss:0.198267 acc:0.94\n",
      "Train Epoch:12[12800/60000 (21%)]\t Loss:0.135265 acc:0.96\n",
      "Train Epoch:12[13312/60000 (22%)]\t Loss:0.125627 acc:0.97\n",
      "Train Epoch:12[13824/60000 (23%)]\t Loss:0.166986 acc:0.95\n",
      "Train Epoch:12[14336/60000 (24%)]\t Loss:0.190208 acc:0.93\n",
      "Train Epoch:12[14848/60000 (25%)]\t Loss:0.098813 acc:0.97\n",
      "Train Epoch:12[15360/60000 (26%)]\t Loss:0.174079 acc:0.94\n",
      "Train Epoch:12[15872/60000 (26%)]\t Loss:0.126166 acc:0.96\n",
      "Train Epoch:12[16384/60000 (27%)]\t Loss:0.137040 acc:0.95\n",
      "Train Epoch:12[16896/60000 (28%)]\t Loss:0.118622 acc:0.97\n",
      "Train Epoch:12[17408/60000 (29%)]\t Loss:0.150928 acc:0.95\n",
      "Train Epoch:12[17920/60000 (30%)]\t Loss:0.124549 acc:0.96\n",
      "Train Epoch:12[18432/60000 (31%)]\t Loss:0.094551 acc:0.97\n",
      "Train Epoch:12[18944/60000 (32%)]\t Loss:0.128768 acc:0.96\n",
      "Train Epoch:12[19456/60000 (32%)]\t Loss:0.120127 acc:0.96\n",
      "Train Epoch:12[19968/60000 (33%)]\t Loss:0.137451 acc:0.96\n",
      "Train Epoch:12[20480/60000 (34%)]\t Loss:0.242341 acc:0.94\n",
      "Train Epoch:12[20992/60000 (35%)]\t Loss:0.120844 acc:0.96\n",
      "Train Epoch:12[21504/60000 (36%)]\t Loss:0.121468 acc:0.96\n",
      "Train Epoch:12[22016/60000 (37%)]\t Loss:0.147058 acc:0.95\n",
      "Train Epoch:12[22528/60000 (38%)]\t Loss:0.181598 acc:0.94\n",
      "Train Epoch:12[23040/60000 (38%)]\t Loss:0.088268 acc:0.98\n",
      "Train Epoch:12[23552/60000 (39%)]\t Loss:0.151429 acc:0.96\n",
      "Train Epoch:12[24064/60000 (40%)]\t Loss:0.106768 acc:0.96\n",
      "Train Epoch:12[24576/60000 (41%)]\t Loss:0.145152 acc:0.96\n",
      "Train Epoch:12[25088/60000 (42%)]\t Loss:0.134045 acc:0.95\n",
      "Train Epoch:12[25600/60000 (43%)]\t Loss:0.132826 acc:0.96\n",
      "Train Epoch:12[26112/60000 (44%)]\t Loss:0.178671 acc:0.96\n",
      "Train Epoch:12[26624/60000 (44%)]\t Loss:0.142710 acc:0.96\n",
      "Train Epoch:12[27136/60000 (45%)]\t Loss:0.156665 acc:0.96\n",
      "Train Epoch:12[27648/60000 (46%)]\t Loss:0.096697 acc:0.98\n",
      "Train Epoch:12[28160/60000 (47%)]\t Loss:0.160903 acc:0.95\n",
      "Train Epoch:12[28672/60000 (48%)]\t Loss:0.108259 acc:0.97\n",
      "Train Epoch:12[29184/60000 (49%)]\t Loss:0.105613 acc:0.97\n",
      "Train Epoch:12[29696/60000 (49%)]\t Loss:0.168282 acc:0.94\n",
      "Train Epoch:12[30208/60000 (50%)]\t Loss:0.111308 acc:0.97\n",
      "Train Epoch:12[30720/60000 (51%)]\t Loss:0.164383 acc:0.94\n",
      "Train Epoch:12[31232/60000 (52%)]\t Loss:0.209444 acc:0.94\n",
      "Train Epoch:12[31744/60000 (53%)]\t Loss:0.125625 acc:0.96\n",
      "Train Epoch:12[32256/60000 (54%)]\t Loss:0.170157 acc:0.95\n",
      "Train Epoch:12[32768/60000 (55%)]\t Loss:0.100765 acc:0.97\n",
      "Train Epoch:12[33280/60000 (55%)]\t Loss:0.130742 acc:0.96\n",
      "Train Epoch:12[33792/60000 (56%)]\t Loss:0.053854 acc:0.99\n",
      "Train Epoch:12[34304/60000 (57%)]\t Loss:0.159495 acc:0.96\n",
      "Train Epoch:12[34816/60000 (58%)]\t Loss:0.125152 acc:0.96\n",
      "Train Epoch:12[35328/60000 (59%)]\t Loss:0.113254 acc:0.98\n",
      "Train Epoch:12[35840/60000 (60%)]\t Loss:0.117736 acc:0.96\n",
      "Train Epoch:12[36352/60000 (61%)]\t Loss:0.118956 acc:0.95\n",
      "Train Epoch:12[36864/60000 (61%)]\t Loss:0.164686 acc:0.95\n",
      "Train Epoch:12[37376/60000 (62%)]\t Loss:0.165751 acc:0.94\n",
      "Train Epoch:12[37888/60000 (63%)]\t Loss:0.101616 acc:0.97\n",
      "Train Epoch:12[38400/60000 (64%)]\t Loss:0.106282 acc:0.97\n",
      "Train Epoch:12[38912/60000 (65%)]\t Loss:0.151922 acc:0.96\n",
      "Train Epoch:12[39424/60000 (66%)]\t Loss:0.131295 acc:0.96\n",
      "Train Epoch:12[39936/60000 (67%)]\t Loss:0.115481 acc:0.97\n",
      "Train Epoch:12[40448/60000 (67%)]\t Loss:0.097236 acc:0.97\n",
      "Train Epoch:12[40960/60000 (68%)]\t Loss:0.190402 acc:0.94\n",
      "Train Epoch:12[41472/60000 (69%)]\t Loss:0.120100 acc:0.95\n",
      "Train Epoch:12[41984/60000 (70%)]\t Loss:0.150241 acc:0.96\n",
      "Train Epoch:12[42496/60000 (71%)]\t Loss:0.172808 acc:0.95\n",
      "Train Epoch:12[43008/60000 (72%)]\t Loss:0.120167 acc:0.97\n",
      "Train Epoch:12[43520/60000 (73%)]\t Loss:0.130145 acc:0.96\n",
      "Train Epoch:12[44032/60000 (73%)]\t Loss:0.136955 acc:0.96\n",
      "Train Epoch:12[44544/60000 (74%)]\t Loss:0.113930 acc:0.95\n",
      "Train Epoch:12[45056/60000 (75%)]\t Loss:0.132832 acc:0.96\n",
      "Train Epoch:12[45568/60000 (76%)]\t Loss:0.155923 acc:0.94\n",
      "Train Epoch:12[46080/60000 (77%)]\t Loss:0.184187 acc:0.94\n",
      "Train Epoch:12[46592/60000 (78%)]\t Loss:0.136574 acc:0.96\n",
      "Train Epoch:12[47104/60000 (79%)]\t Loss:0.176060 acc:0.94\n",
      "Train Epoch:12[47616/60000 (79%)]\t Loss:0.125515 acc:0.96\n",
      "Train Epoch:12[48128/60000 (80%)]\t Loss:0.099841 acc:0.97\n",
      "Train Epoch:12[48640/60000 (81%)]\t Loss:0.169056 acc:0.95\n",
      "Train Epoch:12[49152/60000 (82%)]\t Loss:0.191557 acc:0.92\n",
      "Train Epoch:12[49664/60000 (83%)]\t Loss:0.121464 acc:0.96\n",
      "Train Epoch:12[50176/60000 (84%)]\t Loss:0.185075 acc:0.94\n",
      "Train Epoch:12[50688/60000 (84%)]\t Loss:0.110994 acc:0.96\n",
      "Train Epoch:12[51200/60000 (85%)]\t Loss:0.102976 acc:0.96\n",
      "Train Epoch:12[51712/60000 (86%)]\t Loss:0.162415 acc:0.95\n",
      "Train Epoch:12[52224/60000 (87%)]\t Loss:0.095348 acc:0.98\n",
      "Train Epoch:12[52736/60000 (88%)]\t Loss:0.193021 acc:0.94\n",
      "Train Epoch:12[53248/60000 (89%)]\t Loss:0.085328 acc:0.97\n",
      "Train Epoch:12[53760/60000 (90%)]\t Loss:0.149457 acc:0.96\n",
      "Train Epoch:12[54272/60000 (90%)]\t Loss:0.117943 acc:0.97\n",
      "Train Epoch:12[54784/60000 (91%)]\t Loss:0.145745 acc:0.95\n",
      "Train Epoch:12[55296/60000 (92%)]\t Loss:0.138153 acc:0.96\n",
      "Train Epoch:12[55808/60000 (93%)]\t Loss:0.105758 acc:0.97\n",
      "Train Epoch:12[56320/60000 (94%)]\t Loss:0.111457 acc:0.97\n",
      "Train Epoch:12[56832/60000 (95%)]\t Loss:0.084697 acc:0.98\n",
      "Train Epoch:12[57344/60000 (96%)]\t Loss:0.117730 acc:0.97\n",
      "Train Epoch:12[57856/60000 (96%)]\t Loss:0.064821 acc:0.98\n",
      "Train Epoch:12[58368/60000 (97%)]\t Loss:0.058100 acc:0.98\n",
      "Train Epoch:12[58880/60000 (98%)]\t Loss:0.062216 acc:0.98\n",
      "Train Epoch:12[59392/60000 (99%)]\t Loss:0.147357 acc:0.97\n",
      "Train Epoch:12[59904/60000 (100%)]\t Loss:0.239077 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:12 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:12 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:12 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:12 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:12 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:12 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:12 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:12 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:12 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:12 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:12 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:12 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:12 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:12 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:12 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:12 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:12 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:12 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:12 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:12 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:13[0/60000 (0%)]\t Loss:0.136307 acc:0.96\n",
      "Train Epoch:13[512/60000 (1%)]\t Loss:0.138580 acc:0.96\n",
      "Train Epoch:13[1024/60000 (2%)]\t Loss:0.185844 acc:0.94\n",
      "Train Epoch:13[1536/60000 (3%)]\t Loss:0.080826 acc:0.98\n",
      "Train Epoch:13[2048/60000 (3%)]\t Loss:0.092472 acc:0.97\n",
      "Train Epoch:13[2560/60000 (4%)]\t Loss:0.118675 acc:0.97\n",
      "Train Epoch:13[3072/60000 (5%)]\t Loss:0.082981 acc:0.97\n",
      "Train Epoch:13[3584/60000 (6%)]\t Loss:0.101451 acc:0.97\n",
      "Train Epoch:13[4096/60000 (7%)]\t Loss:0.122477 acc:0.97\n",
      "Train Epoch:13[4608/60000 (8%)]\t Loss:0.145546 acc:0.95\n",
      "Train Epoch:13[5120/60000 (9%)]\t Loss:0.138187 acc:0.97\n",
      "Train Epoch:13[5632/60000 (9%)]\t Loss:0.120661 acc:0.96\n",
      "Train Epoch:13[6144/60000 (10%)]\t Loss:0.112728 acc:0.97\n",
      "Train Epoch:13[6656/60000 (11%)]\t Loss:0.167687 acc:0.96\n",
      "Train Epoch:13[7168/60000 (12%)]\t Loss:0.145597 acc:0.96\n",
      "Train Epoch:13[7680/60000 (13%)]\t Loss:0.145946 acc:0.95\n",
      "Train Epoch:13[8192/60000 (14%)]\t Loss:0.152762 acc:0.95\n",
      "Train Epoch:13[8704/60000 (15%)]\t Loss:0.202444 acc:0.94\n",
      "Train Epoch:13[9216/60000 (15%)]\t Loss:0.148119 acc:0.96\n",
      "Train Epoch:13[9728/60000 (16%)]\t Loss:0.142838 acc:0.95\n",
      "Train Epoch:13[10240/60000 (17%)]\t Loss:0.135919 acc:0.96\n",
      "Train Epoch:13[10752/60000 (18%)]\t Loss:0.129653 acc:0.97\n",
      "Train Epoch:13[11264/60000 (19%)]\t Loss:0.105913 acc:0.97\n",
      "Train Epoch:13[11776/60000 (20%)]\t Loss:0.082109 acc:0.98\n",
      "Train Epoch:13[12288/60000 (20%)]\t Loss:0.188358 acc:0.95\n",
      "Train Epoch:13[12800/60000 (21%)]\t Loss:0.126219 acc:0.96\n",
      "Train Epoch:13[13312/60000 (22%)]\t Loss:0.115392 acc:0.97\n",
      "Train Epoch:13[13824/60000 (23%)]\t Loss:0.155218 acc:0.96\n",
      "Train Epoch:13[14336/60000 (24%)]\t Loss:0.173061 acc:0.94\n",
      "Train Epoch:13[14848/60000 (25%)]\t Loss:0.090606 acc:0.97\n",
      "Train Epoch:13[15360/60000 (26%)]\t Loss:0.161943 acc:0.95\n",
      "Train Epoch:13[15872/60000 (26%)]\t Loss:0.117886 acc:0.96\n",
      "Train Epoch:13[16384/60000 (27%)]\t Loss:0.127163 acc:0.96\n",
      "Train Epoch:13[16896/60000 (28%)]\t Loss:0.114281 acc:0.97\n",
      "Train Epoch:13[17408/60000 (29%)]\t Loss:0.139406 acc:0.95\n",
      "Train Epoch:13[17920/60000 (30%)]\t Loss:0.117981 acc:0.96\n",
      "Train Epoch:13[18432/60000 (31%)]\t Loss:0.084441 acc:0.97\n",
      "Train Epoch:13[18944/60000 (32%)]\t Loss:0.119601 acc:0.96\n",
      "Train Epoch:13[19456/60000 (32%)]\t Loss:0.111501 acc:0.96\n",
      "Train Epoch:13[19968/60000 (33%)]\t Loss:0.129018 acc:0.96\n",
      "Train Epoch:13[20480/60000 (34%)]\t Loss:0.228553 acc:0.94\n",
      "Train Epoch:13[20992/60000 (35%)]\t Loss:0.113708 acc:0.96\n",
      "Train Epoch:13[21504/60000 (36%)]\t Loss:0.113251 acc:0.97\n",
      "Train Epoch:13[22016/60000 (37%)]\t Loss:0.140050 acc:0.95\n",
      "Train Epoch:13[22528/60000 (38%)]\t Loss:0.170914 acc:0.95\n",
      "Train Epoch:13[23040/60000 (38%)]\t Loss:0.081956 acc:0.98\n",
      "Train Epoch:13[23552/60000 (39%)]\t Loss:0.142069 acc:0.96\n",
      "Train Epoch:13[24064/60000 (40%)]\t Loss:0.100699 acc:0.96\n",
      "Train Epoch:13[24576/60000 (41%)]\t Loss:0.134560 acc:0.96\n",
      "Train Epoch:13[25088/60000 (42%)]\t Loss:0.123825 acc:0.96\n",
      "Train Epoch:13[25600/60000 (43%)]\t Loss:0.126049 acc:0.96\n",
      "Train Epoch:13[26112/60000 (44%)]\t Loss:0.170671 acc:0.96\n",
      "Train Epoch:13[26624/60000 (44%)]\t Loss:0.133969 acc:0.96\n",
      "Train Epoch:13[27136/60000 (45%)]\t Loss:0.146015 acc:0.96\n",
      "Train Epoch:13[27648/60000 (46%)]\t Loss:0.092081 acc:0.98\n",
      "Train Epoch:13[28160/60000 (47%)]\t Loss:0.150482 acc:0.95\n",
      "Train Epoch:13[28672/60000 (48%)]\t Loss:0.101524 acc:0.97\n",
      "Train Epoch:13[29184/60000 (49%)]\t Loss:0.098537 acc:0.97\n",
      "Train Epoch:13[29696/60000 (49%)]\t Loss:0.153386 acc:0.95\n",
      "Train Epoch:13[30208/60000 (50%)]\t Loss:0.103329 acc:0.97\n",
      "Train Epoch:13[30720/60000 (51%)]\t Loss:0.150555 acc:0.95\n",
      "Train Epoch:13[31232/60000 (52%)]\t Loss:0.198123 acc:0.95\n",
      "Train Epoch:13[31744/60000 (53%)]\t Loss:0.119054 acc:0.96\n",
      "Train Epoch:13[32256/60000 (54%)]\t Loss:0.158882 acc:0.96\n",
      "Train Epoch:13[32768/60000 (55%)]\t Loss:0.096344 acc:0.97\n",
      "Train Epoch:13[33280/60000 (55%)]\t Loss:0.121733 acc:0.96\n",
      "Train Epoch:13[33792/60000 (56%)]\t Loss:0.049077 acc:0.99\n",
      "Train Epoch:13[34304/60000 (57%)]\t Loss:0.151836 acc:0.97\n",
      "Train Epoch:13[34816/60000 (58%)]\t Loss:0.115931 acc:0.97\n",
      "Train Epoch:13[35328/60000 (59%)]\t Loss:0.105833 acc:0.98\n",
      "Train Epoch:13[35840/60000 (60%)]\t Loss:0.110367 acc:0.96\n",
      "Train Epoch:13[36352/60000 (61%)]\t Loss:0.110489 acc:0.96\n",
      "Train Epoch:13[36864/60000 (61%)]\t Loss:0.157026 acc:0.96\n",
      "Train Epoch:13[37376/60000 (62%)]\t Loss:0.155731 acc:0.95\n",
      "Train Epoch:13[37888/60000 (63%)]\t Loss:0.092575 acc:0.97\n",
      "Train Epoch:13[38400/60000 (64%)]\t Loss:0.101772 acc:0.97\n",
      "Train Epoch:13[38912/60000 (65%)]\t Loss:0.143950 acc:0.96\n",
      "Train Epoch:13[39424/60000 (66%)]\t Loss:0.123231 acc:0.96\n",
      "Train Epoch:13[39936/60000 (67%)]\t Loss:0.108305 acc:0.97\n",
      "Train Epoch:13[40448/60000 (67%)]\t Loss:0.091443 acc:0.97\n",
      "Train Epoch:13[40960/60000 (68%)]\t Loss:0.178550 acc:0.94\n",
      "Train Epoch:13[41472/60000 (69%)]\t Loss:0.113239 acc:0.96\n",
      "Train Epoch:13[41984/60000 (70%)]\t Loss:0.140021 acc:0.96\n",
      "Train Epoch:13[42496/60000 (71%)]\t Loss:0.162598 acc:0.95\n",
      "Train Epoch:13[43008/60000 (72%)]\t Loss:0.112330 acc:0.97\n",
      "Train Epoch:13[43520/60000 (73%)]\t Loss:0.123400 acc:0.96\n",
      "Train Epoch:13[44032/60000 (73%)]\t Loss:0.131040 acc:0.96\n",
      "Train Epoch:13[44544/60000 (74%)]\t Loss:0.106080 acc:0.96\n",
      "Train Epoch:13[45056/60000 (75%)]\t Loss:0.124007 acc:0.96\n",
      "Train Epoch:13[45568/60000 (76%)]\t Loss:0.148187 acc:0.95\n",
      "Train Epoch:13[46080/60000 (77%)]\t Loss:0.173428 acc:0.95\n",
      "Train Epoch:13[46592/60000 (78%)]\t Loss:0.128595 acc:0.97\n",
      "Train Epoch:13[47104/60000 (79%)]\t Loss:0.167569 acc:0.95\n",
      "Train Epoch:13[47616/60000 (79%)]\t Loss:0.120970 acc:0.96\n",
      "Train Epoch:13[48128/60000 (80%)]\t Loss:0.093247 acc:0.98\n",
      "Train Epoch:13[48640/60000 (81%)]\t Loss:0.161048 acc:0.95\n",
      "Train Epoch:13[49152/60000 (82%)]\t Loss:0.177969 acc:0.93\n",
      "Train Epoch:13[49664/60000 (83%)]\t Loss:0.114081 acc:0.96\n",
      "Train Epoch:13[50176/60000 (84%)]\t Loss:0.170568 acc:0.95\n",
      "Train Epoch:13[50688/60000 (84%)]\t Loss:0.105686 acc:0.97\n",
      "Train Epoch:13[51200/60000 (85%)]\t Loss:0.097401 acc:0.96\n",
      "Train Epoch:13[51712/60000 (86%)]\t Loss:0.151480 acc:0.96\n",
      "Train Epoch:13[52224/60000 (87%)]\t Loss:0.087388 acc:0.98\n",
      "Train Epoch:13[52736/60000 (88%)]\t Loss:0.179827 acc:0.95\n",
      "Train Epoch:13[53248/60000 (89%)]\t Loss:0.081014 acc:0.97\n",
      "Train Epoch:13[53760/60000 (90%)]\t Loss:0.140757 acc:0.96\n",
      "Train Epoch:13[54272/60000 (90%)]\t Loss:0.113577 acc:0.97\n",
      "Train Epoch:13[54784/60000 (91%)]\t Loss:0.139459 acc:0.96\n",
      "Train Epoch:13[55296/60000 (92%)]\t Loss:0.130532 acc:0.97\n",
      "Train Epoch:13[55808/60000 (93%)]\t Loss:0.101285 acc:0.97\n",
      "Train Epoch:13[56320/60000 (94%)]\t Loss:0.103289 acc:0.97\n",
      "Train Epoch:13[56832/60000 (95%)]\t Loss:0.080155 acc:0.98\n",
      "Train Epoch:13[57344/60000 (96%)]\t Loss:0.108986 acc:0.97\n",
      "Train Epoch:13[57856/60000 (96%)]\t Loss:0.060870 acc:0.98\n",
      "Train Epoch:13[58368/60000 (97%)]\t Loss:0.054753 acc:0.98\n",
      "Train Epoch:13[58880/60000 (98%)]\t Loss:0.057085 acc:0.98\n",
      "Train Epoch:13[59392/60000 (99%)]\t Loss:0.144816 acc:0.97\n",
      "Train Epoch:13[59904/60000 (100%)]\t Loss:0.236645 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:13 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:13 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:13 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:13 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:13 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:13 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:13 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:13 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:13 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:13 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:13 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:13 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:13 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:13 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:13 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:13 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:13 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:13 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:13 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:13 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:14[0/60000 (0%)]\t Loss:0.131164 acc:0.96\n",
      "Train Epoch:14[512/60000 (1%)]\t Loss:0.129827 acc:0.97\n",
      "Train Epoch:14[1024/60000 (2%)]\t Loss:0.175331 acc:0.94\n",
      "Train Epoch:14[1536/60000 (3%)]\t Loss:0.075700 acc:0.98\n",
      "Train Epoch:14[2048/60000 (3%)]\t Loss:0.086164 acc:0.97\n",
      "Train Epoch:14[2560/60000 (4%)]\t Loss:0.112618 acc:0.97\n",
      "Train Epoch:14[3072/60000 (5%)]\t Loss:0.076857 acc:0.98\n",
      "Train Epoch:14[3584/60000 (6%)]\t Loss:0.096451 acc:0.97\n",
      "Train Epoch:14[4096/60000 (7%)]\t Loss:0.117037 acc:0.97\n",
      "Train Epoch:14[4608/60000 (8%)]\t Loss:0.137478 acc:0.95\n",
      "Train Epoch:14[5120/60000 (9%)]\t Loss:0.131083 acc:0.96\n",
      "Train Epoch:14[5632/60000 (9%)]\t Loss:0.115449 acc:0.96\n",
      "Train Epoch:14[6144/60000 (10%)]\t Loss:0.109636 acc:0.97\n",
      "Train Epoch:14[6656/60000 (11%)]\t Loss:0.161325 acc:0.96\n",
      "Train Epoch:14[7168/60000 (12%)]\t Loss:0.139751 acc:0.96\n",
      "Train Epoch:14[7680/60000 (13%)]\t Loss:0.138873 acc:0.96\n",
      "Train Epoch:14[8192/60000 (14%)]\t Loss:0.145140 acc:0.95\n",
      "Train Epoch:14[8704/60000 (15%)]\t Loss:0.194283 acc:0.94\n",
      "Train Epoch:14[9216/60000 (15%)]\t Loss:0.139831 acc:0.96\n",
      "Train Epoch:14[9728/60000 (16%)]\t Loss:0.131332 acc:0.95\n",
      "Train Epoch:14[10240/60000 (17%)]\t Loss:0.126928 acc:0.96\n",
      "Train Epoch:14[10752/60000 (18%)]\t Loss:0.120518 acc:0.97\n",
      "Train Epoch:14[11264/60000 (19%)]\t Loss:0.099014 acc:0.97\n",
      "Train Epoch:14[11776/60000 (20%)]\t Loss:0.077242 acc:0.98\n",
      "Train Epoch:14[12288/60000 (20%)]\t Loss:0.177221 acc:0.95\n",
      "Train Epoch:14[12800/60000 (21%)]\t Loss:0.118704 acc:0.96\n",
      "Train Epoch:14[13312/60000 (22%)]\t Loss:0.106184 acc:0.97\n",
      "Train Epoch:14[13824/60000 (23%)]\t Loss:0.146010 acc:0.96\n",
      "Train Epoch:14[14336/60000 (24%)]\t Loss:0.160093 acc:0.95\n",
      "Train Epoch:14[14848/60000 (25%)]\t Loss:0.084900 acc:0.97\n",
      "Train Epoch:14[15360/60000 (26%)]\t Loss:0.151781 acc:0.96\n",
      "Train Epoch:14[15872/60000 (26%)]\t Loss:0.111378 acc:0.96\n",
      "Train Epoch:14[16384/60000 (27%)]\t Loss:0.119220 acc:0.96\n",
      "Train Epoch:14[16896/60000 (28%)]\t Loss:0.109228 acc:0.97\n",
      "Train Epoch:14[17408/60000 (29%)]\t Loss:0.129439 acc:0.96\n",
      "Train Epoch:14[17920/60000 (30%)]\t Loss:0.112352 acc:0.96\n",
      "Train Epoch:14[18432/60000 (31%)]\t Loss:0.077204 acc:0.98\n",
      "Train Epoch:14[18944/60000 (32%)]\t Loss:0.112967 acc:0.97\n",
      "Train Epoch:14[19456/60000 (32%)]\t Loss:0.105488 acc:0.96\n",
      "Train Epoch:14[19968/60000 (33%)]\t Loss:0.121814 acc:0.96\n",
      "Train Epoch:14[20480/60000 (34%)]\t Loss:0.217745 acc:0.95\n",
      "Train Epoch:14[20992/60000 (35%)]\t Loss:0.106257 acc:0.96\n",
      "Train Epoch:14[21504/60000 (36%)]\t Loss:0.106062 acc:0.97\n",
      "Train Epoch:14[22016/60000 (37%)]\t Loss:0.132204 acc:0.96\n",
      "Train Epoch:14[22528/60000 (38%)]\t Loss:0.160659 acc:0.95\n",
      "Train Epoch:14[23040/60000 (38%)]\t Loss:0.077279 acc:0.98\n",
      "Train Epoch:14[23552/60000 (39%)]\t Loss:0.133752 acc:0.96\n",
      "Train Epoch:14[24064/60000 (40%)]\t Loss:0.094962 acc:0.96\n",
      "Train Epoch:14[24576/60000 (41%)]\t Loss:0.126481 acc:0.97\n",
      "Train Epoch:14[25088/60000 (42%)]\t Loss:0.115848 acc:0.97\n",
      "Train Epoch:14[25600/60000 (43%)]\t Loss:0.120931 acc:0.96\n",
      "Train Epoch:14[26112/60000 (44%)]\t Loss:0.164306 acc:0.96\n",
      "Train Epoch:14[26624/60000 (44%)]\t Loss:0.127126 acc:0.96\n",
      "Train Epoch:14[27136/60000 (45%)]\t Loss:0.138594 acc:0.96\n",
      "Train Epoch:14[27648/60000 (46%)]\t Loss:0.087945 acc:0.97\n",
      "Train Epoch:14[28160/60000 (47%)]\t Loss:0.141840 acc:0.95\n",
      "Train Epoch:14[28672/60000 (48%)]\t Loss:0.095678 acc:0.97\n",
      "Train Epoch:14[29184/60000 (49%)]\t Loss:0.091805 acc:0.97\n",
      "Train Epoch:14[29696/60000 (49%)]\t Loss:0.142636 acc:0.95\n",
      "Train Epoch:14[30208/60000 (50%)]\t Loss:0.097275 acc:0.97\n",
      "Train Epoch:14[30720/60000 (51%)]\t Loss:0.141104 acc:0.95\n",
      "Train Epoch:14[31232/60000 (52%)]\t Loss:0.187466 acc:0.96\n",
      "Train Epoch:14[31744/60000 (53%)]\t Loss:0.113002 acc:0.96\n",
      "Train Epoch:14[32256/60000 (54%)]\t Loss:0.147374 acc:0.96\n",
      "Train Epoch:14[32768/60000 (55%)]\t Loss:0.091641 acc:0.97\n",
      "Train Epoch:14[33280/60000 (55%)]\t Loss:0.113726 acc:0.96\n",
      "Train Epoch:14[33792/60000 (56%)]\t Loss:0.045479 acc:0.99\n",
      "Train Epoch:14[34304/60000 (57%)]\t Loss:0.144087 acc:0.97\n",
      "Train Epoch:14[34816/60000 (58%)]\t Loss:0.109542 acc:0.97\n",
      "Train Epoch:14[35328/60000 (59%)]\t Loss:0.099091 acc:0.98\n",
      "Train Epoch:14[35840/60000 (60%)]\t Loss:0.103869 acc:0.96\n",
      "Train Epoch:14[36352/60000 (61%)]\t Loss:0.102622 acc:0.96\n",
      "Train Epoch:14[36864/60000 (61%)]\t Loss:0.150114 acc:0.96\n",
      "Train Epoch:14[37376/60000 (62%)]\t Loss:0.147648 acc:0.95\n",
      "Train Epoch:14[37888/60000 (63%)]\t Loss:0.086237 acc:0.97\n",
      "Train Epoch:14[38400/60000 (64%)]\t Loss:0.097791 acc:0.98\n",
      "Train Epoch:14[38912/60000 (65%)]\t Loss:0.137469 acc:0.96\n",
      "Train Epoch:14[39424/60000 (66%)]\t Loss:0.117339 acc:0.96\n",
      "Train Epoch:14[39936/60000 (67%)]\t Loss:0.102312 acc:0.97\n",
      "Train Epoch:14[40448/60000 (67%)]\t Loss:0.086239 acc:0.97\n",
      "Train Epoch:14[40960/60000 (68%)]\t Loss:0.169032 acc:0.95\n",
      "Train Epoch:14[41472/60000 (69%)]\t Loss:0.109509 acc:0.96\n",
      "Train Epoch:14[41984/60000 (70%)]\t Loss:0.130734 acc:0.96\n",
      "Train Epoch:14[42496/60000 (71%)]\t Loss:0.154352 acc:0.95\n",
      "Train Epoch:14[43008/60000 (72%)]\t Loss:0.104399 acc:0.97\n",
      "Train Epoch:14[43520/60000 (73%)]\t Loss:0.116528 acc:0.96\n",
      "Train Epoch:14[44032/60000 (73%)]\t Loss:0.124849 acc:0.96\n",
      "Train Epoch:14[44544/60000 (74%)]\t Loss:0.099811 acc:0.97\n",
      "Train Epoch:14[45056/60000 (75%)]\t Loss:0.116608 acc:0.96\n",
      "Train Epoch:14[45568/60000 (76%)]\t Loss:0.142532 acc:0.95\n",
      "Train Epoch:14[46080/60000 (77%)]\t Loss:0.164258 acc:0.95\n",
      "Train Epoch:14[46592/60000 (78%)]\t Loss:0.121648 acc:0.97\n",
      "Train Epoch:14[47104/60000 (79%)]\t Loss:0.161873 acc:0.95\n",
      "Train Epoch:14[47616/60000 (79%)]\t Loss:0.117053 acc:0.96\n",
      "Train Epoch:14[48128/60000 (80%)]\t Loss:0.086583 acc:0.98\n",
      "Train Epoch:14[48640/60000 (81%)]\t Loss:0.154254 acc:0.95\n",
      "Train Epoch:14[49152/60000 (82%)]\t Loss:0.165585 acc:0.94\n",
      "Train Epoch:14[49664/60000 (83%)]\t Loss:0.107685 acc:0.96\n",
      "Train Epoch:14[50176/60000 (84%)]\t Loss:0.157112 acc:0.96\n",
      "Train Epoch:14[50688/60000 (84%)]\t Loss:0.102433 acc:0.97\n",
      "Train Epoch:14[51200/60000 (85%)]\t Loss:0.092882 acc:0.97\n",
      "Train Epoch:14[51712/60000 (86%)]\t Loss:0.142842 acc:0.96\n",
      "Train Epoch:14[52224/60000 (87%)]\t Loss:0.080046 acc:0.98\n",
      "Train Epoch:14[52736/60000 (88%)]\t Loss:0.168120 acc:0.95\n",
      "Train Epoch:14[53248/60000 (89%)]\t Loss:0.076923 acc:0.98\n",
      "Train Epoch:14[53760/60000 (90%)]\t Loss:0.133467 acc:0.96\n",
      "Train Epoch:14[54272/60000 (90%)]\t Loss:0.109847 acc:0.97\n",
      "Train Epoch:14[54784/60000 (91%)]\t Loss:0.133323 acc:0.96\n",
      "Train Epoch:14[55296/60000 (92%)]\t Loss:0.124682 acc:0.97\n",
      "Train Epoch:14[55808/60000 (93%)]\t Loss:0.097841 acc:0.97\n",
      "Train Epoch:14[56320/60000 (94%)]\t Loss:0.097710 acc:0.97\n",
      "Train Epoch:14[56832/60000 (95%)]\t Loss:0.076419 acc:0.98\n",
      "Train Epoch:14[57344/60000 (96%)]\t Loss:0.101909 acc:0.97\n",
      "Train Epoch:14[57856/60000 (96%)]\t Loss:0.057752 acc:0.98\n",
      "Train Epoch:14[58368/60000 (97%)]\t Loss:0.051968 acc:0.98\n",
      "Train Epoch:14[58880/60000 (98%)]\t Loss:0.051511 acc:0.98\n",
      "Train Epoch:14[59392/60000 (99%)]\t Loss:0.142355 acc:0.98\n",
      "Train Epoch:14[59904/60000 (100%)]\t Loss:0.232942 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:14 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:14 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:14 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:14 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:14 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:14 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:14 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:14 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:14 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:14 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:14 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:14 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:14 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:14 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:14 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:14 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:14 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:14 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:14 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:14 [9728/10000 (97%)]\t acc:0.97\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = SummaryWriter('logs')\n",
    "    # device = torch.device('cuda:0')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    net = LeNet()  # 实例化网络\n",
    "    # data_input = Variable(torch.randn(16,1,28,28))\n",
    "    # print(net(data_input))\n",
    "    net.to(device) # 将参数送入GPU中\n",
    "\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    cost_fun = nn.CrossEntropyLoss()\n",
    "    # optim\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.95, weight_decay=1e-3)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        # train\n",
    "        train(epoch)\n",
    "        writer.add_scalar('Train/Loss', train_loss[-2].item(), epoch)\n",
    "        writer.add_scalar('Train/Acc', train_acc[-2], epoch)\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # save_state\n",
    "        # ----------------------------------------- #\n",
    "        print('===> Saving models...')\n",
    "        state = {\n",
    "            'state': net.state_dict(),\n",
    "            'epoch': epoch  # 将epoch一并保存\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('./checkpoint')\n",
    "        torch.save(state, path_model + 'Epoch-' + str(epoch) + '-Loss-'+ str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # test\n",
    "        # ----------------------------------------- #\n",
    "        test()\n",
    "    writer.close()\n",
    "\n",
    "    # ----------------------------------------- #\n",
    "    # 加载指定的weights进行预测\n",
    "    # ----------------------------------------- #\n",
    "    # predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneTensor(model_path, file_path, labely):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    img0 = cv2.imread(file_path, 0).astype(np.uint8)\n",
    "    # print(img0.shape)\n",
    "    img0 = cv2.resize(img0, (28,28))\n",
    "    img0 = img0 / 255.\n",
    "    img0 = torch.from_numpy(img0)\n",
    "\n",
    "    img = torch.as_tensor(img0, dtype=torch.float32)\n",
    "    img = img.unsqueeze(0) #在第一维度上增加一个维度，作为通道大小\n",
    "    img = Variable(torch.unsqueeze(img, dim=0).float(),).to(device) #在第一维度上增加一个维度，作为batch size大小\n",
    "    # img = img.permute(0, 3, 1, 2) # 将图像channel提到前面即 [batch size, width, height, channel]-> [batch size, channel, width, height]\n",
    "    print(img.shape)\n",
    "    print('===> Loading weights : ' + model_path)\n",
    "    weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        predy = net(img)\n",
    "        # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "        # predicted, actual = classes[torch.argmax(predy[0])], classes[labely]\n",
    "        # 最终输出的预测值与真实值\n",
    "        # print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n",
    "        np.set_printoptions(suppress = True) #非科学计数法\n",
    "        # predy[0]是网络输出，predy[1]是网络中间层输出，为一个字典\n",
    "        for x, y in predy[1].items():\n",
    "            if x == 'softmax_output':\n",
    "                print(f'predicted: \"{y.numpy()}\", actual:\"{labely}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "===> Loading weights : ./checkpoint/model_14_4.pth\n",
      "predicted: \"[[0.00000864 0.00012525 0.99907696 0.00015466 0.00000055 0.00000189\n",
      "  0.00003288 0.         0.00059909 0.        ]]\", actual:\"2\"\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "model_path = './checkpoint/model_14_4.pth' #  ***为指定加载的权重文件名称\n",
    "# file_path = './test_images/pic_3_57585.png'\n",
    "# labely = 3\n",
    "\n",
    "# file_path = './test_images/pic_2_7140.png'\n",
    "# labely = 2\n",
    "\n",
    "file_path = './test_images/pic_2_11796.png'\n",
    "labely = 2\n",
    "\n",
    "# file_path = './test_images/pic_0_15066.png'\n",
    "# labely = 0\n",
    "\n",
    "# file_path = './test_images/pic_4_54348.png'\n",
    "# labely = 4\n",
    "\n",
    "# file_path = './test_images/pic_6_23534.png'\n",
    "# labely = 6\n",
    "\n",
    "# file_path = './test_images/pic_7_39306.png'\n",
    "# labely = 7\n",
    "\n",
    "# file_path = './test_images/padpic_9_13429.png'\n",
    "# labely = 9\n",
    "# predict()\n",
    "predictOneTensor(model_path, file_path, labely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Linear-7                  [-1, 120]          48,120\n",
      "              ReLU-8                  [-1, 120]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             ReLU-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "          Softmax-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#输出每层网络参数信息\n",
    "def variaes_show():\n",
    "    net = LeNet()\n",
    "    data_input = Variable(torch.randn(16,1,28,28))\n",
    "    print(data_input.size())\n",
    "    net(data_input)\n",
    "    print(summary(net,(1,28,28)))\n",
    "\n",
    "variaes_show()\n",
    "\n",
    "# net = LeNet()\n",
    "# summary(net,(1,28,28),batch_size=16,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初版从模型中获取权重的方法\n",
    "# def load_weight(model_path):\n",
    "        \n",
    "#         print('===> Loading weights : ' + model_path)\n",
    "#         weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "\n",
    "#         print('type: ' + str(type(weight_dict)))\n",
    "#         print('len: ' + str(len(weight_dict)))\n",
    "\n",
    "#         for k in weight_dict.keys():\n",
    "#                 print('key: '+ k)\n",
    "\n",
    "#         # print(weight_dict['state'])\n",
    "#         # print(weight_dict['epoch'])\n",
    "#         print(\"================================\")\n",
    "\n",
    "#         for key,value in weight_dict['state'].items():\n",
    "#                 value_np = value.numpy()\n",
    "#                 if not os.path.isdir('csv'):\n",
    "#                         os.mkdir('./csv')\n",
    "#                 # np.savetxt(\"./csv/%s.csv\" %(key), value_np,  delimiter=\",\")\n",
    "#                 # pd.DataFrame(value_np).to_csv(\"./csv/%s.csv\" %(key))\n",
    "#                 # print(key, value.size())\n",
    "#                 print(key)\n",
    "#                 print('shape: '+ str(value_np.shape))\n",
    "#                 if (value_np.ndim == 4):\n",
    "#                         (n_dim, _, _, _) = value_np.shape\n",
    "#                         value_2d = value_np.reshape(n_dim,-1)\n",
    "#                         np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "#                         print(\"csv: \", value_2d.shape,'\\n')\n",
    "#                 elif (value_np.ndim == 3):\n",
    "#                         ndim, _, _ = value_np.shape\n",
    "#                         value_2d = value_np.reshape(n_dim,-1)\n",
    "#                         np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "#                         print(\"csv: \", value_2d.shape,'\\n')\n",
    "#                 # elif (value_np.ndim == 2):\n",
    "#                 #         ndim, _ = value_np.shape\n",
    "#                 #         value_2d = value_np.reshape(n_dim,-1)\n",
    "#                 #         print(value_2d.shape) \n",
    "#                 else :  \n",
    "#                         value_2d = value_np\n",
    "#                         np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "#                         print(\"csv: \", value_2d.shape,'\\n')             \n",
    "\n",
    "\n",
    "#         print(\"================================\")\n",
    "#         print(type(weight_dict['state']))\n",
    "        \n",
    "\n",
    "# state_path = './checkpoint/model_14.pth'\n",
    "# load_weight(state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab0de5f2c42c334a270ce520738908c8f1964f7214e5cf9b2725bca46514c63e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
