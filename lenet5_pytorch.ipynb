{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "path_model = \"./checkpoint/\"\n",
    "batch_size = 512\n",
    "epochs = 15\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "# sampler = torch.utils.data.SubsetRandomSampler(indices=list(range(2000)))\n",
    "\n",
    "# download mnist dataset\n",
    "dataset_train = torchvision.datasets.MNIST(root='./data/',train=True,download=True,transform=transform)\n",
    "dataset_test = torchvision.datasets.MNIST(root='./data/',train=False,download=True,transform=transform)\n",
    "\n",
    "class_names = dataset_train.classes  # 获取数据集的分类信息 返回一个字典\n",
    "# load dataset\n",
    "data_train = dataloader(dataset=dataset_train,batch_size=batch_size,shuffle=False)\n",
    "data_test = dataloader(dataset=dataset_test,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "print(len(data_train))\n",
    "# for batch_idx,(data,target) in enumerate(data_test):\n",
    "#     print(\"id \",batch_idx, \"data shape\",data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()  # 切换到测试模式\n",
    "    test_correct_num = 0\n",
    "    with torch.no_grad():   # 不更新参数\n",
    "\n",
    "        for batch_idx,(data,target) in enumerate(data_test):\n",
    "            # data = data.to(device)\n",
    "            # target = target.to(device)\n",
    "            output, _ = net(data) # 正向传播得到预测值\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            test_correct_num += torch.sum(pred==target).item()\n",
    "            print(\"Test Epoch:{} [{}/{} ({:.0f}%)]\\t acc:{:.2f}\".format(epoch,batch_idx*batch_size,len(data_test.dataset),\n",
    "                                                 100. * batch_size*batch_idx/len(data_test.dataset),test_correct_num/len(data_test.dataset)))\n",
    "def train(epoch):\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(data_train):\n",
    "        # 清除grad累积值\n",
    "        optimizer.zero_grad()\n",
    "        # 读取dataloader中的数据，前半部分是tensor变量，后半部分是真实label\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward之后得到预测值\n",
    "        output, process_output_ = net(data)\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_layerout(epoch, batch_idx, process_output_)\n",
    "        # 计算loss\n",
    "        loss = cost_fun(output, target)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # 收集一组新的梯度，并使用optimizer.step()将其传播回每个网络参数\n",
    "        optimizer.step()\n",
    "        # 给出loss和acc\n",
    "        train_loss.append(loss)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        correct_num = torch.sum(pred == target).item()\n",
    "        train_acc.append(correct_num / batch_size)\n",
    "        print(\"Train Epoch:{}[{}/{} ({:.0f}%)]\\t Loss:{:.6f} acc:{:.2f}\".format(epoch, batch_idx * batch_size,\n",
    "               len(data_train.dataset),100. * batch_size * batch_idx / len(data_train.dataset), loss.item(),correct_num / batch_size))\n",
    "        \n",
    "        # MNIST一共60000个数据，batch_size为512，一共60000/512 = 118个batch\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_weight(epoch, batch_idx)\n",
    "\n",
    "def save_layerout(epoch, batch_idx, process_output_):\n",
    "    cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    # 将网络的过程结果进行保存\n",
    "    col_counter = 0\n",
    "    for key in process_output_.keys():\n",
    "\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = process_output_[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # --\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # --\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名\n",
    "        curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        # 数据存储\n",
    "        if not os.path.isdir('layeroutput_data'):\n",
    "            os.mkdir('.\\layeroutput_data')\n",
    "        layer_output_result_path = '.\\layeroutput_data'\n",
    "        with open(layer_output_result_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\",\n",
    "                    newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            data = process_output_[key].reshape(-1)\n",
    "            data_np = data.detach().numpy()  # TODO 注意确认是否存在通道问题、此处摒弃梯度信息\n",
    "            writer.writerows([data_np])\n",
    "            # writer.writerows([data_curt] for data_curt in data_np)\n",
    "            csvfile.close()\n",
    "            # --\n",
    "        col_counter += 1\n",
    "\n",
    "def save_weight(epoch, batch_idx):\n",
    "#    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "    cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "\n",
    "    # 网络参数输出\n",
    "    parm = {}\n",
    "    for name, parameters in net.named_parameters():\n",
    "        # print('网络参数输出')\n",
    "        # print(name, ':', parameters.size())\n",
    "        parm[name] = parameters.detach().numpy()  # 将tensor变量转换为np格式\n",
    "\n",
    "        # TODO 将读取出来的参数进行保存，注意确认是否存在tensor与np之间的转换通道问题\n",
    "        '''\n",
    "        文件名共分8部分：\n",
    "        epoch step index                   number        channel   length  width  value_name\n",
    "        轮数   步数  序号(按参数在网络中的顺序)  变量中数据块个数 变量通道数  变量长   变量宽  变量名称\n",
    "        '''\n",
    "    col_counter = 0\n",
    "    for key in parm.keys():\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = parm[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # -- 定义有信息的前导尺寸\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # -- 将无信息的前导尺寸设置为缺省值\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名\n",
    "        curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "\n",
    "        # 数据存储\n",
    "        # 创建文件对象\n",
    "        if not os.path.isdir('layer_para'):\n",
    "            os.mkdir('.\\layer_para')\n",
    "        if not os.path.isdir('layer_para\\\\bias'):\n",
    "            os.mkdir('.\\layer_para\\\\bias')\n",
    "        if not os.path.isdir('layer_para\\\\weight'):\n",
    "            os.mkdir('.\\layer_para\\\\weight')\n",
    "        layer_para_path = '.\\layer_para'\n",
    "        layer_bias_para_path = '.\\layer_para\\\\bias'\n",
    "        layer_weight_para_path = '.\\layer_para\\\\weight'\n",
    "        if('bias' in key):\n",
    "            with open(layer_bias_para_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "                writer = csv.writer(csvfile, delimiter=' ')\n",
    "                data = parm[key].reshape(-1)\n",
    "                # writer.writerows([data_curt] for data_curt in data)\n",
    "                writer.writerows([data])\n",
    "                csvfile.close()\n",
    "        else :\n",
    "            with open(layer_weight_para_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "                writer = csv.writer(csvfile, delimiter=' ')\n",
    "                data = parm[key].reshape(-1)\n",
    "                # writer.writerows([data_curt] for data_curt in data)\n",
    "                writer.writerows([data])\n",
    "                csvfile.close()            \n",
    "        # --\n",
    "        col_counter += 1 \n",
    "    \n",
    "\n",
    "def save_state():\n",
    "    print('===> Saving weights...')\n",
    "    state = {\n",
    "        'state': net.state_dict(),\n",
    "        'epoch': epoch  # 将epoch一并保存\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('./checkpoint')\n",
    "    torch.save(state, path_model + 'Epoch:' + str(epoch) + ' Loss:' + str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "def predict():\n",
    "    state_path = './checkpoint/model_14.pth' #  ***为指定加载的权重文件名称\n",
    "    print('===> Loading weights : ' + state_path)\n",
    "    weight_dict = torch.load(state_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "    # 从测试集中选取一个batch做预测\n",
    "    # pred_test = enumerate(data_test)\n",
    "    # batch_idx, (pred_data, pred_gt) = next(pred_test)\n",
    "    # output = net(pred_data)\n",
    "    # print(\"data: \", output.data)\n",
    "    # maxdata, pred = torch.max(output.data, 1) # 得到预测值,返回每一行的最大值，且返回索引\n",
    "    # print(\"maxdata: \", maxdata)\n",
    "    # print(\"ground truth: \",pred_gt)\n",
    "    # print(\"predict value: \",pred)\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    # 把tensor转成Image， 方便可视化\n",
    "    show = ToPILImage()\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "    net.eval()\n",
    "    for i in np.random.randint(0,20,size=10):\n",
    "        x, y = dataset_test[i][0], dataset_test[i][1]\n",
    "        # tensor格式数据可视化\n",
    "        show(x).show()\n",
    "        # 扩展张量维度为4维\n",
    "        x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=False).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "            predicted, actual = classes[torch.argmax(pred[0])], classes[y]\n",
    "            # 最终输出的预测值与真实值\n",
    "            print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "class LeNet(nn.Module): \t\t\t\t\t# 继承于nn.Module这个父类\n",
    "    def __init__(self):\t\t\t\t\t\t# 初始化网络结构\n",
    "        super(LeNet, self).__init__()    \t# 多继承需用到super函数\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),  # 输出为6*28*28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为6*14*14\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 输出为16*10*10\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为16*5*5\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # 正向传播过程\n",
    "        # x = self.block_1(x)\n",
    "        # x = x.view(-1,16*5*5)\n",
    "        # x = self.block_2(x)\n",
    "        block1_conv1_out = self.block_1[0](x)\n",
    "        block1_relu1_out = self.block_1[1](block1_conv1_out)\n",
    "        block1_maxpo1_out = self.block_1[2](block1_relu1_out)\n",
    "        block1_conv2_out = self.block_1[3](block1_maxpo1_out)\n",
    "        block1_relu2_out = self.block_1[4](block1_conv2_out)\n",
    "        block1_maxpo2_out = self.block_1[5](block1_relu2_out)\n",
    "\n",
    "        block1_maxpo2_out = block1_maxpo2_out.view(-1,16*5*5)\n",
    "\n",
    "        block2_fc1_out = self.block_2[0](block1_maxpo2_out)\n",
    "        block2_relu1_out = self.block_2[1](block2_fc1_out)\n",
    "        block2_fc2_out = self.block_2[2](block2_relu1_out)\n",
    "        block2_relu2_out = self.block_2[3](block2_fc2_out)\n",
    "        block2_fc3_out = self.block_2[4](block2_relu2_out)\n",
    "\n",
    "        softmax_output =  self.block_2[5](block2_fc3_out)\n",
    "\n",
    "        process_output = {'block1_conv1_out': block1_conv1_out,\n",
    "                          'block1_relu1_out': block1_relu1_out,\n",
    "                          'block1_maxpo1_out': block1_maxpo1_out,\n",
    "                          'block1_conv2_out': block1_conv2_out,\n",
    "                          'block1_relu2_out': block1_relu2_out,\n",
    "                          'block1_maxpo2_out': block1_maxpo2_out,\n",
    "\n",
    "                          'block2_fc1_out': block2_fc1_out,\n",
    "                          'block2_relu1_out': block2_relu1_out,\n",
    "                          'block2_fc2_out': block2_fc2_out,\n",
    "                          'block2_relu2_out': block2_relu2_out,\n",
    "                          'block2_fc3_out': block2_fc3_out,\n",
    "                          'softmax_output': softmax_output\n",
    "                        }\n",
    "\n",
    "        return block2_fc3_out, process_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0[0/60000 (0%)]\t Loss:2.299441 acc:0.10\n",
      "Train Epoch:0[512/60000 (1%)]\t Loss:2.301670 acc:0.09\n",
      "Train Epoch:0[1024/60000 (2%)]\t Loss:2.302093 acc:0.10\n",
      "Train Epoch:0[1536/60000 (3%)]\t Loss:2.293128 acc:0.11\n",
      "Train Epoch:0[2048/60000 (3%)]\t Loss:2.297524 acc:0.11\n",
      "Train Epoch:0[2560/60000 (4%)]\t Loss:2.300138 acc:0.10\n",
      "Train Epoch:0[3072/60000 (5%)]\t Loss:2.301613 acc:0.10\n",
      "Train Epoch:0[3584/60000 (6%)]\t Loss:2.294523 acc:0.09\n",
      "Train Epoch:0[4096/60000 (7%)]\t Loss:2.299752 acc:0.09\n",
      "Train Epoch:0[4608/60000 (8%)]\t Loss:2.295251 acc:0.09\n",
      "Train Epoch:0[5120/60000 (9%)]\t Loss:2.296507 acc:0.09\n",
      "Train Epoch:0[5632/60000 (9%)]\t Loss:2.290614 acc:0.11\n",
      "Train Epoch:0[6144/60000 (10%)]\t Loss:2.286134 acc:0.09\n",
      "Train Epoch:0[6656/60000 (11%)]\t Loss:2.297364 acc:0.09\n",
      "Train Epoch:0[7168/60000 (12%)]\t Loss:2.288844 acc:0.12\n",
      "Train Epoch:0[7680/60000 (13%)]\t Loss:2.288592 acc:0.10\n",
      "Train Epoch:0[8192/60000 (14%)]\t Loss:2.288130 acc:0.11\n",
      "Train Epoch:0[8704/60000 (15%)]\t Loss:2.283421 acc:0.12\n",
      "Train Epoch:0[9216/60000 (15%)]\t Loss:2.288637 acc:0.11\n",
      "Train Epoch:0[9728/60000 (16%)]\t Loss:2.288468 acc:0.13\n",
      "Train Epoch:0[10240/60000 (17%)]\t Loss:2.283775 acc:0.12\n",
      "Train Epoch:0[10752/60000 (18%)]\t Loss:2.281888 acc:0.11\n",
      "Train Epoch:0[11264/60000 (19%)]\t Loss:2.288805 acc:0.11\n",
      "Train Epoch:0[11776/60000 (20%)]\t Loss:2.283694 acc:0.10\n",
      "Train Epoch:0[12288/60000 (20%)]\t Loss:2.282935 acc:0.11\n",
      "Train Epoch:0[12800/60000 (21%)]\t Loss:2.279559 acc:0.13\n",
      "Train Epoch:0[13312/60000 (22%)]\t Loss:2.277918 acc:0.13\n",
      "Train Epoch:0[13824/60000 (23%)]\t Loss:2.280566 acc:0.11\n",
      "Train Epoch:0[14336/60000 (24%)]\t Loss:2.277836 acc:0.13\n",
      "Train Epoch:0[14848/60000 (25%)]\t Loss:2.276371 acc:0.12\n",
      "Train Epoch:0[15360/60000 (26%)]\t Loss:2.277741 acc:0.14\n",
      "Train Epoch:0[15872/60000 (26%)]\t Loss:2.276183 acc:0.14\n",
      "Train Epoch:0[16384/60000 (27%)]\t Loss:2.269518 acc:0.13\n",
      "Train Epoch:0[16896/60000 (28%)]\t Loss:2.269512 acc:0.11\n",
      "Train Epoch:0[17408/60000 (29%)]\t Loss:2.277975 acc:0.10\n",
      "Train Epoch:0[17920/60000 (30%)]\t Loss:2.266364 acc:0.16\n",
      "Train Epoch:0[18432/60000 (31%)]\t Loss:2.269873 acc:0.14\n",
      "Train Epoch:0[18944/60000 (32%)]\t Loss:2.265595 acc:0.15\n",
      "Train Epoch:0[19456/60000 (32%)]\t Loss:2.264912 acc:0.17\n",
      "Train Epoch:0[19968/60000 (33%)]\t Loss:2.264328 acc:0.15\n",
      "Train Epoch:0[20480/60000 (34%)]\t Loss:2.258158 acc:0.19\n",
      "Train Epoch:0[20992/60000 (35%)]\t Loss:2.256424 acc:0.16\n",
      "Train Epoch:0[21504/60000 (36%)]\t Loss:2.252117 acc:0.22\n",
      "Train Epoch:0[22016/60000 (37%)]\t Loss:2.259946 acc:0.19\n",
      "Train Epoch:0[22528/60000 (38%)]\t Loss:2.259592 acc:0.18\n",
      "Train Epoch:0[23040/60000 (38%)]\t Loss:2.257680 acc:0.17\n",
      "Train Epoch:0[23552/60000 (39%)]\t Loss:2.253942 acc:0.19\n",
      "Train Epoch:0[24064/60000 (40%)]\t Loss:2.252950 acc:0.19\n",
      "Train Epoch:0[24576/60000 (41%)]\t Loss:2.253416 acc:0.17\n",
      "Train Epoch:0[25088/60000 (42%)]\t Loss:2.246444 acc:0.24\n",
      "Train Epoch:0[25600/60000 (43%)]\t Loss:2.250274 acc:0.16\n",
      "Train Epoch:0[26112/60000 (44%)]\t Loss:2.246355 acc:0.19\n",
      "Train Epoch:0[26624/60000 (44%)]\t Loss:2.245322 acc:0.20\n",
      "Train Epoch:0[27136/60000 (45%)]\t Loss:2.241276 acc:0.19\n",
      "Train Epoch:0[27648/60000 (46%)]\t Loss:2.231491 acc:0.24\n",
      "Train Epoch:0[28160/60000 (47%)]\t Loss:2.234720 acc:0.23\n",
      "Train Epoch:0[28672/60000 (48%)]\t Loss:2.235460 acc:0.22\n",
      "Train Epoch:0[29184/60000 (49%)]\t Loss:2.234133 acc:0.20\n",
      "Train Epoch:0[29696/60000 (49%)]\t Loss:2.245143 acc:0.20\n",
      "Train Epoch:0[30208/60000 (50%)]\t Loss:2.236888 acc:0.20\n",
      "Train Epoch:0[30720/60000 (51%)]\t Loss:2.226836 acc:0.23\n",
      "Train Epoch:0[31232/60000 (52%)]\t Loss:2.237437 acc:0.21\n",
      "Train Epoch:0[31744/60000 (53%)]\t Loss:2.231319 acc:0.21\n",
      "Train Epoch:0[32256/60000 (54%)]\t Loss:2.229931 acc:0.21\n",
      "Train Epoch:0[32768/60000 (55%)]\t Loss:2.212246 acc:0.28\n",
      "Train Epoch:0[33280/60000 (55%)]\t Loss:2.217263 acc:0.24\n",
      "Train Epoch:0[33792/60000 (56%)]\t Loss:2.215544 acc:0.26\n",
      "Train Epoch:0[34304/60000 (57%)]\t Loss:2.215952 acc:0.25\n",
      "Train Epoch:0[34816/60000 (58%)]\t Loss:2.213109 acc:0.29\n",
      "Train Epoch:0[35328/60000 (59%)]\t Loss:2.207250 acc:0.27\n",
      "Train Epoch:0[35840/60000 (60%)]\t Loss:2.201331 acc:0.28\n",
      "Train Epoch:0[36352/60000 (61%)]\t Loss:2.208296 acc:0.26\n",
      "Train Epoch:0[36864/60000 (61%)]\t Loss:2.199442 acc:0.30\n",
      "Train Epoch:0[37376/60000 (62%)]\t Loss:2.203030 acc:0.25\n",
      "Train Epoch:0[37888/60000 (63%)]\t Loss:2.198450 acc:0.30\n",
      "Train Epoch:0[38400/60000 (64%)]\t Loss:2.194728 acc:0.28\n",
      "Train Epoch:0[38912/60000 (65%)]\t Loss:2.180391 acc:0.36\n",
      "Train Epoch:0[39424/60000 (66%)]\t Loss:2.198428 acc:0.29\n",
      "Train Epoch:0[39936/60000 (67%)]\t Loss:2.185738 acc:0.29\n",
      "Train Epoch:0[40448/60000 (67%)]\t Loss:2.183952 acc:0.31\n",
      "Train Epoch:0[40960/60000 (68%)]\t Loss:2.185728 acc:0.28\n",
      "Train Epoch:0[41472/60000 (69%)]\t Loss:2.185212 acc:0.31\n",
      "Train Epoch:0[41984/60000 (70%)]\t Loss:2.169282 acc:0.36\n",
      "Train Epoch:0[42496/60000 (71%)]\t Loss:2.162747 acc:0.33\n",
      "Train Epoch:0[43008/60000 (72%)]\t Loss:2.162722 acc:0.36\n",
      "Train Epoch:0[43520/60000 (73%)]\t Loss:2.152784 acc:0.34\n",
      "Train Epoch:0[44032/60000 (73%)]\t Loss:2.162384 acc:0.31\n",
      "Train Epoch:0[44544/60000 (74%)]\t Loss:2.161546 acc:0.31\n",
      "Train Epoch:0[45056/60000 (75%)]\t Loss:2.139231 acc:0.34\n",
      "Train Epoch:0[45568/60000 (76%)]\t Loss:2.146140 acc:0.35\n",
      "Train Epoch:0[46080/60000 (77%)]\t Loss:2.137549 acc:0.39\n",
      "Train Epoch:0[46592/60000 (78%)]\t Loss:2.120930 acc:0.37\n",
      "Train Epoch:0[47104/60000 (79%)]\t Loss:2.130577 acc:0.35\n",
      "Train Epoch:0[47616/60000 (79%)]\t Loss:2.109522 acc:0.38\n",
      "Train Epoch:0[48128/60000 (80%)]\t Loss:2.092255 acc:0.37\n",
      "Train Epoch:0[48640/60000 (81%)]\t Loss:2.117887 acc:0.38\n",
      "Train Epoch:0[49152/60000 (82%)]\t Loss:2.110662 acc:0.39\n",
      "Train Epoch:0[49664/60000 (83%)]\t Loss:2.102033 acc:0.40\n",
      "Train Epoch:0[50176/60000 (84%)]\t Loss:2.101588 acc:0.41\n",
      "Train Epoch:0[50688/60000 (84%)]\t Loss:2.092512 acc:0.37\n",
      "Train Epoch:0[51200/60000 (85%)]\t Loss:2.063775 acc:0.46\n",
      "Train Epoch:0[51712/60000 (86%)]\t Loss:2.082200 acc:0.42\n",
      "Train Epoch:0[52224/60000 (87%)]\t Loss:2.049773 acc:0.44\n",
      "Train Epoch:0[52736/60000 (88%)]\t Loss:2.065137 acc:0.41\n",
      "Train Epoch:0[53248/60000 (89%)]\t Loss:2.046746 acc:0.44\n",
      "Train Epoch:0[53760/60000 (90%)]\t Loss:2.043672 acc:0.46\n",
      "Train Epoch:0[54272/60000 (90%)]\t Loss:1.998943 acc:0.51\n",
      "Train Epoch:0[54784/60000 (91%)]\t Loss:2.009202 acc:0.49\n",
      "Train Epoch:0[55296/60000 (92%)]\t Loss:1.993942 acc:0.49\n",
      "Train Epoch:0[55808/60000 (93%)]\t Loss:1.984468 acc:0.50\n",
      "Train Epoch:0[56320/60000 (94%)]\t Loss:1.974653 acc:0.48\n",
      "Train Epoch:0[56832/60000 (95%)]\t Loss:1.989889 acc:0.48\n",
      "Train Epoch:0[57344/60000 (96%)]\t Loss:1.977420 acc:0.50\n",
      "Train Epoch:0[57856/60000 (96%)]\t Loss:1.943141 acc:0.58\n",
      "Train Epoch:0[58368/60000 (97%)]\t Loss:1.927009 acc:0.59\n",
      "Train Epoch:0[58880/60000 (98%)]\t Loss:1.892492 acc:0.57\n",
      "Train Epoch:0[59392/60000 (99%)]\t Loss:1.896422 acc:0.55\n",
      "Train Epoch:0[59904/60000 (100%)]\t Loss:1.998307 acc:0.11\n",
      "===> Saving models...\n",
      "Test Epoch:0 [0/10000 (0%)]\t acc:0.03\n",
      "Test Epoch:0 [512/10000 (5%)]\t acc:0.06\n",
      "Test Epoch:0 [1024/10000 (10%)]\t acc:0.09\n",
      "Test Epoch:0 [1536/10000 (15%)]\t acc:0.12\n",
      "Test Epoch:0 [2048/10000 (20%)]\t acc:0.14\n",
      "Test Epoch:0 [2560/10000 (26%)]\t acc:0.17\n",
      "Test Epoch:0 [3072/10000 (31%)]\t acc:0.20\n",
      "Test Epoch:0 [3584/10000 (36%)]\t acc:0.23\n",
      "Test Epoch:0 [4096/10000 (41%)]\t acc:0.26\n",
      "Test Epoch:0 [4608/10000 (46%)]\t acc:0.29\n",
      "Test Epoch:0 [5120/10000 (51%)]\t acc:0.32\n",
      "Test Epoch:0 [5632/10000 (56%)]\t acc:0.35\n",
      "Test Epoch:0 [6144/10000 (61%)]\t acc:0.38\n",
      "Test Epoch:0 [6656/10000 (67%)]\t acc:0.41\n",
      "Test Epoch:0 [7168/10000 (72%)]\t acc:0.44\n",
      "Test Epoch:0 [7680/10000 (77%)]\t acc:0.47\n",
      "Test Epoch:0 [8192/10000 (82%)]\t acc:0.49\n",
      "Test Epoch:0 [8704/10000 (87%)]\t acc:0.52\n",
      "Test Epoch:0 [9216/10000 (92%)]\t acc:0.55\n",
      "Test Epoch:0 [9728/10000 (97%)]\t acc:0.56\n",
      "Train Epoch:1[0/60000 (0%)]\t Loss:1.892179 acc:0.56\n",
      "Train Epoch:1[512/60000 (1%)]\t Loss:1.920791 acc:0.48\n",
      "Train Epoch:1[1024/60000 (2%)]\t Loss:1.893776 acc:0.55\n",
      "Train Epoch:1[1536/60000 (3%)]\t Loss:1.825662 acc:0.60\n",
      "Train Epoch:1[2048/60000 (3%)]\t Loss:1.806951 acc:0.68\n",
      "Train Epoch:1[2560/60000 (4%)]\t Loss:1.806614 acc:0.63\n",
      "Train Epoch:1[3072/60000 (5%)]\t Loss:1.827178 acc:0.59\n",
      "Train Epoch:1[3584/60000 (6%)]\t Loss:1.764752 acc:0.62\n",
      "Train Epoch:1[4096/60000 (7%)]\t Loss:1.764980 acc:0.61\n",
      "Train Epoch:1[4608/60000 (8%)]\t Loss:1.731768 acc:0.67\n",
      "Train Epoch:1[5120/60000 (9%)]\t Loss:1.699524 acc:0.65\n",
      "Train Epoch:1[5632/60000 (9%)]\t Loss:1.697191 acc:0.64\n",
      "Train Epoch:1[6144/60000 (10%)]\t Loss:1.632108 acc:0.70\n",
      "Train Epoch:1[6656/60000 (11%)]\t Loss:1.688312 acc:0.67\n",
      "Train Epoch:1[7168/60000 (12%)]\t Loss:1.711170 acc:0.68\n",
      "Train Epoch:1[7680/60000 (13%)]\t Loss:1.631680 acc:0.67\n",
      "Train Epoch:1[8192/60000 (14%)]\t Loss:1.639132 acc:0.63\n",
      "Train Epoch:1[8704/60000 (15%)]\t Loss:1.545704 acc:0.71\n",
      "Train Epoch:1[9216/60000 (15%)]\t Loss:1.498758 acc:0.74\n",
      "Train Epoch:1[9728/60000 (16%)]\t Loss:1.507515 acc:0.71\n",
      "Train Epoch:1[10240/60000 (17%)]\t Loss:1.463754 acc:0.73\n",
      "Train Epoch:1[10752/60000 (18%)]\t Loss:1.443700 acc:0.71\n",
      "Train Epoch:1[11264/60000 (19%)]\t Loss:1.446582 acc:0.68\n",
      "Train Epoch:1[11776/60000 (20%)]\t Loss:1.408869 acc:0.71\n",
      "Train Epoch:1[12288/60000 (20%)]\t Loss:1.447909 acc:0.66\n",
      "Train Epoch:1[12800/60000 (21%)]\t Loss:1.417622 acc:0.66\n",
      "Train Epoch:1[13312/60000 (22%)]\t Loss:1.336957 acc:0.70\n",
      "Train Epoch:1[13824/60000 (23%)]\t Loss:1.360837 acc:0.66\n",
      "Train Epoch:1[14336/60000 (24%)]\t Loss:1.376790 acc:0.69\n",
      "Train Epoch:1[14848/60000 (25%)]\t Loss:1.211486 acc:0.75\n",
      "Train Epoch:1[15360/60000 (26%)]\t Loss:1.286231 acc:0.72\n",
      "Train Epoch:1[15872/60000 (26%)]\t Loss:1.195739 acc:0.74\n",
      "Train Epoch:1[16384/60000 (27%)]\t Loss:1.205041 acc:0.72\n",
      "Train Epoch:1[16896/60000 (28%)]\t Loss:1.206661 acc:0.72\n",
      "Train Epoch:1[17408/60000 (29%)]\t Loss:1.269245 acc:0.68\n",
      "Train Epoch:1[17920/60000 (30%)]\t Loss:1.026556 acc:0.81\n",
      "Train Epoch:1[18432/60000 (31%)]\t Loss:1.051688 acc:0.78\n",
      "Train Epoch:1[18944/60000 (32%)]\t Loss:1.049127 acc:0.76\n",
      "Train Epoch:1[19456/60000 (32%)]\t Loss:0.944496 acc:0.79\n",
      "Train Epoch:1[19968/60000 (33%)]\t Loss:1.025741 acc:0.75\n",
      "Train Epoch:1[20480/60000 (34%)]\t Loss:1.009650 acc:0.76\n",
      "Train Epoch:1[20992/60000 (35%)]\t Loss:0.870923 acc:0.82\n",
      "Train Epoch:1[21504/60000 (36%)]\t Loss:0.818343 acc:0.85\n",
      "Train Epoch:1[22016/60000 (37%)]\t Loss:0.921918 acc:0.79\n",
      "Train Epoch:1[22528/60000 (38%)]\t Loss:0.872754 acc:0.79\n",
      "Train Epoch:1[23040/60000 (38%)]\t Loss:0.817618 acc:0.80\n",
      "Train Epoch:1[23552/60000 (39%)]\t Loss:0.888167 acc:0.78\n",
      "Train Epoch:1[24064/60000 (40%)]\t Loss:0.828580 acc:0.79\n",
      "Train Epoch:1[24576/60000 (41%)]\t Loss:0.817647 acc:0.79\n",
      "Train Epoch:1[25088/60000 (42%)]\t Loss:0.730534 acc:0.81\n",
      "Train Epoch:1[25600/60000 (43%)]\t Loss:0.685524 acc:0.83\n",
      "Train Epoch:1[26112/60000 (44%)]\t Loss:0.792430 acc:0.80\n",
      "Train Epoch:1[26624/60000 (44%)]\t Loss:0.749318 acc:0.81\n",
      "Train Epoch:1[27136/60000 (45%)]\t Loss:0.763440 acc:0.79\n",
      "Train Epoch:1[27648/60000 (46%)]\t Loss:0.643830 acc:0.84\n",
      "Train Epoch:1[28160/60000 (47%)]\t Loss:0.697447 acc:0.80\n",
      "Train Epoch:1[28672/60000 (48%)]\t Loss:0.697164 acc:0.82\n",
      "Train Epoch:1[29184/60000 (49%)]\t Loss:0.644402 acc:0.82\n",
      "Train Epoch:1[29696/60000 (49%)]\t Loss:0.836071 acc:0.75\n",
      "Train Epoch:1[30208/60000 (50%)]\t Loss:0.661394 acc:0.82\n",
      "Train Epoch:1[30720/60000 (51%)]\t Loss:0.672857 acc:0.82\n",
      "Train Epoch:1[31232/60000 (52%)]\t Loss:0.779914 acc:0.81\n",
      "Train Epoch:1[31744/60000 (53%)]\t Loss:0.656080 acc:0.79\n",
      "Train Epoch:1[32256/60000 (54%)]\t Loss:0.724685 acc:0.78\n",
      "Train Epoch:1[32768/60000 (55%)]\t Loss:0.614999 acc:0.83\n",
      "Train Epoch:1[33280/60000 (55%)]\t Loss:0.609533 acc:0.82\n",
      "Train Epoch:1[33792/60000 (56%)]\t Loss:0.468339 acc:0.88\n",
      "Train Epoch:1[34304/60000 (57%)]\t Loss:0.665287 acc:0.79\n",
      "Train Epoch:1[34816/60000 (58%)]\t Loss:0.582555 acc:0.84\n",
      "Train Epoch:1[35328/60000 (59%)]\t Loss:0.542527 acc:0.84\n",
      "Train Epoch:1[35840/60000 (60%)]\t Loss:0.480467 acc:0.86\n",
      "Train Epoch:1[36352/60000 (61%)]\t Loss:0.513640 acc:0.84\n",
      "Train Epoch:1[36864/60000 (61%)]\t Loss:0.654165 acc:0.80\n",
      "Train Epoch:1[37376/60000 (62%)]\t Loss:0.707865 acc:0.78\n",
      "Train Epoch:1[37888/60000 (63%)]\t Loss:0.541283 acc:0.84\n",
      "Train Epoch:1[38400/60000 (64%)]\t Loss:0.550881 acc:0.83\n",
      "Train Epoch:1[38912/60000 (65%)]\t Loss:0.494374 acc:0.85\n",
      "Train Epoch:1[39424/60000 (66%)]\t Loss:0.668850 acc:0.80\n",
      "Train Epoch:1[39936/60000 (67%)]\t Loss:0.523351 acc:0.81\n",
      "Train Epoch:1[40448/60000 (67%)]\t Loss:0.515340 acc:0.85\n",
      "Train Epoch:1[40960/60000 (68%)]\t Loss:0.684142 acc:0.77\n",
      "Train Epoch:1[41472/60000 (69%)]\t Loss:0.567858 acc:0.83\n",
      "Train Epoch:1[41984/60000 (70%)]\t Loss:0.669034 acc:0.78\n",
      "Train Epoch:1[42496/60000 (71%)]\t Loss:0.589702 acc:0.85\n",
      "Train Epoch:1[43008/60000 (72%)]\t Loss:0.488160 acc:0.83\n",
      "Train Epoch:1[43520/60000 (73%)]\t Loss:0.476443 acc:0.86\n",
      "Train Epoch:1[44032/60000 (73%)]\t Loss:0.610177 acc:0.80\n",
      "Train Epoch:1[44544/60000 (74%)]\t Loss:0.502234 acc:0.84\n",
      "Train Epoch:1[45056/60000 (75%)]\t Loss:0.535407 acc:0.83\n",
      "Train Epoch:1[45568/60000 (76%)]\t Loss:0.533775 acc:0.86\n",
      "Train Epoch:1[46080/60000 (77%)]\t Loss:0.526579 acc:0.83\n",
      "Train Epoch:1[46592/60000 (78%)]\t Loss:0.412245 acc:0.88\n",
      "Train Epoch:1[47104/60000 (79%)]\t Loss:0.522507 acc:0.82\n",
      "Train Epoch:1[47616/60000 (79%)]\t Loss:0.481523 acc:0.85\n",
      "Train Epoch:1[48128/60000 (80%)]\t Loss:0.404931 acc:0.89\n",
      "Train Epoch:1[48640/60000 (81%)]\t Loss:0.565308 acc:0.83\n",
      "Train Epoch:1[49152/60000 (82%)]\t Loss:0.554055 acc:0.83\n",
      "Train Epoch:1[49664/60000 (83%)]\t Loss:0.549847 acc:0.82\n",
      "Train Epoch:1[50176/60000 (84%)]\t Loss:0.611129 acc:0.82\n",
      "Train Epoch:1[50688/60000 (84%)]\t Loss:0.510193 acc:0.84\n",
      "Train Epoch:1[51200/60000 (85%)]\t Loss:0.413736 acc:0.88\n",
      "Train Epoch:1[51712/60000 (86%)]\t Loss:0.495929 acc:0.84\n",
      "Train Epoch:1[52224/60000 (87%)]\t Loss:0.464564 acc:0.87\n",
      "Train Epoch:1[52736/60000 (88%)]\t Loss:0.630594 acc:0.82\n",
      "Train Epoch:1[53248/60000 (89%)]\t Loss:0.474167 acc:0.86\n",
      "Train Epoch:1[53760/60000 (90%)]\t Loss:0.463932 acc:0.85\n",
      "Train Epoch:1[54272/60000 (90%)]\t Loss:0.379527 acc:0.88\n",
      "Train Epoch:1[54784/60000 (91%)]\t Loss:0.469262 acc:0.85\n",
      "Train Epoch:1[55296/60000 (92%)]\t Loss:0.410085 acc:0.88\n",
      "Train Epoch:1[55808/60000 (93%)]\t Loss:0.392486 acc:0.87\n",
      "Train Epoch:1[56320/60000 (94%)]\t Loss:0.365202 acc:0.89\n",
      "Train Epoch:1[56832/60000 (95%)]\t Loss:0.412126 acc:0.87\n",
      "Train Epoch:1[57344/60000 (96%)]\t Loss:0.419176 acc:0.88\n",
      "Train Epoch:1[57856/60000 (96%)]\t Loss:0.294686 acc:0.92\n",
      "Train Epoch:1[58368/60000 (97%)]\t Loss:0.299866 acc:0.92\n",
      "Train Epoch:1[58880/60000 (98%)]\t Loss:0.286500 acc:0.92\n",
      "Train Epoch:1[59392/60000 (99%)]\t Loss:0.359610 acc:0.92\n",
      "Train Epoch:1[59904/60000 (100%)]\t Loss:0.635189 acc:0.16\n",
      "===> Saving models...\n",
      "Test Epoch:1 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:1 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:1 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:1 [1536/10000 (15%)]\t acc:0.18\n",
      "Test Epoch:1 [2048/10000 (20%)]\t acc:0.23\n",
      "Test Epoch:1 [2560/10000 (26%)]\t acc:0.27\n",
      "Test Epoch:1 [3072/10000 (31%)]\t acc:0.32\n",
      "Test Epoch:1 [3584/10000 (36%)]\t acc:0.36\n",
      "Test Epoch:1 [4096/10000 (41%)]\t acc:0.41\n",
      "Test Epoch:1 [4608/10000 (46%)]\t acc:0.45\n",
      "Test Epoch:1 [5120/10000 (51%)]\t acc:0.50\n",
      "Test Epoch:1 [5632/10000 (56%)]\t acc:0.54\n",
      "Test Epoch:1 [6144/10000 (61%)]\t acc:0.59\n",
      "Test Epoch:1 [6656/10000 (67%)]\t acc:0.63\n",
      "Test Epoch:1 [7168/10000 (72%)]\t acc:0.68\n",
      "Test Epoch:1 [7680/10000 (77%)]\t acc:0.72\n",
      "Test Epoch:1 [8192/10000 (82%)]\t acc:0.77\n",
      "Test Epoch:1 [8704/10000 (87%)]\t acc:0.81\n",
      "Test Epoch:1 [9216/10000 (92%)]\t acc:0.85\n",
      "Test Epoch:1 [9728/10000 (97%)]\t acc:0.88\n",
      "Train Epoch:2[0/60000 (0%)]\t Loss:0.421404 acc:0.88\n",
      "Train Epoch:2[512/60000 (1%)]\t Loss:0.490399 acc:0.84\n",
      "Train Epoch:2[1024/60000 (2%)]\t Loss:0.479391 acc:0.87\n",
      "Train Epoch:2[1536/60000 (3%)]\t Loss:0.331360 acc:0.91\n",
      "Train Epoch:2[2048/60000 (3%)]\t Loss:0.377336 acc:0.90\n",
      "Train Epoch:2[2560/60000 (4%)]\t Loss:0.420925 acc:0.86\n",
      "Train Epoch:2[3072/60000 (5%)]\t Loss:0.428948 acc:0.88\n",
      "Train Epoch:2[3584/60000 (6%)]\t Loss:0.374461 acc:0.88\n",
      "Train Epoch:2[4096/60000 (7%)]\t Loss:0.394451 acc:0.88\n",
      "Train Epoch:2[4608/60000 (8%)]\t Loss:0.448152 acc:0.89\n",
      "Train Epoch:2[5120/60000 (9%)]\t Loss:0.438353 acc:0.87\n",
      "Train Epoch:2[5632/60000 (9%)]\t Loss:0.398205 acc:0.90\n",
      "Train Epoch:2[6144/60000 (10%)]\t Loss:0.296330 acc:0.90\n",
      "Train Epoch:2[6656/60000 (11%)]\t Loss:0.450061 acc:0.87\n",
      "Train Epoch:2[7168/60000 (12%)]\t Loss:0.431931 acc:0.87\n",
      "Train Epoch:2[7680/60000 (13%)]\t Loss:0.441551 acc:0.88\n",
      "Train Epoch:2[8192/60000 (14%)]\t Loss:0.433989 acc:0.87\n",
      "Train Epoch:2[8704/60000 (15%)]\t Loss:0.474990 acc:0.88\n",
      "Train Epoch:2[9216/60000 (15%)]\t Loss:0.398647 acc:0.89\n",
      "Train Epoch:2[9728/60000 (16%)]\t Loss:0.396397 acc:0.88\n",
      "Train Epoch:2[10240/60000 (17%)]\t Loss:0.289337 acc:0.90\n",
      "Train Epoch:2[10752/60000 (18%)]\t Loss:0.362777 acc:0.91\n",
      "Train Epoch:2[11264/60000 (19%)]\t Loss:0.443837 acc:0.87\n",
      "Train Epoch:2[11776/60000 (20%)]\t Loss:0.362953 acc:0.89\n",
      "Train Epoch:2[12288/60000 (20%)]\t Loss:0.480118 acc:0.86\n",
      "Train Epoch:2[12800/60000 (21%)]\t Loss:0.423559 acc:0.88\n",
      "Train Epoch:2[13312/60000 (22%)]\t Loss:0.353656 acc:0.90\n",
      "Train Epoch:2[13824/60000 (23%)]\t Loss:0.532337 acc:0.84\n",
      "Train Epoch:2[14336/60000 (24%)]\t Loss:0.547880 acc:0.81\n",
      "Train Epoch:2[14848/60000 (25%)]\t Loss:0.360485 acc:0.90\n",
      "Train Epoch:2[15360/60000 (26%)]\t Loss:0.384062 acc:0.87\n",
      "Train Epoch:2[15872/60000 (26%)]\t Loss:0.354020 acc:0.90\n",
      "Train Epoch:2[16384/60000 (27%)]\t Loss:0.393679 acc:0.88\n",
      "Train Epoch:2[16896/60000 (28%)]\t Loss:0.382160 acc:0.89\n",
      "Train Epoch:2[17408/60000 (29%)]\t Loss:0.493393 acc:0.85\n",
      "Train Epoch:2[17920/60000 (30%)]\t Loss:0.284958 acc:0.91\n",
      "Train Epoch:2[18432/60000 (31%)]\t Loss:0.333169 acc:0.92\n",
      "Train Epoch:2[18944/60000 (32%)]\t Loss:0.345462 acc:0.88\n",
      "Train Epoch:2[19456/60000 (32%)]\t Loss:0.296886 acc:0.90\n",
      "Train Epoch:2[19968/60000 (33%)]\t Loss:0.372831 acc:0.92\n",
      "Train Epoch:2[20480/60000 (34%)]\t Loss:0.475879 acc:0.87\n",
      "Train Epoch:2[20992/60000 (35%)]\t Loss:0.331035 acc:0.91\n",
      "Train Epoch:2[21504/60000 (36%)]\t Loss:0.293378 acc:0.93\n",
      "Train Epoch:2[22016/60000 (37%)]\t Loss:0.338892 acc:0.88\n",
      "Train Epoch:2[22528/60000 (38%)]\t Loss:0.346032 acc:0.89\n",
      "Train Epoch:2[23040/60000 (38%)]\t Loss:0.322401 acc:0.89\n",
      "Train Epoch:2[23552/60000 (39%)]\t Loss:0.404003 acc:0.89\n",
      "Train Epoch:2[24064/60000 (40%)]\t Loss:0.399496 acc:0.88\n",
      "Train Epoch:2[24576/60000 (41%)]\t Loss:0.422991 acc:0.86\n",
      "Train Epoch:2[25088/60000 (42%)]\t Loss:0.304288 acc:0.90\n",
      "Train Epoch:2[25600/60000 (43%)]\t Loss:0.343071 acc:0.92\n",
      "Train Epoch:2[26112/60000 (44%)]\t Loss:0.441751 acc:0.89\n",
      "Train Epoch:2[26624/60000 (44%)]\t Loss:0.378880 acc:0.89\n",
      "Train Epoch:2[27136/60000 (45%)]\t Loss:0.381481 acc:0.88\n",
      "Train Epoch:2[27648/60000 (46%)]\t Loss:0.294455 acc:0.91\n",
      "Train Epoch:2[28160/60000 (47%)]\t Loss:0.388836 acc:0.90\n",
      "Train Epoch:2[28672/60000 (48%)]\t Loss:0.333045 acc:0.91\n",
      "Train Epoch:2[29184/60000 (49%)]\t Loss:0.346785 acc:0.90\n",
      "Train Epoch:2[29696/60000 (49%)]\t Loss:0.468731 acc:0.85\n",
      "Train Epoch:2[30208/60000 (50%)]\t Loss:0.364386 acc:0.88\n",
      "Train Epoch:2[30720/60000 (51%)]\t Loss:0.428808 acc:0.89\n",
      "Train Epoch:2[31232/60000 (52%)]\t Loss:0.467290 acc:0.87\n",
      "Train Epoch:2[31744/60000 (53%)]\t Loss:0.368289 acc:0.88\n",
      "Train Epoch:2[32256/60000 (54%)]\t Loss:0.386071 acc:0.88\n",
      "Train Epoch:2[32768/60000 (55%)]\t Loss:0.371050 acc:0.92\n",
      "Train Epoch:2[33280/60000 (55%)]\t Loss:0.331473 acc:0.89\n",
      "Train Epoch:2[33792/60000 (56%)]\t Loss:0.229107 acc:0.94\n",
      "Train Epoch:2[34304/60000 (57%)]\t Loss:0.442142 acc:0.87\n",
      "Train Epoch:2[34816/60000 (58%)]\t Loss:0.318829 acc:0.91\n",
      "Train Epoch:2[35328/60000 (59%)]\t Loss:0.301036 acc:0.91\n",
      "Train Epoch:2[35840/60000 (60%)]\t Loss:0.270229 acc:0.91\n",
      "Train Epoch:2[36352/60000 (61%)]\t Loss:0.298501 acc:0.92\n",
      "Train Epoch:2[36864/60000 (61%)]\t Loss:0.430865 acc:0.87\n",
      "Train Epoch:2[37376/60000 (62%)]\t Loss:0.437768 acc:0.87\n",
      "Train Epoch:2[37888/60000 (63%)]\t Loss:0.324902 acc:0.90\n",
      "Train Epoch:2[38400/60000 (64%)]\t Loss:0.344805 acc:0.89\n",
      "Train Epoch:2[38912/60000 (65%)]\t Loss:0.320804 acc:0.92\n",
      "Train Epoch:2[39424/60000 (66%)]\t Loss:0.381912 acc:0.90\n",
      "Train Epoch:2[39936/60000 (67%)]\t Loss:0.312195 acc:0.90\n",
      "Train Epoch:2[40448/60000 (67%)]\t Loss:0.299790 acc:0.92\n",
      "Train Epoch:2[40960/60000 (68%)]\t Loss:0.447313 acc:0.86\n",
      "Train Epoch:2[41472/60000 (69%)]\t Loss:0.352620 acc:0.89\n",
      "Train Epoch:2[41984/60000 (70%)]\t Loss:0.425082 acc:0.88\n",
      "Train Epoch:2[42496/60000 (71%)]\t Loss:0.387387 acc:0.88\n",
      "Train Epoch:2[43008/60000 (72%)]\t Loss:0.298635 acc:0.90\n",
      "Train Epoch:2[43520/60000 (73%)]\t Loss:0.309614 acc:0.90\n",
      "Train Epoch:2[44032/60000 (73%)]\t Loss:0.407874 acc:0.85\n",
      "Train Epoch:2[44544/60000 (74%)]\t Loss:0.353213 acc:0.89\n",
      "Train Epoch:2[45056/60000 (75%)]\t Loss:0.320545 acc:0.90\n",
      "Train Epoch:2[45568/60000 (76%)]\t Loss:0.371674 acc:0.89\n",
      "Train Epoch:2[46080/60000 (77%)]\t Loss:0.346244 acc:0.90\n",
      "Train Epoch:2[46592/60000 (78%)]\t Loss:0.259756 acc:0.91\n",
      "Train Epoch:2[47104/60000 (79%)]\t Loss:0.352028 acc:0.89\n",
      "Train Epoch:2[47616/60000 (79%)]\t Loss:0.302215 acc:0.91\n",
      "Train Epoch:2[48128/60000 (80%)]\t Loss:0.254420 acc:0.93\n",
      "Train Epoch:2[48640/60000 (81%)]\t Loss:0.381138 acc:0.89\n",
      "Train Epoch:2[49152/60000 (82%)]\t Loss:0.393159 acc:0.86\n",
      "Train Epoch:2[49664/60000 (83%)]\t Loss:0.358841 acc:0.90\n",
      "Train Epoch:2[50176/60000 (84%)]\t Loss:0.424856 acc:0.88\n",
      "Train Epoch:2[50688/60000 (84%)]\t Loss:0.335848 acc:0.89\n",
      "Train Epoch:2[51200/60000 (85%)]\t Loss:0.278719 acc:0.92\n",
      "Train Epoch:2[51712/60000 (86%)]\t Loss:0.332554 acc:0.91\n",
      "Train Epoch:2[52224/60000 (87%)]\t Loss:0.313816 acc:0.90\n",
      "Train Epoch:2[52736/60000 (88%)]\t Loss:0.424721 acc:0.87\n",
      "Train Epoch:2[53248/60000 (89%)]\t Loss:0.320063 acc:0.91\n",
      "Train Epoch:2[53760/60000 (90%)]\t Loss:0.325221 acc:0.89\n",
      "Train Epoch:2[54272/60000 (90%)]\t Loss:0.251571 acc:0.91\n",
      "Train Epoch:2[54784/60000 (91%)]\t Loss:0.322411 acc:0.89\n",
      "Train Epoch:2[55296/60000 (92%)]\t Loss:0.272703 acc:0.93\n",
      "Train Epoch:2[55808/60000 (93%)]\t Loss:0.252722 acc:0.92\n",
      "Train Epoch:2[56320/60000 (94%)]\t Loss:0.262198 acc:0.93\n",
      "Train Epoch:2[56832/60000 (95%)]\t Loss:0.257434 acc:0.92\n",
      "Train Epoch:2[57344/60000 (96%)]\t Loss:0.292365 acc:0.92\n",
      "Train Epoch:2[57856/60000 (96%)]\t Loss:0.191635 acc:0.95\n",
      "Train Epoch:2[58368/60000 (97%)]\t Loss:0.184938 acc:0.95\n",
      "Train Epoch:2[58880/60000 (98%)]\t Loss:0.160715 acc:0.95\n",
      "Train Epoch:2[59392/60000 (99%)]\t Loss:0.254129 acc:0.93\n",
      "Train Epoch:2[59904/60000 (100%)]\t Loss:0.376192 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:2 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:2 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:2 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:2 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:2 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:2 [2560/10000 (26%)]\t acc:0.28\n",
      "Test Epoch:2 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:2 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:2 [4096/10000 (41%)]\t acc:0.42\n",
      "Test Epoch:2 [4608/10000 (46%)]\t acc:0.47\n",
      "Test Epoch:2 [5120/10000 (51%)]\t acc:0.51\n",
      "Test Epoch:2 [5632/10000 (56%)]\t acc:0.56\n",
      "Test Epoch:2 [6144/10000 (61%)]\t acc:0.61\n",
      "Test Epoch:2 [6656/10000 (67%)]\t acc:0.66\n",
      "Test Epoch:2 [7168/10000 (72%)]\t acc:0.70\n",
      "Test Epoch:2 [7680/10000 (77%)]\t acc:0.75\n",
      "Test Epoch:2 [8192/10000 (82%)]\t acc:0.80\n",
      "Test Epoch:2 [8704/10000 (87%)]\t acc:0.84\n",
      "Test Epoch:2 [9216/10000 (92%)]\t acc:0.89\n",
      "Test Epoch:2 [9728/10000 (97%)]\t acc:0.92\n",
      "Train Epoch:3[0/60000 (0%)]\t Loss:0.308871 acc:0.92\n",
      "Train Epoch:3[512/60000 (1%)]\t Loss:0.358677 acc:0.90\n",
      "Train Epoch:3[1024/60000 (2%)]\t Loss:0.357629 acc:0.89\n",
      "Train Epoch:3[1536/60000 (3%)]\t Loss:0.232784 acc:0.93\n",
      "Train Epoch:3[2048/60000 (3%)]\t Loss:0.256759 acc:0.93\n",
      "Train Epoch:3[2560/60000 (4%)]\t Loss:0.285260 acc:0.90\n",
      "Train Epoch:3[3072/60000 (5%)]\t Loss:0.268288 acc:0.91\n",
      "Train Epoch:3[3584/60000 (6%)]\t Loss:0.251900 acc:0.93\n",
      "Train Epoch:3[4096/60000 (7%)]\t Loss:0.271718 acc:0.92\n",
      "Train Epoch:3[4608/60000 (8%)]\t Loss:0.320296 acc:0.92\n",
      "Train Epoch:3[5120/60000 (9%)]\t Loss:0.301549 acc:0.91\n",
      "Train Epoch:3[5632/60000 (9%)]\t Loss:0.283697 acc:0.93\n",
      "Train Epoch:3[6144/60000 (10%)]\t Loss:0.197030 acc:0.94\n",
      "Train Epoch:3[6656/60000 (11%)]\t Loss:0.328462 acc:0.90\n",
      "Train Epoch:3[7168/60000 (12%)]\t Loss:0.302995 acc:0.92\n",
      "Train Epoch:3[7680/60000 (13%)]\t Loss:0.302213 acc:0.93\n",
      "Train Epoch:3[8192/60000 (14%)]\t Loss:0.319378 acc:0.91\n",
      "Train Epoch:3[8704/60000 (15%)]\t Loss:0.412634 acc:0.90\n",
      "Train Epoch:3[9216/60000 (15%)]\t Loss:0.306903 acc:0.92\n",
      "Train Epoch:3[9728/60000 (16%)]\t Loss:0.287362 acc:0.92\n",
      "Train Epoch:3[10240/60000 (17%)]\t Loss:0.217488 acc:0.93\n",
      "Train Epoch:3[10752/60000 (18%)]\t Loss:0.250014 acc:0.94\n",
      "Train Epoch:3[11264/60000 (19%)]\t Loss:0.320753 acc:0.90\n",
      "Train Epoch:3[11776/60000 (20%)]\t Loss:0.262516 acc:0.91\n",
      "Train Epoch:3[12288/60000 (20%)]\t Loss:0.349013 acc:0.89\n",
      "Train Epoch:3[12800/60000 (21%)]\t Loss:0.300739 acc:0.91\n",
      "Train Epoch:3[13312/60000 (22%)]\t Loss:0.271837 acc:0.90\n",
      "Train Epoch:3[13824/60000 (23%)]\t Loss:0.382394 acc:0.88\n",
      "Train Epoch:3[14336/60000 (24%)]\t Loss:0.442992 acc:0.86\n",
      "Train Epoch:3[14848/60000 (25%)]\t Loss:0.277190 acc:0.93\n",
      "Train Epoch:3[15360/60000 (26%)]\t Loss:0.290749 acc:0.90\n",
      "Train Epoch:3[15872/60000 (26%)]\t Loss:0.272123 acc:0.92\n",
      "Train Epoch:3[16384/60000 (27%)]\t Loss:0.311618 acc:0.90\n",
      "Train Epoch:3[16896/60000 (28%)]\t Loss:0.268697 acc:0.92\n",
      "Train Epoch:3[17408/60000 (29%)]\t Loss:0.351113 acc:0.89\n",
      "Train Epoch:3[17920/60000 (30%)]\t Loss:0.195838 acc:0.94\n",
      "Train Epoch:3[18432/60000 (31%)]\t Loss:0.240051 acc:0.94\n",
      "Train Epoch:3[18944/60000 (32%)]\t Loss:0.262130 acc:0.92\n",
      "Train Epoch:3[19456/60000 (32%)]\t Loss:0.231338 acc:0.92\n",
      "Train Epoch:3[19968/60000 (33%)]\t Loss:0.282644 acc:0.93\n",
      "Train Epoch:3[20480/60000 (34%)]\t Loss:0.370650 acc:0.90\n",
      "Train Epoch:3[20992/60000 (35%)]\t Loss:0.255608 acc:0.93\n",
      "Train Epoch:3[21504/60000 (36%)]\t Loss:0.217710 acc:0.95\n",
      "Train Epoch:3[22016/60000 (37%)]\t Loss:0.250874 acc:0.91\n",
      "Train Epoch:3[22528/60000 (38%)]\t Loss:0.256321 acc:0.91\n",
      "Train Epoch:3[23040/60000 (38%)]\t Loss:0.231318 acc:0.92\n",
      "Train Epoch:3[23552/60000 (39%)]\t Loss:0.304958 acc:0.91\n",
      "Train Epoch:3[24064/60000 (40%)]\t Loss:0.296627 acc:0.89\n",
      "Train Epoch:3[24576/60000 (41%)]\t Loss:0.330440 acc:0.89\n",
      "Train Epoch:3[25088/60000 (42%)]\t Loss:0.236625 acc:0.92\n",
      "Train Epoch:3[25600/60000 (43%)]\t Loss:0.245981 acc:0.93\n",
      "Train Epoch:3[26112/60000 (44%)]\t Loss:0.328200 acc:0.91\n",
      "Train Epoch:3[26624/60000 (44%)]\t Loss:0.297254 acc:0.92\n",
      "Train Epoch:3[27136/60000 (45%)]\t Loss:0.287603 acc:0.92\n",
      "Train Epoch:3[27648/60000 (46%)]\t Loss:0.217461 acc:0.94\n",
      "Train Epoch:3[28160/60000 (47%)]\t Loss:0.307277 acc:0.91\n",
      "Train Epoch:3[28672/60000 (48%)]\t Loss:0.258058 acc:0.93\n",
      "Train Epoch:3[29184/60000 (49%)]\t Loss:0.261276 acc:0.92\n",
      "Train Epoch:3[29696/60000 (49%)]\t Loss:0.367295 acc:0.89\n",
      "Train Epoch:3[30208/60000 (50%)]\t Loss:0.280453 acc:0.91\n",
      "Train Epoch:3[30720/60000 (51%)]\t Loss:0.343613 acc:0.90\n",
      "Train Epoch:3[31232/60000 (52%)]\t Loss:0.382616 acc:0.88\n",
      "Train Epoch:3[31744/60000 (53%)]\t Loss:0.276561 acc:0.91\n",
      "Train Epoch:3[32256/60000 (54%)]\t Loss:0.303538 acc:0.90\n",
      "Train Epoch:3[32768/60000 (55%)]\t Loss:0.278988 acc:0.95\n",
      "Train Epoch:3[33280/60000 (55%)]\t Loss:0.253626 acc:0.92\n",
      "Train Epoch:3[33792/60000 (56%)]\t Loss:0.166108 acc:0.96\n",
      "Train Epoch:3[34304/60000 (57%)]\t Loss:0.343518 acc:0.89\n",
      "Train Epoch:3[34816/60000 (58%)]\t Loss:0.242620 acc:0.93\n",
      "Train Epoch:3[35328/60000 (59%)]\t Loss:0.234144 acc:0.92\n",
      "Train Epoch:3[35840/60000 (60%)]\t Loss:0.209419 acc:0.93\n",
      "Train Epoch:3[36352/60000 (61%)]\t Loss:0.248282 acc:0.93\n",
      "Train Epoch:3[36864/60000 (61%)]\t Loss:0.324955 acc:0.91\n",
      "Train Epoch:3[37376/60000 (62%)]\t Loss:0.325640 acc:0.90\n",
      "Train Epoch:3[37888/60000 (63%)]\t Loss:0.249072 acc:0.92\n",
      "Train Epoch:3[38400/60000 (64%)]\t Loss:0.263645 acc:0.92\n",
      "Train Epoch:3[38912/60000 (65%)]\t Loss:0.265402 acc:0.93\n",
      "Train Epoch:3[39424/60000 (66%)]\t Loss:0.287501 acc:0.93\n",
      "Train Epoch:3[39936/60000 (67%)]\t Loss:0.240540 acc:0.92\n",
      "Train Epoch:3[40448/60000 (67%)]\t Loss:0.223995 acc:0.94\n",
      "Train Epoch:3[40960/60000 (68%)]\t Loss:0.337749 acc:0.90\n",
      "Train Epoch:3[41472/60000 (69%)]\t Loss:0.269278 acc:0.92\n",
      "Train Epoch:3[41984/60000 (70%)]\t Loss:0.340280 acc:0.91\n",
      "Train Epoch:3[42496/60000 (71%)]\t Loss:0.316702 acc:0.91\n",
      "Train Epoch:3[43008/60000 (72%)]\t Loss:0.226047 acc:0.92\n",
      "Train Epoch:3[43520/60000 (73%)]\t Loss:0.242766 acc:0.94\n",
      "Train Epoch:3[44032/60000 (73%)]\t Loss:0.322230 acc:0.90\n",
      "Train Epoch:3[44544/60000 (74%)]\t Loss:0.267851 acc:0.91\n",
      "Train Epoch:3[45056/60000 (75%)]\t Loss:0.241955 acc:0.93\n",
      "Train Epoch:3[45568/60000 (76%)]\t Loss:0.311593 acc:0.91\n",
      "Train Epoch:3[46080/60000 (77%)]\t Loss:0.285434 acc:0.92\n",
      "Train Epoch:3[46592/60000 (78%)]\t Loss:0.210870 acc:0.93\n",
      "Train Epoch:3[47104/60000 (79%)]\t Loss:0.289440 acc:0.91\n",
      "Train Epoch:3[47616/60000 (79%)]\t Loss:0.230605 acc:0.94\n",
      "Train Epoch:3[48128/60000 (80%)]\t Loss:0.193797 acc:0.94\n",
      "Train Epoch:3[48640/60000 (81%)]\t Loss:0.302456 acc:0.91\n",
      "Train Epoch:3[49152/60000 (82%)]\t Loss:0.317905 acc:0.90\n",
      "Train Epoch:3[49664/60000 (83%)]\t Loss:0.278618 acc:0.91\n",
      "Train Epoch:3[50176/60000 (84%)]\t Loss:0.359677 acc:0.91\n",
      "Train Epoch:3[50688/60000 (84%)]\t Loss:0.249737 acc:0.92\n",
      "Train Epoch:3[51200/60000 (85%)]\t Loss:0.221216 acc:0.93\n",
      "Train Epoch:3[51712/60000 (86%)]\t Loss:0.263854 acc:0.92\n",
      "Train Epoch:3[52224/60000 (87%)]\t Loss:0.242088 acc:0.92\n",
      "Train Epoch:3[52736/60000 (88%)]\t Loss:0.339494 acc:0.90\n",
      "Train Epoch:3[53248/60000 (89%)]\t Loss:0.254618 acc:0.93\n",
      "Train Epoch:3[53760/60000 (90%)]\t Loss:0.263339 acc:0.92\n",
      "Train Epoch:3[54272/60000 (90%)]\t Loss:0.200447 acc:0.94\n",
      "Train Epoch:3[54784/60000 (91%)]\t Loss:0.259826 acc:0.91\n",
      "Train Epoch:3[55296/60000 (92%)]\t Loss:0.215793 acc:0.94\n",
      "Train Epoch:3[55808/60000 (93%)]\t Loss:0.191949 acc:0.94\n",
      "Train Epoch:3[56320/60000 (94%)]\t Loss:0.224981 acc:0.94\n",
      "Train Epoch:3[56832/60000 (95%)]\t Loss:0.189379 acc:0.94\n",
      "Train Epoch:3[57344/60000 (96%)]\t Loss:0.227285 acc:0.94\n",
      "Train Epoch:3[57856/60000 (96%)]\t Loss:0.152717 acc:0.96\n",
      "Train Epoch:3[58368/60000 (97%)]\t Loss:0.142493 acc:0.96\n",
      "Train Epoch:3[58880/60000 (98%)]\t Loss:0.117383 acc:0.97\n",
      "Train Epoch:3[59392/60000 (99%)]\t Loss:0.207431 acc:0.95\n",
      "Train Epoch:3[59904/60000 (100%)]\t Loss:0.299756 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:3 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:3 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:3 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:3 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:3 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:3 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:3 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:3 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:3 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:3 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:3 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:3 [5632/10000 (56%)]\t acc:0.57\n",
      "Test Epoch:3 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:3 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:3 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:3 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:3 [8192/10000 (82%)]\t acc:0.81\n",
      "Test Epoch:3 [8704/10000 (87%)]\t acc:0.86\n",
      "Test Epoch:3 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:3 [9728/10000 (97%)]\t acc:0.93\n",
      "Train Epoch:4[0/60000 (0%)]\t Loss:0.254508 acc:0.93\n",
      "Train Epoch:4[512/60000 (1%)]\t Loss:0.288536 acc:0.91\n",
      "Train Epoch:4[1024/60000 (2%)]\t Loss:0.297942 acc:0.92\n",
      "Train Epoch:4[1536/60000 (3%)]\t Loss:0.181572 acc:0.95\n",
      "Train Epoch:4[2048/60000 (3%)]\t Loss:0.198728 acc:0.94\n",
      "Train Epoch:4[2560/60000 (4%)]\t Loss:0.227693 acc:0.93\n",
      "Train Epoch:4[3072/60000 (5%)]\t Loss:0.200508 acc:0.95\n",
      "Train Epoch:4[3584/60000 (6%)]\t Loss:0.195373 acc:0.95\n",
      "Train Epoch:4[4096/60000 (7%)]\t Loss:0.220046 acc:0.94\n",
      "Train Epoch:4[4608/60000 (8%)]\t Loss:0.258551 acc:0.94\n",
      "Train Epoch:4[5120/60000 (9%)]\t Loss:0.246201 acc:0.93\n",
      "Train Epoch:4[5632/60000 (9%)]\t Loss:0.242732 acc:0.94\n",
      "Train Epoch:4[6144/60000 (10%)]\t Loss:0.158899 acc:0.96\n",
      "Train Epoch:4[6656/60000 (11%)]\t Loss:0.273704 acc:0.91\n",
      "Train Epoch:4[7168/60000 (12%)]\t Loss:0.241674 acc:0.93\n",
      "Train Epoch:4[7680/60000 (13%)]\t Loss:0.239497 acc:0.94\n",
      "Train Epoch:4[8192/60000 (14%)]\t Loss:0.264369 acc:0.93\n",
      "Train Epoch:4[8704/60000 (15%)]\t Loss:0.362466 acc:0.91\n",
      "Train Epoch:4[9216/60000 (15%)]\t Loss:0.252293 acc:0.93\n",
      "Train Epoch:4[9728/60000 (16%)]\t Loss:0.241761 acc:0.93\n",
      "Train Epoch:4[10240/60000 (17%)]\t Loss:0.183062 acc:0.94\n",
      "Train Epoch:4[10752/60000 (18%)]\t Loss:0.213682 acc:0.95\n",
      "Train Epoch:4[11264/60000 (19%)]\t Loss:0.267596 acc:0.92\n",
      "Train Epoch:4[11776/60000 (20%)]\t Loss:0.214506 acc:0.93\n",
      "Train Epoch:4[12288/60000 (20%)]\t Loss:0.284598 acc:0.91\n",
      "Train Epoch:4[12800/60000 (21%)]\t Loss:0.246013 acc:0.92\n",
      "Train Epoch:4[13312/60000 (22%)]\t Loss:0.223516 acc:0.93\n",
      "Train Epoch:4[13824/60000 (23%)]\t Loss:0.307083 acc:0.90\n",
      "Train Epoch:4[14336/60000 (24%)]\t Loss:0.371020 acc:0.88\n",
      "Train Epoch:4[14848/60000 (25%)]\t Loss:0.224155 acc:0.94\n",
      "Train Epoch:4[15360/60000 (26%)]\t Loss:0.242270 acc:0.91\n",
      "Train Epoch:4[15872/60000 (26%)]\t Loss:0.223996 acc:0.93\n",
      "Train Epoch:4[16384/60000 (27%)]\t Loss:0.258856 acc:0.92\n",
      "Train Epoch:4[16896/60000 (28%)]\t Loss:0.217126 acc:0.93\n",
      "Train Epoch:4[17408/60000 (29%)]\t Loss:0.283883 acc:0.91\n",
      "Train Epoch:4[17920/60000 (30%)]\t Loss:0.160166 acc:0.95\n",
      "Train Epoch:4[18432/60000 (31%)]\t Loss:0.187680 acc:0.95\n",
      "Train Epoch:4[18944/60000 (32%)]\t Loss:0.219515 acc:0.93\n",
      "Train Epoch:4[19456/60000 (32%)]\t Loss:0.190717 acc:0.94\n",
      "Train Epoch:4[19968/60000 (33%)]\t Loss:0.231064 acc:0.94\n",
      "Train Epoch:4[20480/60000 (34%)]\t Loss:0.304709 acc:0.91\n",
      "Train Epoch:4[20992/60000 (35%)]\t Loss:0.212093 acc:0.94\n",
      "Train Epoch:4[21504/60000 (36%)]\t Loss:0.177683 acc:0.96\n",
      "Train Epoch:4[22016/60000 (37%)]\t Loss:0.208951 acc:0.93\n",
      "Train Epoch:4[22528/60000 (38%)]\t Loss:0.217898 acc:0.93\n",
      "Train Epoch:4[23040/60000 (38%)]\t Loss:0.174543 acc:0.94\n",
      "Train Epoch:4[23552/60000 (39%)]\t Loss:0.247884 acc:0.93\n",
      "Train Epoch:4[24064/60000 (40%)]\t Loss:0.229447 acc:0.92\n",
      "Train Epoch:4[24576/60000 (41%)]\t Loss:0.271742 acc:0.92\n",
      "Train Epoch:4[25088/60000 (42%)]\t Loss:0.197522 acc:0.94\n",
      "Train Epoch:4[25600/60000 (43%)]\t Loss:0.198629 acc:0.95\n",
      "Train Epoch:4[26112/60000 (44%)]\t Loss:0.277528 acc:0.93\n",
      "Train Epoch:4[26624/60000 (44%)]\t Loss:0.254129 acc:0.93\n",
      "Train Epoch:4[27136/60000 (45%)]\t Loss:0.244639 acc:0.93\n",
      "Train Epoch:4[27648/60000 (46%)]\t Loss:0.178379 acc:0.95\n",
      "Train Epoch:4[28160/60000 (47%)]\t Loss:0.263405 acc:0.93\n",
      "Train Epoch:4[28672/60000 (48%)]\t Loss:0.214937 acc:0.94\n",
      "Train Epoch:4[29184/60000 (49%)]\t Loss:0.213947 acc:0.93\n",
      "Train Epoch:4[29696/60000 (49%)]\t Loss:0.304075 acc:0.91\n",
      "Train Epoch:4[30208/60000 (50%)]\t Loss:0.228794 acc:0.93\n",
      "Train Epoch:4[30720/60000 (51%)]\t Loss:0.285556 acc:0.92\n",
      "Train Epoch:4[31232/60000 (52%)]\t Loss:0.332303 acc:0.90\n",
      "Train Epoch:4[31744/60000 (53%)]\t Loss:0.229916 acc:0.93\n",
      "Train Epoch:4[32256/60000 (54%)]\t Loss:0.254803 acc:0.92\n",
      "Train Epoch:4[32768/60000 (55%)]\t Loss:0.229143 acc:0.96\n",
      "Train Epoch:4[33280/60000 (55%)]\t Loss:0.211161 acc:0.93\n",
      "Train Epoch:4[33792/60000 (56%)]\t Loss:0.131823 acc:0.97\n",
      "Train Epoch:4[34304/60000 (57%)]\t Loss:0.294160 acc:0.90\n",
      "Train Epoch:4[34816/60000 (58%)]\t Loss:0.198291 acc:0.95\n",
      "Train Epoch:4[35328/60000 (59%)]\t Loss:0.196794 acc:0.94\n",
      "Train Epoch:4[35840/60000 (60%)]\t Loss:0.179453 acc:0.94\n",
      "Train Epoch:4[36352/60000 (61%)]\t Loss:0.216454 acc:0.93\n",
      "Train Epoch:4[36864/60000 (61%)]\t Loss:0.275411 acc:0.93\n",
      "Train Epoch:4[37376/60000 (62%)]\t Loss:0.275789 acc:0.91\n",
      "Train Epoch:4[37888/60000 (63%)]\t Loss:0.206922 acc:0.94\n",
      "Train Epoch:4[38400/60000 (64%)]\t Loss:0.223227 acc:0.94\n",
      "Train Epoch:4[38912/60000 (65%)]\t Loss:0.232851 acc:0.93\n",
      "Train Epoch:4[39424/60000 (66%)]\t Loss:0.236736 acc:0.94\n",
      "Train Epoch:4[39936/60000 (67%)]\t Loss:0.196749 acc:0.94\n",
      "Train Epoch:4[40448/60000 (67%)]\t Loss:0.181779 acc:0.95\n",
      "Train Epoch:4[40960/60000 (68%)]\t Loss:0.283613 acc:0.92\n",
      "Train Epoch:4[41472/60000 (69%)]\t Loss:0.223810 acc:0.94\n",
      "Train Epoch:4[41984/60000 (70%)]\t Loss:0.288682 acc:0.91\n",
      "Train Epoch:4[42496/60000 (71%)]\t Loss:0.273763 acc:0.93\n",
      "Train Epoch:4[43008/60000 (72%)]\t Loss:0.188796 acc:0.92\n",
      "Train Epoch:4[43520/60000 (73%)]\t Loss:0.207552 acc:0.94\n",
      "Train Epoch:4[44032/60000 (73%)]\t Loss:0.284343 acc:0.91\n",
      "Train Epoch:4[44544/60000 (74%)]\t Loss:0.223270 acc:0.92\n",
      "Train Epoch:4[45056/60000 (75%)]\t Loss:0.192253 acc:0.94\n",
      "Train Epoch:4[45568/60000 (76%)]\t Loss:0.274983 acc:0.92\n",
      "Train Epoch:4[46080/60000 (77%)]\t Loss:0.246615 acc:0.93\n",
      "Train Epoch:4[46592/60000 (78%)]\t Loss:0.177243 acc:0.94\n",
      "Train Epoch:4[47104/60000 (79%)]\t Loss:0.248155 acc:0.92\n",
      "Train Epoch:4[47616/60000 (79%)]\t Loss:0.190164 acc:0.94\n",
      "Train Epoch:4[48128/60000 (80%)]\t Loss:0.165753 acc:0.95\n",
      "Train Epoch:4[48640/60000 (81%)]\t Loss:0.263028 acc:0.92\n",
      "Train Epoch:4[49152/60000 (82%)]\t Loss:0.280901 acc:0.91\n",
      "Train Epoch:4[49664/60000 (83%)]\t Loss:0.241078 acc:0.92\n",
      "Train Epoch:4[50176/60000 (84%)]\t Loss:0.322238 acc:0.92\n",
      "Train Epoch:4[50688/60000 (84%)]\t Loss:0.204810 acc:0.93\n",
      "Train Epoch:4[51200/60000 (85%)]\t Loss:0.188692 acc:0.94\n",
      "Train Epoch:4[51712/60000 (86%)]\t Loss:0.226228 acc:0.94\n",
      "Train Epoch:4[52224/60000 (87%)]\t Loss:0.196423 acc:0.94\n",
      "Train Epoch:4[52736/60000 (88%)]\t Loss:0.283158 acc:0.92\n",
      "Train Epoch:4[53248/60000 (89%)]\t Loss:0.212125 acc:0.94\n",
      "Train Epoch:4[53760/60000 (90%)]\t Loss:0.222881 acc:0.93\n",
      "Train Epoch:4[54272/60000 (90%)]\t Loss:0.168398 acc:0.95\n",
      "Train Epoch:4[54784/60000 (91%)]\t Loss:0.224572 acc:0.91\n",
      "Train Epoch:4[55296/60000 (92%)]\t Loss:0.187527 acc:0.95\n",
      "Train Epoch:4[55808/60000 (93%)]\t Loss:0.161724 acc:0.95\n",
      "Train Epoch:4[56320/60000 (94%)]\t Loss:0.198944 acc:0.94\n",
      "Train Epoch:4[56832/60000 (95%)]\t Loss:0.155303 acc:0.96\n",
      "Train Epoch:4[57344/60000 (96%)]\t Loss:0.192534 acc:0.95\n",
      "Train Epoch:4[57856/60000 (96%)]\t Loss:0.134972 acc:0.96\n",
      "Train Epoch:4[58368/60000 (97%)]\t Loss:0.119421 acc:0.97\n",
      "Train Epoch:4[58880/60000 (98%)]\t Loss:0.095902 acc:0.97\n",
      "Train Epoch:4[59392/60000 (99%)]\t Loss:0.183150 acc:0.96\n",
      "Train Epoch:4[59904/60000 (100%)]\t Loss:0.270121 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:4 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:4 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:4 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:4 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:4 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:4 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:4 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:4 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:4 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:4 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:4 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:4 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:4 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:4 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:4 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:4 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:4 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:4 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:4 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:4 [9728/10000 (97%)]\t acc:0.94\n",
      "Train Epoch:5[0/60000 (0%)]\t Loss:0.220270 acc:0.94\n",
      "Train Epoch:5[512/60000 (1%)]\t Loss:0.242853 acc:0.93\n",
      "Train Epoch:5[1024/60000 (2%)]\t Loss:0.261582 acc:0.92\n",
      "Train Epoch:5[1536/60000 (3%)]\t Loss:0.149084 acc:0.96\n",
      "Train Epoch:5[2048/60000 (3%)]\t Loss:0.163848 acc:0.96\n",
      "Train Epoch:5[2560/60000 (4%)]\t Loss:0.194972 acc:0.95\n",
      "Train Epoch:5[3072/60000 (5%)]\t Loss:0.159543 acc:0.96\n",
      "Train Epoch:5[3584/60000 (6%)]\t Loss:0.163687 acc:0.96\n",
      "Train Epoch:5[4096/60000 (7%)]\t Loss:0.192667 acc:0.94\n",
      "Train Epoch:5[4608/60000 (8%)]\t Loss:0.217399 acc:0.95\n",
      "Train Epoch:5[5120/60000 (9%)]\t Loss:0.209765 acc:0.94\n",
      "Train Epoch:5[5632/60000 (9%)]\t Loss:0.213674 acc:0.95\n",
      "Train Epoch:5[6144/60000 (10%)]\t Loss:0.140573 acc:0.96\n",
      "Train Epoch:5[6656/60000 (11%)]\t Loss:0.236925 acc:0.94\n",
      "Train Epoch:5[7168/60000 (12%)]\t Loss:0.208352 acc:0.93\n",
      "Train Epoch:5[7680/60000 (13%)]\t Loss:0.202803 acc:0.95\n",
      "Train Epoch:5[8192/60000 (14%)]\t Loss:0.229301 acc:0.93\n",
      "Train Epoch:5[8704/60000 (15%)]\t Loss:0.324263 acc:0.92\n",
      "Train Epoch:5[9216/60000 (15%)]\t Loss:0.214554 acc:0.94\n",
      "Train Epoch:5[9728/60000 (16%)]\t Loss:0.207857 acc:0.94\n",
      "Train Epoch:5[10240/60000 (17%)]\t Loss:0.162621 acc:0.95\n",
      "Train Epoch:5[10752/60000 (18%)]\t Loss:0.186431 acc:0.95\n",
      "Train Epoch:5[11264/60000 (19%)]\t Loss:0.228251 acc:0.93\n",
      "Train Epoch:5[11776/60000 (20%)]\t Loss:0.179777 acc:0.94\n",
      "Train Epoch:5[12288/60000 (20%)]\t Loss:0.245894 acc:0.92\n",
      "Train Epoch:5[12800/60000 (21%)]\t Loss:0.205570 acc:0.93\n",
      "Train Epoch:5[13312/60000 (22%)]\t Loss:0.186610 acc:0.95\n",
      "Train Epoch:5[13824/60000 (23%)]\t Loss:0.255277 acc:0.92\n",
      "Train Epoch:5[14336/60000 (24%)]\t Loss:0.321879 acc:0.90\n",
      "Train Epoch:5[14848/60000 (25%)]\t Loss:0.191968 acc:0.95\n",
      "Train Epoch:5[15360/60000 (26%)]\t Loss:0.211892 acc:0.92\n",
      "Train Epoch:5[15872/60000 (26%)]\t Loss:0.193336 acc:0.94\n",
      "Train Epoch:5[16384/60000 (27%)]\t Loss:0.223973 acc:0.93\n",
      "Train Epoch:5[16896/60000 (28%)]\t Loss:0.181403 acc:0.94\n",
      "Train Epoch:5[17408/60000 (29%)]\t Loss:0.235174 acc:0.94\n",
      "Train Epoch:5[17920/60000 (30%)]\t Loss:0.137747 acc:0.96\n",
      "Train Epoch:5[18432/60000 (31%)]\t Loss:0.154046 acc:0.96\n",
      "Train Epoch:5[18944/60000 (32%)]\t Loss:0.193845 acc:0.94\n",
      "Train Epoch:5[19456/60000 (32%)]\t Loss:0.164358 acc:0.95\n",
      "Train Epoch:5[19968/60000 (33%)]\t Loss:0.196285 acc:0.95\n",
      "Train Epoch:5[20480/60000 (34%)]\t Loss:0.262302 acc:0.92\n",
      "Train Epoch:5[20992/60000 (35%)]\t Loss:0.185098 acc:0.94\n",
      "Train Epoch:5[21504/60000 (36%)]\t Loss:0.153328 acc:0.96\n",
      "Train Epoch:5[22016/60000 (37%)]\t Loss:0.184998 acc:0.94\n",
      "Train Epoch:5[22528/60000 (38%)]\t Loss:0.194612 acc:0.93\n",
      "Train Epoch:5[23040/60000 (38%)]\t Loss:0.139426 acc:0.95\n",
      "Train Epoch:5[23552/60000 (39%)]\t Loss:0.206757 acc:0.94\n",
      "Train Epoch:5[24064/60000 (40%)]\t Loss:0.183876 acc:0.94\n",
      "Train Epoch:5[24576/60000 (41%)]\t Loss:0.234810 acc:0.93\n",
      "Train Epoch:5[25088/60000 (42%)]\t Loss:0.171361 acc:0.95\n",
      "Train Epoch:5[25600/60000 (43%)]\t Loss:0.167786 acc:0.95\n",
      "Train Epoch:5[26112/60000 (44%)]\t Loss:0.244848 acc:0.93\n",
      "Train Epoch:5[26624/60000 (44%)]\t Loss:0.221141 acc:0.94\n",
      "Train Epoch:5[27136/60000 (45%)]\t Loss:0.216638 acc:0.94\n",
      "Train Epoch:5[27648/60000 (46%)]\t Loss:0.153909 acc:0.96\n",
      "Train Epoch:5[28160/60000 (47%)]\t Loss:0.235480 acc:0.94\n",
      "Train Epoch:5[28672/60000 (48%)]\t Loss:0.186935 acc:0.95\n",
      "Train Epoch:5[29184/60000 (49%)]\t Loss:0.185330 acc:0.94\n",
      "Train Epoch:5[29696/60000 (49%)]\t Loss:0.258379 acc:0.92\n",
      "Train Epoch:5[30208/60000 (50%)]\t Loss:0.189884 acc:0.95\n",
      "Train Epoch:5[30720/60000 (51%)]\t Loss:0.238433 acc:0.93\n",
      "Train Epoch:5[31232/60000 (52%)]\t Loss:0.287850 acc:0.91\n",
      "Train Epoch:5[31744/60000 (53%)]\t Loss:0.196361 acc:0.95\n",
      "Train Epoch:5[32256/60000 (54%)]\t Loss:0.224003 acc:0.93\n",
      "Train Epoch:5[32768/60000 (55%)]\t Loss:0.196333 acc:0.96\n",
      "Train Epoch:5[33280/60000 (55%)]\t Loss:0.184653 acc:0.94\n",
      "Train Epoch:5[33792/60000 (56%)]\t Loss:0.110948 acc:0.97\n",
      "Train Epoch:5[34304/60000 (57%)]\t Loss:0.261085 acc:0.92\n",
      "Train Epoch:5[34816/60000 (58%)]\t Loss:0.167173 acc:0.95\n",
      "Train Epoch:5[35328/60000 (59%)]\t Loss:0.171055 acc:0.94\n",
      "Train Epoch:5[35840/60000 (60%)]\t Loss:0.160497 acc:0.95\n",
      "Train Epoch:5[36352/60000 (61%)]\t Loss:0.193056 acc:0.94\n",
      "Train Epoch:5[36864/60000 (61%)]\t Loss:0.238936 acc:0.94\n",
      "Train Epoch:5[37376/60000 (62%)]\t Loss:0.237585 acc:0.93\n",
      "Train Epoch:5[37888/60000 (63%)]\t Loss:0.171100 acc:0.94\n",
      "Train Epoch:5[38400/60000 (64%)]\t Loss:0.195171 acc:0.94\n",
      "Train Epoch:5[38912/60000 (65%)]\t Loss:0.207041 acc:0.93\n",
      "Train Epoch:5[39424/60000 (66%)]\t Loss:0.200912 acc:0.94\n",
      "Train Epoch:5[39936/60000 (67%)]\t Loss:0.171629 acc:0.96\n",
      "Train Epoch:5[40448/60000 (67%)]\t Loss:0.153245 acc:0.96\n",
      "Train Epoch:5[40960/60000 (68%)]\t Loss:0.244357 acc:0.93\n",
      "Train Epoch:5[41472/60000 (69%)]\t Loss:0.191187 acc:0.95\n",
      "Train Epoch:5[41984/60000 (70%)]\t Loss:0.253672 acc:0.92\n",
      "Train Epoch:5[42496/60000 (71%)]\t Loss:0.240684 acc:0.93\n",
      "Train Epoch:5[43008/60000 (72%)]\t Loss:0.162177 acc:0.94\n",
      "Train Epoch:5[43520/60000 (73%)]\t Loss:0.181914 acc:0.95\n",
      "Train Epoch:5[44032/60000 (73%)]\t Loss:0.252069 acc:0.92\n",
      "Train Epoch:5[44544/60000 (74%)]\t Loss:0.194970 acc:0.93\n",
      "Train Epoch:5[45056/60000 (75%)]\t Loss:0.159242 acc:0.95\n",
      "Train Epoch:5[45568/60000 (76%)]\t Loss:0.252895 acc:0.93\n",
      "Train Epoch:5[46080/60000 (77%)]\t Loss:0.220642 acc:0.93\n",
      "Train Epoch:5[46592/60000 (78%)]\t Loss:0.152274 acc:0.94\n",
      "Train Epoch:5[47104/60000 (79%)]\t Loss:0.226313 acc:0.93\n",
      "Train Epoch:5[47616/60000 (79%)]\t Loss:0.161530 acc:0.95\n",
      "Train Epoch:5[48128/60000 (80%)]\t Loss:0.144115 acc:0.96\n",
      "Train Epoch:5[48640/60000 (81%)]\t Loss:0.231882 acc:0.93\n",
      "Train Epoch:5[49152/60000 (82%)]\t Loss:0.251480 acc:0.92\n",
      "Train Epoch:5[49664/60000 (83%)]\t Loss:0.210631 acc:0.94\n",
      "Train Epoch:5[50176/60000 (84%)]\t Loss:0.292599 acc:0.92\n",
      "Train Epoch:5[50688/60000 (84%)]\t Loss:0.171562 acc:0.95\n",
      "Train Epoch:5[51200/60000 (85%)]\t Loss:0.168267 acc:0.94\n",
      "Train Epoch:5[51712/60000 (86%)]\t Loss:0.199527 acc:0.94\n",
      "Train Epoch:5[52224/60000 (87%)]\t Loss:0.165424 acc:0.94\n",
      "Train Epoch:5[52736/60000 (88%)]\t Loss:0.248417 acc:0.93\n",
      "Train Epoch:5[53248/60000 (89%)]\t Loss:0.183295 acc:0.95\n",
      "Train Epoch:5[53760/60000 (90%)]\t Loss:0.196980 acc:0.94\n",
      "Train Epoch:5[54272/60000 (90%)]\t Loss:0.146611 acc:0.96\n",
      "Train Epoch:5[54784/60000 (91%)]\t Loss:0.200572 acc:0.92\n",
      "Train Epoch:5[55296/60000 (92%)]\t Loss:0.165609 acc:0.95\n",
      "Train Epoch:5[55808/60000 (93%)]\t Loss:0.141912 acc:0.95\n",
      "Train Epoch:5[56320/60000 (94%)]\t Loss:0.172529 acc:0.95\n",
      "Train Epoch:5[56832/60000 (95%)]\t Loss:0.132306 acc:0.96\n",
      "Train Epoch:5[57344/60000 (96%)]\t Loss:0.169566 acc:0.95\n",
      "Train Epoch:5[57856/60000 (96%)]\t Loss:0.121823 acc:0.97\n",
      "Train Epoch:5[58368/60000 (97%)]\t Loss:0.103282 acc:0.97\n",
      "Train Epoch:5[58880/60000 (98%)]\t Loss:0.084087 acc:0.97\n",
      "Train Epoch:5[59392/60000 (99%)]\t Loss:0.162962 acc:0.97\n",
      "Train Epoch:5[59904/60000 (100%)]\t Loss:0.260928 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:5 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:5 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:5 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:5 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:5 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:5 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:5 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:5 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:5 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:5 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:5 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:5 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:5 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:5 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:5 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:5 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:5 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:5 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:5 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:5 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:6[0/60000 (0%)]\t Loss:0.198449 acc:0.94\n",
      "Train Epoch:6[512/60000 (1%)]\t Loss:0.209230 acc:0.95\n",
      "Train Epoch:6[1024/60000 (2%)]\t Loss:0.234292 acc:0.93\n",
      "Train Epoch:6[1536/60000 (3%)]\t Loss:0.127954 acc:0.96\n",
      "Train Epoch:6[2048/60000 (3%)]\t Loss:0.136808 acc:0.96\n",
      "Train Epoch:6[2560/60000 (4%)]\t Loss:0.168740 acc:0.96\n",
      "Train Epoch:6[3072/60000 (5%)]\t Loss:0.130535 acc:0.97\n",
      "Train Epoch:6[3584/60000 (6%)]\t Loss:0.139454 acc:0.96\n",
      "Train Epoch:6[4096/60000 (7%)]\t Loss:0.173642 acc:0.95\n",
      "Train Epoch:6[4608/60000 (8%)]\t Loss:0.188917 acc:0.95\n",
      "Train Epoch:6[5120/60000 (9%)]\t Loss:0.182659 acc:0.95\n",
      "Train Epoch:6[5632/60000 (9%)]\t Loss:0.192573 acc:0.96\n",
      "Train Epoch:6[6144/60000 (10%)]\t Loss:0.133302 acc:0.96\n",
      "Train Epoch:6[6656/60000 (11%)]\t Loss:0.210485 acc:0.95\n",
      "Train Epoch:6[7168/60000 (12%)]\t Loss:0.184181 acc:0.94\n",
      "Train Epoch:6[7680/60000 (13%)]\t Loss:0.175239 acc:0.95\n",
      "Train Epoch:6[8192/60000 (14%)]\t Loss:0.199988 acc:0.94\n",
      "Train Epoch:6[8704/60000 (15%)]\t Loss:0.291520 acc:0.92\n",
      "Train Epoch:6[9216/60000 (15%)]\t Loss:0.188395 acc:0.94\n",
      "Train Epoch:6[9728/60000 (16%)]\t Loss:0.184515 acc:0.95\n",
      "Train Epoch:6[10240/60000 (17%)]\t Loss:0.148256 acc:0.95\n",
      "Train Epoch:6[10752/60000 (18%)]\t Loss:0.165198 acc:0.96\n",
      "Train Epoch:6[11264/60000 (19%)]\t Loss:0.195634 acc:0.94\n",
      "Train Epoch:6[11776/60000 (20%)]\t Loss:0.157178 acc:0.96\n",
      "Train Epoch:6[12288/60000 (20%)]\t Loss:0.220761 acc:0.93\n",
      "Train Epoch:6[12800/60000 (21%)]\t Loss:0.181982 acc:0.94\n",
      "Train Epoch:6[13312/60000 (22%)]\t Loss:0.159336 acc:0.96\n",
      "Train Epoch:6[13824/60000 (23%)]\t Loss:0.216079 acc:0.92\n",
      "Train Epoch:6[14336/60000 (24%)]\t Loss:0.277429 acc:0.91\n",
      "Train Epoch:6[14848/60000 (25%)]\t Loss:0.167403 acc:0.95\n",
      "Train Epoch:6[15360/60000 (26%)]\t Loss:0.190346 acc:0.94\n",
      "Train Epoch:6[15872/60000 (26%)]\t Loss:0.171665 acc:0.95\n",
      "Train Epoch:6[16384/60000 (27%)]\t Loss:0.199317 acc:0.95\n",
      "Train Epoch:6[16896/60000 (28%)]\t Loss:0.159887 acc:0.95\n",
      "Train Epoch:6[17408/60000 (29%)]\t Loss:0.203251 acc:0.94\n",
      "Train Epoch:6[17920/60000 (30%)]\t Loss:0.124999 acc:0.96\n",
      "Train Epoch:6[18432/60000 (31%)]\t Loss:0.132987 acc:0.96\n",
      "Train Epoch:6[18944/60000 (32%)]\t Loss:0.176320 acc:0.94\n",
      "Train Epoch:6[19456/60000 (32%)]\t Loss:0.150008 acc:0.96\n",
      "Train Epoch:6[19968/60000 (33%)]\t Loss:0.175777 acc:0.95\n",
      "Train Epoch:6[20480/60000 (34%)]\t Loss:0.227662 acc:0.94\n",
      "Train Epoch:6[20992/60000 (35%)]\t Loss:0.163371 acc:0.95\n",
      "Train Epoch:6[21504/60000 (36%)]\t Loss:0.133871 acc:0.97\n",
      "Train Epoch:6[22016/60000 (37%)]\t Loss:0.167521 acc:0.94\n",
      "Train Epoch:6[22528/60000 (38%)]\t Loss:0.176879 acc:0.94\n",
      "Train Epoch:6[23040/60000 (38%)]\t Loss:0.115761 acc:0.96\n",
      "Train Epoch:6[23552/60000 (39%)]\t Loss:0.180199 acc:0.96\n",
      "Train Epoch:6[24064/60000 (40%)]\t Loss:0.155313 acc:0.95\n",
      "Train Epoch:6[24576/60000 (41%)]\t Loss:0.206410 acc:0.93\n",
      "Train Epoch:6[25088/60000 (42%)]\t Loss:0.154306 acc:0.96\n",
      "Train Epoch:6[25600/60000 (43%)]\t Loss:0.148393 acc:0.95\n",
      "Train Epoch:6[26112/60000 (44%)]\t Loss:0.218886 acc:0.94\n",
      "Train Epoch:6[26624/60000 (44%)]\t Loss:0.194094 acc:0.95\n",
      "Train Epoch:6[27136/60000 (45%)]\t Loss:0.191412 acc:0.94\n",
      "Train Epoch:6[27648/60000 (46%)]\t Loss:0.136424 acc:0.96\n",
      "Train Epoch:6[28160/60000 (47%)]\t Loss:0.211264 acc:0.95\n",
      "Train Epoch:6[28672/60000 (48%)]\t Loss:0.164437 acc:0.95\n",
      "Train Epoch:6[29184/60000 (49%)]\t Loss:0.165283 acc:0.94\n",
      "Train Epoch:6[29696/60000 (49%)]\t Loss:0.225604 acc:0.93\n",
      "Train Epoch:6[30208/60000 (50%)]\t Loss:0.159808 acc:0.96\n",
      "Train Epoch:6[30720/60000 (51%)]\t Loss:0.201274 acc:0.94\n",
      "Train Epoch:6[31232/60000 (52%)]\t Loss:0.252521 acc:0.93\n",
      "Train Epoch:6[31744/60000 (53%)]\t Loss:0.168940 acc:0.95\n",
      "Train Epoch:6[32256/60000 (54%)]\t Loss:0.194044 acc:0.95\n",
      "Train Epoch:6[32768/60000 (55%)]\t Loss:0.171775 acc:0.96\n",
      "Train Epoch:6[33280/60000 (55%)]\t Loss:0.165104 acc:0.94\n",
      "Train Epoch:6[33792/60000 (56%)]\t Loss:0.096913 acc:0.97\n",
      "Train Epoch:6[34304/60000 (57%)]\t Loss:0.238394 acc:0.93\n",
      "Train Epoch:6[34816/60000 (58%)]\t Loss:0.146625 acc:0.95\n",
      "Train Epoch:6[35328/60000 (59%)]\t Loss:0.153155 acc:0.95\n",
      "Train Epoch:6[35840/60000 (60%)]\t Loss:0.143707 acc:0.95\n",
      "Train Epoch:6[36352/60000 (61%)]\t Loss:0.173844 acc:0.94\n",
      "Train Epoch:6[36864/60000 (61%)]\t Loss:0.210316 acc:0.95\n",
      "Train Epoch:6[37376/60000 (62%)]\t Loss:0.207373 acc:0.94\n",
      "Train Epoch:6[37888/60000 (63%)]\t Loss:0.142424 acc:0.95\n",
      "Train Epoch:6[38400/60000 (64%)]\t Loss:0.170430 acc:0.95\n",
      "Train Epoch:6[38912/60000 (65%)]\t Loss:0.187289 acc:0.93\n",
      "Train Epoch:6[39424/60000 (66%)]\t Loss:0.175085 acc:0.95\n",
      "Train Epoch:6[39936/60000 (67%)]\t Loss:0.152071 acc:0.97\n",
      "Train Epoch:6[40448/60000 (67%)]\t Loss:0.131113 acc:0.96\n",
      "Train Epoch:6[40960/60000 (68%)]\t Loss:0.215786 acc:0.93\n",
      "Train Epoch:6[41472/60000 (69%)]\t Loss:0.167813 acc:0.96\n",
      "Train Epoch:6[41984/60000 (70%)]\t Loss:0.227651 acc:0.93\n",
      "Train Epoch:6[42496/60000 (71%)]\t Loss:0.215040 acc:0.94\n",
      "Train Epoch:6[43008/60000 (72%)]\t Loss:0.144561 acc:0.95\n",
      "Train Epoch:6[43520/60000 (73%)]\t Loss:0.160956 acc:0.96\n",
      "Train Epoch:6[44032/60000 (73%)]\t Loss:0.221833 acc:0.93\n",
      "Train Epoch:6[44544/60000 (74%)]\t Loss:0.175476 acc:0.94\n",
      "Train Epoch:6[45056/60000 (75%)]\t Loss:0.135647 acc:0.95\n",
      "Train Epoch:6[45568/60000 (76%)]\t Loss:0.235703 acc:0.94\n",
      "Train Epoch:6[46080/60000 (77%)]\t Loss:0.200957 acc:0.94\n",
      "Train Epoch:6[46592/60000 (78%)]\t Loss:0.136051 acc:0.95\n",
      "Train Epoch:6[47104/60000 (79%)]\t Loss:0.212166 acc:0.94\n",
      "Train Epoch:6[47616/60000 (79%)]\t Loss:0.145064 acc:0.95\n",
      "Train Epoch:6[48128/60000 (80%)]\t Loss:0.128282 acc:0.96\n",
      "Train Epoch:6[48640/60000 (81%)]\t Loss:0.211545 acc:0.94\n",
      "Train Epoch:6[49152/60000 (82%)]\t Loss:0.226531 acc:0.93\n",
      "Train Epoch:6[49664/60000 (83%)]\t Loss:0.187430 acc:0.95\n",
      "Train Epoch:6[50176/60000 (84%)]\t Loss:0.267340 acc:0.93\n",
      "Train Epoch:6[50688/60000 (84%)]\t Loss:0.143533 acc:0.96\n",
      "Train Epoch:6[51200/60000 (85%)]\t Loss:0.154487 acc:0.95\n",
      "Train Epoch:6[51712/60000 (86%)]\t Loss:0.176853 acc:0.96\n",
      "Train Epoch:6[52224/60000 (87%)]\t Loss:0.144071 acc:0.95\n",
      "Train Epoch:6[52736/60000 (88%)]\t Loss:0.224413 acc:0.94\n",
      "Train Epoch:6[53248/60000 (89%)]\t Loss:0.162624 acc:0.96\n",
      "Train Epoch:6[53760/60000 (90%)]\t Loss:0.179384 acc:0.94\n",
      "Train Epoch:6[54272/60000 (90%)]\t Loss:0.130697 acc:0.96\n",
      "Train Epoch:6[54784/60000 (91%)]\t Loss:0.182213 acc:0.93\n",
      "Train Epoch:6[55296/60000 (92%)]\t Loss:0.147256 acc:0.96\n",
      "Train Epoch:6[55808/60000 (93%)]\t Loss:0.127658 acc:0.95\n",
      "Train Epoch:6[56320/60000 (94%)]\t Loss:0.147952 acc:0.95\n",
      "Train Epoch:6[56832/60000 (95%)]\t Loss:0.115314 acc:0.96\n",
      "Train Epoch:6[57344/60000 (96%)]\t Loss:0.151902 acc:0.95\n",
      "Train Epoch:6[57856/60000 (96%)]\t Loss:0.105997 acc:0.97\n",
      "Train Epoch:6[58368/60000 (97%)]\t Loss:0.091543 acc:0.97\n",
      "Train Epoch:6[58880/60000 (98%)]\t Loss:0.073525 acc:0.97\n",
      "Train Epoch:6[59392/60000 (99%)]\t Loss:0.147529 acc:0.97\n",
      "Train Epoch:6[59904/60000 (100%)]\t Loss:0.252095 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:6 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:6 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:6 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:6 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:6 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:6 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:6 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:6 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:6 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:6 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:6 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:6 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:6 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:6 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:6 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:6 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:6 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:6 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:6 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:6 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:7[0/60000 (0%)]\t Loss:0.182957 acc:0.95\n",
      "Train Epoch:7[512/60000 (1%)]\t Loss:0.185942 acc:0.95\n",
      "Train Epoch:7[1024/60000 (2%)]\t Loss:0.213673 acc:0.93\n",
      "Train Epoch:7[1536/60000 (3%)]\t Loss:0.114374 acc:0.96\n",
      "Train Epoch:7[2048/60000 (3%)]\t Loss:0.115749 acc:0.96\n",
      "Train Epoch:7[2560/60000 (4%)]\t Loss:0.147356 acc:0.96\n",
      "Train Epoch:7[3072/60000 (5%)]\t Loss:0.106848 acc:0.97\n",
      "Train Epoch:7[3584/60000 (6%)]\t Loss:0.117573 acc:0.96\n",
      "Train Epoch:7[4096/60000 (7%)]\t Loss:0.153986 acc:0.95\n",
      "Train Epoch:7[4608/60000 (8%)]\t Loss:0.167013 acc:0.96\n",
      "Train Epoch:7[5120/60000 (9%)]\t Loss:0.162430 acc:0.96\n",
      "Train Epoch:7[5632/60000 (9%)]\t Loss:0.175455 acc:0.96\n",
      "Train Epoch:7[6144/60000 (10%)]\t Loss:0.126339 acc:0.96\n",
      "Train Epoch:7[6656/60000 (11%)]\t Loss:0.191567 acc:0.96\n",
      "Train Epoch:7[7168/60000 (12%)]\t Loss:0.167936 acc:0.94\n",
      "Train Epoch:7[7680/60000 (13%)]\t Loss:0.156138 acc:0.95\n",
      "Train Epoch:7[8192/60000 (14%)]\t Loss:0.177550 acc:0.95\n",
      "Train Epoch:7[8704/60000 (15%)]\t Loss:0.264606 acc:0.92\n",
      "Train Epoch:7[9216/60000 (15%)]\t Loss:0.166239 acc:0.95\n",
      "Train Epoch:7[9728/60000 (16%)]\t Loss:0.167229 acc:0.95\n",
      "Train Epoch:7[10240/60000 (17%)]\t Loss:0.132263 acc:0.96\n",
      "Train Epoch:7[10752/60000 (18%)]\t Loss:0.147253 acc:0.96\n",
      "Train Epoch:7[11264/60000 (19%)]\t Loss:0.169511 acc:0.95\n",
      "Train Epoch:7[11776/60000 (20%)]\t Loss:0.141729 acc:0.96\n",
      "Train Epoch:7[12288/60000 (20%)]\t Loss:0.201722 acc:0.94\n",
      "Train Epoch:7[12800/60000 (21%)]\t Loss:0.165717 acc:0.95\n",
      "Train Epoch:7[13312/60000 (22%)]\t Loss:0.140580 acc:0.97\n",
      "Train Epoch:7[13824/60000 (23%)]\t Loss:0.189965 acc:0.93\n",
      "Train Epoch:7[14336/60000 (24%)]\t Loss:0.243866 acc:0.91\n",
      "Train Epoch:7[14848/60000 (25%)]\t Loss:0.147615 acc:0.96\n",
      "Train Epoch:7[15360/60000 (26%)]\t Loss:0.173177 acc:0.94\n",
      "Train Epoch:7[15872/60000 (26%)]\t Loss:0.153241 acc:0.95\n",
      "Train Epoch:7[16384/60000 (27%)]\t Loss:0.177184 acc:0.96\n",
      "Train Epoch:7[16896/60000 (28%)]\t Loss:0.142938 acc:0.95\n",
      "Train Epoch:7[17408/60000 (29%)]\t Loss:0.181946 acc:0.95\n",
      "Train Epoch:7[17920/60000 (30%)]\t Loss:0.114048 acc:0.96\n",
      "Train Epoch:7[18432/60000 (31%)]\t Loss:0.118413 acc:0.97\n",
      "Train Epoch:7[18944/60000 (32%)]\t Loss:0.160348 acc:0.95\n",
      "Train Epoch:7[19456/60000 (32%)]\t Loss:0.138977 acc:0.96\n",
      "Train Epoch:7[19968/60000 (33%)]\t Loss:0.162406 acc:0.95\n",
      "Train Epoch:7[20480/60000 (34%)]\t Loss:0.202505 acc:0.94\n",
      "Train Epoch:7[20992/60000 (35%)]\t Loss:0.146536 acc:0.95\n",
      "Train Epoch:7[21504/60000 (36%)]\t Loss:0.117902 acc:0.97\n",
      "Train Epoch:7[22016/60000 (37%)]\t Loss:0.153014 acc:0.95\n",
      "Train Epoch:7[22528/60000 (38%)]\t Loss:0.158636 acc:0.94\n",
      "Train Epoch:7[23040/60000 (38%)]\t Loss:0.097754 acc:0.97\n",
      "Train Epoch:7[23552/60000 (39%)]\t Loss:0.163811 acc:0.96\n",
      "Train Epoch:7[24064/60000 (40%)]\t Loss:0.139030 acc:0.95\n",
      "Train Epoch:7[24576/60000 (41%)]\t Loss:0.180458 acc:0.95\n",
      "Train Epoch:7[25088/60000 (42%)]\t Loss:0.140765 acc:0.96\n",
      "Train Epoch:7[25600/60000 (43%)]\t Loss:0.135264 acc:0.96\n",
      "Train Epoch:7[26112/60000 (44%)]\t Loss:0.198196 acc:0.94\n",
      "Train Epoch:7[26624/60000 (44%)]\t Loss:0.176323 acc:0.95\n",
      "Train Epoch:7[27136/60000 (45%)]\t Loss:0.172509 acc:0.95\n",
      "Train Epoch:7[27648/60000 (46%)]\t Loss:0.125812 acc:0.96\n",
      "Train Epoch:7[28160/60000 (47%)]\t Loss:0.192205 acc:0.95\n",
      "Train Epoch:7[28672/60000 (48%)]\t Loss:0.145583 acc:0.96\n",
      "Train Epoch:7[29184/60000 (49%)]\t Loss:0.148815 acc:0.95\n",
      "Train Epoch:7[29696/60000 (49%)]\t Loss:0.204410 acc:0.93\n",
      "Train Epoch:7[30208/60000 (50%)]\t Loss:0.138358 acc:0.96\n",
      "Train Epoch:7[30720/60000 (51%)]\t Loss:0.177016 acc:0.95\n",
      "Train Epoch:7[31232/60000 (52%)]\t Loss:0.229438 acc:0.93\n",
      "Train Epoch:7[31744/60000 (53%)]\t Loss:0.150461 acc:0.96\n",
      "Train Epoch:7[32256/60000 (54%)]\t Loss:0.174926 acc:0.95\n",
      "Train Epoch:7[32768/60000 (55%)]\t Loss:0.151989 acc:0.97\n",
      "Train Epoch:7[33280/60000 (55%)]\t Loss:0.148991 acc:0.95\n",
      "Train Epoch:7[33792/60000 (56%)]\t Loss:0.086552 acc:0.98\n",
      "Train Epoch:7[34304/60000 (57%)]\t Loss:0.219161 acc:0.94\n",
      "Train Epoch:7[34816/60000 (58%)]\t Loss:0.134223 acc:0.96\n",
      "Train Epoch:7[35328/60000 (59%)]\t Loss:0.141097 acc:0.95\n",
      "Train Epoch:7[35840/60000 (60%)]\t Loss:0.133411 acc:0.95\n",
      "Train Epoch:7[36352/60000 (61%)]\t Loss:0.158958 acc:0.95\n",
      "Train Epoch:7[36864/60000 (61%)]\t Loss:0.187902 acc:0.96\n",
      "Train Epoch:7[37376/60000 (62%)]\t Loss:0.188168 acc:0.95\n",
      "Train Epoch:7[37888/60000 (63%)]\t Loss:0.120680 acc:0.97\n",
      "Train Epoch:7[38400/60000 (64%)]\t Loss:0.153255 acc:0.95\n",
      "Train Epoch:7[38912/60000 (65%)]\t Loss:0.168905 acc:0.94\n",
      "Train Epoch:7[39424/60000 (66%)]\t Loss:0.155216 acc:0.96\n",
      "Train Epoch:7[39936/60000 (67%)]\t Loss:0.135623 acc:0.97\n",
      "Train Epoch:7[40448/60000 (67%)]\t Loss:0.115706 acc:0.96\n",
      "Train Epoch:7[40960/60000 (68%)]\t Loss:0.194098 acc:0.95\n",
      "Train Epoch:7[41472/60000 (69%)]\t Loss:0.152134 acc:0.96\n",
      "Train Epoch:7[41984/60000 (70%)]\t Loss:0.209856 acc:0.93\n",
      "Train Epoch:7[42496/60000 (71%)]\t Loss:0.195859 acc:0.94\n",
      "Train Epoch:7[43008/60000 (72%)]\t Loss:0.131030 acc:0.95\n",
      "Train Epoch:7[43520/60000 (73%)]\t Loss:0.145178 acc:0.95\n",
      "Train Epoch:7[44032/60000 (73%)]\t Loss:0.198055 acc:0.94\n",
      "Train Epoch:7[44544/60000 (74%)]\t Loss:0.159859 acc:0.95\n",
      "Train Epoch:7[45056/60000 (75%)]\t Loss:0.117594 acc:0.96\n",
      "Train Epoch:7[45568/60000 (76%)]\t Loss:0.220515 acc:0.94\n",
      "Train Epoch:7[46080/60000 (77%)]\t Loss:0.186260 acc:0.94\n",
      "Train Epoch:7[46592/60000 (78%)]\t Loss:0.122167 acc:0.96\n",
      "Train Epoch:7[47104/60000 (79%)]\t Loss:0.202836 acc:0.93\n",
      "Train Epoch:7[47616/60000 (79%)]\t Loss:0.131802 acc:0.95\n",
      "Train Epoch:7[48128/60000 (80%)]\t Loss:0.113638 acc:0.96\n",
      "Train Epoch:7[48640/60000 (81%)]\t Loss:0.195862 acc:0.94\n",
      "Train Epoch:7[49152/60000 (82%)]\t Loss:0.210219 acc:0.93\n",
      "Train Epoch:7[49664/60000 (83%)]\t Loss:0.168811 acc:0.95\n",
      "Train Epoch:7[50176/60000 (84%)]\t Loss:0.245791 acc:0.94\n",
      "Train Epoch:7[50688/60000 (84%)]\t Loss:0.121920 acc:0.96\n",
      "Train Epoch:7[51200/60000 (85%)]\t Loss:0.142936 acc:0.95\n",
      "Train Epoch:7[51712/60000 (86%)]\t Loss:0.159559 acc:0.96\n",
      "Train Epoch:7[52224/60000 (87%)]\t Loss:0.127349 acc:0.96\n",
      "Train Epoch:7[52736/60000 (88%)]\t Loss:0.208393 acc:0.95\n",
      "Train Epoch:7[53248/60000 (89%)]\t Loss:0.148893 acc:0.96\n",
      "Train Epoch:7[53760/60000 (90%)]\t Loss:0.163700 acc:0.96\n",
      "Train Epoch:7[54272/60000 (90%)]\t Loss:0.117802 acc:0.97\n",
      "Train Epoch:7[54784/60000 (91%)]\t Loss:0.165888 acc:0.94\n",
      "Train Epoch:7[55296/60000 (92%)]\t Loss:0.134883 acc:0.96\n",
      "Train Epoch:7[55808/60000 (93%)]\t Loss:0.115854 acc:0.96\n",
      "Train Epoch:7[56320/60000 (94%)]\t Loss:0.130858 acc:0.96\n",
      "Train Epoch:7[56832/60000 (95%)]\t Loss:0.103354 acc:0.97\n",
      "Train Epoch:7[57344/60000 (96%)]\t Loss:0.137904 acc:0.96\n",
      "Train Epoch:7[57856/60000 (96%)]\t Loss:0.095110 acc:0.97\n",
      "Train Epoch:7[58368/60000 (97%)]\t Loss:0.083286 acc:0.97\n",
      "Train Epoch:7[58880/60000 (98%)]\t Loss:0.065821 acc:0.98\n",
      "Train Epoch:7[59392/60000 (99%)]\t Loss:0.135310 acc:0.98\n",
      "Train Epoch:7[59904/60000 (100%)]\t Loss:0.242018 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:7 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:7 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:7 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:7 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:7 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:7 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:7 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:7 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:7 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:7 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:7 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:7 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:7 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:7 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:7 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:7 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:7 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:7 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:7 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:7 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:8[0/60000 (0%)]\t Loss:0.169358 acc:0.95\n",
      "Train Epoch:8[512/60000 (1%)]\t Loss:0.170212 acc:0.96\n",
      "Train Epoch:8[1024/60000 (2%)]\t Loss:0.196239 acc:0.94\n",
      "Train Epoch:8[1536/60000 (3%)]\t Loss:0.103739 acc:0.97\n",
      "Train Epoch:8[2048/60000 (3%)]\t Loss:0.100169 acc:0.97\n",
      "Train Epoch:8[2560/60000 (4%)]\t Loss:0.130480 acc:0.97\n",
      "Train Epoch:8[3072/60000 (5%)]\t Loss:0.090519 acc:0.97\n",
      "Train Epoch:8[3584/60000 (6%)]\t Loss:0.101734 acc:0.98\n",
      "Train Epoch:8[4096/60000 (7%)]\t Loss:0.139631 acc:0.96\n",
      "Train Epoch:8[4608/60000 (8%)]\t Loss:0.151604 acc:0.96\n",
      "Train Epoch:8[5120/60000 (9%)]\t Loss:0.147798 acc:0.96\n",
      "Train Epoch:8[5632/60000 (9%)]\t Loss:0.162603 acc:0.96\n",
      "Train Epoch:8[6144/60000 (10%)]\t Loss:0.120624 acc:0.96\n",
      "Train Epoch:8[6656/60000 (11%)]\t Loss:0.177040 acc:0.96\n",
      "Train Epoch:8[7168/60000 (12%)]\t Loss:0.156268 acc:0.95\n",
      "Train Epoch:8[7680/60000 (13%)]\t Loss:0.142517 acc:0.95\n",
      "Train Epoch:8[8192/60000 (14%)]\t Loss:0.161687 acc:0.96\n",
      "Train Epoch:8[8704/60000 (15%)]\t Loss:0.245228 acc:0.93\n",
      "Train Epoch:8[9216/60000 (15%)]\t Loss:0.152148 acc:0.95\n",
      "Train Epoch:8[9728/60000 (16%)]\t Loss:0.152836 acc:0.95\n",
      "Train Epoch:8[10240/60000 (17%)]\t Loss:0.120140 acc:0.96\n",
      "Train Epoch:8[10752/60000 (18%)]\t Loss:0.132908 acc:0.96\n",
      "Train Epoch:8[11264/60000 (19%)]\t Loss:0.148523 acc:0.95\n",
      "Train Epoch:8[11776/60000 (20%)]\t Loss:0.129712 acc:0.96\n",
      "Train Epoch:8[12288/60000 (20%)]\t Loss:0.181683 acc:0.95\n",
      "Train Epoch:8[12800/60000 (21%)]\t Loss:0.153146 acc:0.95\n",
      "Train Epoch:8[13312/60000 (22%)]\t Loss:0.127510 acc:0.97\n",
      "Train Epoch:8[13824/60000 (23%)]\t Loss:0.170876 acc:0.94\n",
      "Train Epoch:8[14336/60000 (24%)]\t Loss:0.218005 acc:0.91\n",
      "Train Epoch:8[14848/60000 (25%)]\t Loss:0.131753 acc:0.96\n",
      "Train Epoch:8[15360/60000 (26%)]\t Loss:0.157781 acc:0.95\n",
      "Train Epoch:8[15872/60000 (26%)]\t Loss:0.138524 acc:0.96\n",
      "Train Epoch:8[16384/60000 (27%)]\t Loss:0.161035 acc:0.96\n",
      "Train Epoch:8[16896/60000 (28%)]\t Loss:0.129870 acc:0.95\n",
      "Train Epoch:8[17408/60000 (29%)]\t Loss:0.165104 acc:0.96\n",
      "Train Epoch:8[17920/60000 (30%)]\t Loss:0.105265 acc:0.97\n",
      "Train Epoch:8[18432/60000 (31%)]\t Loss:0.107905 acc:0.97\n",
      "Train Epoch:8[18944/60000 (32%)]\t Loss:0.147539 acc:0.96\n",
      "Train Epoch:8[19456/60000 (32%)]\t Loss:0.128822 acc:0.96\n",
      "Train Epoch:8[19968/60000 (33%)]\t Loss:0.152587 acc:0.95\n",
      "Train Epoch:8[20480/60000 (34%)]\t Loss:0.185688 acc:0.94\n",
      "Train Epoch:8[20992/60000 (35%)]\t Loss:0.133615 acc:0.95\n",
      "Train Epoch:8[21504/60000 (36%)]\t Loss:0.105268 acc:0.97\n",
      "Train Epoch:8[22016/60000 (37%)]\t Loss:0.138663 acc:0.95\n",
      "Train Epoch:8[22528/60000 (38%)]\t Loss:0.141406 acc:0.95\n",
      "Train Epoch:8[23040/60000 (38%)]\t Loss:0.084610 acc:0.98\n",
      "Train Epoch:8[23552/60000 (39%)]\t Loss:0.151076 acc:0.96\n",
      "Train Epoch:8[24064/60000 (40%)]\t Loss:0.127512 acc:0.95\n",
      "Train Epoch:8[24576/60000 (41%)]\t Loss:0.160819 acc:0.95\n",
      "Train Epoch:8[25088/60000 (42%)]\t Loss:0.129967 acc:0.96\n",
      "Train Epoch:8[25600/60000 (43%)]\t Loss:0.123902 acc:0.96\n",
      "Train Epoch:8[26112/60000 (44%)]\t Loss:0.180612 acc:0.95\n",
      "Train Epoch:8[26624/60000 (44%)]\t Loss:0.161497 acc:0.96\n",
      "Train Epoch:8[27136/60000 (45%)]\t Loss:0.157597 acc:0.96\n",
      "Train Epoch:8[27648/60000 (46%)]\t Loss:0.117097 acc:0.96\n",
      "Train Epoch:8[28160/60000 (47%)]\t Loss:0.177658 acc:0.95\n",
      "Train Epoch:8[28672/60000 (48%)]\t Loss:0.129190 acc:0.96\n",
      "Train Epoch:8[29184/60000 (49%)]\t Loss:0.134269 acc:0.95\n",
      "Train Epoch:8[29696/60000 (49%)]\t Loss:0.189484 acc:0.94\n",
      "Train Epoch:8[30208/60000 (50%)]\t Loss:0.124180 acc:0.96\n",
      "Train Epoch:8[30720/60000 (51%)]\t Loss:0.158665 acc:0.96\n",
      "Train Epoch:8[31232/60000 (52%)]\t Loss:0.212263 acc:0.94\n",
      "Train Epoch:8[31744/60000 (53%)]\t Loss:0.134764 acc:0.96\n",
      "Train Epoch:8[32256/60000 (54%)]\t Loss:0.161553 acc:0.95\n",
      "Train Epoch:8[32768/60000 (55%)]\t Loss:0.137135 acc:0.97\n",
      "Train Epoch:8[33280/60000 (55%)]\t Loss:0.136716 acc:0.95\n",
      "Train Epoch:8[33792/60000 (56%)]\t Loss:0.080087 acc:0.98\n",
      "Train Epoch:8[34304/60000 (57%)]\t Loss:0.201538 acc:0.94\n",
      "Train Epoch:8[34816/60000 (58%)]\t Loss:0.125030 acc:0.96\n",
      "Train Epoch:8[35328/60000 (59%)]\t Loss:0.132981 acc:0.96\n",
      "Train Epoch:8[35840/60000 (60%)]\t Loss:0.122455 acc:0.96\n",
      "Train Epoch:8[36352/60000 (61%)]\t Loss:0.145871 acc:0.96\n",
      "Train Epoch:8[36864/60000 (61%)]\t Loss:0.170456 acc:0.96\n",
      "Train Epoch:8[37376/60000 (62%)]\t Loss:0.172447 acc:0.95\n",
      "Train Epoch:8[37888/60000 (63%)]\t Loss:0.104393 acc:0.97\n",
      "Train Epoch:8[38400/60000 (64%)]\t Loss:0.139206 acc:0.96\n",
      "Train Epoch:8[38912/60000 (65%)]\t Loss:0.157219 acc:0.95\n",
      "Train Epoch:8[39424/60000 (66%)]\t Loss:0.143046 acc:0.96\n",
      "Train Epoch:8[39936/60000 (67%)]\t Loss:0.123838 acc:0.97\n",
      "Train Epoch:8[40448/60000 (67%)]\t Loss:0.105078 acc:0.97\n",
      "Train Epoch:8[40960/60000 (68%)]\t Loss:0.175861 acc:0.95\n",
      "Train Epoch:8[41472/60000 (69%)]\t Loss:0.139375 acc:0.97\n",
      "Train Epoch:8[41984/60000 (70%)]\t Loss:0.192448 acc:0.93\n",
      "Train Epoch:8[42496/60000 (71%)]\t Loss:0.181170 acc:0.95\n",
      "Train Epoch:8[43008/60000 (72%)]\t Loss:0.121544 acc:0.95\n",
      "Train Epoch:8[43520/60000 (73%)]\t Loss:0.133246 acc:0.96\n",
      "Train Epoch:8[44032/60000 (73%)]\t Loss:0.180846 acc:0.94\n",
      "Train Epoch:8[44544/60000 (74%)]\t Loss:0.147734 acc:0.95\n",
      "Train Epoch:8[45056/60000 (75%)]\t Loss:0.105644 acc:0.97\n",
      "Train Epoch:8[45568/60000 (76%)]\t Loss:0.206042 acc:0.95\n",
      "Train Epoch:8[46080/60000 (77%)]\t Loss:0.175762 acc:0.95\n",
      "Train Epoch:8[46592/60000 (78%)]\t Loss:0.114192 acc:0.96\n",
      "Train Epoch:8[47104/60000 (79%)]\t Loss:0.192227 acc:0.94\n",
      "Train Epoch:8[47616/60000 (79%)]\t Loss:0.123077 acc:0.96\n",
      "Train Epoch:8[48128/60000 (80%)]\t Loss:0.102941 acc:0.96\n",
      "Train Epoch:8[48640/60000 (81%)]\t Loss:0.183329 acc:0.94\n",
      "Train Epoch:8[49152/60000 (82%)]\t Loss:0.200620 acc:0.94\n",
      "Train Epoch:8[49664/60000 (83%)]\t Loss:0.156706 acc:0.95\n",
      "Train Epoch:8[50176/60000 (84%)]\t Loss:0.227563 acc:0.94\n",
      "Train Epoch:8[50688/60000 (84%)]\t Loss:0.107876 acc:0.97\n",
      "Train Epoch:8[51200/60000 (85%)]\t Loss:0.133594 acc:0.95\n",
      "Train Epoch:8[51712/60000 (86%)]\t Loss:0.146608 acc:0.96\n",
      "Train Epoch:8[52224/60000 (87%)]\t Loss:0.115146 acc:0.96\n",
      "Train Epoch:8[52736/60000 (88%)]\t Loss:0.199180 acc:0.94\n",
      "Train Epoch:8[53248/60000 (89%)]\t Loss:0.138519 acc:0.96\n",
      "Train Epoch:8[53760/60000 (90%)]\t Loss:0.152541 acc:0.96\n",
      "Train Epoch:8[54272/60000 (90%)]\t Loss:0.109226 acc:0.97\n",
      "Train Epoch:8[54784/60000 (91%)]\t Loss:0.151324 acc:0.94\n",
      "Train Epoch:8[55296/60000 (92%)]\t Loss:0.122304 acc:0.96\n",
      "Train Epoch:8[55808/60000 (93%)]\t Loss:0.106549 acc:0.96\n",
      "Train Epoch:8[56320/60000 (94%)]\t Loss:0.117306 acc:0.96\n",
      "Train Epoch:8[56832/60000 (95%)]\t Loss:0.094939 acc:0.97\n",
      "Train Epoch:8[57344/60000 (96%)]\t Loss:0.125926 acc:0.96\n",
      "Train Epoch:8[57856/60000 (96%)]\t Loss:0.086762 acc:0.97\n",
      "Train Epoch:8[58368/60000 (97%)]\t Loss:0.077939 acc:0.98\n",
      "Train Epoch:8[58880/60000 (98%)]\t Loss:0.059465 acc:0.97\n",
      "Train Epoch:8[59392/60000 (99%)]\t Loss:0.125659 acc:0.98\n",
      "Train Epoch:8[59904/60000 (100%)]\t Loss:0.236024 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:8 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:8 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:8 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:8 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:8 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:8 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:8 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:8 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:8 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:8 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:8 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:8 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:8 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:8 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:8 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:8 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:8 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:8 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:8 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:8 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:9[0/60000 (0%)]\t Loss:0.158210 acc:0.96\n",
      "Train Epoch:9[512/60000 (1%)]\t Loss:0.157019 acc:0.96\n",
      "Train Epoch:9[1024/60000 (2%)]\t Loss:0.178967 acc:0.94\n",
      "Train Epoch:9[1536/60000 (3%)]\t Loss:0.095540 acc:0.97\n",
      "Train Epoch:9[2048/60000 (3%)]\t Loss:0.088214 acc:0.97\n",
      "Train Epoch:9[2560/60000 (4%)]\t Loss:0.117998 acc:0.97\n",
      "Train Epoch:9[3072/60000 (5%)]\t Loss:0.079905 acc:0.98\n",
      "Train Epoch:9[3584/60000 (6%)]\t Loss:0.090560 acc:0.98\n",
      "Train Epoch:9[4096/60000 (7%)]\t Loss:0.128874 acc:0.96\n",
      "Train Epoch:9[4608/60000 (8%)]\t Loss:0.140140 acc:0.97\n",
      "Train Epoch:9[5120/60000 (9%)]\t Loss:0.136112 acc:0.97\n",
      "Train Epoch:9[5632/60000 (9%)]\t Loss:0.152302 acc:0.96\n",
      "Train Epoch:9[6144/60000 (10%)]\t Loss:0.118874 acc:0.96\n",
      "Train Epoch:9[6656/60000 (11%)]\t Loss:0.165867 acc:0.96\n",
      "Train Epoch:9[7168/60000 (12%)]\t Loss:0.147285 acc:0.95\n",
      "Train Epoch:9[7680/60000 (13%)]\t Loss:0.132833 acc:0.96\n",
      "Train Epoch:9[8192/60000 (14%)]\t Loss:0.150387 acc:0.96\n",
      "Train Epoch:9[8704/60000 (15%)]\t Loss:0.232276 acc:0.93\n",
      "Train Epoch:9[9216/60000 (15%)]\t Loss:0.141631 acc:0.95\n",
      "Train Epoch:9[9728/60000 (16%)]\t Loss:0.141132 acc:0.95\n",
      "Train Epoch:9[10240/60000 (17%)]\t Loss:0.108954 acc:0.97\n",
      "Train Epoch:9[10752/60000 (18%)]\t Loss:0.122636 acc:0.97\n",
      "Train Epoch:9[11264/60000 (19%)]\t Loss:0.131117 acc:0.96\n",
      "Train Epoch:9[11776/60000 (20%)]\t Loss:0.119155 acc:0.97\n",
      "Train Epoch:9[12288/60000 (20%)]\t Loss:0.162457 acc:0.95\n",
      "Train Epoch:9[12800/60000 (21%)]\t Loss:0.141313 acc:0.96\n",
      "Train Epoch:9[13312/60000 (22%)]\t Loss:0.116118 acc:0.97\n",
      "Train Epoch:9[13824/60000 (23%)]\t Loss:0.153912 acc:0.95\n",
      "Train Epoch:9[14336/60000 (24%)]\t Loss:0.197181 acc:0.92\n",
      "Train Epoch:9[14848/60000 (25%)]\t Loss:0.121217 acc:0.96\n",
      "Train Epoch:9[15360/60000 (26%)]\t Loss:0.145469 acc:0.95\n",
      "Train Epoch:9[15872/60000 (26%)]\t Loss:0.128975 acc:0.96\n",
      "Train Epoch:9[16384/60000 (27%)]\t Loss:0.148546 acc:0.96\n",
      "Train Epoch:9[16896/60000 (28%)]\t Loss:0.118566 acc:0.96\n",
      "Train Epoch:9[17408/60000 (29%)]\t Loss:0.149568 acc:0.96\n",
      "Train Epoch:9[17920/60000 (30%)]\t Loss:0.097713 acc:0.97\n",
      "Train Epoch:9[18432/60000 (31%)]\t Loss:0.098026 acc:0.97\n",
      "Train Epoch:9[18944/60000 (32%)]\t Loss:0.137139 acc:0.96\n",
      "Train Epoch:9[19456/60000 (32%)]\t Loss:0.120224 acc:0.97\n",
      "Train Epoch:9[19968/60000 (33%)]\t Loss:0.141974 acc:0.95\n",
      "Train Epoch:9[20480/60000 (34%)]\t Loss:0.173848 acc:0.95\n",
      "Train Epoch:9[20992/60000 (35%)]\t Loss:0.123386 acc:0.96\n",
      "Train Epoch:9[21504/60000 (36%)]\t Loss:0.094797 acc:0.97\n",
      "Train Epoch:9[22016/60000 (37%)]\t Loss:0.124898 acc:0.96\n",
      "Train Epoch:9[22528/60000 (38%)]\t Loss:0.128453 acc:0.95\n",
      "Train Epoch:9[23040/60000 (38%)]\t Loss:0.074407 acc:0.98\n",
      "Train Epoch:9[23552/60000 (39%)]\t Loss:0.141344 acc:0.97\n",
      "Train Epoch:9[24064/60000 (40%)]\t Loss:0.117390 acc:0.96\n",
      "Train Epoch:9[24576/60000 (41%)]\t Loss:0.146050 acc:0.96\n",
      "Train Epoch:9[25088/60000 (42%)]\t Loss:0.122453 acc:0.96\n",
      "Train Epoch:9[25600/60000 (43%)]\t Loss:0.115745 acc:0.96\n",
      "Train Epoch:9[26112/60000 (44%)]\t Loss:0.164820 acc:0.95\n",
      "Train Epoch:9[26624/60000 (44%)]\t Loss:0.150155 acc:0.96\n",
      "Train Epoch:9[27136/60000 (45%)]\t Loss:0.147095 acc:0.96\n",
      "Train Epoch:9[27648/60000 (46%)]\t Loss:0.109345 acc:0.96\n",
      "Train Epoch:9[28160/60000 (47%)]\t Loss:0.166419 acc:0.96\n",
      "Train Epoch:9[28672/60000 (48%)]\t Loss:0.116400 acc:0.97\n",
      "Train Epoch:9[29184/60000 (49%)]\t Loss:0.122824 acc:0.95\n",
      "Train Epoch:9[29696/60000 (49%)]\t Loss:0.176077 acc:0.95\n",
      "Train Epoch:9[30208/60000 (50%)]\t Loss:0.113080 acc:0.97\n",
      "Train Epoch:9[30720/60000 (51%)]\t Loss:0.144772 acc:0.96\n",
      "Train Epoch:9[31232/60000 (52%)]\t Loss:0.199133 acc:0.94\n",
      "Train Epoch:9[31744/60000 (53%)]\t Loss:0.122061 acc:0.97\n",
      "Train Epoch:9[32256/60000 (54%)]\t Loss:0.148178 acc:0.96\n",
      "Train Epoch:9[32768/60000 (55%)]\t Loss:0.125001 acc:0.97\n",
      "Train Epoch:9[33280/60000 (55%)]\t Loss:0.127976 acc:0.95\n",
      "Train Epoch:9[33792/60000 (56%)]\t Loss:0.075227 acc:0.98\n",
      "Train Epoch:9[34304/60000 (57%)]\t Loss:0.187926 acc:0.94\n",
      "Train Epoch:9[34816/60000 (58%)]\t Loss:0.118321 acc:0.96\n",
      "Train Epoch:9[35328/60000 (59%)]\t Loss:0.127396 acc:0.96\n",
      "Train Epoch:9[35840/60000 (60%)]\t Loss:0.112698 acc:0.96\n",
      "Train Epoch:9[36352/60000 (61%)]\t Loss:0.134943 acc:0.96\n",
      "Train Epoch:9[36864/60000 (61%)]\t Loss:0.156002 acc:0.96\n",
      "Train Epoch:9[37376/60000 (62%)]\t Loss:0.158510 acc:0.95\n",
      "Train Epoch:9[37888/60000 (63%)]\t Loss:0.091833 acc:0.98\n",
      "Train Epoch:9[38400/60000 (64%)]\t Loss:0.128609 acc:0.96\n",
      "Train Epoch:9[38912/60000 (65%)]\t Loss:0.148855 acc:0.96\n",
      "Train Epoch:9[39424/60000 (66%)]\t Loss:0.134709 acc:0.95\n",
      "Train Epoch:9[39936/60000 (67%)]\t Loss:0.114399 acc:0.97\n",
      "Train Epoch:9[40448/60000 (67%)]\t Loss:0.097609 acc:0.97\n",
      "Train Epoch:9[40960/60000 (68%)]\t Loss:0.164117 acc:0.95\n",
      "Train Epoch:9[41472/60000 (69%)]\t Loss:0.128470 acc:0.96\n",
      "Train Epoch:9[41984/60000 (70%)]\t Loss:0.174980 acc:0.94\n",
      "Train Epoch:9[42496/60000 (71%)]\t Loss:0.168083 acc:0.95\n",
      "Train Epoch:9[43008/60000 (72%)]\t Loss:0.112371 acc:0.95\n",
      "Train Epoch:9[43520/60000 (73%)]\t Loss:0.123318 acc:0.96\n",
      "Train Epoch:9[44032/60000 (73%)]\t Loss:0.167185 acc:0.95\n",
      "Train Epoch:9[44544/60000 (74%)]\t Loss:0.138901 acc:0.96\n",
      "Train Epoch:9[45056/60000 (75%)]\t Loss:0.097221 acc:0.97\n",
      "Train Epoch:9[45568/60000 (76%)]\t Loss:0.193507 acc:0.95\n",
      "Train Epoch:9[46080/60000 (77%)]\t Loss:0.168593 acc:0.95\n",
      "Train Epoch:9[46592/60000 (78%)]\t Loss:0.109700 acc:0.96\n",
      "Train Epoch:9[47104/60000 (79%)]\t Loss:0.178215 acc:0.94\n",
      "Train Epoch:9[47616/60000 (79%)]\t Loss:0.115680 acc:0.96\n",
      "Train Epoch:9[48128/60000 (80%)]\t Loss:0.094447 acc:0.97\n",
      "Train Epoch:9[48640/60000 (81%)]\t Loss:0.173525 acc:0.95\n",
      "Train Epoch:9[49152/60000 (82%)]\t Loss:0.194065 acc:0.94\n",
      "Train Epoch:9[49664/60000 (83%)]\t Loss:0.147258 acc:0.96\n",
      "Train Epoch:9[50176/60000 (84%)]\t Loss:0.213242 acc:0.95\n",
      "Train Epoch:9[50688/60000 (84%)]\t Loss:0.094540 acc:0.97\n",
      "Train Epoch:9[51200/60000 (85%)]\t Loss:0.124032 acc:0.95\n",
      "Train Epoch:9[51712/60000 (86%)]\t Loss:0.135561 acc:0.96\n",
      "Train Epoch:9[52224/60000 (87%)]\t Loss:0.104483 acc:0.96\n",
      "Train Epoch:9[52736/60000 (88%)]\t Loss:0.190548 acc:0.95\n",
      "Train Epoch:9[53248/60000 (89%)]\t Loss:0.131259 acc:0.96\n",
      "Train Epoch:9[53760/60000 (90%)]\t Loss:0.145073 acc:0.96\n",
      "Train Epoch:9[54272/60000 (90%)]\t Loss:0.104334 acc:0.97\n",
      "Train Epoch:9[54784/60000 (91%)]\t Loss:0.141231 acc:0.95\n",
      "Train Epoch:9[55296/60000 (92%)]\t Loss:0.112284 acc:0.97\n",
      "Train Epoch:9[55808/60000 (93%)]\t Loss:0.100317 acc:0.96\n",
      "Train Epoch:9[56320/60000 (94%)]\t Loss:0.107315 acc:0.96\n",
      "Train Epoch:9[56832/60000 (95%)]\t Loss:0.088025 acc:0.97\n",
      "Train Epoch:9[57344/60000 (96%)]\t Loss:0.115419 acc:0.96\n",
      "Train Epoch:9[57856/60000 (96%)]\t Loss:0.080988 acc:0.97\n",
      "Train Epoch:9[58368/60000 (97%)]\t Loss:0.074095 acc:0.98\n",
      "Train Epoch:9[58880/60000 (98%)]\t Loss:0.054259 acc:0.98\n",
      "Train Epoch:9[59392/60000 (99%)]\t Loss:0.118402 acc:0.98\n",
      "Train Epoch:9[59904/60000 (100%)]\t Loss:0.231387 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:9 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:9 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:9 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:9 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:9 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:9 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:9 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:9 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:9 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:9 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:9 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:9 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:9 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:9 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:9 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:9 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:9 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:9 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:9 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:9 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:10[0/60000 (0%)]\t Loss:0.151323 acc:0.96\n",
      "Train Epoch:10[512/60000 (1%)]\t Loss:0.148115 acc:0.97\n",
      "Train Epoch:10[1024/60000 (2%)]\t Loss:0.163639 acc:0.95\n",
      "Train Epoch:10[1536/60000 (3%)]\t Loss:0.089655 acc:0.97\n",
      "Train Epoch:10[2048/60000 (3%)]\t Loss:0.078543 acc:0.98\n",
      "Train Epoch:10[2560/60000 (4%)]\t Loss:0.108764 acc:0.97\n",
      "Train Epoch:10[3072/60000 (5%)]\t Loss:0.071611 acc:0.97\n",
      "Train Epoch:10[3584/60000 (6%)]\t Loss:0.081589 acc:0.97\n",
      "Train Epoch:10[4096/60000 (7%)]\t Loss:0.119993 acc:0.97\n",
      "Train Epoch:10[4608/60000 (8%)]\t Loss:0.130854 acc:0.96\n",
      "Train Epoch:10[5120/60000 (9%)]\t Loss:0.127510 acc:0.97\n",
      "Train Epoch:10[5632/60000 (9%)]\t Loss:0.145699 acc:0.96\n",
      "Train Epoch:10[6144/60000 (10%)]\t Loss:0.120065 acc:0.97\n",
      "Train Epoch:10[6656/60000 (11%)]\t Loss:0.157624 acc:0.96\n",
      "Train Epoch:10[7168/60000 (12%)]\t Loss:0.139738 acc:0.95\n",
      "Train Epoch:10[7680/60000 (13%)]\t Loss:0.123192 acc:0.97\n",
      "Train Epoch:10[8192/60000 (14%)]\t Loss:0.141788 acc:0.96\n",
      "Train Epoch:10[8704/60000 (15%)]\t Loss:0.218903 acc:0.94\n",
      "Train Epoch:10[9216/60000 (15%)]\t Loss:0.135099 acc:0.95\n",
      "Train Epoch:10[9728/60000 (16%)]\t Loss:0.134290 acc:0.96\n",
      "Train Epoch:10[10240/60000 (17%)]\t Loss:0.098233 acc:0.97\n",
      "Train Epoch:10[10752/60000 (18%)]\t Loss:0.114765 acc:0.97\n",
      "Train Epoch:10[11264/60000 (19%)]\t Loss:0.118988 acc:0.96\n",
      "Train Epoch:10[11776/60000 (20%)]\t Loss:0.109752 acc:0.97\n",
      "Train Epoch:10[12288/60000 (20%)]\t Loss:0.145438 acc:0.95\n",
      "Train Epoch:10[12800/60000 (21%)]\t Loss:0.131145 acc:0.96\n",
      "Train Epoch:10[13312/60000 (22%)]\t Loss:0.105617 acc:0.97\n",
      "Train Epoch:10[13824/60000 (23%)]\t Loss:0.142007 acc:0.95\n",
      "Train Epoch:10[14336/60000 (24%)]\t Loss:0.183488 acc:0.93\n",
      "Train Epoch:10[14848/60000 (25%)]\t Loss:0.115330 acc:0.96\n",
      "Train Epoch:10[15360/60000 (26%)]\t Loss:0.137741 acc:0.95\n",
      "Train Epoch:10[15872/60000 (26%)]\t Loss:0.122810 acc:0.96\n",
      "Train Epoch:10[16384/60000 (27%)]\t Loss:0.139591 acc:0.96\n",
      "Train Epoch:10[16896/60000 (28%)]\t Loss:0.110763 acc:0.96\n",
      "Train Epoch:10[17408/60000 (29%)]\t Loss:0.137598 acc:0.97\n",
      "Train Epoch:10[17920/60000 (30%)]\t Loss:0.091139 acc:0.97\n",
      "Train Epoch:10[18432/60000 (31%)]\t Loss:0.089925 acc:0.97\n",
      "Train Epoch:10[18944/60000 (32%)]\t Loss:0.129407 acc:0.96\n",
      "Train Epoch:10[19456/60000 (32%)]\t Loss:0.116689 acc:0.97\n",
      "Train Epoch:10[19968/60000 (33%)]\t Loss:0.133572 acc:0.96\n",
      "Train Epoch:10[20480/60000 (34%)]\t Loss:0.166427 acc:0.95\n",
      "Train Epoch:10[20992/60000 (35%)]\t Loss:0.116237 acc:0.96\n",
      "Train Epoch:10[21504/60000 (36%)]\t Loss:0.086955 acc:0.97\n",
      "Train Epoch:10[22016/60000 (37%)]\t Loss:0.112994 acc:0.96\n",
      "Train Epoch:10[22528/60000 (38%)]\t Loss:0.118313 acc:0.96\n",
      "Train Epoch:10[23040/60000 (38%)]\t Loss:0.067878 acc:0.98\n",
      "Train Epoch:10[23552/60000 (39%)]\t Loss:0.134006 acc:0.97\n",
      "Train Epoch:10[24064/60000 (40%)]\t Loss:0.109848 acc:0.96\n",
      "Train Epoch:10[24576/60000 (41%)]\t Loss:0.134363 acc:0.96\n",
      "Train Epoch:10[25088/60000 (42%)]\t Loss:0.115774 acc:0.96\n",
      "Train Epoch:10[25600/60000 (43%)]\t Loss:0.110494 acc:0.96\n",
      "Train Epoch:10[26112/60000 (44%)]\t Loss:0.154726 acc:0.95\n",
      "Train Epoch:10[26624/60000 (44%)]\t Loss:0.142096 acc:0.97\n",
      "Train Epoch:10[27136/60000 (45%)]\t Loss:0.139014 acc:0.96\n",
      "Train Epoch:10[27648/60000 (46%)]\t Loss:0.103039 acc:0.97\n",
      "Train Epoch:10[28160/60000 (47%)]\t Loss:0.156684 acc:0.96\n",
      "Train Epoch:10[28672/60000 (48%)]\t Loss:0.105564 acc:0.97\n",
      "Train Epoch:10[29184/60000 (49%)]\t Loss:0.113686 acc:0.96\n",
      "Train Epoch:10[29696/60000 (49%)]\t Loss:0.165549 acc:0.95\n",
      "Train Epoch:10[30208/60000 (50%)]\t Loss:0.105452 acc:0.97\n",
      "Train Epoch:10[30720/60000 (51%)]\t Loss:0.135201 acc:0.96\n",
      "Train Epoch:10[31232/60000 (52%)]\t Loss:0.191697 acc:0.95\n",
      "Train Epoch:10[31744/60000 (53%)]\t Loss:0.112901 acc:0.97\n",
      "Train Epoch:10[32256/60000 (54%)]\t Loss:0.138097 acc:0.96\n",
      "Train Epoch:10[32768/60000 (55%)]\t Loss:0.115882 acc:0.97\n",
      "Train Epoch:10[33280/60000 (55%)]\t Loss:0.120731 acc:0.96\n",
      "Train Epoch:10[33792/60000 (56%)]\t Loss:0.071209 acc:0.98\n",
      "Train Epoch:10[34304/60000 (57%)]\t Loss:0.177766 acc:0.95\n",
      "Train Epoch:10[34816/60000 (58%)]\t Loss:0.112814 acc:0.96\n",
      "Train Epoch:10[35328/60000 (59%)]\t Loss:0.123315 acc:0.96\n",
      "Train Epoch:10[35840/60000 (60%)]\t Loss:0.103904 acc:0.96\n",
      "Train Epoch:10[36352/60000 (61%)]\t Loss:0.128000 acc:0.96\n",
      "Train Epoch:10[36864/60000 (61%)]\t Loss:0.145392 acc:0.96\n",
      "Train Epoch:10[37376/60000 (62%)]\t Loss:0.145956 acc:0.96\n",
      "Train Epoch:10[37888/60000 (63%)]\t Loss:0.081846 acc:0.98\n",
      "Train Epoch:10[38400/60000 (64%)]\t Loss:0.118998 acc:0.96\n",
      "Train Epoch:10[38912/60000 (65%)]\t Loss:0.142963 acc:0.96\n",
      "Train Epoch:10[39424/60000 (66%)]\t Loss:0.130053 acc:0.95\n",
      "Train Epoch:10[39936/60000 (67%)]\t Loss:0.107791 acc:0.97\n",
      "Train Epoch:10[40448/60000 (67%)]\t Loss:0.092531 acc:0.97\n",
      "Train Epoch:10[40960/60000 (68%)]\t Loss:0.155307 acc:0.95\n",
      "Train Epoch:10[41472/60000 (69%)]\t Loss:0.119560 acc:0.96\n",
      "Train Epoch:10[41984/60000 (70%)]\t Loss:0.158705 acc:0.94\n",
      "Train Epoch:10[42496/60000 (71%)]\t Loss:0.155236 acc:0.96\n",
      "Train Epoch:10[43008/60000 (72%)]\t Loss:0.103907 acc:0.96\n",
      "Train Epoch:10[43520/60000 (73%)]\t Loss:0.113527 acc:0.96\n",
      "Train Epoch:10[44032/60000 (73%)]\t Loss:0.157030 acc:0.96\n",
      "Train Epoch:10[44544/60000 (74%)]\t Loss:0.131133 acc:0.96\n",
      "Train Epoch:10[45056/60000 (75%)]\t Loss:0.093467 acc:0.97\n",
      "Train Epoch:10[45568/60000 (76%)]\t Loss:0.184925 acc:0.95\n",
      "Train Epoch:10[46080/60000 (77%)]\t Loss:0.164965 acc:0.95\n",
      "Train Epoch:10[46592/60000 (78%)]\t Loss:0.107825 acc:0.96\n",
      "Train Epoch:10[47104/60000 (79%)]\t Loss:0.164690 acc:0.95\n",
      "Train Epoch:10[47616/60000 (79%)]\t Loss:0.109942 acc:0.97\n",
      "Train Epoch:10[48128/60000 (80%)]\t Loss:0.087521 acc:0.97\n",
      "Train Epoch:10[48640/60000 (81%)]\t Loss:0.164044 acc:0.95\n",
      "Train Epoch:10[49152/60000 (82%)]\t Loss:0.187332 acc:0.94\n",
      "Train Epoch:10[49664/60000 (83%)]\t Loss:0.140809 acc:0.96\n",
      "Train Epoch:10[50176/60000 (84%)]\t Loss:0.202951 acc:0.94\n",
      "Train Epoch:10[50688/60000 (84%)]\t Loss:0.085658 acc:0.97\n",
      "Train Epoch:10[51200/60000 (85%)]\t Loss:0.116292 acc:0.96\n",
      "Train Epoch:10[51712/60000 (86%)]\t Loss:0.126300 acc:0.96\n",
      "Train Epoch:10[52224/60000 (87%)]\t Loss:0.094876 acc:0.96\n",
      "Train Epoch:10[52736/60000 (88%)]\t Loss:0.182358 acc:0.94\n",
      "Train Epoch:10[53248/60000 (89%)]\t Loss:0.124845 acc:0.96\n",
      "Train Epoch:10[53760/60000 (90%)]\t Loss:0.139045 acc:0.96\n",
      "Train Epoch:10[54272/60000 (90%)]\t Loss:0.100573 acc:0.97\n",
      "Train Epoch:10[54784/60000 (91%)]\t Loss:0.133911 acc:0.95\n",
      "Train Epoch:10[55296/60000 (92%)]\t Loss:0.104420 acc:0.98\n",
      "Train Epoch:10[55808/60000 (93%)]\t Loss:0.095481 acc:0.96\n",
      "Train Epoch:10[56320/60000 (94%)]\t Loss:0.101284 acc:0.97\n",
      "Train Epoch:10[56832/60000 (95%)]\t Loss:0.081639 acc:0.98\n",
      "Train Epoch:10[57344/60000 (96%)]\t Loss:0.106745 acc:0.97\n",
      "Train Epoch:10[57856/60000 (96%)]\t Loss:0.076469 acc:0.97\n",
      "Train Epoch:10[58368/60000 (97%)]\t Loss:0.070630 acc:0.97\n",
      "Train Epoch:10[58880/60000 (98%)]\t Loss:0.049130 acc:0.98\n",
      "Train Epoch:10[59392/60000 (99%)]\t Loss:0.113050 acc:0.98\n",
      "Train Epoch:10[59904/60000 (100%)]\t Loss:0.225575 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:10 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:10 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:10 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:10 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:10 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:10 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:10 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:10 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:10 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:10 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:10 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:10 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:10 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:10 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:10 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:10 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:10 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:10 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:10 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:10 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:11[0/60000 (0%)]\t Loss:0.145961 acc:0.96\n",
      "Train Epoch:11[512/60000 (1%)]\t Loss:0.141373 acc:0.97\n",
      "Train Epoch:11[1024/60000 (2%)]\t Loss:0.149989 acc:0.96\n",
      "Train Epoch:11[1536/60000 (3%)]\t Loss:0.084460 acc:0.97\n",
      "Train Epoch:11[2048/60000 (3%)]\t Loss:0.070956 acc:0.99\n",
      "Train Epoch:11[2560/60000 (4%)]\t Loss:0.101446 acc:0.97\n",
      "Train Epoch:11[3072/60000 (5%)]\t Loss:0.065589 acc:0.97\n",
      "Train Epoch:11[3584/60000 (6%)]\t Loss:0.074884 acc:0.97\n",
      "Train Epoch:11[4096/60000 (7%)]\t Loss:0.111549 acc:0.97\n",
      "Train Epoch:11[4608/60000 (8%)]\t Loss:0.123810 acc:0.96\n",
      "Train Epoch:11[5120/60000 (9%)]\t Loss:0.120600 acc:0.97\n",
      "Train Epoch:11[5632/60000 (9%)]\t Loss:0.139378 acc:0.96\n",
      "Train Epoch:11[6144/60000 (10%)]\t Loss:0.120941 acc:0.97\n",
      "Train Epoch:11[6656/60000 (11%)]\t Loss:0.151671 acc:0.96\n",
      "Train Epoch:11[7168/60000 (12%)]\t Loss:0.130684 acc:0.95\n",
      "Train Epoch:11[7680/60000 (13%)]\t Loss:0.112403 acc:0.97\n",
      "Train Epoch:11[8192/60000 (14%)]\t Loss:0.135061 acc:0.96\n",
      "Train Epoch:11[8704/60000 (15%)]\t Loss:0.205563 acc:0.94\n",
      "Train Epoch:11[9216/60000 (15%)]\t Loss:0.129761 acc:0.96\n",
      "Train Epoch:11[9728/60000 (16%)]\t Loss:0.129170 acc:0.96\n",
      "Train Epoch:11[10240/60000 (17%)]\t Loss:0.090089 acc:0.98\n",
      "Train Epoch:11[10752/60000 (18%)]\t Loss:0.109568 acc:0.97\n",
      "Train Epoch:11[11264/60000 (19%)]\t Loss:0.111648 acc:0.96\n",
      "Train Epoch:11[11776/60000 (20%)]\t Loss:0.103070 acc:0.97\n",
      "Train Epoch:11[12288/60000 (20%)]\t Loss:0.128754 acc:0.96\n",
      "Train Epoch:11[12800/60000 (21%)]\t Loss:0.120030 acc:0.96\n",
      "Train Epoch:11[13312/60000 (22%)]\t Loss:0.096331 acc:0.98\n",
      "Train Epoch:11[13824/60000 (23%)]\t Loss:0.132833 acc:0.95\n",
      "Train Epoch:11[14336/60000 (24%)]\t Loss:0.173465 acc:0.93\n",
      "Train Epoch:11[14848/60000 (25%)]\t Loss:0.111413 acc:0.96\n",
      "Train Epoch:11[15360/60000 (26%)]\t Loss:0.131725 acc:0.96\n",
      "Train Epoch:11[15872/60000 (26%)]\t Loss:0.120258 acc:0.96\n",
      "Train Epoch:11[16384/60000 (27%)]\t Loss:0.134276 acc:0.97\n",
      "Train Epoch:11[16896/60000 (28%)]\t Loss:0.106243 acc:0.96\n",
      "Train Epoch:11[17408/60000 (29%)]\t Loss:0.129903 acc:0.97\n",
      "Train Epoch:11[17920/60000 (30%)]\t Loss:0.085416 acc:0.97\n",
      "Train Epoch:11[18432/60000 (31%)]\t Loss:0.082865 acc:0.98\n",
      "Train Epoch:11[18944/60000 (32%)]\t Loss:0.122422 acc:0.96\n",
      "Train Epoch:11[19456/60000 (32%)]\t Loss:0.111489 acc:0.97\n",
      "Train Epoch:11[19968/60000 (33%)]\t Loss:0.123202 acc:0.96\n",
      "Train Epoch:11[20480/60000 (34%)]\t Loss:0.160419 acc:0.96\n",
      "Train Epoch:11[20992/60000 (35%)]\t Loss:0.111810 acc:0.96\n",
      "Train Epoch:11[21504/60000 (36%)]\t Loss:0.081193 acc:0.97\n",
      "Train Epoch:11[22016/60000 (37%)]\t Loss:0.103937 acc:0.96\n",
      "Train Epoch:11[22528/60000 (38%)]\t Loss:0.106701 acc:0.96\n",
      "Train Epoch:11[23040/60000 (38%)]\t Loss:0.062472 acc:0.98\n",
      "Train Epoch:11[23552/60000 (39%)]\t Loss:0.126174 acc:0.97\n",
      "Train Epoch:11[24064/60000 (40%)]\t Loss:0.099241 acc:0.96\n",
      "Train Epoch:11[24576/60000 (41%)]\t Loss:0.124624 acc:0.96\n",
      "Train Epoch:11[25088/60000 (42%)]\t Loss:0.110552 acc:0.96\n",
      "Train Epoch:11[25600/60000 (43%)]\t Loss:0.106707 acc:0.97\n",
      "Train Epoch:11[26112/60000 (44%)]\t Loss:0.149112 acc:0.95\n",
      "Train Epoch:11[26624/60000 (44%)]\t Loss:0.137836 acc:0.97\n",
      "Train Epoch:11[27136/60000 (45%)]\t Loss:0.138279 acc:0.96\n",
      "Train Epoch:11[27648/60000 (46%)]\t Loss:0.097172 acc:0.97\n",
      "Train Epoch:11[28160/60000 (47%)]\t Loss:0.148067 acc:0.96\n",
      "Train Epoch:11[28672/60000 (48%)]\t Loss:0.095756 acc:0.97\n",
      "Train Epoch:11[29184/60000 (49%)]\t Loss:0.105568 acc:0.96\n",
      "Train Epoch:11[29696/60000 (49%)]\t Loss:0.153904 acc:0.95\n",
      "Train Epoch:11[30208/60000 (50%)]\t Loss:0.099095 acc:0.98\n",
      "Train Epoch:11[30720/60000 (51%)]\t Loss:0.128367 acc:0.96\n",
      "Train Epoch:11[31232/60000 (52%)]\t Loss:0.188230 acc:0.94\n",
      "Train Epoch:11[31744/60000 (53%)]\t Loss:0.107035 acc:0.97\n",
      "Train Epoch:11[32256/60000 (54%)]\t Loss:0.128388 acc:0.96\n",
      "Train Epoch:11[32768/60000 (55%)]\t Loss:0.107552 acc:0.97\n",
      "Train Epoch:11[33280/60000 (55%)]\t Loss:0.113739 acc:0.96\n",
      "Train Epoch:11[33792/60000 (56%)]\t Loss:0.067802 acc:0.98\n",
      "Train Epoch:11[34304/60000 (57%)]\t Loss:0.168976 acc:0.95\n",
      "Train Epoch:11[34816/60000 (58%)]\t Loss:0.107860 acc:0.96\n",
      "Train Epoch:11[35328/60000 (59%)]\t Loss:0.119448 acc:0.96\n",
      "Train Epoch:11[35840/60000 (60%)]\t Loss:0.096328 acc:0.96\n",
      "Train Epoch:11[36352/60000 (61%)]\t Loss:0.125925 acc:0.96\n",
      "Train Epoch:11[36864/60000 (61%)]\t Loss:0.137493 acc:0.96\n",
      "Train Epoch:11[37376/60000 (62%)]\t Loss:0.133909 acc:0.96\n",
      "Train Epoch:11[37888/60000 (63%)]\t Loss:0.073813 acc:0.98\n",
      "Train Epoch:11[38400/60000 (64%)]\t Loss:0.109199 acc:0.97\n",
      "Train Epoch:11[38912/60000 (65%)]\t Loss:0.136540 acc:0.96\n",
      "Train Epoch:11[39424/60000 (66%)]\t Loss:0.125765 acc:0.95\n",
      "Train Epoch:11[39936/60000 (67%)]\t Loss:0.101690 acc:0.97\n",
      "Train Epoch:11[40448/60000 (67%)]\t Loss:0.088632 acc:0.97\n",
      "Train Epoch:11[40960/60000 (68%)]\t Loss:0.150401 acc:0.95\n",
      "Train Epoch:11[41472/60000 (69%)]\t Loss:0.112554 acc:0.96\n",
      "Train Epoch:11[41984/60000 (70%)]\t Loss:0.142325 acc:0.95\n",
      "Train Epoch:11[42496/60000 (71%)]\t Loss:0.144368 acc:0.96\n",
      "Train Epoch:11[43008/60000 (72%)]\t Loss:0.097571 acc:0.96\n",
      "Train Epoch:11[43520/60000 (73%)]\t Loss:0.104827 acc:0.96\n",
      "Train Epoch:11[44032/60000 (73%)]\t Loss:0.147165 acc:0.96\n",
      "Train Epoch:11[44544/60000 (74%)]\t Loss:0.123311 acc:0.96\n",
      "Train Epoch:11[45056/60000 (75%)]\t Loss:0.091862 acc:0.97\n",
      "Train Epoch:11[45568/60000 (76%)]\t Loss:0.178817 acc:0.95\n",
      "Train Epoch:11[46080/60000 (77%)]\t Loss:0.162970 acc:0.95\n",
      "Train Epoch:11[46592/60000 (78%)]\t Loss:0.108476 acc:0.96\n",
      "Train Epoch:11[47104/60000 (79%)]\t Loss:0.150588 acc:0.96\n",
      "Train Epoch:11[47616/60000 (79%)]\t Loss:0.104329 acc:0.97\n",
      "Train Epoch:11[48128/60000 (80%)]\t Loss:0.081271 acc:0.97\n",
      "Train Epoch:11[48640/60000 (81%)]\t Loss:0.156160 acc:0.95\n",
      "Train Epoch:11[49152/60000 (82%)]\t Loss:0.179201 acc:0.94\n",
      "Train Epoch:11[49664/60000 (83%)]\t Loss:0.134965 acc:0.96\n",
      "Train Epoch:11[50176/60000 (84%)]\t Loss:0.195237 acc:0.94\n",
      "Train Epoch:11[50688/60000 (84%)]\t Loss:0.078545 acc:0.98\n",
      "Train Epoch:11[51200/60000 (85%)]\t Loss:0.109986 acc:0.96\n",
      "Train Epoch:11[51712/60000 (86%)]\t Loss:0.118550 acc:0.97\n",
      "Train Epoch:11[52224/60000 (87%)]\t Loss:0.085664 acc:0.97\n",
      "Train Epoch:11[52736/60000 (88%)]\t Loss:0.171330 acc:0.96\n",
      "Train Epoch:11[53248/60000 (89%)]\t Loss:0.118800 acc:0.96\n",
      "Train Epoch:11[53760/60000 (90%)]\t Loss:0.131308 acc:0.96\n",
      "Train Epoch:11[54272/60000 (90%)]\t Loss:0.095191 acc:0.97\n",
      "Train Epoch:11[54784/60000 (91%)]\t Loss:0.129137 acc:0.95\n",
      "Train Epoch:11[55296/60000 (92%)]\t Loss:0.099291 acc:0.98\n",
      "Train Epoch:11[55808/60000 (93%)]\t Loss:0.092368 acc:0.96\n",
      "Train Epoch:11[56320/60000 (94%)]\t Loss:0.097069 acc:0.97\n",
      "Train Epoch:11[56832/60000 (95%)]\t Loss:0.075789 acc:0.98\n",
      "Train Epoch:11[57344/60000 (96%)]\t Loss:0.101546 acc:0.97\n",
      "Train Epoch:11[57856/60000 (96%)]\t Loss:0.072507 acc:0.98\n",
      "Train Epoch:11[58368/60000 (97%)]\t Loss:0.066421 acc:0.98\n",
      "Train Epoch:11[58880/60000 (98%)]\t Loss:0.044343 acc:0.98\n",
      "Train Epoch:11[59392/60000 (99%)]\t Loss:0.108042 acc:0.98\n",
      "Train Epoch:11[59904/60000 (100%)]\t Loss:0.217856 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:11 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:11 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:11 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:11 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:11 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:11 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:11 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:11 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:11 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:11 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:11 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:11 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:11 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:11 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:11 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:11 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:11 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:11 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:11 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:11 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:12[0/60000 (0%)]\t Loss:0.140914 acc:0.96\n",
      "Train Epoch:12[512/60000 (1%)]\t Loss:0.135649 acc:0.96\n",
      "Train Epoch:12[1024/60000 (2%)]\t Loss:0.137728 acc:0.96\n",
      "Train Epoch:12[1536/60000 (3%)]\t Loss:0.079586 acc:0.98\n",
      "Train Epoch:12[2048/60000 (3%)]\t Loss:0.064960 acc:0.99\n",
      "Train Epoch:12[2560/60000 (4%)]\t Loss:0.094816 acc:0.97\n",
      "Train Epoch:12[3072/60000 (5%)]\t Loss:0.060198 acc:0.98\n",
      "Train Epoch:12[3584/60000 (6%)]\t Loss:0.069044 acc:0.97\n",
      "Train Epoch:12[4096/60000 (7%)]\t Loss:0.103027 acc:0.97\n",
      "Train Epoch:12[4608/60000 (8%)]\t Loss:0.116929 acc:0.97\n",
      "Train Epoch:12[5120/60000 (9%)]\t Loss:0.114510 acc:0.98\n",
      "Train Epoch:12[5632/60000 (9%)]\t Loss:0.133603 acc:0.97\n",
      "Train Epoch:12[6144/60000 (10%)]\t Loss:0.119260 acc:0.97\n",
      "Train Epoch:12[6656/60000 (11%)]\t Loss:0.146994 acc:0.96\n",
      "Train Epoch:12[7168/60000 (12%)]\t Loss:0.121907 acc:0.96\n",
      "Train Epoch:12[7680/60000 (13%)]\t Loss:0.101306 acc:0.97\n",
      "Train Epoch:12[8192/60000 (14%)]\t Loss:0.128460 acc:0.96\n",
      "Train Epoch:12[8704/60000 (15%)]\t Loss:0.191459 acc:0.95\n",
      "Train Epoch:12[9216/60000 (15%)]\t Loss:0.122604 acc:0.96\n",
      "Train Epoch:12[9728/60000 (16%)]\t Loss:0.123398 acc:0.96\n",
      "Train Epoch:12[10240/60000 (17%)]\t Loss:0.084815 acc:0.98\n",
      "Train Epoch:12[10752/60000 (18%)]\t Loss:0.106251 acc:0.97\n",
      "Train Epoch:12[11264/60000 (19%)]\t Loss:0.107800 acc:0.96\n",
      "Train Epoch:12[11776/60000 (20%)]\t Loss:0.098507 acc:0.97\n",
      "Train Epoch:12[12288/60000 (20%)]\t Loss:0.113543 acc:0.96\n",
      "Train Epoch:12[12800/60000 (21%)]\t Loss:0.108404 acc:0.97\n",
      "Train Epoch:12[13312/60000 (22%)]\t Loss:0.088742 acc:0.98\n",
      "Train Epoch:12[13824/60000 (23%)]\t Loss:0.123122 acc:0.96\n",
      "Train Epoch:12[14336/60000 (24%)]\t Loss:0.162535 acc:0.94\n",
      "Train Epoch:12[14848/60000 (25%)]\t Loss:0.106194 acc:0.96\n",
      "Train Epoch:12[15360/60000 (26%)]\t Loss:0.126443 acc:0.96\n",
      "Train Epoch:12[15872/60000 (26%)]\t Loss:0.118505 acc:0.96\n",
      "Train Epoch:12[16384/60000 (27%)]\t Loss:0.132227 acc:0.97\n",
      "Train Epoch:12[16896/60000 (28%)]\t Loss:0.104662 acc:0.96\n",
      "Train Epoch:12[17408/60000 (29%)]\t Loss:0.124740 acc:0.97\n",
      "Train Epoch:12[17920/60000 (30%)]\t Loss:0.080716 acc:0.98\n",
      "Train Epoch:12[18432/60000 (31%)]\t Loss:0.075962 acc:0.98\n",
      "Train Epoch:12[18944/60000 (32%)]\t Loss:0.114971 acc:0.97\n",
      "Train Epoch:12[19456/60000 (32%)]\t Loss:0.103454 acc:0.97\n",
      "Train Epoch:12[19968/60000 (33%)]\t Loss:0.112336 acc:0.97\n",
      "Train Epoch:12[20480/60000 (34%)]\t Loss:0.153016 acc:0.96\n",
      "Train Epoch:12[20992/60000 (35%)]\t Loss:0.107075 acc:0.96\n",
      "Train Epoch:12[21504/60000 (36%)]\t Loss:0.077256 acc:0.97\n",
      "Train Epoch:12[22016/60000 (37%)]\t Loss:0.099676 acc:0.97\n",
      "Train Epoch:12[22528/60000 (38%)]\t Loss:0.095460 acc:0.96\n",
      "Train Epoch:12[23040/60000 (38%)]\t Loss:0.058932 acc:0.98\n",
      "Train Epoch:12[23552/60000 (39%)]\t Loss:0.116822 acc:0.97\n",
      "Train Epoch:12[24064/60000 (40%)]\t Loss:0.086812 acc:0.97\n",
      "Train Epoch:12[24576/60000 (41%)]\t Loss:0.116052 acc:0.97\n",
      "Train Epoch:12[25088/60000 (42%)]\t Loss:0.105862 acc:0.96\n",
      "Train Epoch:12[25600/60000 (43%)]\t Loss:0.103685 acc:0.97\n",
      "Train Epoch:12[26112/60000 (44%)]\t Loss:0.146258 acc:0.95\n",
      "Train Epoch:12[26624/60000 (44%)]\t Loss:0.135782 acc:0.97\n",
      "Train Epoch:12[27136/60000 (45%)]\t Loss:0.143116 acc:0.96\n",
      "Train Epoch:12[27648/60000 (46%)]\t Loss:0.093496 acc:0.97\n",
      "Train Epoch:12[28160/60000 (47%)]\t Loss:0.141186 acc:0.96\n",
      "Train Epoch:12[28672/60000 (48%)]\t Loss:0.087382 acc:0.97\n",
      "Train Epoch:12[29184/60000 (49%)]\t Loss:0.097525 acc:0.97\n",
      "Train Epoch:12[29696/60000 (49%)]\t Loss:0.141771 acc:0.95\n",
      "Train Epoch:12[30208/60000 (50%)]\t Loss:0.090878 acc:0.98\n",
      "Train Epoch:12[30720/60000 (51%)]\t Loss:0.120870 acc:0.96\n",
      "Train Epoch:12[31232/60000 (52%)]\t Loss:0.184615 acc:0.94\n",
      "Train Epoch:12[31744/60000 (53%)]\t Loss:0.103857 acc:0.97\n",
      "Train Epoch:12[32256/60000 (54%)]\t Loss:0.121519 acc:0.96\n",
      "Train Epoch:12[32768/60000 (55%)]\t Loss:0.101423 acc:0.97\n",
      "Train Epoch:12[33280/60000 (55%)]\t Loss:0.108149 acc:0.96\n",
      "Train Epoch:12[33792/60000 (56%)]\t Loss:0.064003 acc:0.98\n",
      "Train Epoch:12[34304/60000 (57%)]\t Loss:0.162211 acc:0.95\n",
      "Train Epoch:12[34816/60000 (58%)]\t Loss:0.101078 acc:0.96\n",
      "Train Epoch:12[35328/60000 (59%)]\t Loss:0.112249 acc:0.96\n",
      "Train Epoch:12[35840/60000 (60%)]\t Loss:0.089767 acc:0.96\n",
      "Train Epoch:12[36352/60000 (61%)]\t Loss:0.123952 acc:0.96\n",
      "Train Epoch:12[36864/60000 (61%)]\t Loss:0.131196 acc:0.96\n",
      "Train Epoch:12[37376/60000 (62%)]\t Loss:0.125892 acc:0.97\n",
      "Train Epoch:12[37888/60000 (63%)]\t Loss:0.066891 acc:0.98\n",
      "Train Epoch:12[38400/60000 (64%)]\t Loss:0.101056 acc:0.97\n",
      "Train Epoch:12[38912/60000 (65%)]\t Loss:0.131377 acc:0.96\n",
      "Train Epoch:12[39424/60000 (66%)]\t Loss:0.118993 acc:0.96\n",
      "Train Epoch:12[39936/60000 (67%)]\t Loss:0.092033 acc:0.98\n",
      "Train Epoch:12[40448/60000 (67%)]\t Loss:0.082700 acc:0.97\n",
      "Train Epoch:12[40960/60000 (68%)]\t Loss:0.144185 acc:0.95\n",
      "Train Epoch:12[41472/60000 (69%)]\t Loss:0.107592 acc:0.97\n",
      "Train Epoch:12[41984/60000 (70%)]\t Loss:0.132368 acc:0.95\n",
      "Train Epoch:12[42496/60000 (71%)]\t Loss:0.136886 acc:0.96\n",
      "Train Epoch:12[43008/60000 (72%)]\t Loss:0.094622 acc:0.96\n",
      "Train Epoch:12[43520/60000 (73%)]\t Loss:0.097540 acc:0.97\n",
      "Train Epoch:12[44032/60000 (73%)]\t Loss:0.138390 acc:0.96\n",
      "Train Epoch:12[44544/60000 (74%)]\t Loss:0.115174 acc:0.96\n",
      "Train Epoch:12[45056/60000 (75%)]\t Loss:0.089518 acc:0.97\n",
      "Train Epoch:12[45568/60000 (76%)]\t Loss:0.170135 acc:0.95\n",
      "Train Epoch:12[46080/60000 (77%)]\t Loss:0.156972 acc:0.95\n",
      "Train Epoch:12[46592/60000 (78%)]\t Loss:0.109210 acc:0.96\n",
      "Train Epoch:12[47104/60000 (79%)]\t Loss:0.141282 acc:0.96\n",
      "Train Epoch:12[47616/60000 (79%)]\t Loss:0.100432 acc:0.97\n",
      "Train Epoch:12[48128/60000 (80%)]\t Loss:0.077002 acc:0.97\n",
      "Train Epoch:12[48640/60000 (81%)]\t Loss:0.149505 acc:0.95\n",
      "Train Epoch:12[49152/60000 (82%)]\t Loss:0.167179 acc:0.94\n",
      "Train Epoch:12[49664/60000 (83%)]\t Loss:0.127554 acc:0.96\n",
      "Train Epoch:12[50176/60000 (84%)]\t Loss:0.187597 acc:0.95\n",
      "Train Epoch:12[50688/60000 (84%)]\t Loss:0.071637 acc:0.98\n",
      "Train Epoch:12[51200/60000 (85%)]\t Loss:0.103109 acc:0.96\n",
      "Train Epoch:12[51712/60000 (86%)]\t Loss:0.112099 acc:0.97\n",
      "Train Epoch:12[52224/60000 (87%)]\t Loss:0.078740 acc:0.97\n",
      "Train Epoch:12[52736/60000 (88%)]\t Loss:0.162295 acc:0.96\n",
      "Train Epoch:12[53248/60000 (89%)]\t Loss:0.114675 acc:0.97\n",
      "Train Epoch:12[53760/60000 (90%)]\t Loss:0.122924 acc:0.97\n",
      "Train Epoch:12[54272/60000 (90%)]\t Loss:0.086471 acc:0.97\n",
      "Train Epoch:12[54784/60000 (91%)]\t Loss:0.120890 acc:0.96\n",
      "Train Epoch:12[55296/60000 (92%)]\t Loss:0.094316 acc:0.98\n",
      "Train Epoch:12[55808/60000 (93%)]\t Loss:0.087649 acc:0.96\n",
      "Train Epoch:12[56320/60000 (94%)]\t Loss:0.092277 acc:0.97\n",
      "Train Epoch:12[56832/60000 (95%)]\t Loss:0.072266 acc:0.97\n",
      "Train Epoch:12[57344/60000 (96%)]\t Loss:0.098999 acc:0.97\n",
      "Train Epoch:12[57856/60000 (96%)]\t Loss:0.070861 acc:0.98\n",
      "Train Epoch:12[58368/60000 (97%)]\t Loss:0.064315 acc:0.98\n",
      "Train Epoch:12[58880/60000 (98%)]\t Loss:0.041225 acc:0.98\n",
      "Train Epoch:12[59392/60000 (99%)]\t Loss:0.104898 acc:0.98\n",
      "Train Epoch:12[59904/60000 (100%)]\t Loss:0.204793 acc:0.19\n",
      "===> Saving models...\n",
      "Test Epoch:12 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:12 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:12 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:12 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:12 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:12 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:12 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:12 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:12 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:12 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:12 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:12 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:12 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:12 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:12 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:12 [7680/10000 (77%)]\t acc:0.80\n",
      "Test Epoch:12 [8192/10000 (82%)]\t acc:0.85\n",
      "Test Epoch:12 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:12 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:12 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:13[0/60000 (0%)]\t Loss:0.132019 acc:0.96\n",
      "Train Epoch:13[512/60000 (1%)]\t Loss:0.127374 acc:0.96\n",
      "Train Epoch:13[1024/60000 (2%)]\t Loss:0.128592 acc:0.96\n",
      "Train Epoch:13[1536/60000 (3%)]\t Loss:0.075132 acc:0.98\n",
      "Train Epoch:13[2048/60000 (3%)]\t Loss:0.061111 acc:0.99\n",
      "Train Epoch:13[2560/60000 (4%)]\t Loss:0.090346 acc:0.97\n",
      "Train Epoch:13[3072/60000 (5%)]\t Loss:0.057181 acc:0.98\n",
      "Train Epoch:13[3584/60000 (6%)]\t Loss:0.064985 acc:0.98\n",
      "Train Epoch:13[4096/60000 (7%)]\t Loss:0.093228 acc:0.97\n",
      "Train Epoch:13[4608/60000 (8%)]\t Loss:0.109099 acc:0.97\n",
      "Train Epoch:13[5120/60000 (9%)]\t Loss:0.107445 acc:0.98\n",
      "Train Epoch:13[5632/60000 (9%)]\t Loss:0.124764 acc:0.97\n",
      "Train Epoch:13[6144/60000 (10%)]\t Loss:0.111840 acc:0.97\n",
      "Train Epoch:13[6656/60000 (11%)]\t Loss:0.140416 acc:0.96\n",
      "Train Epoch:13[7168/60000 (12%)]\t Loss:0.115333 acc:0.96\n",
      "Train Epoch:13[7680/60000 (13%)]\t Loss:0.093131 acc:0.97\n",
      "Train Epoch:13[8192/60000 (14%)]\t Loss:0.124075 acc:0.96\n",
      "Train Epoch:13[8704/60000 (15%)]\t Loss:0.178151 acc:0.95\n",
      "Train Epoch:13[9216/60000 (15%)]\t Loss:0.113912 acc:0.96\n",
      "Train Epoch:13[9728/60000 (16%)]\t Loss:0.115441 acc:0.96\n",
      "Train Epoch:13[10240/60000 (17%)]\t Loss:0.080644 acc:0.97\n",
      "Train Epoch:13[10752/60000 (18%)]\t Loss:0.102101 acc:0.97\n",
      "Train Epoch:13[11264/60000 (19%)]\t Loss:0.102290 acc:0.96\n",
      "Train Epoch:13[11776/60000 (20%)]\t Loss:0.094986 acc:0.97\n",
      "Train Epoch:13[12288/60000 (20%)]\t Loss:0.102920 acc:0.97\n",
      "Train Epoch:13[12800/60000 (21%)]\t Loss:0.098445 acc:0.96\n",
      "Train Epoch:13[13312/60000 (22%)]\t Loss:0.082861 acc:0.98\n",
      "Train Epoch:13[13824/60000 (23%)]\t Loss:0.115598 acc:0.96\n",
      "Train Epoch:13[14336/60000 (24%)]\t Loss:0.151896 acc:0.95\n",
      "Train Epoch:13[14848/60000 (25%)]\t Loss:0.098237 acc:0.96\n",
      "Train Epoch:13[15360/60000 (26%)]\t Loss:0.119028 acc:0.96\n",
      "Train Epoch:13[15872/60000 (26%)]\t Loss:0.114813 acc:0.96\n",
      "Train Epoch:13[16384/60000 (27%)]\t Loss:0.127278 acc:0.96\n",
      "Train Epoch:13[16896/60000 (28%)]\t Loss:0.102610 acc:0.96\n",
      "Train Epoch:13[17408/60000 (29%)]\t Loss:0.120722 acc:0.96\n",
      "Train Epoch:13[17920/60000 (30%)]\t Loss:0.078510 acc:0.98\n",
      "Train Epoch:13[18432/60000 (31%)]\t Loss:0.070147 acc:0.98\n",
      "Train Epoch:13[18944/60000 (32%)]\t Loss:0.107947 acc:0.97\n",
      "Train Epoch:13[19456/60000 (32%)]\t Loss:0.092780 acc:0.97\n",
      "Train Epoch:13[19968/60000 (33%)]\t Loss:0.101697 acc:0.97\n",
      "Train Epoch:13[20480/60000 (34%)]\t Loss:0.142151 acc:0.96\n",
      "Train Epoch:13[20992/60000 (35%)]\t Loss:0.101971 acc:0.96\n",
      "Train Epoch:13[21504/60000 (36%)]\t Loss:0.073368 acc:0.98\n",
      "Train Epoch:13[22016/60000 (37%)]\t Loss:0.096468 acc:0.97\n",
      "Train Epoch:13[22528/60000 (38%)]\t Loss:0.086230 acc:0.96\n",
      "Train Epoch:13[23040/60000 (38%)]\t Loss:0.057697 acc:0.98\n",
      "Train Epoch:13[23552/60000 (39%)]\t Loss:0.109814 acc:0.98\n",
      "Train Epoch:13[24064/60000 (40%)]\t Loss:0.076379 acc:0.98\n",
      "Train Epoch:13[24576/60000 (41%)]\t Loss:0.108568 acc:0.97\n",
      "Train Epoch:13[25088/60000 (42%)]\t Loss:0.101471 acc:0.97\n",
      "Train Epoch:13[25600/60000 (43%)]\t Loss:0.099821 acc:0.97\n",
      "Train Epoch:13[26112/60000 (44%)]\t Loss:0.139524 acc:0.95\n",
      "Train Epoch:13[26624/60000 (44%)]\t Loss:0.131797 acc:0.97\n",
      "Train Epoch:13[27136/60000 (45%)]\t Loss:0.144809 acc:0.96\n",
      "Train Epoch:13[27648/60000 (46%)]\t Loss:0.091925 acc:0.96\n",
      "Train Epoch:13[28160/60000 (47%)]\t Loss:0.138918 acc:0.96\n",
      "Train Epoch:13[28672/60000 (48%)]\t Loss:0.081137 acc:0.97\n",
      "Train Epoch:13[29184/60000 (49%)]\t Loss:0.090891 acc:0.96\n",
      "Train Epoch:13[29696/60000 (49%)]\t Loss:0.131579 acc:0.96\n",
      "Train Epoch:13[30208/60000 (50%)]\t Loss:0.082247 acc:0.98\n",
      "Train Epoch:13[30720/60000 (51%)]\t Loss:0.111364 acc:0.96\n",
      "Train Epoch:13[31232/60000 (52%)]\t Loss:0.174392 acc:0.95\n",
      "Train Epoch:13[31744/60000 (53%)]\t Loss:0.099485 acc:0.97\n",
      "Train Epoch:13[32256/60000 (54%)]\t Loss:0.115753 acc:0.97\n",
      "Train Epoch:13[32768/60000 (55%)]\t Loss:0.096590 acc:0.97\n",
      "Train Epoch:13[33280/60000 (55%)]\t Loss:0.104151 acc:0.96\n",
      "Train Epoch:13[33792/60000 (56%)]\t Loss:0.062234 acc:0.98\n",
      "Train Epoch:13[34304/60000 (57%)]\t Loss:0.157593 acc:0.95\n",
      "Train Epoch:13[34816/60000 (58%)]\t Loss:0.094069 acc:0.97\n",
      "Train Epoch:13[35328/60000 (59%)]\t Loss:0.101138 acc:0.97\n",
      "Train Epoch:13[35840/60000 (60%)]\t Loss:0.086025 acc:0.96\n",
      "Train Epoch:13[36352/60000 (61%)]\t Loss:0.116457 acc:0.97\n",
      "Train Epoch:13[36864/60000 (61%)]\t Loss:0.123125 acc:0.96\n",
      "Train Epoch:13[37376/60000 (62%)]\t Loss:0.121286 acc:0.97\n",
      "Train Epoch:13[37888/60000 (63%)]\t Loss:0.061458 acc:0.98\n",
      "Train Epoch:13[38400/60000 (64%)]\t Loss:0.094509 acc:0.97\n",
      "Train Epoch:13[38912/60000 (65%)]\t Loss:0.130615 acc:0.96\n",
      "Train Epoch:13[39424/60000 (66%)]\t Loss:0.111730 acc:0.96\n",
      "Train Epoch:13[39936/60000 (67%)]\t Loss:0.079639 acc:0.98\n",
      "Train Epoch:13[40448/60000 (67%)]\t Loss:0.074751 acc:0.97\n",
      "Train Epoch:13[40960/60000 (68%)]\t Loss:0.135414 acc:0.96\n",
      "Train Epoch:13[41472/60000 (69%)]\t Loss:0.101759 acc:0.97\n",
      "Train Epoch:13[41984/60000 (70%)]\t Loss:0.126061 acc:0.96\n",
      "Train Epoch:13[42496/60000 (71%)]\t Loss:0.131552 acc:0.96\n",
      "Train Epoch:13[43008/60000 (72%)]\t Loss:0.093448 acc:0.96\n",
      "Train Epoch:13[43520/60000 (73%)]\t Loss:0.091237 acc:0.97\n",
      "Train Epoch:13[44032/60000 (73%)]\t Loss:0.132858 acc:0.96\n",
      "Train Epoch:13[44544/60000 (74%)]\t Loss:0.108126 acc:0.96\n",
      "Train Epoch:13[45056/60000 (75%)]\t Loss:0.085728 acc:0.97\n",
      "Train Epoch:13[45568/60000 (76%)]\t Loss:0.161998 acc:0.96\n",
      "Train Epoch:13[46080/60000 (77%)]\t Loss:0.145558 acc:0.95\n",
      "Train Epoch:13[46592/60000 (78%)]\t Loss:0.102301 acc:0.96\n",
      "Train Epoch:13[47104/60000 (79%)]\t Loss:0.134430 acc:0.96\n",
      "Train Epoch:13[47616/60000 (79%)]\t Loss:0.097205 acc:0.97\n",
      "Train Epoch:13[48128/60000 (80%)]\t Loss:0.072890 acc:0.98\n",
      "Train Epoch:13[48640/60000 (81%)]\t Loss:0.144746 acc:0.95\n",
      "Train Epoch:13[49152/60000 (82%)]\t Loss:0.156299 acc:0.95\n",
      "Train Epoch:13[49664/60000 (83%)]\t Loss:0.119741 acc:0.96\n",
      "Train Epoch:13[50176/60000 (84%)]\t Loss:0.182018 acc:0.95\n",
      "Train Epoch:13[50688/60000 (84%)]\t Loss:0.063606 acc:0.98\n",
      "Train Epoch:13[51200/60000 (85%)]\t Loss:0.096224 acc:0.96\n",
      "Train Epoch:13[51712/60000 (86%)]\t Loss:0.105480 acc:0.97\n",
      "Train Epoch:13[52224/60000 (87%)]\t Loss:0.073967 acc:0.97\n",
      "Train Epoch:13[52736/60000 (88%)]\t Loss:0.153565 acc:0.96\n",
      "Train Epoch:13[53248/60000 (89%)]\t Loss:0.112966 acc:0.97\n",
      "Train Epoch:13[53760/60000 (90%)]\t Loss:0.116409 acc:0.97\n",
      "Train Epoch:13[54272/60000 (90%)]\t Loss:0.078133 acc:0.97\n",
      "Train Epoch:13[54784/60000 (91%)]\t Loss:0.112423 acc:0.96\n",
      "Train Epoch:13[55296/60000 (92%)]\t Loss:0.090899 acc:0.98\n",
      "Train Epoch:13[55808/60000 (93%)]\t Loss:0.081569 acc:0.97\n",
      "Train Epoch:13[56320/60000 (94%)]\t Loss:0.086769 acc:0.97\n",
      "Train Epoch:13[56832/60000 (95%)]\t Loss:0.069068 acc:0.98\n",
      "Train Epoch:13[57344/60000 (96%)]\t Loss:0.096550 acc:0.97\n",
      "Train Epoch:13[57856/60000 (96%)]\t Loss:0.070042 acc:0.98\n",
      "Train Epoch:13[58368/60000 (97%)]\t Loss:0.063177 acc:0.98\n",
      "Train Epoch:13[58880/60000 (98%)]\t Loss:0.040255 acc:0.99\n",
      "Train Epoch:13[59392/60000 (99%)]\t Loss:0.103465 acc:0.98\n",
      "Train Epoch:13[59904/60000 (100%)]\t Loss:0.191593 acc:0.19\n",
      "===> Saving models...\n",
      "Test Epoch:13 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:13 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:13 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:13 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:13 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:13 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:13 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:13 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:13 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:13 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:13 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:13 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:13 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:13 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:13 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:13 [7680/10000 (77%)]\t acc:0.80\n",
      "Test Epoch:13 [8192/10000 (82%)]\t acc:0.85\n",
      "Test Epoch:13 [8704/10000 (87%)]\t acc:0.90\n",
      "Test Epoch:13 [9216/10000 (92%)]\t acc:0.95\n",
      "Test Epoch:13 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:14[0/60000 (0%)]\t Loss:0.124376 acc:0.96\n",
      "Train Epoch:14[512/60000 (1%)]\t Loss:0.120197 acc:0.97\n",
      "Train Epoch:14[1024/60000 (2%)]\t Loss:0.121728 acc:0.96\n",
      "Train Epoch:14[1536/60000 (3%)]\t Loss:0.070236 acc:0.98\n",
      "Train Epoch:14[2048/60000 (3%)]\t Loss:0.057373 acc:0.99\n",
      "Train Epoch:14[2560/60000 (4%)]\t Loss:0.086938 acc:0.97\n",
      "Train Epoch:14[3072/60000 (5%)]\t Loss:0.054771 acc:0.98\n",
      "Train Epoch:14[3584/60000 (6%)]\t Loss:0.063278 acc:0.98\n",
      "Train Epoch:14[4096/60000 (7%)]\t Loss:0.086891 acc:0.97\n",
      "Train Epoch:14[4608/60000 (8%)]\t Loss:0.104187 acc:0.97\n",
      "Train Epoch:14[5120/60000 (9%)]\t Loss:0.101700 acc:0.97\n",
      "Train Epoch:14[5632/60000 (9%)]\t Loss:0.118582 acc:0.97\n",
      "Train Epoch:14[6144/60000 (10%)]\t Loss:0.103435 acc:0.98\n",
      "Train Epoch:14[6656/60000 (11%)]\t Loss:0.133202 acc:0.97\n",
      "Train Epoch:14[7168/60000 (12%)]\t Loss:0.109467 acc:0.96\n",
      "Train Epoch:14[7680/60000 (13%)]\t Loss:0.087269 acc:0.97\n",
      "Train Epoch:14[8192/60000 (14%)]\t Loss:0.119424 acc:0.96\n",
      "Train Epoch:14[8704/60000 (15%)]\t Loss:0.167920 acc:0.96\n",
      "Train Epoch:14[9216/60000 (15%)]\t Loss:0.107277 acc:0.97\n",
      "Train Epoch:14[9728/60000 (16%)]\t Loss:0.108975 acc:0.96\n",
      "Train Epoch:14[10240/60000 (17%)]\t Loss:0.079105 acc:0.97\n",
      "Train Epoch:14[10752/60000 (18%)]\t Loss:0.099119 acc:0.97\n",
      "Train Epoch:14[11264/60000 (19%)]\t Loss:0.096024 acc:0.96\n",
      "Train Epoch:14[11776/60000 (20%)]\t Loss:0.092108 acc:0.97\n",
      "Train Epoch:14[12288/60000 (20%)]\t Loss:0.093733 acc:0.97\n",
      "Train Epoch:14[12800/60000 (21%)]\t Loss:0.091989 acc:0.97\n",
      "Train Epoch:14[13312/60000 (22%)]\t Loss:0.078800 acc:0.98\n",
      "Train Epoch:14[13824/60000 (23%)]\t Loss:0.111355 acc:0.96\n",
      "Train Epoch:14[14336/60000 (24%)]\t Loss:0.146234 acc:0.95\n",
      "Train Epoch:14[14848/60000 (25%)]\t Loss:0.091002 acc:0.96\n",
      "Train Epoch:14[15360/60000 (26%)]\t Loss:0.111007 acc:0.96\n",
      "Train Epoch:14[15872/60000 (26%)]\t Loss:0.109621 acc:0.96\n",
      "Train Epoch:14[16384/60000 (27%)]\t Loss:0.119923 acc:0.97\n",
      "Train Epoch:14[16896/60000 (28%)]\t Loss:0.097338 acc:0.96\n",
      "Train Epoch:14[17408/60000 (29%)]\t Loss:0.115793 acc:0.96\n",
      "Train Epoch:14[17920/60000 (30%)]\t Loss:0.076318 acc:0.98\n",
      "Train Epoch:14[18432/60000 (31%)]\t Loss:0.066220 acc:0.98\n",
      "Train Epoch:14[18944/60000 (32%)]\t Loss:0.103740 acc:0.97\n",
      "Train Epoch:14[19456/60000 (32%)]\t Loss:0.087037 acc:0.97\n",
      "Train Epoch:14[19968/60000 (33%)]\t Loss:0.092642 acc:0.97\n",
      "Train Epoch:14[20480/60000 (34%)]\t Loss:0.132675 acc:0.96\n",
      "Train Epoch:14[20992/60000 (35%)]\t Loss:0.094885 acc:0.96\n",
      "Train Epoch:14[21504/60000 (36%)]\t Loss:0.068581 acc:0.98\n",
      "Train Epoch:14[22016/60000 (37%)]\t Loss:0.090467 acc:0.98\n",
      "Train Epoch:14[22528/60000 (38%)]\t Loss:0.079851 acc:0.96\n",
      "Train Epoch:14[23040/60000 (38%)]\t Loss:0.055189 acc:0.98\n",
      "Train Epoch:14[23552/60000 (39%)]\t Loss:0.106665 acc:0.98\n",
      "Train Epoch:14[24064/60000 (40%)]\t Loss:0.069478 acc:0.98\n",
      "Train Epoch:14[24576/60000 (41%)]\t Loss:0.104178 acc:0.97\n",
      "Train Epoch:14[25088/60000 (42%)]\t Loss:0.098546 acc:0.97\n",
      "Train Epoch:14[25600/60000 (43%)]\t Loss:0.095619 acc:0.97\n",
      "Train Epoch:14[26112/60000 (44%)]\t Loss:0.133766 acc:0.96\n",
      "Train Epoch:14[26624/60000 (44%)]\t Loss:0.125310 acc:0.97\n",
      "Train Epoch:14[27136/60000 (45%)]\t Loss:0.143698 acc:0.96\n",
      "Train Epoch:14[27648/60000 (46%)]\t Loss:0.088953 acc:0.97\n",
      "Train Epoch:14[28160/60000 (47%)]\t Loss:0.136593 acc:0.96\n",
      "Train Epoch:14[28672/60000 (48%)]\t Loss:0.077374 acc:0.97\n",
      "Train Epoch:14[29184/60000 (49%)]\t Loss:0.085717 acc:0.96\n",
      "Train Epoch:14[29696/60000 (49%)]\t Loss:0.124958 acc:0.96\n",
      "Train Epoch:14[30208/60000 (50%)]\t Loss:0.075859 acc:0.98\n",
      "Train Epoch:14[30720/60000 (51%)]\t Loss:0.104062 acc:0.97\n",
      "Train Epoch:14[31232/60000 (52%)]\t Loss:0.165369 acc:0.95\n",
      "Train Epoch:14[31744/60000 (53%)]\t Loss:0.094438 acc:0.98\n",
      "Train Epoch:14[32256/60000 (54%)]\t Loss:0.110367 acc:0.97\n",
      "Train Epoch:14[32768/60000 (55%)]\t Loss:0.091621 acc:0.98\n",
      "Train Epoch:14[33280/60000 (55%)]\t Loss:0.101566 acc:0.96\n",
      "Train Epoch:14[33792/60000 (56%)]\t Loss:0.060274 acc:0.98\n",
      "Train Epoch:14[34304/60000 (57%)]\t Loss:0.153093 acc:0.95\n",
      "Train Epoch:14[34816/60000 (58%)]\t Loss:0.090112 acc:0.97\n",
      "Train Epoch:14[35328/60000 (59%)]\t Loss:0.094652 acc:0.98\n",
      "Train Epoch:14[35840/60000 (60%)]\t Loss:0.083686 acc:0.97\n",
      "Train Epoch:14[36352/60000 (61%)]\t Loss:0.109627 acc:0.97\n",
      "Train Epoch:14[36864/60000 (61%)]\t Loss:0.115114 acc:0.96\n",
      "Train Epoch:14[37376/60000 (62%)]\t Loss:0.117456 acc:0.98\n",
      "Train Epoch:14[37888/60000 (63%)]\t Loss:0.056331 acc:0.99\n",
      "Train Epoch:14[38400/60000 (64%)]\t Loss:0.090035 acc:0.98\n",
      "Train Epoch:14[38912/60000 (65%)]\t Loss:0.128672 acc:0.96\n",
      "Train Epoch:14[39424/60000 (66%)]\t Loss:0.106607 acc:0.96\n",
      "Train Epoch:14[39936/60000 (67%)]\t Loss:0.071707 acc:0.98\n",
      "Train Epoch:14[40448/60000 (67%)]\t Loss:0.069488 acc:0.98\n",
      "Train Epoch:14[40960/60000 (68%)]\t Loss:0.128452 acc:0.96\n",
      "Train Epoch:14[41472/60000 (69%)]\t Loss:0.096363 acc:0.97\n",
      "Train Epoch:14[41984/60000 (70%)]\t Loss:0.121942 acc:0.96\n",
      "Train Epoch:14[42496/60000 (71%)]\t Loss:0.126303 acc:0.96\n",
      "Train Epoch:14[43008/60000 (72%)]\t Loss:0.090264 acc:0.97\n",
      "Train Epoch:14[43520/60000 (73%)]\t Loss:0.086320 acc:0.97\n",
      "Train Epoch:14[44032/60000 (73%)]\t Loss:0.129199 acc:0.96\n",
      "Train Epoch:14[44544/60000 (74%)]\t Loss:0.103293 acc:0.96\n",
      "Train Epoch:14[45056/60000 (75%)]\t Loss:0.083631 acc:0.97\n",
      "Train Epoch:14[45568/60000 (76%)]\t Loss:0.155874 acc:0.96\n",
      "Train Epoch:14[46080/60000 (77%)]\t Loss:0.136192 acc:0.96\n",
      "Train Epoch:14[46592/60000 (78%)]\t Loss:0.095461 acc:0.97\n",
      "Train Epoch:14[47104/60000 (79%)]\t Loss:0.129967 acc:0.96\n",
      "Train Epoch:14[47616/60000 (79%)]\t Loss:0.093615 acc:0.97\n",
      "Train Epoch:14[48128/60000 (80%)]\t Loss:0.068730 acc:0.98\n",
      "Train Epoch:14[48640/60000 (81%)]\t Loss:0.139637 acc:0.96\n",
      "Train Epoch:14[49152/60000 (82%)]\t Loss:0.148971 acc:0.95\n",
      "Train Epoch:14[49664/60000 (83%)]\t Loss:0.116402 acc:0.96\n",
      "Train Epoch:14[50176/60000 (84%)]\t Loss:0.178449 acc:0.95\n",
      "Train Epoch:14[50688/60000 (84%)]\t Loss:0.057479 acc:0.98\n",
      "Train Epoch:14[51200/60000 (85%)]\t Loss:0.090528 acc:0.96\n",
      "Train Epoch:14[51712/60000 (86%)]\t Loss:0.099334 acc:0.97\n",
      "Train Epoch:14[52224/60000 (87%)]\t Loss:0.069874 acc:0.97\n",
      "Train Epoch:14[52736/60000 (88%)]\t Loss:0.147303 acc:0.96\n",
      "Train Epoch:14[53248/60000 (89%)]\t Loss:0.109814 acc:0.97\n",
      "Train Epoch:14[53760/60000 (90%)]\t Loss:0.112424 acc:0.98\n",
      "Train Epoch:14[54272/60000 (90%)]\t Loss:0.072882 acc:0.98\n",
      "Train Epoch:14[54784/60000 (91%)]\t Loss:0.106745 acc:0.97\n",
      "Train Epoch:14[55296/60000 (92%)]\t Loss:0.088035 acc:0.98\n",
      "Train Epoch:14[55808/60000 (93%)]\t Loss:0.076359 acc:0.97\n",
      "Train Epoch:14[56320/60000 (94%)]\t Loss:0.080724 acc:0.98\n",
      "Train Epoch:14[56832/60000 (95%)]\t Loss:0.066779 acc:0.98\n",
      "Train Epoch:14[57344/60000 (96%)]\t Loss:0.092170 acc:0.97\n",
      "Train Epoch:14[57856/60000 (96%)]\t Loss:0.067962 acc:0.98\n",
      "Train Epoch:14[58368/60000 (97%)]\t Loss:0.062419 acc:0.98\n",
      "Train Epoch:14[58880/60000 (98%)]\t Loss:0.038483 acc:0.99\n",
      "Train Epoch:14[59392/60000 (99%)]\t Loss:0.101657 acc:0.98\n",
      "Train Epoch:14[59904/60000 (100%)]\t Loss:0.183219 acc:0.19\n",
      "===> Saving models...\n",
      "Test Epoch:14 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:14 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:14 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:14 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:14 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:14 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:14 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:14 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:14 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:14 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:14 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:14 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:14 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:14 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:14 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:14 [7680/10000 (77%)]\t acc:0.80\n",
      "Test Epoch:14 [8192/10000 (82%)]\t acc:0.85\n",
      "Test Epoch:14 [8704/10000 (87%)]\t acc:0.90\n",
      "Test Epoch:14 [9216/10000 (92%)]\t acc:0.95\n",
      "Test Epoch:14 [9728/10000 (97%)]\t acc:0.97\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = SummaryWriter('logs')\n",
    "    # device = torch.device('cuda:0')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    net = LeNet()  # 实例化网络\n",
    "    # data_input = Variable(torch.randn(16,1,28,28))\n",
    "    # print(net(data_input))\n",
    "    net.to(device) # 将参数送入GPU中\n",
    "\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    cost_fun = nn.CrossEntropyLoss()\n",
    "    # optim\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.95, weight_decay=1e-3)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        # train\n",
    "        train(epoch)\n",
    "        writer.add_scalar('Train/Loss', train_loss[-2].item(), epoch)\n",
    "        writer.add_scalar('Train/Acc', train_acc[-2], epoch)\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # save_state\n",
    "        # ----------------------------------------- #\n",
    "        print('===> Saving models...')\n",
    "        state = {\n",
    "            'state': net.state_dict(),\n",
    "            'epoch': epoch  # 将epoch一并保存\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('./checkpoint')\n",
    "        torch.save(state, path_model + 'Epoch-' + str(epoch) + '-Loss-'+ str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # test\n",
    "        # ----------------------------------------- #\n",
    "        test()\n",
    "    writer.close()\n",
    "\n",
    "    # ----------------------------------------- #\n",
    "    # 加载指定的weights进行预测\n",
    "    # ----------------------------------------- #\n",
    "    # predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneTensor(model_path, file_path, labely):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    img0 = cv2.imread(file_path, 0).astype(np.uint8)\n",
    "    print(img0.shape)\n",
    "    img0 = cv2.resize(img0, (28,28))\n",
    "    img0 = img0 / 255.\n",
    "    img0 = torch.from_numpy(img0)\n",
    "\n",
    "    img = torch.as_tensor(img0, dtype=torch.float32)\n",
    "    img = img.unsqueeze(0) #在第一维度上增加一个维度，作为通道大小\n",
    "    img = Variable(torch.unsqueeze(img, dim=0).float(),).to(device) #在第一维度上增加一个维度，作为batch size大小\n",
    "    # img = img.permute(0, 3, 1, 2) # 将图像channel提到前面即 [batch size, width, height, channel]-> [batch size, channel, width, height]\n",
    "    print(img.shape)\n",
    "    print('===> Loading weights : ' + model_path)\n",
    "    weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        predy = net(img)\n",
    "        # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "\n",
    "        # predicted, actual = classes[torch.argmax(predy[0])], classes[labely]\n",
    "        # 最终输出的预测值与真实值\n",
    "        # print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n",
    "        np.set_printoptions(suppress = True) #非科学计数法\n",
    "        # predy[0] = F.softmax(predy[0],dim=1)\n",
    "        for x, y in predy[1].items():\n",
    "            if x == 'softmax_output':\n",
    "                print(f'predicted: \"{y.numpy()}\", actual:\"{labely}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "torch.Size([1, 1, 28, 28])\n",
      "===> Loading weights : ./checkpoint/model_14_2.pth\n",
      "predicted: \"[[0.00040186 0.         0.00000441 0.         0.00001509 0.00000096\n",
      "  0.99957746 0.         0.00000016 0.        ]]\", actual:\"6\"\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "model_path = './checkpoint/model_14_2.pth' #  ***为指定加载的权重文件名称\n",
    "file_path = './test_images/pic_6_23534.png'\n",
    "# file_path = './test_images/padpic_9_13429.png'\n",
    "labely = 6\n",
    "# predict()\n",
    "predictOneTensor(model_path, file_path, labely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Linear-7                  [-1, 120]          48,120\n",
      "              ReLU-8                  [-1, 120]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             ReLU-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "          Softmax-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#输出每层网络参数信息\n",
    "def variaes_show():\n",
    "    net = LeNet()\n",
    "    data_input = Variable(torch.randn(16,1,28,28))\n",
    "    print(data_input.size())\n",
    "    net(data_input)\n",
    "    print(summary(net,(1,28,28)))\n",
    "\n",
    "variaes_show()\n",
    "\n",
    "# net = LeNet()\n",
    "# summary(net,(1,28,28),batch_size=16,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading weights : ./checkpoint/model_14.pth\n",
      "type: <class 'dict'>\n",
      "len: 2\n",
      "key: state\n",
      "key: epoch\n",
      "================================\n",
      "block_1.0.weight\n",
      "shape: (6, 1, 5, 5)\n",
      "csv:  (6, 25) \n",
      "\n",
      "block_1.0.bias\n",
      "shape: (6,)\n",
      "csv:  (6,) \n",
      "\n",
      "block_1.3.weight\n",
      "shape: (16, 6, 5, 5)\n",
      "csv:  (16, 150) \n",
      "\n",
      "block_1.3.bias\n",
      "shape: (16,)\n",
      "csv:  (16,) \n",
      "\n",
      "block_2.0.weight\n",
      "shape: (120, 400)\n",
      "csv:  (120, 400) \n",
      "\n",
      "block_2.0.bias\n",
      "shape: (120,)\n",
      "csv:  (120,) \n",
      "\n",
      "block_2.2.weight\n",
      "shape: (84, 120)\n",
      "csv:  (84, 120) \n",
      "\n",
      "block_2.2.bias\n",
      "shape: (84,)\n",
      "csv:  (84,) \n",
      "\n",
      "block_2.4.weight\n",
      "shape: (10, 84)\n",
      "csv:  (10, 84) \n",
      "\n",
      "block_2.4.bias\n",
      "shape: (10,)\n",
      "csv:  (10,) \n",
      "\n",
      "================================\n",
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "def load_weight(model_path):\n",
    "        \n",
    "        print('===> Loading weights : ' + model_path)\n",
    "        weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "\n",
    "        print('type: ' + str(type(weight_dict)))\n",
    "        print('len: ' + str(len(weight_dict)))\n",
    "\n",
    "        for k in weight_dict.keys():\n",
    "                print('key: '+ k)\n",
    "\n",
    "        # print(weight_dict['state'])\n",
    "        # print(weight_dict['epoch'])\n",
    "        print(\"================================\")\n",
    "\n",
    "        for key,value in weight_dict['state'].items():\n",
    "                value_np = value.numpy()\n",
    "                if not os.path.isdir('csv'):\n",
    "                        os.mkdir('./csv')\n",
    "                # np.savetxt(\"./csv/%s.csv\" %(key), value_np,  delimiter=\",\")\n",
    "                # pd.DataFrame(value_np).to_csv(\"./csv/%s.csv\" %(key))\n",
    "                # print(key, value.size())\n",
    "                print(key)\n",
    "                print('shape: '+ str(value_np.shape))\n",
    "                if (value_np.ndim == 4):\n",
    "                        (n_dim, _, _, _) = value_np.shape\n",
    "                        value_2d = value_np.reshape(n_dim,-1)\n",
    "                        np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "                        print(\"csv: \", value_2d.shape,'\\n')\n",
    "                elif (value_np.ndim == 3):\n",
    "                        ndim, _, _ = value_np.shape\n",
    "                        value_2d = value_np.reshape(n_dim,-1)\n",
    "                        np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "                        print(\"csv: \", value_2d.shape,'\\n')\n",
    "                # elif (value_np.ndim == 2):\n",
    "                #         ndim, _ = value_np.shape\n",
    "                #         value_2d = value_np.reshape(n_dim,-1)\n",
    "                #         print(value_2d.shape) \n",
    "                else :  \n",
    "                        value_2d = value_np\n",
    "                        np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "                        print(\"csv: \", value_2d.shape,'\\n')             \n",
    "\n",
    "\n",
    "        print(\"================================\")\n",
    "        print(type(weight_dict['state']))\n",
    "        \n",
    "\n",
    "state_path = './checkpoint/model_14.pth'\n",
    "load_weight(state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab0de5f2c42c334a270ce520738908c8f1964f7214e5cf9b2725bca46514c63e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
