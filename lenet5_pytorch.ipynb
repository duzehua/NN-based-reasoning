{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "path_model = \"./checkpoint/\"\n",
    "batch_size = 512\n",
    "epochs = 15\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "# sampler = torch.utils.data.SubsetRandomSampler(indices=list(range(2000)))\n",
    "\n",
    "# download mnist dataset\n",
    "dataset_train = torchvision.datasets.MNIST(root='./data/',train=True,download=True,transform=transform)\n",
    "dataset_test = torchvision.datasets.MNIST(root='./data/',train=False,download=True,transform=transform)\n",
    "\n",
    "class_names = dataset_train.classes  # 获取数据集的分类信息 返回一个字典\n",
    "# load dataset\n",
    "data_train = dataloader(dataset=dataset_train,batch_size=batch_size,shuffle=False)\n",
    "data_test = dataloader(dataset=dataset_test,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "print(len(data_train))\n",
    "# for batch_idx,(data,target) in enumerate(data_test):\n",
    "#     print(\"id \",batch_idx, \"data shape\",data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()  # 切换到测试模式\n",
    "    test_correct_num = 0\n",
    "    with torch.no_grad():   # 不更新参数\n",
    "\n",
    "        for batch_idx,(data,target) in enumerate(data_test):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output, _ = net(data) # 正向传播得到预测值\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            test_correct_num += torch.sum(pred==target).item()\n",
    "            print(\"Test Epoch:{} [{}/{} ({:.0f}%)]\\t acc:{:.2f}\".format(epoch,batch_idx*batch_size,len(data_test.dataset),\n",
    "                                                 100. * batch_size*batch_idx/len(data_test.dataset),test_correct_num/len(data_test.dataset)))\n",
    "def train(epoch):\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(data_train):\n",
    "        # 清除grad累积值\n",
    "        optimizer.zero_grad()\n",
    "        # 读取dataloader中的数据，前半部分是tensor变量，后半部分是真实label\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward之后得到预测值\n",
    "        output, process_output_ = net(data)\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_layerout(epoch, batch_idx, process_output_)\n",
    "        # 计算loss\n",
    "        loss = cost_fun(output, target)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # 收集一组新的梯度，并使用optimizer.step()将其传播回每个网络参数\n",
    "        optimizer.step()\n",
    "        # 给出loss和acc\n",
    "        train_loss.append(loss)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        correct_num = torch.sum(pred == target).item()\n",
    "        train_acc.append(correct_num / batch_size)\n",
    "        print(\"Train Epoch:{}[{}/{} ({:.0f}%)]\\t Loss:{:.6f} acc:{:.2f}\".format(epoch, batch_idx * batch_size,\n",
    "               len(data_train.dataset),100. * batch_size * batch_idx / len(data_train.dataset), loss.item(),correct_num / batch_size))\n",
    "        \n",
    "        # MNIST一共60000个数据，batch_size为512，一共60000/512 = 118个batch\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_weight(epoch, batch_idx)\n",
    "\n",
    "def save_layerout(epoch, batch_idx, process_output_):\n",
    "\n",
    "    if(str(device) == 'cpu') : device_sr = 'CPU'\n",
    "    else : device_sr = 'GPU'\n",
    "\n",
    "    # TODO 将读取出来的参数进行保存，注意确认是否存在tensor与np之间的转换通道问题\n",
    "    '''\n",
    "    文件名共分8部分：\n",
    "    epoch filenums index                       number        channel   length  width  value_name\n",
    "    轮数   文件总数  序号(按参数在网络中的顺序)  变量中数据块个数 变量通道数  变量长   变量宽  变量名称\n",
    "    ''' \n",
    "    # TODO 根据需求改前缀字符串\n",
    "    # cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    cscfphn_str = device_sr + '_' + str(len(process_output_)) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    # 将网络的过程结果进行保存\n",
    "    col_counter = 0\n",
    "\n",
    "    if (100 > len(process_output_) > 9):\n",
    "        cn_prex_flag = 1  # 层数个数达两位数\n",
    "    elif (1000 > len(process_output_) > 99):\n",
    "        cn_prex_flag = 2  # 层数个数达三位数\n",
    "    else: cn_prex_flag = 0  # 层数个数达一位数\n",
    "\n",
    "    for key in process_output_.keys():\n",
    "\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = process_output_[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # --\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            # TODO 根据需求改第一维的数值\n",
    "            if cvsl_idx == 0:  # 第一维个数改为1\n",
    "                pre_load_len_name = pre_load_len_name + '1' + '_'\n",
    "            else :\n",
    "                pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # --\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名，根据文件总数进行补‘0’，以使文件被顺序读取\n",
    "        if cn_prex_flag == 1:  # 层数个数达两位数\n",
    "            if 9 >= col_counter >= 0 :   # 小于两位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        elif cn_prex_flag == 2: # 层数个数达三位数\n",
    "            if 9 >= col_counter >= 0 :  # 小于三位数多添两个0\n",
    "                curt_csv_file_name = cscfphn_str + '00' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            elif 99 >= col_counter >= 10 :  # 小于三位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        else :\n",
    "            curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        \n",
    "        # 数据存储\n",
    "        if not os.path.isdir('layeroutput_data'):\n",
    "            os.mkdir('.\\layeroutput_data')\n",
    "        layer_output_result_path = '.\\layeroutput_data'\n",
    "        with open(layer_output_result_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\",\n",
    "                    newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            data = process_output_[key].reshape(-1)\n",
    "            data_np = data.cpu().detach().numpy()  # TODO 注意确认是否存在通道问题、此处摒弃梯度信息\n",
    "            writer.writerows([data_np])\n",
    "            # writer.writerows([data_curt] for data_curt in data_np)\n",
    "            csvfile.close()\n",
    "            # --\n",
    "        col_counter += 1\n",
    "\n",
    "def save_weight(epoch, batch_idx):\n",
    "\n",
    "    if(str(device) == 'cpu') : device_sr = 'CPU'\n",
    "    else : device_sr = 'GPU'\n",
    "\n",
    "\n",
    "    # 网络参数输出\n",
    "    parm = {}\n",
    "    for name, parameters in net.named_parameters():\n",
    "        # print('网络参数输出')\n",
    "        # print(name, ':', parameters.size())\n",
    "        parm[name] = parameters.cpu().detach().numpy()  # 将tensor变量转换为np格式\n",
    "\n",
    "    # TODO 将读取出来的参数进行保存，注意确认是否存在tensor与np之间的转换通道问题\n",
    "    '''\n",
    "    文件名共分8部分：\n",
    "    epoch filenums index                       number        channel   length  width  value_name\n",
    "    轮数   文件总数  序号(按参数在网络中的顺序)  变量中数据块个数 变量通道数  变量长   变量宽  变量名称\n",
    "    '''\n",
    "    \n",
    "    # TODO 根据需求改前缀字符串\n",
    "    # cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    cscfphn_str = device_sr + '_' + str(len(parm)) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    \n",
    "    if (100 > len(parm) > 9):\n",
    "        cn_prex_flag = 1  # 层数个数达两位数\n",
    "    elif (1000 > len(parm) > 99):\n",
    "        cn_prex_flag = 2  # 层数个数达三位数\n",
    "    else: cn_prex_flag = 0  # 层数个数达一位数\n",
    "\n",
    "    col_counter = 0\n",
    "    for key in parm.keys():\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = parm[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # -- 定义有信息的前导尺寸\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # -- 将无信息的前导尺寸设置为缺省值\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名，根据文件总数进行补‘0’，以使文件被顺序读取\n",
    "        if cn_prex_flag == 1:  # 层数个数达两位数\n",
    "            if 9 >= col_counter >= 0 :   # 小于两位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        elif cn_prex_flag == 2: # 层数个数达三位数\n",
    "            if 9 >= col_counter >= 0 :  # 小于三位数多添两个0\n",
    "                curt_csv_file_name = cscfphn_str + '00' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            elif 99 >= col_counter >= 10 :  # 小于三位数多添一个0\n",
    "                curt_csv_file_name = cscfphn_str + '0' + str(col_counter) + '_' + pre_load_len_name + key\n",
    "            else :\n",
    "                curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        else :\n",
    "            curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        # 数据存储\n",
    "        # 创建文件对象\n",
    "        if not os.path.isdir('layer_para'):\n",
    "            os.mkdir('.\\layer_para')\n",
    "        if not os.path.isdir('layer_para\\\\bias'):\n",
    "            os.mkdir('.\\layer_para\\\\bias')\n",
    "        if not os.path.isdir('layer_para\\\\weight'):\n",
    "            os.mkdir('.\\layer_para\\\\weight')\n",
    "        layer_para_path = '.\\layer_para'\n",
    "        layer_bias_para_path = '.\\layer_para\\\\bias'\n",
    "        layer_weight_para_path = '.\\layer_para\\\\weight'\n",
    "        if('bias' in key):\n",
    "            with open(layer_bias_para_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "                writer = csv.writer(csvfile, delimiter=' ')\n",
    "                data = parm[key].reshape(-1)\n",
    "                # writer.writerows([data_curt] for data_curt in data)\n",
    "                writer.writerows([data])\n",
    "                csvfile.close()\n",
    "        else :\n",
    "            with open(layer_weight_para_path + '\\\\' + curt_csv_file_name + \".csv\", \"w+\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "                writer = csv.writer(csvfile, delimiter=' ')\n",
    "                data = parm[key].reshape(-1)\n",
    "                # writer.writerows([data_curt] for data_curt in data)\n",
    "                writer.writerows([data])\n",
    "                csvfile.close()            \n",
    "        # --\n",
    "        col_counter += 1 \n",
    "    \n",
    "def save_state():\n",
    "    print('===> Saving weights...')\n",
    "    state = {\n",
    "        'state': net.state_dict(),\n",
    "        'epoch': epoch  # 将epoch一并保存\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('./checkpoint')\n",
    "    torch.save(state, path_model + 'Epoch:' + str(epoch) + ' Loss:' + str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "def predict():\n",
    "    state_path = './checkpoint/model_14.pth' #  ***为指定加载的权重文件名称\n",
    "    print('===> Loading weights : ' + state_path)\n",
    "    weight_dict = torch.load(state_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "    # 从测试集中选取一个batch做预测\n",
    "    # pred_test = enumerate(data_test)\n",
    "    # batch_idx, (pred_data, pred_gt) = next(pred_test)\n",
    "    # output = net(pred_data)\n",
    "    # print(\"data: \", output.data)\n",
    "    # maxdata, pred = torch.max(output.data, 1) # 得到预测值,返回每一行的最大值，且返回索引\n",
    "    # print(\"maxdata: \", maxdata)\n",
    "    # print(\"ground truth: \",pred_gt)\n",
    "    # print(\"predict value: \",pred)\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    # 把tensor转成Image， 方便可视化\n",
    "    show = ToPILImage()\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "    net.eval()\n",
    "    for i in np.random.randint(0,20,size=10):\n",
    "        x, y = dataset_test[i][0], dataset_test[i][1]\n",
    "        # tensor格式数据可视化\n",
    "        show(x).show()\n",
    "        # 扩展张量维度为4维\n",
    "        x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=False).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "            predicted, actual = classes[torch.argmax(pred[0])], classes[y]\n",
    "            # 最终输出的预测值与真实值\n",
    "            print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "class LeNet(nn.Module): \t\t\t\t\t# 继承于nn.Module这个父类\n",
    "    def __init__(self):\t\t\t\t\t\t# 初始化网络结构\n",
    "        super(LeNet, self).__init__()    \t# 多继承需用到super函数\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),  # 输出为6*28*28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为6*14*14\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 输出为16*10*10\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为16*5*5\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # 正向传播过程\n",
    "        # x = self.block_1(x)\n",
    "        # x = x.view(-1,16*5*5)\n",
    "        # x = self.block_2(x)\n",
    "        block1_conv1_out = self.block_1[0](x)\n",
    "        block1_relu1_out = self.block_1[1](block1_conv1_out)\n",
    "        block1_maxpo1_out = self.block_1[2](block1_relu1_out)\n",
    "        block1_conv2_out = self.block_1[3](block1_maxpo1_out)\n",
    "        block1_relu2_out = self.block_1[4](block1_conv2_out)\n",
    "        block1_maxpo2_out = self.block_1[5](block1_relu2_out)\n",
    "\n",
    "        block1_flatten_out = block1_maxpo2_out.view(-1,16*5*5)\n",
    "\n",
    "        block2_fc1_out = self.block_2[0](block1_flatten_out)\n",
    "        block2_relu1_out = self.block_2[1](block2_fc1_out)\n",
    "        block2_fc2_out = self.block_2[2](block2_relu1_out)\n",
    "        block2_relu2_out = self.block_2[3](block2_fc2_out)\n",
    "        block2_fc3_out = self.block_2[4](block2_relu2_out)\n",
    "\n",
    "        softmax_output =  self.block_2[5](block2_fc3_out)\n",
    "\n",
    "        process_output = {'block1_conv1_out': block1_conv1_out,\n",
    "                        #   'block1_relu1_out': block1_relu1_out,\n",
    "                          'block1_maxpo1_out': block1_maxpo1_out,\n",
    "                          'block1_conv2_out': block1_conv2_out,\n",
    "                        #   'block1_relu2_out': block1_relu2_out,\n",
    "                          'block1_maxpo2_out': block1_maxpo2_out,\n",
    "                          'block1_flatten_out': block1_flatten_out,\n",
    "\n",
    "                          'block2_fc1_out': block2_fc1_out,\n",
    "                        #   'block2_relu1_out': block2_relu1_out,\n",
    "                          'block2_fc2_out': block2_fc2_out,\n",
    "                        #   'block2_relu2_out': block2_relu2_out,\n",
    "                          'block2_fc3_out': block2_fc3_out,\n",
    "                          'softmax_output': softmax_output\n",
    "                        }\n",
    "\n",
    "        return block2_fc3_out, process_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0[0/60000 (0%)]\t Loss:2.311608 acc:0.13\n",
      "Train Epoch:0[512/60000 (1%)]\t Loss:2.312769 acc:0.10\n",
      "Train Epoch:0[1024/60000 (2%)]\t Loss:2.314353 acc:0.10\n",
      "Train Epoch:0[1536/60000 (3%)]\t Loss:2.319026 acc:0.10\n",
      "Train Epoch:0[2048/60000 (3%)]\t Loss:2.314056 acc:0.10\n",
      "Train Epoch:0[2560/60000 (4%)]\t Loss:2.318543 acc:0.11\n",
      "Train Epoch:0[3072/60000 (5%)]\t Loss:2.318732 acc:0.10\n",
      "Train Epoch:0[3584/60000 (6%)]\t Loss:2.320846 acc:0.09\n",
      "Train Epoch:0[4096/60000 (7%)]\t Loss:2.313335 acc:0.11\n",
      "Train Epoch:0[4608/60000 (8%)]\t Loss:2.315973 acc:0.09\n",
      "Train Epoch:0[5120/60000 (9%)]\t Loss:2.324854 acc:0.10\n",
      "Train Epoch:0[5632/60000 (9%)]\t Loss:2.315119 acc:0.10\n",
      "Train Epoch:0[6144/60000 (10%)]\t Loss:2.318169 acc:0.12\n",
      "Train Epoch:0[6656/60000 (11%)]\t Loss:2.315549 acc:0.10\n",
      "Train Epoch:0[7168/60000 (12%)]\t Loss:2.315140 acc:0.12\n",
      "Train Epoch:0[7680/60000 (13%)]\t Loss:2.313997 acc:0.12\n",
      "Train Epoch:0[8192/60000 (14%)]\t Loss:2.308019 acc:0.12\n",
      "Train Epoch:0[8704/60000 (15%)]\t Loss:2.313951 acc:0.11\n",
      "Train Epoch:0[9216/60000 (15%)]\t Loss:2.315143 acc:0.09\n",
      "Train Epoch:0[9728/60000 (16%)]\t Loss:2.322052 acc:0.08\n",
      "Train Epoch:0[10240/60000 (17%)]\t Loss:2.303909 acc:0.11\n",
      "Train Epoch:0[10752/60000 (18%)]\t Loss:2.311204 acc:0.10\n",
      "Train Epoch:0[11264/60000 (19%)]\t Loss:2.303680 acc:0.13\n",
      "Train Epoch:0[11776/60000 (20%)]\t Loss:2.305749 acc:0.10\n",
      "Train Epoch:0[12288/60000 (20%)]\t Loss:2.305186 acc:0.12\n",
      "Train Epoch:0[12800/60000 (21%)]\t Loss:2.309978 acc:0.11\n",
      "Train Epoch:0[13312/60000 (22%)]\t Loss:2.306622 acc:0.13\n",
      "Train Epoch:0[13824/60000 (23%)]\t Loss:2.308208 acc:0.10\n",
      "Train Epoch:0[14336/60000 (24%)]\t Loss:2.304265 acc:0.11\n",
      "Train Epoch:0[14848/60000 (25%)]\t Loss:2.299583 acc:0.13\n",
      "Train Epoch:0[15360/60000 (26%)]\t Loss:2.301400 acc:0.12\n",
      "Train Epoch:0[15872/60000 (26%)]\t Loss:2.301868 acc:0.14\n",
      "Train Epoch:0[16384/60000 (27%)]\t Loss:2.301144 acc:0.12\n",
      "Train Epoch:0[16896/60000 (28%)]\t Loss:2.301788 acc:0.12\n",
      "Train Epoch:0[17408/60000 (29%)]\t Loss:2.292617 acc:0.15\n",
      "Train Epoch:0[17920/60000 (30%)]\t Loss:2.293468 acc:0.14\n",
      "Train Epoch:0[18432/60000 (31%)]\t Loss:2.296323 acc:0.13\n",
      "Train Epoch:0[18944/60000 (32%)]\t Loss:2.293523 acc:0.14\n",
      "Train Epoch:0[19456/60000 (32%)]\t Loss:2.295041 acc:0.13\n",
      "Train Epoch:0[19968/60000 (33%)]\t Loss:2.292277 acc:0.13\n",
      "Train Epoch:0[20480/60000 (34%)]\t Loss:2.297482 acc:0.12\n",
      "Train Epoch:0[20992/60000 (35%)]\t Loss:2.291837 acc:0.13\n",
      "Train Epoch:0[21504/60000 (36%)]\t Loss:2.295041 acc:0.12\n",
      "Train Epoch:0[22016/60000 (37%)]\t Loss:2.300268 acc:0.12\n",
      "Train Epoch:0[22528/60000 (38%)]\t Loss:2.288974 acc:0.15\n",
      "Train Epoch:0[23040/60000 (38%)]\t Loss:2.292392 acc:0.14\n",
      "Train Epoch:0[23552/60000 (39%)]\t Loss:2.291022 acc:0.12\n",
      "Train Epoch:0[24064/60000 (40%)]\t Loss:2.288979 acc:0.13\n",
      "Train Epoch:0[24576/60000 (41%)]\t Loss:2.287268 acc:0.14\n",
      "Train Epoch:0[25088/60000 (42%)]\t Loss:2.290795 acc:0.13\n",
      "Train Epoch:0[25600/60000 (43%)]\t Loss:2.284718 acc:0.15\n",
      "Train Epoch:0[26112/60000 (44%)]\t Loss:2.284204 acc:0.14\n",
      "Train Epoch:0[26624/60000 (44%)]\t Loss:2.291767 acc:0.12\n",
      "Train Epoch:0[27136/60000 (45%)]\t Loss:2.291223 acc:0.12\n",
      "Train Epoch:0[27648/60000 (46%)]\t Loss:2.282947 acc:0.14\n",
      "Train Epoch:0[28160/60000 (47%)]\t Loss:2.285365 acc:0.14\n",
      "Train Epoch:0[28672/60000 (48%)]\t Loss:2.286038 acc:0.12\n",
      "Train Epoch:0[29184/60000 (49%)]\t Loss:2.283040 acc:0.14\n",
      "Train Epoch:0[29696/60000 (49%)]\t Loss:2.281536 acc:0.13\n",
      "Train Epoch:0[30208/60000 (50%)]\t Loss:2.287993 acc:0.12\n",
      "Train Epoch:0[30720/60000 (51%)]\t Loss:2.282901 acc:0.12\n",
      "Train Epoch:0[31232/60000 (52%)]\t Loss:2.280699 acc:0.13\n",
      "Train Epoch:0[31744/60000 (53%)]\t Loss:2.277157 acc:0.15\n",
      "Train Epoch:0[32256/60000 (54%)]\t Loss:2.288886 acc:0.12\n",
      "Train Epoch:0[32768/60000 (55%)]\t Loss:2.279123 acc:0.14\n",
      "Train Epoch:0[33280/60000 (55%)]\t Loss:2.272597 acc:0.16\n",
      "Train Epoch:0[33792/60000 (56%)]\t Loss:2.270645 acc:0.15\n",
      "Train Epoch:0[34304/60000 (57%)]\t Loss:2.280933 acc:0.13\n",
      "Train Epoch:0[34816/60000 (58%)]\t Loss:2.283056 acc:0.11\n",
      "Train Epoch:0[35328/60000 (59%)]\t Loss:2.277006 acc:0.14\n",
      "Train Epoch:0[35840/60000 (60%)]\t Loss:2.280718 acc:0.12\n",
      "Train Epoch:0[36352/60000 (61%)]\t Loss:2.275566 acc:0.14\n",
      "Train Epoch:0[36864/60000 (61%)]\t Loss:2.272477 acc:0.12\n",
      "Train Epoch:0[37376/60000 (62%)]\t Loss:2.281927 acc:0.12\n",
      "Train Epoch:0[37888/60000 (63%)]\t Loss:2.272650 acc:0.12\n",
      "Train Epoch:0[38400/60000 (64%)]\t Loss:2.263638 acc:0.17\n",
      "Train Epoch:0[38912/60000 (65%)]\t Loss:2.266478 acc:0.15\n",
      "Train Epoch:0[39424/60000 (66%)]\t Loss:2.273354 acc:0.13\n",
      "Train Epoch:0[39936/60000 (67%)]\t Loss:2.270455 acc:0.14\n",
      "Train Epoch:0[40448/60000 (67%)]\t Loss:2.268439 acc:0.14\n",
      "Train Epoch:0[40960/60000 (68%)]\t Loss:2.273849 acc:0.13\n",
      "Train Epoch:0[41472/60000 (69%)]\t Loss:2.259670 acc:0.18\n",
      "Train Epoch:0[41984/60000 (70%)]\t Loss:2.271633 acc:0.15\n",
      "Train Epoch:0[42496/60000 (71%)]\t Loss:2.266089 acc:0.15\n",
      "Train Epoch:0[43008/60000 (72%)]\t Loss:2.266668 acc:0.14\n",
      "Train Epoch:0[43520/60000 (73%)]\t Loss:2.263379 acc:0.13\n",
      "Train Epoch:0[44032/60000 (73%)]\t Loss:2.264933 acc:0.14\n",
      "Train Epoch:0[44544/60000 (74%)]\t Loss:2.260159 acc:0.15\n",
      "Train Epoch:0[45056/60000 (75%)]\t Loss:2.267779 acc:0.14\n",
      "Train Epoch:0[45568/60000 (76%)]\t Loss:2.264340 acc:0.14\n",
      "Train Epoch:0[46080/60000 (77%)]\t Loss:2.254139 acc:0.16\n",
      "Train Epoch:0[46592/60000 (78%)]\t Loss:2.260100 acc:0.14\n",
      "Train Epoch:0[47104/60000 (79%)]\t Loss:2.258560 acc:0.16\n",
      "Train Epoch:0[47616/60000 (79%)]\t Loss:2.254120 acc:0.19\n",
      "Train Epoch:0[48128/60000 (80%)]\t Loss:2.252875 acc:0.15\n",
      "Train Epoch:0[48640/60000 (81%)]\t Loss:2.252113 acc:0.18\n",
      "Train Epoch:0[49152/60000 (82%)]\t Loss:2.257782 acc:0.16\n",
      "Train Epoch:0[49664/60000 (83%)]\t Loss:2.257345 acc:0.14\n",
      "Train Epoch:0[50176/60000 (84%)]\t Loss:2.250433 acc:0.15\n",
      "Train Epoch:0[50688/60000 (84%)]\t Loss:2.251459 acc:0.14\n",
      "Train Epoch:0[51200/60000 (85%)]\t Loss:2.253607 acc:0.16\n",
      "Train Epoch:0[51712/60000 (86%)]\t Loss:2.248104 acc:0.16\n",
      "Train Epoch:0[52224/60000 (87%)]\t Loss:2.236191 acc:0.19\n",
      "Train Epoch:0[52736/60000 (88%)]\t Loss:2.243312 acc:0.17\n",
      "Train Epoch:0[53248/60000 (89%)]\t Loss:2.239731 acc:0.16\n",
      "Train Epoch:0[53760/60000 (90%)]\t Loss:2.242598 acc:0.17\n",
      "Train Epoch:0[54272/60000 (90%)]\t Loss:2.240343 acc:0.17\n",
      "Train Epoch:0[54784/60000 (91%)]\t Loss:2.237562 acc:0.16\n",
      "Train Epoch:0[55296/60000 (92%)]\t Loss:2.234091 acc:0.20\n",
      "Train Epoch:0[55808/60000 (93%)]\t Loss:2.234442 acc:0.18\n",
      "Train Epoch:0[56320/60000 (94%)]\t Loss:2.231295 acc:0.21\n",
      "Train Epoch:0[56832/60000 (95%)]\t Loss:2.232536 acc:0.18\n",
      "Train Epoch:0[57344/60000 (96%)]\t Loss:2.229998 acc:0.19\n",
      "Train Epoch:0[57856/60000 (96%)]\t Loss:2.225899 acc:0.21\n",
      "Train Epoch:0[58368/60000 (97%)]\t Loss:2.222559 acc:0.21\n",
      "Train Epoch:0[58880/60000 (98%)]\t Loss:2.220033 acc:0.24\n",
      "Train Epoch:0[59392/60000 (99%)]\t Loss:2.212615 acc:0.23\n",
      "Train Epoch:0[59904/60000 (100%)]\t Loss:2.251126 acc:0.03\n",
      "===> Saving models...\n",
      "Test Epoch:0 [0/10000 (0%)]\t acc:0.01\n",
      "Test Epoch:0 [512/10000 (5%)]\t acc:0.02\n",
      "Test Epoch:0 [1024/10000 (10%)]\t acc:0.04\n",
      "Test Epoch:0 [1536/10000 (15%)]\t acc:0.05\n",
      "Test Epoch:0 [2048/10000 (20%)]\t acc:0.06\n",
      "Test Epoch:0 [2560/10000 (26%)]\t acc:0.07\n",
      "Test Epoch:0 [3072/10000 (31%)]\t acc:0.08\n",
      "Test Epoch:0 [3584/10000 (36%)]\t acc:0.09\n",
      "Test Epoch:0 [4096/10000 (41%)]\t acc:0.11\n",
      "Test Epoch:0 [4608/10000 (46%)]\t acc:0.12\n",
      "Test Epoch:0 [5120/10000 (51%)]\t acc:0.13\n",
      "Test Epoch:0 [5632/10000 (56%)]\t acc:0.14\n",
      "Test Epoch:0 [6144/10000 (61%)]\t acc:0.16\n",
      "Test Epoch:0 [6656/10000 (67%)]\t acc:0.17\n",
      "Test Epoch:0 [7168/10000 (72%)]\t acc:0.18\n",
      "Test Epoch:0 [7680/10000 (77%)]\t acc:0.19\n",
      "Test Epoch:0 [8192/10000 (82%)]\t acc:0.20\n",
      "Test Epoch:0 [8704/10000 (87%)]\t acc:0.21\n",
      "Test Epoch:0 [9216/10000 (92%)]\t acc:0.22\n",
      "Test Epoch:0 [9728/10000 (97%)]\t acc:0.23\n",
      "Train Epoch:1[0/60000 (0%)]\t Loss:2.205440 acc:0.26\n",
      "Train Epoch:1[512/60000 (1%)]\t Loss:2.212208 acc:0.25\n",
      "Train Epoch:1[1024/60000 (2%)]\t Loss:2.215591 acc:0.24\n",
      "Train Epoch:1[1536/60000 (3%)]\t Loss:2.207031 acc:0.25\n",
      "Train Epoch:1[2048/60000 (3%)]\t Loss:2.203717 acc:0.27\n",
      "Train Epoch:1[2560/60000 (4%)]\t Loss:2.197883 acc:0.26\n",
      "Train Epoch:1[3072/60000 (5%)]\t Loss:2.203559 acc:0.23\n",
      "Train Epoch:1[3584/60000 (6%)]\t Loss:2.202273 acc:0.24\n",
      "Train Epoch:1[4096/60000 (7%)]\t Loss:2.182164 acc:0.32\n",
      "Train Epoch:1[4608/60000 (8%)]\t Loss:2.188098 acc:0.32\n",
      "Train Epoch:1[5120/60000 (9%)]\t Loss:2.196620 acc:0.27\n",
      "Train Epoch:1[5632/60000 (9%)]\t Loss:2.191671 acc:0.26\n",
      "Train Epoch:1[6144/60000 (10%)]\t Loss:2.183762 acc:0.28\n",
      "Train Epoch:1[6656/60000 (11%)]\t Loss:2.187711 acc:0.26\n",
      "Train Epoch:1[7168/60000 (12%)]\t Loss:2.197339 acc:0.24\n",
      "Train Epoch:1[7680/60000 (13%)]\t Loss:2.175775 acc:0.31\n",
      "Train Epoch:1[8192/60000 (14%)]\t Loss:2.174164 acc:0.29\n",
      "Train Epoch:1[8704/60000 (15%)]\t Loss:2.176351 acc:0.27\n",
      "Train Epoch:1[9216/60000 (15%)]\t Loss:2.169141 acc:0.30\n",
      "Train Epoch:1[9728/60000 (16%)]\t Loss:2.178047 acc:0.29\n",
      "Train Epoch:1[10240/60000 (17%)]\t Loss:2.143685 acc:0.34\n",
      "Train Epoch:1[10752/60000 (18%)]\t Loss:2.155551 acc:0.31\n",
      "Train Epoch:1[11264/60000 (19%)]\t Loss:2.141509 acc:0.31\n",
      "Train Epoch:1[11776/60000 (20%)]\t Loss:2.151200 acc:0.29\n",
      "Train Epoch:1[12288/60000 (20%)]\t Loss:2.157233 acc:0.31\n",
      "Train Epoch:1[12800/60000 (21%)]\t Loss:2.161721 acc:0.28\n",
      "Train Epoch:1[13312/60000 (22%)]\t Loss:2.141772 acc:0.31\n",
      "Train Epoch:1[13824/60000 (23%)]\t Loss:2.149276 acc:0.33\n",
      "Train Epoch:1[14336/60000 (24%)]\t Loss:2.158853 acc:0.26\n",
      "Train Epoch:1[14848/60000 (25%)]\t Loss:2.119636 acc:0.34\n",
      "Train Epoch:1[15360/60000 (26%)]\t Loss:2.126485 acc:0.32\n",
      "Train Epoch:1[15872/60000 (26%)]\t Loss:2.120987 acc:0.33\n",
      "Train Epoch:1[16384/60000 (27%)]\t Loss:2.118875 acc:0.31\n",
      "Train Epoch:1[16896/60000 (28%)]\t Loss:2.121303 acc:0.32\n",
      "Train Epoch:1[17408/60000 (29%)]\t Loss:2.112255 acc:0.32\n",
      "Train Epoch:1[17920/60000 (30%)]\t Loss:2.089540 acc:0.32\n",
      "Train Epoch:1[18432/60000 (31%)]\t Loss:2.097299 acc:0.35\n",
      "Train Epoch:1[18944/60000 (32%)]\t Loss:2.079015 acc:0.32\n",
      "Train Epoch:1[19456/60000 (32%)]\t Loss:2.072629 acc:0.38\n",
      "Train Epoch:1[19968/60000 (33%)]\t Loss:2.086442 acc:0.33\n",
      "Train Epoch:1[20480/60000 (34%)]\t Loss:2.074798 acc:0.32\n",
      "Train Epoch:1[20992/60000 (35%)]\t Loss:2.083694 acc:0.34\n",
      "Train Epoch:1[21504/60000 (36%)]\t Loss:2.053174 acc:0.36\n",
      "Train Epoch:1[22016/60000 (37%)]\t Loss:2.098036 acc:0.30\n",
      "Train Epoch:1[22528/60000 (38%)]\t Loss:2.042724 acc:0.39\n",
      "Train Epoch:1[23040/60000 (38%)]\t Loss:2.042670 acc:0.37\n",
      "Train Epoch:1[23552/60000 (39%)]\t Loss:2.047844 acc:0.34\n",
      "Train Epoch:1[24064/60000 (40%)]\t Loss:2.017302 acc:0.36\n",
      "Train Epoch:1[24576/60000 (41%)]\t Loss:2.012678 acc:0.35\n",
      "Train Epoch:1[25088/60000 (42%)]\t Loss:2.018706 acc:0.40\n",
      "Train Epoch:1[25600/60000 (43%)]\t Loss:1.970529 acc:0.42\n",
      "Train Epoch:1[26112/60000 (44%)]\t Loss:2.007076 acc:0.32\n",
      "Train Epoch:1[26624/60000 (44%)]\t Loss:2.009430 acc:0.36\n",
      "Train Epoch:1[27136/60000 (45%)]\t Loss:2.010915 acc:0.38\n",
      "Train Epoch:1[27648/60000 (46%)]\t Loss:1.962775 acc:0.38\n",
      "Train Epoch:1[28160/60000 (47%)]\t Loss:1.947020 acc:0.39\n",
      "Train Epoch:1[28672/60000 (48%)]\t Loss:1.977777 acc:0.37\n",
      "Train Epoch:1[29184/60000 (49%)]\t Loss:1.920528 acc:0.42\n",
      "Train Epoch:1[29696/60000 (49%)]\t Loss:1.976729 acc:0.35\n",
      "Train Epoch:1[30208/60000 (50%)]\t Loss:1.954211 acc:0.38\n",
      "Train Epoch:1[30720/60000 (51%)]\t Loss:1.934396 acc:0.36\n",
      "Train Epoch:1[31232/60000 (52%)]\t Loss:1.930861 acc:0.38\n",
      "Train Epoch:1[31744/60000 (53%)]\t Loss:1.905024 acc:0.38\n",
      "Train Epoch:1[32256/60000 (54%)]\t Loss:1.960489 acc:0.38\n",
      "Train Epoch:1[32768/60000 (55%)]\t Loss:1.893234 acc:0.38\n",
      "Train Epoch:1[33280/60000 (55%)]\t Loss:1.842186 acc:0.41\n",
      "Train Epoch:1[33792/60000 (56%)]\t Loss:1.806742 acc:0.46\n",
      "Train Epoch:1[34304/60000 (57%)]\t Loss:1.839984 acc:0.42\n",
      "Train Epoch:1[34816/60000 (58%)]\t Loss:1.886639 acc:0.36\n",
      "Train Epoch:1[35328/60000 (59%)]\t Loss:1.835292 acc:0.41\n",
      "Train Epoch:1[35840/60000 (60%)]\t Loss:1.813851 acc:0.40\n",
      "Train Epoch:1[36352/60000 (61%)]\t Loss:1.787802 acc:0.41\n",
      "Train Epoch:1[36864/60000 (61%)]\t Loss:1.804447 acc:0.39\n",
      "Train Epoch:1[37376/60000 (62%)]\t Loss:1.811641 acc:0.40\n",
      "Train Epoch:1[37888/60000 (63%)]\t Loss:1.746887 acc:0.45\n",
      "Train Epoch:1[38400/60000 (64%)]\t Loss:1.705247 acc:0.45\n",
      "Train Epoch:1[38912/60000 (65%)]\t Loss:1.691362 acc:0.47\n",
      "Train Epoch:1[39424/60000 (66%)]\t Loss:1.699797 acc:0.47\n",
      "Train Epoch:1[39936/60000 (67%)]\t Loss:1.665606 acc:0.46\n",
      "Train Epoch:1[40448/60000 (67%)]\t Loss:1.666250 acc:0.47\n",
      "Train Epoch:1[40960/60000 (68%)]\t Loss:1.725161 acc:0.46\n",
      "Train Epoch:1[41472/60000 (69%)]\t Loss:1.667475 acc:0.49\n",
      "Train Epoch:1[41984/60000 (70%)]\t Loss:1.691367 acc:0.45\n",
      "Train Epoch:1[42496/60000 (71%)]\t Loss:1.629934 acc:0.49\n",
      "Train Epoch:1[43008/60000 (72%)]\t Loss:1.613841 acc:0.48\n",
      "Train Epoch:1[43520/60000 (73%)]\t Loss:1.589034 acc:0.48\n",
      "Train Epoch:1[44032/60000 (73%)]\t Loss:1.634415 acc:0.50\n",
      "Train Epoch:1[44544/60000 (74%)]\t Loss:1.530173 acc:0.51\n",
      "Train Epoch:1[45056/60000 (75%)]\t Loss:1.545418 acc:0.51\n",
      "Train Epoch:1[45568/60000 (76%)]\t Loss:1.562816 acc:0.56\n",
      "Train Epoch:1[46080/60000 (77%)]\t Loss:1.506740 acc:0.54\n",
      "Train Epoch:1[46592/60000 (78%)]\t Loss:1.454696 acc:0.61\n",
      "Train Epoch:1[47104/60000 (79%)]\t Loss:1.494824 acc:0.55\n",
      "Train Epoch:1[47616/60000 (79%)]\t Loss:1.441481 acc:0.63\n",
      "Train Epoch:1[48128/60000 (80%)]\t Loss:1.340606 acc:0.63\n",
      "Train Epoch:1[48640/60000 (81%)]\t Loss:1.422604 acc:0.59\n",
      "Train Epoch:1[49152/60000 (82%)]\t Loss:1.438936 acc:0.60\n",
      "Train Epoch:1[49664/60000 (83%)]\t Loss:1.448579 acc:0.58\n",
      "Train Epoch:1[50176/60000 (84%)]\t Loss:1.344911 acc:0.65\n",
      "Train Epoch:1[50688/60000 (84%)]\t Loss:1.367323 acc:0.61\n",
      "Train Epoch:1[51200/60000 (85%)]\t Loss:1.341888 acc:0.62\n",
      "Train Epoch:1[51712/60000 (86%)]\t Loss:1.349932 acc:0.62\n",
      "Train Epoch:1[52224/60000 (87%)]\t Loss:1.243269 acc:0.65\n",
      "Train Epoch:1[52736/60000 (88%)]\t Loss:1.307345 acc:0.63\n",
      "Train Epoch:1[53248/60000 (89%)]\t Loss:1.170548 acc:0.71\n",
      "Train Epoch:1[53760/60000 (90%)]\t Loss:1.204527 acc:0.70\n",
      "Train Epoch:1[54272/60000 (90%)]\t Loss:1.132006 acc:0.74\n",
      "Train Epoch:1[54784/60000 (91%)]\t Loss:1.162265 acc:0.72\n",
      "Train Epoch:1[55296/60000 (92%)]\t Loss:1.101600 acc:0.72\n",
      "Train Epoch:1[55808/60000 (93%)]\t Loss:1.084907 acc:0.74\n",
      "Train Epoch:1[56320/60000 (94%)]\t Loss:1.103814 acc:0.73\n",
      "Train Epoch:1[56832/60000 (95%)]\t Loss:1.145390 acc:0.69\n",
      "Train Epoch:1[57344/60000 (96%)]\t Loss:1.114209 acc:0.70\n",
      "Train Epoch:1[57856/60000 (96%)]\t Loss:1.015023 acc:0.75\n",
      "Train Epoch:1[58368/60000 (97%)]\t Loss:0.977478 acc:0.79\n",
      "Train Epoch:1[58880/60000 (98%)]\t Loss:0.918885 acc:0.82\n",
      "Train Epoch:1[59392/60000 (99%)]\t Loss:0.848061 acc:0.83\n",
      "Train Epoch:1[59904/60000 (100%)]\t Loss:1.173101 acc:0.12\n",
      "===> Saving models...\n",
      "Test Epoch:1 [0/10000 (0%)]\t acc:0.04\n",
      "Test Epoch:1 [512/10000 (5%)]\t acc:0.07\n",
      "Test Epoch:1 [1024/10000 (10%)]\t acc:0.11\n",
      "Test Epoch:1 [1536/10000 (15%)]\t acc:0.15\n",
      "Test Epoch:1 [2048/10000 (20%)]\t acc:0.19\n",
      "Test Epoch:1 [2560/10000 (26%)]\t acc:0.23\n",
      "Test Epoch:1 [3072/10000 (31%)]\t acc:0.27\n",
      "Test Epoch:1 [3584/10000 (36%)]\t acc:0.31\n",
      "Test Epoch:1 [4096/10000 (41%)]\t acc:0.34\n",
      "Test Epoch:1 [4608/10000 (46%)]\t acc:0.38\n",
      "Test Epoch:1 [5120/10000 (51%)]\t acc:0.42\n",
      "Test Epoch:1 [5632/10000 (56%)]\t acc:0.46\n",
      "Test Epoch:1 [6144/10000 (61%)]\t acc:0.50\n",
      "Test Epoch:1 [6656/10000 (67%)]\t acc:0.54\n",
      "Test Epoch:1 [7168/10000 (72%)]\t acc:0.57\n",
      "Test Epoch:1 [7680/10000 (77%)]\t acc:0.61\n",
      "Test Epoch:1 [8192/10000 (82%)]\t acc:0.65\n",
      "Test Epoch:1 [8704/10000 (87%)]\t acc:0.69\n",
      "Test Epoch:1 [9216/10000 (92%)]\t acc:0.73\n",
      "Test Epoch:1 [9728/10000 (97%)]\t acc:0.75\n",
      "Train Epoch:2[0/60000 (0%)]\t Loss:0.963156 acc:0.77\n",
      "Train Epoch:2[512/60000 (1%)]\t Loss:1.000989 acc:0.74\n",
      "Train Epoch:2[1024/60000 (2%)]\t Loss:1.050606 acc:0.69\n",
      "Train Epoch:2[1536/60000 (3%)]\t Loss:0.851348 acc:0.79\n",
      "Train Epoch:2[2048/60000 (3%)]\t Loss:0.854882 acc:0.76\n",
      "Train Epoch:2[2560/60000 (4%)]\t Loss:0.882386 acc:0.75\n",
      "Train Epoch:2[3072/60000 (5%)]\t Loss:0.911399 acc:0.72\n",
      "Train Epoch:2[3584/60000 (6%)]\t Loss:0.889290 acc:0.75\n",
      "Train Epoch:2[4096/60000 (7%)]\t Loss:0.783799 acc:0.80\n",
      "Train Epoch:2[4608/60000 (8%)]\t Loss:0.906869 acc:0.71\n",
      "Train Epoch:2[5120/60000 (9%)]\t Loss:0.854653 acc:0.73\n",
      "Train Epoch:2[5632/60000 (9%)]\t Loss:0.823066 acc:0.73\n",
      "Train Epoch:2[6144/60000 (10%)]\t Loss:0.730859 acc:0.79\n",
      "Train Epoch:2[6656/60000 (11%)]\t Loss:0.824632 acc:0.76\n",
      "Train Epoch:2[7168/60000 (12%)]\t Loss:0.926111 acc:0.73\n",
      "Train Epoch:2[7680/60000 (13%)]\t Loss:0.775408 acc:0.77\n",
      "Train Epoch:2[8192/60000 (14%)]\t Loss:0.882977 acc:0.72\n",
      "Train Epoch:2[8704/60000 (15%)]\t Loss:0.806786 acc:0.75\n",
      "Train Epoch:2[9216/60000 (15%)]\t Loss:0.728271 acc:0.78\n",
      "Train Epoch:2[9728/60000 (16%)]\t Loss:0.731364 acc:0.80\n",
      "Train Epoch:2[10240/60000 (17%)]\t Loss:0.645470 acc:0.79\n",
      "Train Epoch:2[10752/60000 (18%)]\t Loss:0.667026 acc:0.79\n",
      "Train Epoch:2[11264/60000 (19%)]\t Loss:0.748450 acc:0.76\n",
      "Train Epoch:2[11776/60000 (20%)]\t Loss:0.705382 acc:0.78\n",
      "Train Epoch:2[12288/60000 (20%)]\t Loss:0.799678 acc:0.73\n",
      "Train Epoch:2[12800/60000 (21%)]\t Loss:0.801739 acc:0.73\n",
      "Train Epoch:2[13312/60000 (22%)]\t Loss:0.609500 acc:0.84\n",
      "Train Epoch:2[13824/60000 (23%)]\t Loss:0.768959 acc:0.75\n",
      "Train Epoch:2[14336/60000 (24%)]\t Loss:0.914828 acc:0.70\n",
      "Train Epoch:2[14848/60000 (25%)]\t Loss:0.666013 acc:0.80\n",
      "Train Epoch:2[15360/60000 (26%)]\t Loss:0.637611 acc:0.80\n",
      "Train Epoch:2[15872/60000 (26%)]\t Loss:0.714807 acc:0.78\n",
      "Train Epoch:2[16384/60000 (27%)]\t Loss:0.603639 acc:0.83\n",
      "Train Epoch:2[16896/60000 (28%)]\t Loss:0.719281 acc:0.76\n",
      "Train Epoch:2[17408/60000 (29%)]\t Loss:0.779199 acc:0.75\n",
      "Train Epoch:2[17920/60000 (30%)]\t Loss:0.568423 acc:0.84\n",
      "Train Epoch:2[18432/60000 (31%)]\t Loss:0.601733 acc:0.83\n",
      "Train Epoch:2[18944/60000 (32%)]\t Loss:0.631770 acc:0.79\n",
      "Train Epoch:2[19456/60000 (32%)]\t Loss:0.518832 acc:0.85\n",
      "Train Epoch:2[19968/60000 (33%)]\t Loss:0.630364 acc:0.82\n",
      "Train Epoch:2[20480/60000 (34%)]\t Loss:0.649447 acc:0.78\n",
      "Train Epoch:2[20992/60000 (35%)]\t Loss:0.595904 acc:0.82\n",
      "Train Epoch:2[21504/60000 (36%)]\t Loss:0.505465 acc:0.85\n",
      "Train Epoch:2[22016/60000 (37%)]\t Loss:0.634045 acc:0.77\n",
      "Train Epoch:2[22528/60000 (38%)]\t Loss:0.553754 acc:0.82\n",
      "Train Epoch:2[23040/60000 (38%)]\t Loss:0.528443 acc:0.82\n",
      "Train Epoch:2[23552/60000 (39%)]\t Loss:0.586188 acc:0.82\n",
      "Train Epoch:2[24064/60000 (40%)]\t Loss:0.590244 acc:0.80\n",
      "Train Epoch:2[24576/60000 (41%)]\t Loss:0.616918 acc:0.79\n",
      "Train Epoch:2[25088/60000 (42%)]\t Loss:0.518843 acc:0.83\n",
      "Train Epoch:2[25600/60000 (43%)]\t Loss:0.475883 acc:0.85\n",
      "Train Epoch:2[26112/60000 (44%)]\t Loss:0.573072 acc:0.84\n",
      "Train Epoch:2[26624/60000 (44%)]\t Loss:0.605525 acc:0.82\n",
      "Train Epoch:2[27136/60000 (45%)]\t Loss:0.595183 acc:0.85\n",
      "Train Epoch:2[27648/60000 (46%)]\t Loss:0.440918 acc:0.86\n",
      "Train Epoch:2[28160/60000 (47%)]\t Loss:0.534775 acc:0.84\n",
      "Train Epoch:2[28672/60000 (48%)]\t Loss:0.529759 acc:0.83\n",
      "Train Epoch:2[29184/60000 (49%)]\t Loss:0.509150 acc:0.85\n",
      "Train Epoch:2[29696/60000 (49%)]\t Loss:0.728890 acc:0.75\n",
      "Train Epoch:2[30208/60000 (50%)]\t Loss:0.599081 acc:0.81\n",
      "Train Epoch:2[30720/60000 (51%)]\t Loss:0.575499 acc:0.83\n",
      "Train Epoch:2[31232/60000 (52%)]\t Loss:0.686755 acc:0.79\n",
      "Train Epoch:2[31744/60000 (53%)]\t Loss:0.555517 acc:0.83\n",
      "Train Epoch:2[32256/60000 (54%)]\t Loss:0.635563 acc:0.81\n",
      "Train Epoch:2[32768/60000 (55%)]\t Loss:0.535549 acc:0.85\n",
      "Train Epoch:2[33280/60000 (55%)]\t Loss:0.525109 acc:0.84\n",
      "Train Epoch:2[33792/60000 (56%)]\t Loss:0.348370 acc:0.88\n",
      "Train Epoch:2[34304/60000 (57%)]\t Loss:0.530105 acc:0.81\n",
      "Train Epoch:2[34816/60000 (58%)]\t Loss:0.513188 acc:0.84\n",
      "Train Epoch:2[35328/60000 (59%)]\t Loss:0.467046 acc:0.84\n",
      "Train Epoch:2[35840/60000 (60%)]\t Loss:0.461171 acc:0.83\n",
      "Train Epoch:2[36352/60000 (61%)]\t Loss:0.449771 acc:0.85\n",
      "Train Epoch:2[36864/60000 (61%)]\t Loss:0.544544 acc:0.85\n",
      "Train Epoch:2[37376/60000 (62%)]\t Loss:0.557373 acc:0.83\n",
      "Train Epoch:2[37888/60000 (63%)]\t Loss:0.507145 acc:0.86\n",
      "Train Epoch:2[38400/60000 (64%)]\t Loss:0.435109 acc:0.87\n",
      "Train Epoch:2[38912/60000 (65%)]\t Loss:0.461888 acc:0.86\n",
      "Train Epoch:2[39424/60000 (66%)]\t Loss:0.541274 acc:0.82\n",
      "Train Epoch:2[39936/60000 (67%)]\t Loss:0.415472 acc:0.86\n",
      "Train Epoch:2[40448/60000 (67%)]\t Loss:0.411683 acc:0.89\n",
      "Train Epoch:2[40960/60000 (68%)]\t Loss:0.552314 acc:0.85\n",
      "Train Epoch:2[41472/60000 (69%)]\t Loss:0.482304 acc:0.86\n",
      "Train Epoch:2[41984/60000 (70%)]\t Loss:0.648656 acc:0.80\n",
      "Train Epoch:2[42496/60000 (71%)]\t Loss:0.519028 acc:0.84\n",
      "Train Epoch:2[43008/60000 (72%)]\t Loss:0.433702 acc:0.86\n",
      "Train Epoch:2[43520/60000 (73%)]\t Loss:0.426666 acc:0.87\n",
      "Train Epoch:2[44032/60000 (73%)]\t Loss:0.563548 acc:0.81\n",
      "Train Epoch:2[44544/60000 (74%)]\t Loss:0.441913 acc:0.87\n",
      "Train Epoch:2[45056/60000 (75%)]\t Loss:0.458918 acc:0.87\n",
      "Train Epoch:2[45568/60000 (76%)]\t Loss:0.502425 acc:0.83\n",
      "Train Epoch:2[46080/60000 (77%)]\t Loss:0.509236 acc:0.85\n",
      "Train Epoch:2[46592/60000 (78%)]\t Loss:0.412305 acc:0.88\n",
      "Train Epoch:2[47104/60000 (79%)]\t Loss:0.482872 acc:0.84\n",
      "Train Epoch:2[47616/60000 (79%)]\t Loss:0.378270 acc:0.89\n",
      "Train Epoch:2[48128/60000 (80%)]\t Loss:0.401414 acc:0.88\n",
      "Train Epoch:2[48640/60000 (81%)]\t Loss:0.485605 acc:0.85\n",
      "Train Epoch:2[49152/60000 (82%)]\t Loss:0.527721 acc:0.84\n",
      "Train Epoch:2[49664/60000 (83%)]\t Loss:0.494373 acc:0.84\n",
      "Train Epoch:2[50176/60000 (84%)]\t Loss:0.542015 acc:0.85\n",
      "Train Epoch:2[50688/60000 (84%)]\t Loss:0.397476 acc:0.87\n",
      "Train Epoch:2[51200/60000 (85%)]\t Loss:0.392563 acc:0.88\n",
      "Train Epoch:2[51712/60000 (86%)]\t Loss:0.500638 acc:0.84\n",
      "Train Epoch:2[52224/60000 (87%)]\t Loss:0.406848 acc:0.89\n",
      "Train Epoch:2[52736/60000 (88%)]\t Loss:0.575520 acc:0.83\n",
      "Train Epoch:2[53248/60000 (89%)]\t Loss:0.340844 acc:0.91\n",
      "Train Epoch:2[53760/60000 (90%)]\t Loss:0.396885 acc:0.85\n",
      "Train Epoch:2[54272/60000 (90%)]\t Loss:0.344432 acc:0.88\n",
      "Train Epoch:2[54784/60000 (91%)]\t Loss:0.429742 acc:0.85\n",
      "Train Epoch:2[55296/60000 (92%)]\t Loss:0.374706 acc:0.89\n",
      "Train Epoch:2[55808/60000 (93%)]\t Loss:0.329533 acc:0.91\n",
      "Train Epoch:2[56320/60000 (94%)]\t Loss:0.375602 acc:0.89\n",
      "Train Epoch:2[56832/60000 (95%)]\t Loss:0.382116 acc:0.88\n",
      "Train Epoch:2[57344/60000 (96%)]\t Loss:0.409353 acc:0.87\n",
      "Train Epoch:2[57856/60000 (96%)]\t Loss:0.265430 acc:0.93\n",
      "Train Epoch:2[58368/60000 (97%)]\t Loss:0.274176 acc:0.92\n",
      "Train Epoch:2[58880/60000 (98%)]\t Loss:0.280252 acc:0.92\n",
      "Train Epoch:2[59392/60000 (99%)]\t Loss:0.292857 acc:0.94\n",
      "Train Epoch:2[59904/60000 (100%)]\t Loss:0.469135 acc:0.16\n",
      "===> Saving models...\n",
      "Test Epoch:2 [0/10000 (0%)]\t acc:0.04\n",
      "Test Epoch:2 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:2 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:2 [1536/10000 (15%)]\t acc:0.18\n",
      "Test Epoch:2 [2048/10000 (20%)]\t acc:0.23\n",
      "Test Epoch:2 [2560/10000 (26%)]\t acc:0.27\n",
      "Test Epoch:2 [3072/10000 (31%)]\t acc:0.32\n",
      "Test Epoch:2 [3584/10000 (36%)]\t acc:0.36\n",
      "Test Epoch:2 [4096/10000 (41%)]\t acc:0.41\n",
      "Test Epoch:2 [4608/10000 (46%)]\t acc:0.45\n",
      "Test Epoch:2 [5120/10000 (51%)]\t acc:0.50\n",
      "Test Epoch:2 [5632/10000 (56%)]\t acc:0.54\n",
      "Test Epoch:2 [6144/10000 (61%)]\t acc:0.59\n",
      "Test Epoch:2 [6656/10000 (67%)]\t acc:0.64\n",
      "Test Epoch:2 [7168/10000 (72%)]\t acc:0.68\n",
      "Test Epoch:2 [7680/10000 (77%)]\t acc:0.73\n",
      "Test Epoch:2 [8192/10000 (82%)]\t acc:0.77\n",
      "Test Epoch:2 [8704/10000 (87%)]\t acc:0.82\n",
      "Test Epoch:2 [9216/10000 (92%)]\t acc:0.86\n",
      "Test Epoch:2 [9728/10000 (97%)]\t acc:0.89\n",
      "Train Epoch:3[0/60000 (0%)]\t Loss:0.410022 acc:0.88\n",
      "Train Epoch:3[512/60000 (1%)]\t Loss:0.448922 acc:0.87\n",
      "Train Epoch:3[1024/60000 (2%)]\t Loss:0.500113 acc:0.86\n",
      "Train Epoch:3[1536/60000 (3%)]\t Loss:0.304187 acc:0.91\n",
      "Train Epoch:3[2048/60000 (3%)]\t Loss:0.334063 acc:0.88\n",
      "Train Epoch:3[2560/60000 (4%)]\t Loss:0.366874 acc:0.89\n",
      "Train Epoch:3[3072/60000 (5%)]\t Loss:0.349881 acc:0.90\n",
      "Train Epoch:3[3584/60000 (6%)]\t Loss:0.379429 acc:0.90\n",
      "Train Epoch:3[4096/60000 (7%)]\t Loss:0.354251 acc:0.90\n",
      "Train Epoch:3[4608/60000 (8%)]\t Loss:0.399703 acc:0.89\n",
      "Train Epoch:3[5120/60000 (9%)]\t Loss:0.410698 acc:0.88\n",
      "Train Epoch:3[5632/60000 (9%)]\t Loss:0.349347 acc:0.89\n",
      "Train Epoch:3[6144/60000 (10%)]\t Loss:0.315179 acc:0.90\n",
      "Train Epoch:3[6656/60000 (11%)]\t Loss:0.415174 acc:0.86\n",
      "Train Epoch:3[7168/60000 (12%)]\t Loss:0.427883 acc:0.87\n",
      "Train Epoch:3[7680/60000 (13%)]\t Loss:0.410290 acc:0.88\n",
      "Train Epoch:3[8192/60000 (14%)]\t Loss:0.461953 acc:0.87\n",
      "Train Epoch:3[8704/60000 (15%)]\t Loss:0.503524 acc:0.87\n",
      "Train Epoch:3[9216/60000 (15%)]\t Loss:0.379869 acc:0.89\n",
      "Train Epoch:3[9728/60000 (16%)]\t Loss:0.394695 acc:0.88\n",
      "Train Epoch:3[10240/60000 (17%)]\t Loss:0.321298 acc:0.90\n",
      "Train Epoch:3[10752/60000 (18%)]\t Loss:0.355298 acc:0.91\n",
      "Train Epoch:3[11264/60000 (19%)]\t Loss:0.413940 acc:0.88\n",
      "Train Epoch:3[11776/60000 (20%)]\t Loss:0.364935 acc:0.88\n",
      "Train Epoch:3[12288/60000 (20%)]\t Loss:0.491025 acc:0.86\n",
      "Train Epoch:3[12800/60000 (21%)]\t Loss:0.419037 acc:0.88\n",
      "Train Epoch:3[13312/60000 (22%)]\t Loss:0.338332 acc:0.89\n",
      "Train Epoch:3[13824/60000 (23%)]\t Loss:0.497856 acc:0.83\n",
      "Train Epoch:3[14336/60000 (24%)]\t Loss:0.570374 acc:0.80\n",
      "Train Epoch:3[14848/60000 (25%)]\t Loss:0.380366 acc:0.88\n",
      "Train Epoch:3[15360/60000 (26%)]\t Loss:0.358465 acc:0.89\n",
      "Train Epoch:3[15872/60000 (26%)]\t Loss:0.388395 acc:0.87\n",
      "Train Epoch:3[16384/60000 (27%)]\t Loss:0.377964 acc:0.89\n",
      "Train Epoch:3[16896/60000 (28%)]\t Loss:0.433742 acc:0.85\n",
      "Train Epoch:3[17408/60000 (29%)]\t Loss:0.504013 acc:0.85\n",
      "Train Epoch:3[17920/60000 (30%)]\t Loss:0.297799 acc:0.92\n",
      "Train Epoch:3[18432/60000 (31%)]\t Loss:0.345938 acc:0.92\n",
      "Train Epoch:3[18944/60000 (32%)]\t Loss:0.367631 acc:0.88\n",
      "Train Epoch:3[19456/60000 (32%)]\t Loss:0.313303 acc:0.91\n",
      "Train Epoch:3[19968/60000 (33%)]\t Loss:0.372219 acc:0.90\n",
      "Train Epoch:3[20480/60000 (34%)]\t Loss:0.481058 acc:0.84\n",
      "Train Epoch:3[20992/60000 (35%)]\t Loss:0.323772 acc:0.91\n",
      "Train Epoch:3[21504/60000 (36%)]\t Loss:0.314514 acc:0.92\n",
      "Train Epoch:3[22016/60000 (37%)]\t Loss:0.351738 acc:0.88\n",
      "Train Epoch:3[22528/60000 (38%)]\t Loss:0.318376 acc:0.90\n",
      "Train Epoch:3[23040/60000 (38%)]\t Loss:0.299350 acc:0.90\n",
      "Train Epoch:3[23552/60000 (39%)]\t Loss:0.389500 acc:0.88\n",
      "Train Epoch:3[24064/60000 (40%)]\t Loss:0.371426 acc:0.89\n",
      "Train Epoch:3[24576/60000 (41%)]\t Loss:0.393486 acc:0.87\n",
      "Train Epoch:3[25088/60000 (42%)]\t Loss:0.322821 acc:0.91\n",
      "Train Epoch:3[25600/60000 (43%)]\t Loss:0.296204 acc:0.90\n",
      "Train Epoch:3[26112/60000 (44%)]\t Loss:0.373781 acc:0.89\n",
      "Train Epoch:3[26624/60000 (44%)]\t Loss:0.417534 acc:0.90\n",
      "Train Epoch:3[27136/60000 (45%)]\t Loss:0.403916 acc:0.90\n",
      "Train Epoch:3[27648/60000 (46%)]\t Loss:0.274655 acc:0.91\n",
      "Train Epoch:3[28160/60000 (47%)]\t Loss:0.387921 acc:0.89\n",
      "Train Epoch:3[28672/60000 (48%)]\t Loss:0.336388 acc:0.90\n",
      "Train Epoch:3[29184/60000 (49%)]\t Loss:0.354596 acc:0.90\n",
      "Train Epoch:3[29696/60000 (49%)]\t Loss:0.518784 acc:0.84\n",
      "Train Epoch:3[30208/60000 (50%)]\t Loss:0.378751 acc:0.88\n",
      "Train Epoch:3[30720/60000 (51%)]\t Loss:0.398346 acc:0.89\n",
      "Train Epoch:3[31232/60000 (52%)]\t Loss:0.502730 acc:0.84\n",
      "Train Epoch:3[31744/60000 (53%)]\t Loss:0.389223 acc:0.88\n",
      "Train Epoch:3[32256/60000 (54%)]\t Loss:0.425006 acc:0.87\n",
      "Train Epoch:3[32768/60000 (55%)]\t Loss:0.354700 acc:0.91\n",
      "Train Epoch:3[33280/60000 (55%)]\t Loss:0.361372 acc:0.90\n",
      "Train Epoch:3[33792/60000 (56%)]\t Loss:0.215027 acc:0.94\n",
      "Train Epoch:3[34304/60000 (57%)]\t Loss:0.389113 acc:0.87\n",
      "Train Epoch:3[34816/60000 (58%)]\t Loss:0.350194 acc:0.89\n",
      "Train Epoch:3[35328/60000 (59%)]\t Loss:0.288135 acc:0.90\n",
      "Train Epoch:3[35840/60000 (60%)]\t Loss:0.286323 acc:0.90\n",
      "Train Epoch:3[36352/60000 (61%)]\t Loss:0.309128 acc:0.90\n",
      "Train Epoch:3[36864/60000 (61%)]\t Loss:0.382987 acc:0.88\n",
      "Train Epoch:3[37376/60000 (62%)]\t Loss:0.388785 acc:0.90\n",
      "Train Epoch:3[37888/60000 (63%)]\t Loss:0.344504 acc:0.90\n",
      "Train Epoch:3[38400/60000 (64%)]\t Loss:0.285096 acc:0.93\n",
      "Train Epoch:3[38912/60000 (65%)]\t Loss:0.331447 acc:0.91\n",
      "Train Epoch:3[39424/60000 (66%)]\t Loss:0.409512 acc:0.88\n",
      "Train Epoch:3[39936/60000 (67%)]\t Loss:0.305806 acc:0.90\n",
      "Train Epoch:3[40448/60000 (67%)]\t Loss:0.283492 acc:0.92\n",
      "Train Epoch:3[40960/60000 (68%)]\t Loss:0.397378 acc:0.89\n",
      "Train Epoch:3[41472/60000 (69%)]\t Loss:0.329131 acc:0.90\n",
      "Train Epoch:3[41984/60000 (70%)]\t Loss:0.464478 acc:0.86\n",
      "Train Epoch:3[42496/60000 (71%)]\t Loss:0.394053 acc:0.88\n",
      "Train Epoch:3[43008/60000 (72%)]\t Loss:0.301383 acc:0.90\n",
      "Train Epoch:3[43520/60000 (73%)]\t Loss:0.320736 acc:0.91\n",
      "Train Epoch:3[44032/60000 (73%)]\t Loss:0.414170 acc:0.86\n",
      "Train Epoch:3[44544/60000 (74%)]\t Loss:0.349609 acc:0.89\n",
      "Train Epoch:3[45056/60000 (75%)]\t Loss:0.339630 acc:0.90\n",
      "Train Epoch:3[45568/60000 (76%)]\t Loss:0.380103 acc:0.88\n",
      "Train Epoch:3[46080/60000 (77%)]\t Loss:0.387059 acc:0.88\n",
      "Train Epoch:3[46592/60000 (78%)]\t Loss:0.281822 acc:0.91\n",
      "Train Epoch:3[47104/60000 (79%)]\t Loss:0.357095 acc:0.89\n",
      "Train Epoch:3[47616/60000 (79%)]\t Loss:0.278808 acc:0.91\n",
      "Train Epoch:3[48128/60000 (80%)]\t Loss:0.316154 acc:0.90\n",
      "Train Epoch:3[48640/60000 (81%)]\t Loss:0.367819 acc:0.89\n",
      "Train Epoch:3[49152/60000 (82%)]\t Loss:0.410987 acc:0.86\n",
      "Train Epoch:3[49664/60000 (83%)]\t Loss:0.386216 acc:0.88\n",
      "Train Epoch:3[50176/60000 (84%)]\t Loss:0.429817 acc:0.89\n",
      "Train Epoch:3[50688/60000 (84%)]\t Loss:0.315419 acc:0.89\n",
      "Train Epoch:3[51200/60000 (85%)]\t Loss:0.294508 acc:0.90\n",
      "Train Epoch:3[51712/60000 (86%)]\t Loss:0.387938 acc:0.88\n",
      "Train Epoch:3[52224/60000 (87%)]\t Loss:0.316799 acc:0.91\n",
      "Train Epoch:3[52736/60000 (88%)]\t Loss:0.432981 acc:0.87\n",
      "Train Epoch:3[53248/60000 (89%)]\t Loss:0.255332 acc:0.93\n",
      "Train Epoch:3[53760/60000 (90%)]\t Loss:0.297245 acc:0.89\n",
      "Train Epoch:3[54272/60000 (90%)]\t Loss:0.247741 acc:0.92\n",
      "Train Epoch:3[54784/60000 (91%)]\t Loss:0.333428 acc:0.89\n",
      "Train Epoch:3[55296/60000 (92%)]\t Loss:0.299571 acc:0.91\n",
      "Train Epoch:3[55808/60000 (93%)]\t Loss:0.250363 acc:0.93\n",
      "Train Epoch:3[56320/60000 (94%)]\t Loss:0.273715 acc:0.93\n",
      "Train Epoch:3[56832/60000 (95%)]\t Loss:0.263202 acc:0.92\n",
      "Train Epoch:3[57344/60000 (96%)]\t Loss:0.319242 acc:0.90\n",
      "Train Epoch:3[57856/60000 (96%)]\t Loss:0.183111 acc:0.95\n",
      "Train Epoch:3[58368/60000 (97%)]\t Loss:0.188081 acc:0.95\n",
      "Train Epoch:3[58880/60000 (98%)]\t Loss:0.201447 acc:0.95\n",
      "Train Epoch:3[59392/60000 (99%)]\t Loss:0.244016 acc:0.94\n",
      "Train Epoch:3[59904/60000 (100%)]\t Loss:0.365940 acc:0.17\n",
      "===> Saving models...\n",
      "Test Epoch:3 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:3 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:3 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:3 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:3 [2048/10000 (20%)]\t acc:0.23\n",
      "Test Epoch:3 [2560/10000 (26%)]\t acc:0.28\n",
      "Test Epoch:3 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:3 [3584/10000 (36%)]\t acc:0.37\n",
      "Test Epoch:3 [4096/10000 (41%)]\t acc:0.42\n",
      "Test Epoch:3 [4608/10000 (46%)]\t acc:0.47\n",
      "Test Epoch:3 [5120/10000 (51%)]\t acc:0.52\n",
      "Test Epoch:3 [5632/10000 (56%)]\t acc:0.56\n",
      "Test Epoch:3 [6144/10000 (61%)]\t acc:0.61\n",
      "Test Epoch:3 [6656/10000 (67%)]\t acc:0.65\n",
      "Test Epoch:3 [7168/10000 (72%)]\t acc:0.70\n",
      "Test Epoch:3 [7680/10000 (77%)]\t acc:0.75\n",
      "Test Epoch:3 [8192/10000 (82%)]\t acc:0.79\n",
      "Test Epoch:3 [8704/10000 (87%)]\t acc:0.84\n",
      "Test Epoch:3 [9216/10000 (92%)]\t acc:0.89\n",
      "Test Epoch:3 [9728/10000 (97%)]\t acc:0.91\n",
      "Train Epoch:4[0/60000 (0%)]\t Loss:0.329845 acc:0.91\n",
      "Train Epoch:4[512/60000 (1%)]\t Loss:0.337959 acc:0.90\n",
      "Train Epoch:4[1024/60000 (2%)]\t Loss:0.397943 acc:0.89\n",
      "Train Epoch:4[1536/60000 (3%)]\t Loss:0.225242 acc:0.93\n",
      "Train Epoch:4[2048/60000 (3%)]\t Loss:0.241100 acc:0.93\n",
      "Train Epoch:4[2560/60000 (4%)]\t Loss:0.264703 acc:0.92\n",
      "Train Epoch:4[3072/60000 (5%)]\t Loss:0.232893 acc:0.94\n",
      "Train Epoch:4[3584/60000 (6%)]\t Loss:0.273932 acc:0.93\n",
      "Train Epoch:4[4096/60000 (7%)]\t Loss:0.274691 acc:0.92\n",
      "Train Epoch:4[4608/60000 (8%)]\t Loss:0.312597 acc:0.91\n",
      "Train Epoch:4[5120/60000 (9%)]\t Loss:0.326251 acc:0.90\n",
      "Train Epoch:4[5632/60000 (9%)]\t Loss:0.288616 acc:0.91\n",
      "Train Epoch:4[6144/60000 (10%)]\t Loss:0.221380 acc:0.93\n",
      "Train Epoch:4[6656/60000 (11%)]\t Loss:0.340766 acc:0.90\n",
      "Train Epoch:4[7168/60000 (12%)]\t Loss:0.324664 acc:0.90\n",
      "Train Epoch:4[7680/60000 (13%)]\t Loss:0.323733 acc:0.89\n",
      "Train Epoch:4[8192/60000 (14%)]\t Loss:0.355888 acc:0.89\n",
      "Train Epoch:4[8704/60000 (15%)]\t Loss:0.411575 acc:0.87\n",
      "Train Epoch:4[9216/60000 (15%)]\t Loss:0.295861 acc:0.91\n",
      "Train Epoch:4[9728/60000 (16%)]\t Loss:0.288375 acc:0.92\n",
      "Train Epoch:4[10240/60000 (17%)]\t Loss:0.259903 acc:0.90\n",
      "Train Epoch:4[10752/60000 (18%)]\t Loss:0.285944 acc:0.93\n",
      "Train Epoch:4[11264/60000 (19%)]\t Loss:0.327295 acc:0.90\n",
      "Train Epoch:4[11776/60000 (20%)]\t Loss:0.298827 acc:0.89\n",
      "Train Epoch:4[12288/60000 (20%)]\t Loss:0.422240 acc:0.88\n",
      "Train Epoch:4[12800/60000 (21%)]\t Loss:0.318049 acc:0.90\n",
      "Train Epoch:4[13312/60000 (22%)]\t Loss:0.262895 acc:0.92\n",
      "Train Epoch:4[13824/60000 (23%)]\t Loss:0.382183 acc:0.87\n",
      "Train Epoch:4[14336/60000 (24%)]\t Loss:0.422574 acc:0.86\n",
      "Train Epoch:4[14848/60000 (25%)]\t Loss:0.303523 acc:0.90\n",
      "Train Epoch:4[15360/60000 (26%)]\t Loss:0.294765 acc:0.92\n",
      "Train Epoch:4[15872/60000 (26%)]\t Loss:0.303924 acc:0.90\n",
      "Train Epoch:4[16384/60000 (27%)]\t Loss:0.303920 acc:0.90\n",
      "Train Epoch:4[16896/60000 (28%)]\t Loss:0.322440 acc:0.89\n",
      "Train Epoch:4[17408/60000 (29%)]\t Loss:0.385554 acc:0.87\n",
      "Train Epoch:4[17920/60000 (30%)]\t Loss:0.225074 acc:0.95\n",
      "Train Epoch:4[18432/60000 (31%)]\t Loss:0.269463 acc:0.94\n",
      "Train Epoch:4[18944/60000 (32%)]\t Loss:0.275955 acc:0.91\n",
      "Train Epoch:4[19456/60000 (32%)]\t Loss:0.243935 acc:0.93\n",
      "Train Epoch:4[19968/60000 (33%)]\t Loss:0.290401 acc:0.92\n",
      "Train Epoch:4[20480/60000 (34%)]\t Loss:0.400159 acc:0.89\n",
      "Train Epoch:4[20992/60000 (35%)]\t Loss:0.243261 acc:0.93\n",
      "Train Epoch:4[21504/60000 (36%)]\t Loss:0.237783 acc:0.93\n",
      "Train Epoch:4[22016/60000 (37%)]\t Loss:0.263903 acc:0.92\n",
      "Train Epoch:4[22528/60000 (38%)]\t Loss:0.257216 acc:0.91\n",
      "Train Epoch:4[23040/60000 (38%)]\t Loss:0.230890 acc:0.93\n",
      "Train Epoch:4[23552/60000 (39%)]\t Loss:0.312305 acc:0.90\n",
      "Train Epoch:4[24064/60000 (40%)]\t Loss:0.301583 acc:0.90\n",
      "Train Epoch:4[24576/60000 (41%)]\t Loss:0.322092 acc:0.91\n",
      "Train Epoch:4[25088/60000 (42%)]\t Loss:0.269744 acc:0.91\n",
      "Train Epoch:4[25600/60000 (43%)]\t Loss:0.238536 acc:0.92\n",
      "Train Epoch:4[26112/60000 (44%)]\t Loss:0.309551 acc:0.91\n",
      "Train Epoch:4[26624/60000 (44%)]\t Loss:0.354872 acc:0.91\n",
      "Train Epoch:4[27136/60000 (45%)]\t Loss:0.327575 acc:0.90\n",
      "Train Epoch:4[27648/60000 (46%)]\t Loss:0.224429 acc:0.93\n",
      "Train Epoch:4[28160/60000 (47%)]\t Loss:0.311959 acc:0.91\n",
      "Train Epoch:4[28672/60000 (48%)]\t Loss:0.272777 acc:0.92\n",
      "Train Epoch:4[29184/60000 (49%)]\t Loss:0.284835 acc:0.92\n",
      "Train Epoch:4[29696/60000 (49%)]\t Loss:0.419272 acc:0.86\n",
      "Train Epoch:4[30208/60000 (50%)]\t Loss:0.311447 acc:0.91\n",
      "Train Epoch:4[30720/60000 (51%)]\t Loss:0.346056 acc:0.90\n",
      "Train Epoch:4[31232/60000 (52%)]\t Loss:0.418687 acc:0.87\n",
      "Train Epoch:4[31744/60000 (53%)]\t Loss:0.320264 acc:0.89\n",
      "Train Epoch:4[32256/60000 (54%)]\t Loss:0.346254 acc:0.90\n",
      "Train Epoch:4[32768/60000 (55%)]\t Loss:0.271918 acc:0.94\n",
      "Train Epoch:4[33280/60000 (55%)]\t Loss:0.284196 acc:0.91\n",
      "Train Epoch:4[33792/60000 (56%)]\t Loss:0.181687 acc:0.95\n",
      "Train Epoch:4[34304/60000 (57%)]\t Loss:0.344817 acc:0.89\n",
      "Train Epoch:4[34816/60000 (58%)]\t Loss:0.289427 acc:0.91\n",
      "Train Epoch:4[35328/60000 (59%)]\t Loss:0.221959 acc:0.94\n",
      "Train Epoch:4[35840/60000 (60%)]\t Loss:0.218572 acc:0.92\n",
      "Train Epoch:4[36352/60000 (61%)]\t Loss:0.246936 acc:0.92\n",
      "Train Epoch:4[36864/60000 (61%)]\t Loss:0.314321 acc:0.90\n",
      "Train Epoch:4[37376/60000 (62%)]\t Loss:0.341038 acc:0.90\n",
      "Train Epoch:4[37888/60000 (63%)]\t Loss:0.278234 acc:0.91\n",
      "Train Epoch:4[38400/60000 (64%)]\t Loss:0.229319 acc:0.94\n",
      "Train Epoch:4[38912/60000 (65%)]\t Loss:0.271819 acc:0.92\n",
      "Train Epoch:4[39424/60000 (66%)]\t Loss:0.319339 acc:0.91\n",
      "Train Epoch:4[39936/60000 (67%)]\t Loss:0.243266 acc:0.92\n",
      "Train Epoch:4[40448/60000 (67%)]\t Loss:0.237232 acc:0.93\n",
      "Train Epoch:4[40960/60000 (68%)]\t Loss:0.354528 acc:0.91\n",
      "Train Epoch:4[41472/60000 (69%)]\t Loss:0.275114 acc:0.90\n",
      "Train Epoch:4[41984/60000 (70%)]\t Loss:0.380468 acc:0.88\n",
      "Train Epoch:4[42496/60000 (71%)]\t Loss:0.337840 acc:0.89\n",
      "Train Epoch:4[43008/60000 (72%)]\t Loss:0.246071 acc:0.92\n",
      "Train Epoch:4[43520/60000 (73%)]\t Loss:0.265231 acc:0.92\n",
      "Train Epoch:4[44032/60000 (73%)]\t Loss:0.322880 acc:0.90\n",
      "Train Epoch:4[44544/60000 (74%)]\t Loss:0.306386 acc:0.90\n",
      "Train Epoch:4[45056/60000 (75%)]\t Loss:0.285475 acc:0.92\n",
      "Train Epoch:4[45568/60000 (76%)]\t Loss:0.327800 acc:0.89\n",
      "Train Epoch:4[46080/60000 (77%)]\t Loss:0.316067 acc:0.91\n",
      "Train Epoch:4[46592/60000 (78%)]\t Loss:0.220094 acc:0.93\n",
      "Train Epoch:4[47104/60000 (79%)]\t Loss:0.303964 acc:0.91\n",
      "Train Epoch:4[47616/60000 (79%)]\t Loss:0.233644 acc:0.93\n",
      "Train Epoch:4[48128/60000 (80%)]\t Loss:0.266529 acc:0.91\n",
      "Train Epoch:4[48640/60000 (81%)]\t Loss:0.323258 acc:0.90\n",
      "Train Epoch:4[49152/60000 (82%)]\t Loss:0.353596 acc:0.88\n",
      "Train Epoch:4[49664/60000 (83%)]\t Loss:0.313543 acc:0.91\n",
      "Train Epoch:4[50176/60000 (84%)]\t Loss:0.367393 acc:0.90\n",
      "Train Epoch:4[50688/60000 (84%)]\t Loss:0.257558 acc:0.91\n",
      "Train Epoch:4[51200/60000 (85%)]\t Loss:0.242221 acc:0.92\n",
      "Train Epoch:4[51712/60000 (86%)]\t Loss:0.319656 acc:0.89\n",
      "Train Epoch:4[52224/60000 (87%)]\t Loss:0.259083 acc:0.91\n",
      "Train Epoch:4[52736/60000 (88%)]\t Loss:0.356959 acc:0.89\n",
      "Train Epoch:4[53248/60000 (89%)]\t Loss:0.218196 acc:0.94\n",
      "Train Epoch:4[53760/60000 (90%)]\t Loss:0.255762 acc:0.92\n",
      "Train Epoch:4[54272/60000 (90%)]\t Loss:0.202878 acc:0.93\n",
      "Train Epoch:4[54784/60000 (91%)]\t Loss:0.288006 acc:0.91\n",
      "Train Epoch:4[55296/60000 (92%)]\t Loss:0.259660 acc:0.92\n",
      "Train Epoch:4[55808/60000 (93%)]\t Loss:0.209566 acc:0.94\n",
      "Train Epoch:4[56320/60000 (94%)]\t Loss:0.232198 acc:0.94\n",
      "Train Epoch:4[56832/60000 (95%)]\t Loss:0.204572 acc:0.94\n",
      "Train Epoch:4[57344/60000 (96%)]\t Loss:0.264697 acc:0.91\n",
      "Train Epoch:4[57856/60000 (96%)]\t Loss:0.149390 acc:0.95\n",
      "Train Epoch:4[58368/60000 (97%)]\t Loss:0.151803 acc:0.95\n",
      "Train Epoch:4[58880/60000 (98%)]\t Loss:0.145992 acc:0.96\n",
      "Train Epoch:4[59392/60000 (99%)]\t Loss:0.212310 acc:0.95\n",
      "Train Epoch:4[59904/60000 (100%)]\t Loss:0.307004 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:4 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:4 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:4 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:4 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:4 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:4 [2560/10000 (26%)]\t acc:0.28\n",
      "Test Epoch:4 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:4 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:4 [4096/10000 (41%)]\t acc:0.42\n",
      "Test Epoch:4 [4608/10000 (46%)]\t acc:0.47\n",
      "Test Epoch:4 [5120/10000 (51%)]\t acc:0.52\n",
      "Test Epoch:4 [5632/10000 (56%)]\t acc:0.57\n",
      "Test Epoch:4 [6144/10000 (61%)]\t acc:0.61\n",
      "Test Epoch:4 [6656/10000 (67%)]\t acc:0.66\n",
      "Test Epoch:4 [7168/10000 (72%)]\t acc:0.71\n",
      "Test Epoch:4 [7680/10000 (77%)]\t acc:0.76\n",
      "Test Epoch:4 [8192/10000 (82%)]\t acc:0.80\n",
      "Test Epoch:4 [8704/10000 (87%)]\t acc:0.85\n",
      "Test Epoch:4 [9216/10000 (92%)]\t acc:0.90\n",
      "Test Epoch:4 [9728/10000 (97%)]\t acc:0.92\n",
      "Train Epoch:5[0/60000 (0%)]\t Loss:0.286260 acc:0.93\n",
      "Train Epoch:5[512/60000 (1%)]\t Loss:0.298736 acc:0.92\n",
      "Train Epoch:5[1024/60000 (2%)]\t Loss:0.336536 acc:0.91\n",
      "Train Epoch:5[1536/60000 (3%)]\t Loss:0.191992 acc:0.94\n",
      "Train Epoch:5[2048/60000 (3%)]\t Loss:0.195258 acc:0.94\n",
      "Train Epoch:5[2560/60000 (4%)]\t Loss:0.226206 acc:0.93\n",
      "Train Epoch:5[3072/60000 (5%)]\t Loss:0.186418 acc:0.96\n",
      "Train Epoch:5[3584/60000 (6%)]\t Loss:0.226615 acc:0.94\n",
      "Train Epoch:5[4096/60000 (7%)]\t Loss:0.230890 acc:0.93\n",
      "Train Epoch:5[4608/60000 (8%)]\t Loss:0.265012 acc:0.91\n",
      "Train Epoch:5[5120/60000 (9%)]\t Loss:0.271652 acc:0.92\n",
      "Train Epoch:5[5632/60000 (9%)]\t Loss:0.255001 acc:0.92\n",
      "Train Epoch:5[6144/60000 (10%)]\t Loss:0.191114 acc:0.95\n",
      "Train Epoch:5[6656/60000 (11%)]\t Loss:0.292598 acc:0.91\n",
      "Train Epoch:5[7168/60000 (12%)]\t Loss:0.268679 acc:0.92\n",
      "Train Epoch:5[7680/60000 (13%)]\t Loss:0.278342 acc:0.91\n",
      "Train Epoch:5[8192/60000 (14%)]\t Loss:0.311242 acc:0.90\n",
      "Train Epoch:5[8704/60000 (15%)]\t Loss:0.368399 acc:0.88\n",
      "Train Epoch:5[9216/60000 (15%)]\t Loss:0.257393 acc:0.92\n",
      "Train Epoch:5[9728/60000 (16%)]\t Loss:0.242134 acc:0.93\n",
      "Train Epoch:5[10240/60000 (17%)]\t Loss:0.221903 acc:0.92\n",
      "Train Epoch:5[10752/60000 (18%)]\t Loss:0.233447 acc:0.96\n",
      "Train Epoch:5[11264/60000 (19%)]\t Loss:0.273488 acc:0.91\n",
      "Train Epoch:5[11776/60000 (20%)]\t Loss:0.248169 acc:0.91\n",
      "Train Epoch:5[12288/60000 (20%)]\t Loss:0.379223 acc:0.91\n",
      "Train Epoch:5[12800/60000 (21%)]\t Loss:0.268409 acc:0.92\n",
      "Train Epoch:5[13312/60000 (22%)]\t Loss:0.224548 acc:0.94\n",
      "Train Epoch:5[13824/60000 (23%)]\t Loss:0.325021 acc:0.89\n",
      "Train Epoch:5[14336/60000 (24%)]\t Loss:0.349013 acc:0.89\n",
      "Train Epoch:5[14848/60000 (25%)]\t Loss:0.252792 acc:0.92\n",
      "Train Epoch:5[15360/60000 (26%)]\t Loss:0.263777 acc:0.92\n",
      "Train Epoch:5[15872/60000 (26%)]\t Loss:0.250574 acc:0.92\n",
      "Train Epoch:5[16384/60000 (27%)]\t Loss:0.267929 acc:0.92\n",
      "Train Epoch:5[16896/60000 (28%)]\t Loss:0.263125 acc:0.92\n",
      "Train Epoch:5[17408/60000 (29%)]\t Loss:0.319217 acc:0.89\n",
      "Train Epoch:5[17920/60000 (30%)]\t Loss:0.185129 acc:0.95\n",
      "Train Epoch:5[18432/60000 (31%)]\t Loss:0.220890 acc:0.94\n",
      "Train Epoch:5[18944/60000 (32%)]\t Loss:0.227963 acc:0.92\n",
      "Train Epoch:5[19456/60000 (32%)]\t Loss:0.206109 acc:0.94\n",
      "Train Epoch:5[19968/60000 (33%)]\t Loss:0.240718 acc:0.93\n",
      "Train Epoch:5[20480/60000 (34%)]\t Loss:0.349108 acc:0.91\n",
      "Train Epoch:5[20992/60000 (35%)]\t Loss:0.206737 acc:0.94\n",
      "Train Epoch:5[21504/60000 (36%)]\t Loss:0.200108 acc:0.94\n",
      "Train Epoch:5[22016/60000 (37%)]\t Loss:0.222306 acc:0.93\n",
      "Train Epoch:5[22528/60000 (38%)]\t Loss:0.232663 acc:0.92\n",
      "Train Epoch:5[23040/60000 (38%)]\t Loss:0.193865 acc:0.94\n",
      "Train Epoch:5[23552/60000 (39%)]\t Loss:0.267296 acc:0.91\n",
      "Train Epoch:5[24064/60000 (40%)]\t Loss:0.261945 acc:0.92\n",
      "Train Epoch:5[24576/60000 (41%)]\t Loss:0.280282 acc:0.92\n",
      "Train Epoch:5[25088/60000 (42%)]\t Loss:0.247258 acc:0.93\n",
      "Train Epoch:5[25600/60000 (43%)]\t Loss:0.210528 acc:0.93\n",
      "Train Epoch:5[26112/60000 (44%)]\t Loss:0.265824 acc:0.93\n",
      "Train Epoch:5[26624/60000 (44%)]\t Loss:0.306895 acc:0.92\n",
      "Train Epoch:5[27136/60000 (45%)]\t Loss:0.279876 acc:0.91\n",
      "Train Epoch:5[27648/60000 (46%)]\t Loss:0.191326 acc:0.94\n",
      "Train Epoch:5[28160/60000 (47%)]\t Loss:0.268497 acc:0.91\n",
      "Train Epoch:5[28672/60000 (48%)]\t Loss:0.235188 acc:0.93\n",
      "Train Epoch:5[29184/60000 (49%)]\t Loss:0.240649 acc:0.93\n",
      "Train Epoch:5[29696/60000 (49%)]\t Loss:0.347807 acc:0.89\n",
      "Train Epoch:5[30208/60000 (50%)]\t Loss:0.262592 acc:0.93\n",
      "Train Epoch:5[30720/60000 (51%)]\t Loss:0.310087 acc:0.92\n",
      "Train Epoch:5[31232/60000 (52%)]\t Loss:0.364259 acc:0.89\n",
      "Train Epoch:5[31744/60000 (53%)]\t Loss:0.276770 acc:0.90\n",
      "Train Epoch:5[32256/60000 (54%)]\t Loss:0.305725 acc:0.91\n",
      "Train Epoch:5[32768/60000 (55%)]\t Loss:0.226215 acc:0.95\n",
      "Train Epoch:5[33280/60000 (55%)]\t Loss:0.236985 acc:0.92\n",
      "Train Epoch:5[33792/60000 (56%)]\t Loss:0.148401 acc:0.96\n",
      "Train Epoch:5[34304/60000 (57%)]\t Loss:0.306478 acc:0.90\n",
      "Train Epoch:5[34816/60000 (58%)]\t Loss:0.254289 acc:0.92\n",
      "Train Epoch:5[35328/60000 (59%)]\t Loss:0.189742 acc:0.94\n",
      "Train Epoch:5[35840/60000 (60%)]\t Loss:0.190473 acc:0.93\n",
      "Train Epoch:5[36352/60000 (61%)]\t Loss:0.204125 acc:0.93\n",
      "Train Epoch:5[36864/60000 (61%)]\t Loss:0.267871 acc:0.92\n",
      "Train Epoch:5[37376/60000 (62%)]\t Loss:0.304624 acc:0.91\n",
      "Train Epoch:5[37888/60000 (63%)]\t Loss:0.233735 acc:0.93\n",
      "Train Epoch:5[38400/60000 (64%)]\t Loss:0.203498 acc:0.95\n",
      "Train Epoch:5[38912/60000 (65%)]\t Loss:0.237345 acc:0.94\n",
      "Train Epoch:5[39424/60000 (66%)]\t Loss:0.263513 acc:0.92\n",
      "Train Epoch:5[39936/60000 (67%)]\t Loss:0.203768 acc:0.93\n",
      "Train Epoch:5[40448/60000 (67%)]\t Loss:0.206180 acc:0.93\n",
      "Train Epoch:5[40960/60000 (68%)]\t Loss:0.316970 acc:0.90\n",
      "Train Epoch:5[41472/60000 (69%)]\t Loss:0.244326 acc:0.92\n",
      "Train Epoch:5[41984/60000 (70%)]\t Loss:0.324306 acc:0.90\n",
      "Train Epoch:5[42496/60000 (71%)]\t Loss:0.299684 acc:0.91\n",
      "Train Epoch:5[43008/60000 (72%)]\t Loss:0.212474 acc:0.93\n",
      "Train Epoch:5[43520/60000 (73%)]\t Loss:0.232581 acc:0.93\n",
      "Train Epoch:5[44032/60000 (73%)]\t Loss:0.269958 acc:0.92\n",
      "Train Epoch:5[44544/60000 (74%)]\t Loss:0.266915 acc:0.91\n",
      "Train Epoch:5[45056/60000 (75%)]\t Loss:0.252844 acc:0.92\n",
      "Train Epoch:5[45568/60000 (76%)]\t Loss:0.299171 acc:0.91\n",
      "Train Epoch:5[46080/60000 (77%)]\t Loss:0.287987 acc:0.92\n",
      "Train Epoch:5[46592/60000 (78%)]\t Loss:0.190699 acc:0.94\n",
      "Train Epoch:5[47104/60000 (79%)]\t Loss:0.274540 acc:0.91\n",
      "Train Epoch:5[47616/60000 (79%)]\t Loss:0.204373 acc:0.94\n",
      "Train Epoch:5[48128/60000 (80%)]\t Loss:0.227248 acc:0.93\n",
      "Train Epoch:5[48640/60000 (81%)]\t Loss:0.285412 acc:0.90\n",
      "Train Epoch:5[49152/60000 (82%)]\t Loss:0.314184 acc:0.90\n",
      "Train Epoch:5[49664/60000 (83%)]\t Loss:0.263591 acc:0.93\n",
      "Train Epoch:5[50176/60000 (84%)]\t Loss:0.334467 acc:0.92\n",
      "Train Epoch:5[50688/60000 (84%)]\t Loss:0.213262 acc:0.93\n",
      "Train Epoch:5[51200/60000 (85%)]\t Loss:0.207763 acc:0.92\n",
      "Train Epoch:5[51712/60000 (86%)]\t Loss:0.281888 acc:0.91\n",
      "Train Epoch:5[52224/60000 (87%)]\t Loss:0.220353 acc:0.93\n",
      "Train Epoch:5[52736/60000 (88%)]\t Loss:0.314283 acc:0.91\n",
      "Train Epoch:5[53248/60000 (89%)]\t Loss:0.194630 acc:0.95\n",
      "Train Epoch:5[53760/60000 (90%)]\t Loss:0.224558 acc:0.92\n",
      "Train Epoch:5[54272/60000 (90%)]\t Loss:0.177007 acc:0.94\n",
      "Train Epoch:5[54784/60000 (91%)]\t Loss:0.262229 acc:0.92\n",
      "Train Epoch:5[55296/60000 (92%)]\t Loss:0.239502 acc:0.93\n",
      "Train Epoch:5[55808/60000 (93%)]\t Loss:0.183407 acc:0.94\n",
      "Train Epoch:5[56320/60000 (94%)]\t Loss:0.207145 acc:0.95\n",
      "Train Epoch:5[56832/60000 (95%)]\t Loss:0.171849 acc:0.96\n",
      "Train Epoch:5[57344/60000 (96%)]\t Loss:0.226760 acc:0.93\n",
      "Train Epoch:5[57856/60000 (96%)]\t Loss:0.125767 acc:0.96\n",
      "Train Epoch:5[58368/60000 (97%)]\t Loss:0.129348 acc:0.96\n",
      "Train Epoch:5[58880/60000 (98%)]\t Loss:0.118569 acc:0.97\n",
      "Train Epoch:5[59392/60000 (99%)]\t Loss:0.197155 acc:0.95\n",
      "Train Epoch:5[59904/60000 (100%)]\t Loss:0.269298 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:5 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:5 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:5 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:5 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:5 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:5 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:5 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:5 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:5 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:5 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:5 [5120/10000 (51%)]\t acc:0.52\n",
      "Test Epoch:5 [5632/10000 (56%)]\t acc:0.57\n",
      "Test Epoch:5 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:5 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:5 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:5 [7680/10000 (77%)]\t acc:0.76\n",
      "Test Epoch:5 [8192/10000 (82%)]\t acc:0.81\n",
      "Test Epoch:5 [8704/10000 (87%)]\t acc:0.86\n",
      "Test Epoch:5 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:5 [9728/10000 (97%)]\t acc:0.93\n",
      "Train Epoch:6[0/60000 (0%)]\t Loss:0.250704 acc:0.93\n",
      "Train Epoch:6[512/60000 (1%)]\t Loss:0.270940 acc:0.92\n",
      "Train Epoch:6[1024/60000 (2%)]\t Loss:0.303460 acc:0.91\n",
      "Train Epoch:6[1536/60000 (3%)]\t Loss:0.172042 acc:0.95\n",
      "Train Epoch:6[2048/60000 (3%)]\t Loss:0.168195 acc:0.95\n",
      "Train Epoch:6[2560/60000 (4%)]\t Loss:0.206812 acc:0.94\n",
      "Train Epoch:6[3072/60000 (5%)]\t Loss:0.157851 acc:0.96\n",
      "Train Epoch:6[3584/60000 (6%)]\t Loss:0.197080 acc:0.95\n",
      "Train Epoch:6[4096/60000 (7%)]\t Loss:0.202433 acc:0.94\n",
      "Train Epoch:6[4608/60000 (8%)]\t Loss:0.232453 acc:0.92\n",
      "Train Epoch:6[5120/60000 (9%)]\t Loss:0.230039 acc:0.93\n",
      "Train Epoch:6[5632/60000 (9%)]\t Loss:0.224680 acc:0.93\n",
      "Train Epoch:6[6144/60000 (10%)]\t Loss:0.170902 acc:0.95\n",
      "Train Epoch:6[6656/60000 (11%)]\t Loss:0.263118 acc:0.93\n",
      "Train Epoch:6[7168/60000 (12%)]\t Loss:0.231923 acc:0.94\n",
      "Train Epoch:6[7680/60000 (13%)]\t Loss:0.242163 acc:0.92\n",
      "Train Epoch:6[8192/60000 (14%)]\t Loss:0.277309 acc:0.91\n",
      "Train Epoch:6[8704/60000 (15%)]\t Loss:0.336810 acc:0.90\n",
      "Train Epoch:6[9216/60000 (15%)]\t Loss:0.231879 acc:0.92\n",
      "Train Epoch:6[9728/60000 (16%)]\t Loss:0.218345 acc:0.94\n",
      "Train Epoch:6[10240/60000 (17%)]\t Loss:0.199206 acc:0.93\n",
      "Train Epoch:6[10752/60000 (18%)]\t Loss:0.204308 acc:0.96\n",
      "Train Epoch:6[11264/60000 (19%)]\t Loss:0.246251 acc:0.92\n",
      "Train Epoch:6[11776/60000 (20%)]\t Loss:0.214984 acc:0.92\n",
      "Train Epoch:6[12288/60000 (20%)]\t Loss:0.333562 acc:0.91\n",
      "Train Epoch:6[12800/60000 (21%)]\t Loss:0.229071 acc:0.93\n",
      "Train Epoch:6[13312/60000 (22%)]\t Loss:0.197500 acc:0.94\n",
      "Train Epoch:6[13824/60000 (23%)]\t Loss:0.286413 acc:0.90\n",
      "Train Epoch:6[14336/60000 (24%)]\t Loss:0.299740 acc:0.91\n",
      "Train Epoch:6[14848/60000 (25%)]\t Loss:0.220899 acc:0.94\n",
      "Train Epoch:6[15360/60000 (26%)]\t Loss:0.234849 acc:0.93\n",
      "Train Epoch:6[15872/60000 (26%)]\t Loss:0.215489 acc:0.93\n",
      "Train Epoch:6[16384/60000 (27%)]\t Loss:0.244037 acc:0.93\n",
      "Train Epoch:6[16896/60000 (28%)]\t Loss:0.224153 acc:0.93\n",
      "Train Epoch:6[17408/60000 (29%)]\t Loss:0.274801 acc:0.90\n",
      "Train Epoch:6[17920/60000 (30%)]\t Loss:0.160955 acc:0.96\n",
      "Train Epoch:6[18432/60000 (31%)]\t Loss:0.187235 acc:0.95\n",
      "Train Epoch:6[18944/60000 (32%)]\t Loss:0.197023 acc:0.93\n",
      "Train Epoch:6[19456/60000 (32%)]\t Loss:0.181539 acc:0.95\n",
      "Train Epoch:6[19968/60000 (33%)]\t Loss:0.205717 acc:0.94\n",
      "Train Epoch:6[20480/60000 (34%)]\t Loss:0.316884 acc:0.92\n",
      "Train Epoch:6[20992/60000 (35%)]\t Loss:0.181722 acc:0.96\n",
      "Train Epoch:6[21504/60000 (36%)]\t Loss:0.171551 acc:0.95\n",
      "Train Epoch:6[22016/60000 (37%)]\t Loss:0.197091 acc:0.93\n",
      "Train Epoch:6[22528/60000 (38%)]\t Loss:0.215355 acc:0.94\n",
      "Train Epoch:6[23040/60000 (38%)]\t Loss:0.167913 acc:0.95\n",
      "Train Epoch:6[23552/60000 (39%)]\t Loss:0.232676 acc:0.93\n",
      "Train Epoch:6[24064/60000 (40%)]\t Loss:0.225150 acc:0.93\n",
      "Train Epoch:6[24576/60000 (41%)]\t Loss:0.245270 acc:0.92\n",
      "Train Epoch:6[25088/60000 (42%)]\t Loss:0.227693 acc:0.93\n",
      "Train Epoch:6[25600/60000 (43%)]\t Loss:0.194569 acc:0.94\n",
      "Train Epoch:6[26112/60000 (44%)]\t Loss:0.241470 acc:0.94\n",
      "Train Epoch:6[26624/60000 (44%)]\t Loss:0.272493 acc:0.92\n",
      "Train Epoch:6[27136/60000 (45%)]\t Loss:0.244690 acc:0.93\n",
      "Train Epoch:6[27648/60000 (46%)]\t Loss:0.162995 acc:0.94\n",
      "Train Epoch:6[28160/60000 (47%)]\t Loss:0.232443 acc:0.93\n",
      "Train Epoch:6[28672/60000 (48%)]\t Loss:0.206268 acc:0.94\n",
      "Train Epoch:6[29184/60000 (49%)]\t Loss:0.211719 acc:0.94\n",
      "Train Epoch:6[29696/60000 (49%)]\t Loss:0.295895 acc:0.90\n",
      "Train Epoch:6[30208/60000 (50%)]\t Loss:0.227009 acc:0.94\n",
      "Train Epoch:6[30720/60000 (51%)]\t Loss:0.277171 acc:0.93\n",
      "Train Epoch:6[31232/60000 (52%)]\t Loss:0.320510 acc:0.90\n",
      "Train Epoch:6[31744/60000 (53%)]\t Loss:0.238499 acc:0.91\n",
      "Train Epoch:6[32256/60000 (54%)]\t Loss:0.272676 acc:0.92\n",
      "Train Epoch:6[32768/60000 (55%)]\t Loss:0.197472 acc:0.96\n",
      "Train Epoch:6[33280/60000 (55%)]\t Loss:0.213904 acc:0.94\n",
      "Train Epoch:6[33792/60000 (56%)]\t Loss:0.127525 acc:0.97\n",
      "Train Epoch:6[34304/60000 (57%)]\t Loss:0.276209 acc:0.92\n",
      "Train Epoch:6[34816/60000 (58%)]\t Loss:0.223455 acc:0.93\n",
      "Train Epoch:6[35328/60000 (59%)]\t Loss:0.165914 acc:0.95\n",
      "Train Epoch:6[35840/60000 (60%)]\t Loss:0.172820 acc:0.94\n",
      "Train Epoch:6[36352/60000 (61%)]\t Loss:0.179281 acc:0.94\n",
      "Train Epoch:6[36864/60000 (61%)]\t Loss:0.237374 acc:0.93\n",
      "Train Epoch:6[37376/60000 (62%)]\t Loss:0.269424 acc:0.93\n",
      "Train Epoch:6[37888/60000 (63%)]\t Loss:0.200161 acc:0.94\n",
      "Train Epoch:6[38400/60000 (64%)]\t Loss:0.182075 acc:0.95\n",
      "Train Epoch:6[38912/60000 (65%)]\t Loss:0.211922 acc:0.94\n",
      "Train Epoch:6[39424/60000 (66%)]\t Loss:0.226953 acc:0.94\n",
      "Train Epoch:6[39936/60000 (67%)]\t Loss:0.179550 acc:0.95\n",
      "Train Epoch:6[40448/60000 (67%)]\t Loss:0.182204 acc:0.94\n",
      "Train Epoch:6[40960/60000 (68%)]\t Loss:0.287297 acc:0.91\n",
      "Train Epoch:6[41472/60000 (69%)]\t Loss:0.221620 acc:0.93\n",
      "Train Epoch:6[41984/60000 (70%)]\t Loss:0.277607 acc:0.91\n",
      "Train Epoch:6[42496/60000 (71%)]\t Loss:0.268966 acc:0.92\n",
      "Train Epoch:6[43008/60000 (72%)]\t Loss:0.188932 acc:0.94\n",
      "Train Epoch:6[43520/60000 (73%)]\t Loss:0.206939 acc:0.93\n",
      "Train Epoch:6[44032/60000 (73%)]\t Loss:0.235842 acc:0.93\n",
      "Train Epoch:6[44544/60000 (74%)]\t Loss:0.234279 acc:0.93\n",
      "Train Epoch:6[45056/60000 (75%)]\t Loss:0.226742 acc:0.93\n",
      "Train Epoch:6[45568/60000 (76%)]\t Loss:0.274394 acc:0.91\n",
      "Train Epoch:6[46080/60000 (77%)]\t Loss:0.265426 acc:0.93\n",
      "Train Epoch:6[46592/60000 (78%)]\t Loss:0.169185 acc:0.95\n",
      "Train Epoch:6[47104/60000 (79%)]\t Loss:0.247348 acc:0.92\n",
      "Train Epoch:6[47616/60000 (79%)]\t Loss:0.184869 acc:0.95\n",
      "Train Epoch:6[48128/60000 (80%)]\t Loss:0.202014 acc:0.93\n",
      "Train Epoch:6[48640/60000 (81%)]\t Loss:0.258005 acc:0.91\n",
      "Train Epoch:6[49152/60000 (82%)]\t Loss:0.286935 acc:0.90\n",
      "Train Epoch:6[49664/60000 (83%)]\t Loss:0.226329 acc:0.94\n",
      "Train Epoch:6[50176/60000 (84%)]\t Loss:0.310168 acc:0.93\n",
      "Train Epoch:6[50688/60000 (84%)]\t Loss:0.177804 acc:0.94\n",
      "Train Epoch:6[51200/60000 (85%)]\t Loss:0.184591 acc:0.94\n",
      "Train Epoch:6[51712/60000 (86%)]\t Loss:0.252487 acc:0.92\n",
      "Train Epoch:6[52224/60000 (87%)]\t Loss:0.193043 acc:0.93\n",
      "Train Epoch:6[52736/60000 (88%)]\t Loss:0.282251 acc:0.93\n",
      "Train Epoch:6[53248/60000 (89%)]\t Loss:0.172998 acc:0.95\n",
      "Train Epoch:6[53760/60000 (90%)]\t Loss:0.198256 acc:0.94\n",
      "Train Epoch:6[54272/60000 (90%)]\t Loss:0.156010 acc:0.95\n",
      "Train Epoch:6[54784/60000 (91%)]\t Loss:0.239176 acc:0.93\n",
      "Train Epoch:6[55296/60000 (92%)]\t Loss:0.223233 acc:0.94\n",
      "Train Epoch:6[55808/60000 (93%)]\t Loss:0.167777 acc:0.95\n",
      "Train Epoch:6[56320/60000 (94%)]\t Loss:0.192843 acc:0.95\n",
      "Train Epoch:6[56832/60000 (95%)]\t Loss:0.151060 acc:0.96\n",
      "Train Epoch:6[57344/60000 (96%)]\t Loss:0.201173 acc:0.94\n",
      "Train Epoch:6[57856/60000 (96%)]\t Loss:0.110275 acc:0.97\n",
      "Train Epoch:6[58368/60000 (97%)]\t Loss:0.112877 acc:0.96\n",
      "Train Epoch:6[58880/60000 (98%)]\t Loss:0.099695 acc:0.97\n",
      "Train Epoch:6[59392/60000 (99%)]\t Loss:0.185329 acc:0.96\n",
      "Train Epoch:6[59904/60000 (100%)]\t Loss:0.252332 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:6 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:6 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:6 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:6 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:6 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:6 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:6 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:6 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:6 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:6 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:6 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:6 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:6 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:6 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:6 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:6 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:6 [8192/10000 (82%)]\t acc:0.81\n",
      "Test Epoch:6 [8704/10000 (87%)]\t acc:0.86\n",
      "Test Epoch:6 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:6 [9728/10000 (97%)]\t acc:0.94\n",
      "Train Epoch:7[0/60000 (0%)]\t Loss:0.221660 acc:0.94\n",
      "Train Epoch:7[512/60000 (1%)]\t Loss:0.246496 acc:0.93\n",
      "Train Epoch:7[1024/60000 (2%)]\t Loss:0.281205 acc:0.92\n",
      "Train Epoch:7[1536/60000 (3%)]\t Loss:0.155671 acc:0.95\n",
      "Train Epoch:7[2048/60000 (3%)]\t Loss:0.148827 acc:0.96\n",
      "Train Epoch:7[2560/60000 (4%)]\t Loss:0.194481 acc:0.95\n",
      "Train Epoch:7[3072/60000 (5%)]\t Loss:0.138994 acc:0.96\n",
      "Train Epoch:7[3584/60000 (6%)]\t Loss:0.178746 acc:0.95\n",
      "Train Epoch:7[4096/60000 (7%)]\t Loss:0.187028 acc:0.94\n",
      "Train Epoch:7[4608/60000 (8%)]\t Loss:0.207224 acc:0.93\n",
      "Train Epoch:7[5120/60000 (9%)]\t Loss:0.204319 acc:0.94\n",
      "Train Epoch:7[5632/60000 (9%)]\t Loss:0.205092 acc:0.94\n",
      "Train Epoch:7[6144/60000 (10%)]\t Loss:0.157174 acc:0.95\n",
      "Train Epoch:7[6656/60000 (11%)]\t Loss:0.241439 acc:0.93\n",
      "Train Epoch:7[7168/60000 (12%)]\t Loss:0.200597 acc:0.94\n",
      "Train Epoch:7[7680/60000 (13%)]\t Loss:0.215782 acc:0.93\n",
      "Train Epoch:7[8192/60000 (14%)]\t Loss:0.247920 acc:0.92\n",
      "Train Epoch:7[8704/60000 (15%)]\t Loss:0.307219 acc:0.90\n",
      "Train Epoch:7[9216/60000 (15%)]\t Loss:0.212136 acc:0.93\n",
      "Train Epoch:7[9728/60000 (16%)]\t Loss:0.204341 acc:0.94\n",
      "Train Epoch:7[10240/60000 (17%)]\t Loss:0.183162 acc:0.94\n",
      "Train Epoch:7[10752/60000 (18%)]\t Loss:0.187100 acc:0.96\n",
      "Train Epoch:7[11264/60000 (19%)]\t Loss:0.230473 acc:0.93\n",
      "Train Epoch:7[11776/60000 (20%)]\t Loss:0.190277 acc:0.94\n",
      "Train Epoch:7[12288/60000 (20%)]\t Loss:0.294517 acc:0.92\n",
      "Train Epoch:7[12800/60000 (21%)]\t Loss:0.198036 acc:0.94\n",
      "Train Epoch:7[13312/60000 (22%)]\t Loss:0.174510 acc:0.95\n",
      "Train Epoch:7[13824/60000 (23%)]\t Loss:0.254340 acc:0.92\n",
      "Train Epoch:7[14336/60000 (24%)]\t Loss:0.260314 acc:0.91\n",
      "Train Epoch:7[14848/60000 (25%)]\t Loss:0.196872 acc:0.94\n",
      "Train Epoch:7[15360/60000 (26%)]\t Loss:0.211684 acc:0.93\n",
      "Train Epoch:7[15872/60000 (26%)]\t Loss:0.188434 acc:0.94\n",
      "Train Epoch:7[16384/60000 (27%)]\t Loss:0.226721 acc:0.93\n",
      "Train Epoch:7[16896/60000 (28%)]\t Loss:0.199141 acc:0.93\n",
      "Train Epoch:7[17408/60000 (29%)]\t Loss:0.243749 acc:0.91\n",
      "Train Epoch:7[17920/60000 (30%)]\t Loss:0.145287 acc:0.96\n",
      "Train Epoch:7[18432/60000 (31%)]\t Loss:0.162290 acc:0.96\n",
      "Train Epoch:7[18944/60000 (32%)]\t Loss:0.174849 acc:0.95\n",
      "Train Epoch:7[19456/60000 (32%)]\t Loss:0.163853 acc:0.95\n",
      "Train Epoch:7[19968/60000 (33%)]\t Loss:0.181767 acc:0.95\n",
      "Train Epoch:7[20480/60000 (34%)]\t Loss:0.297942 acc:0.93\n",
      "Train Epoch:7[20992/60000 (35%)]\t Loss:0.164332 acc:0.96\n",
      "Train Epoch:7[21504/60000 (36%)]\t Loss:0.147922 acc:0.96\n",
      "Train Epoch:7[22016/60000 (37%)]\t Loss:0.177499 acc:0.94\n",
      "Train Epoch:7[22528/60000 (38%)]\t Loss:0.197356 acc:0.94\n",
      "Train Epoch:7[23040/60000 (38%)]\t Loss:0.144522 acc:0.95\n",
      "Train Epoch:7[23552/60000 (39%)]\t Loss:0.207369 acc:0.94\n",
      "Train Epoch:7[24064/60000 (40%)]\t Loss:0.195084 acc:0.93\n",
      "Train Epoch:7[24576/60000 (41%)]\t Loss:0.215322 acc:0.93\n",
      "Train Epoch:7[25088/60000 (42%)]\t Loss:0.209591 acc:0.94\n",
      "Train Epoch:7[25600/60000 (43%)]\t Loss:0.183434 acc:0.95\n",
      "Train Epoch:7[26112/60000 (44%)]\t Loss:0.225601 acc:0.94\n",
      "Train Epoch:7[26624/60000 (44%)]\t Loss:0.248187 acc:0.93\n",
      "Train Epoch:7[27136/60000 (45%)]\t Loss:0.218862 acc:0.94\n",
      "Train Epoch:7[27648/60000 (46%)]\t Loss:0.144693 acc:0.95\n",
      "Train Epoch:7[28160/60000 (47%)]\t Loss:0.205115 acc:0.93\n",
      "Train Epoch:7[28672/60000 (48%)]\t Loss:0.182486 acc:0.94\n",
      "Train Epoch:7[29184/60000 (49%)]\t Loss:0.190250 acc:0.95\n",
      "Train Epoch:7[29696/60000 (49%)]\t Loss:0.258638 acc:0.92\n",
      "Train Epoch:7[30208/60000 (50%)]\t Loss:0.198062 acc:0.94\n",
      "Train Epoch:7[30720/60000 (51%)]\t Loss:0.246401 acc:0.93\n",
      "Train Epoch:7[31232/60000 (52%)]\t Loss:0.288338 acc:0.91\n",
      "Train Epoch:7[31744/60000 (53%)]\t Loss:0.208368 acc:0.93\n",
      "Train Epoch:7[32256/60000 (54%)]\t Loss:0.244951 acc:0.93\n",
      "Train Epoch:7[32768/60000 (55%)]\t Loss:0.173191 acc:0.96\n",
      "Train Epoch:7[33280/60000 (55%)]\t Loss:0.197658 acc:0.95\n",
      "Train Epoch:7[33792/60000 (56%)]\t Loss:0.114365 acc:0.97\n",
      "Train Epoch:7[34304/60000 (57%)]\t Loss:0.256241 acc:0.91\n",
      "Train Epoch:7[34816/60000 (58%)]\t Loss:0.203307 acc:0.93\n",
      "Train Epoch:7[35328/60000 (59%)]\t Loss:0.149029 acc:0.96\n",
      "Train Epoch:7[35840/60000 (60%)]\t Loss:0.160209 acc:0.95\n",
      "Train Epoch:7[36352/60000 (61%)]\t Loss:0.162221 acc:0.95\n",
      "Train Epoch:7[36864/60000 (61%)]\t Loss:0.212965 acc:0.94\n",
      "Train Epoch:7[37376/60000 (62%)]\t Loss:0.239299 acc:0.94\n",
      "Train Epoch:7[37888/60000 (63%)]\t Loss:0.176689 acc:0.95\n",
      "Train Epoch:7[38400/60000 (64%)]\t Loss:0.163543 acc:0.96\n",
      "Train Epoch:7[38912/60000 (65%)]\t Loss:0.192411 acc:0.94\n",
      "Train Epoch:7[39424/60000 (66%)]\t Loss:0.196410 acc:0.94\n",
      "Train Epoch:7[39936/60000 (67%)]\t Loss:0.162090 acc:0.96\n",
      "Train Epoch:7[40448/60000 (67%)]\t Loss:0.161140 acc:0.95\n",
      "Train Epoch:7[40960/60000 (68%)]\t Loss:0.262364 acc:0.93\n",
      "Train Epoch:7[41472/60000 (69%)]\t Loss:0.199739 acc:0.94\n",
      "Train Epoch:7[41984/60000 (70%)]\t Loss:0.235369 acc:0.93\n",
      "Train Epoch:7[42496/60000 (71%)]\t Loss:0.242460 acc:0.93\n",
      "Train Epoch:7[43008/60000 (72%)]\t Loss:0.170535 acc:0.95\n",
      "Train Epoch:7[43520/60000 (73%)]\t Loss:0.184915 acc:0.95\n",
      "Train Epoch:7[44032/60000 (73%)]\t Loss:0.208465 acc:0.94\n",
      "Train Epoch:7[44544/60000 (74%)]\t Loss:0.206016 acc:0.94\n",
      "Train Epoch:7[45056/60000 (75%)]\t Loss:0.202388 acc:0.94\n",
      "Train Epoch:7[45568/60000 (76%)]\t Loss:0.253649 acc:0.92\n",
      "Train Epoch:7[46080/60000 (77%)]\t Loss:0.242665 acc:0.93\n",
      "Train Epoch:7[46592/60000 (78%)]\t Loss:0.152365 acc:0.96\n",
      "Train Epoch:7[47104/60000 (79%)]\t Loss:0.220926 acc:0.92\n",
      "Train Epoch:7[47616/60000 (79%)]\t Loss:0.165441 acc:0.95\n",
      "Train Epoch:7[48128/60000 (80%)]\t Loss:0.179252 acc:0.94\n",
      "Train Epoch:7[48640/60000 (81%)]\t Loss:0.234333 acc:0.92\n",
      "Train Epoch:7[49152/60000 (82%)]\t Loss:0.261874 acc:0.91\n",
      "Train Epoch:7[49664/60000 (83%)]\t Loss:0.197866 acc:0.95\n",
      "Train Epoch:7[50176/60000 (84%)]\t Loss:0.290838 acc:0.94\n",
      "Train Epoch:7[50688/60000 (84%)]\t Loss:0.151832 acc:0.95\n",
      "Train Epoch:7[51200/60000 (85%)]\t Loss:0.167846 acc:0.94\n",
      "Train Epoch:7[51712/60000 (86%)]\t Loss:0.228219 acc:0.93\n",
      "Train Epoch:7[52224/60000 (87%)]\t Loss:0.172187 acc:0.95\n",
      "Train Epoch:7[52736/60000 (88%)]\t Loss:0.254270 acc:0.93\n",
      "Train Epoch:7[53248/60000 (89%)]\t Loss:0.152053 acc:0.95\n",
      "Train Epoch:7[53760/60000 (90%)]\t Loss:0.176475 acc:0.95\n",
      "Train Epoch:7[54272/60000 (90%)]\t Loss:0.136321 acc:0.96\n",
      "Train Epoch:7[54784/60000 (91%)]\t Loss:0.215205 acc:0.94\n",
      "Train Epoch:7[55296/60000 (92%)]\t Loss:0.205827 acc:0.95\n",
      "Train Epoch:7[55808/60000 (93%)]\t Loss:0.153946 acc:0.96\n",
      "Train Epoch:7[56320/60000 (94%)]\t Loss:0.179407 acc:0.95\n",
      "Train Epoch:7[56832/60000 (95%)]\t Loss:0.135297 acc:0.97\n",
      "Train Epoch:7[57344/60000 (96%)]\t Loss:0.183503 acc:0.94\n",
      "Train Epoch:7[57856/60000 (96%)]\t Loss:0.101337 acc:0.97\n",
      "Train Epoch:7[58368/60000 (97%)]\t Loss:0.100656 acc:0.96\n",
      "Train Epoch:7[58880/60000 (98%)]\t Loss:0.085316 acc:0.97\n",
      "Train Epoch:7[59392/60000 (99%)]\t Loss:0.171987 acc:0.96\n",
      "Train Epoch:7[59904/60000 (100%)]\t Loss:0.246829 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:7 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:7 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:7 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:7 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:7 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:7 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:7 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:7 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:7 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:7 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:7 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:7 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:7 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:7 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:7 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:7 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:7 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:7 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:7 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:7 [9728/10000 (97%)]\t acc:0.94\n",
      "Train Epoch:8[0/60000 (0%)]\t Loss:0.196568 acc:0.95\n",
      "Train Epoch:8[512/60000 (1%)]\t Loss:0.224443 acc:0.94\n",
      "Train Epoch:8[1024/60000 (2%)]\t Loss:0.260898 acc:0.93\n",
      "Train Epoch:8[1536/60000 (3%)]\t Loss:0.138232 acc:0.96\n",
      "Train Epoch:8[2048/60000 (3%)]\t Loss:0.132398 acc:0.96\n",
      "Train Epoch:8[2560/60000 (4%)]\t Loss:0.179438 acc:0.95\n",
      "Train Epoch:8[3072/60000 (5%)]\t Loss:0.122545 acc:0.97\n",
      "Train Epoch:8[3584/60000 (6%)]\t Loss:0.162156 acc:0.95\n",
      "Train Epoch:8[4096/60000 (7%)]\t Loss:0.173993 acc:0.94\n",
      "Train Epoch:8[4608/60000 (8%)]\t Loss:0.188220 acc:0.94\n",
      "Train Epoch:8[5120/60000 (9%)]\t Loss:0.184446 acc:0.95\n",
      "Train Epoch:8[5632/60000 (9%)]\t Loss:0.190363 acc:0.95\n",
      "Train Epoch:8[6144/60000 (10%)]\t Loss:0.149992 acc:0.95\n",
      "Train Epoch:8[6656/60000 (11%)]\t Loss:0.225005 acc:0.92\n",
      "Train Epoch:8[7168/60000 (12%)]\t Loss:0.177902 acc:0.95\n",
      "Train Epoch:8[7680/60000 (13%)]\t Loss:0.197262 acc:0.94\n",
      "Train Epoch:8[8192/60000 (14%)]\t Loss:0.222724 acc:0.93\n",
      "Train Epoch:8[8704/60000 (15%)]\t Loss:0.275953 acc:0.91\n",
      "Train Epoch:8[9216/60000 (15%)]\t Loss:0.191758 acc:0.93\n",
      "Train Epoch:8[9728/60000 (16%)]\t Loss:0.187947 acc:0.94\n",
      "Train Epoch:8[10240/60000 (17%)]\t Loss:0.169566 acc:0.94\n",
      "Train Epoch:8[10752/60000 (18%)]\t Loss:0.171930 acc:0.96\n",
      "Train Epoch:8[11264/60000 (19%)]\t Loss:0.213990 acc:0.93\n",
      "Train Epoch:8[11776/60000 (20%)]\t Loss:0.173306 acc:0.94\n",
      "Train Epoch:8[12288/60000 (20%)]\t Loss:0.266746 acc:0.93\n",
      "Train Epoch:8[12800/60000 (21%)]\t Loss:0.173884 acc:0.94\n",
      "Train Epoch:8[13312/60000 (22%)]\t Loss:0.155730 acc:0.95\n",
      "Train Epoch:8[13824/60000 (23%)]\t Loss:0.229285 acc:0.93\n",
      "Train Epoch:8[14336/60000 (24%)]\t Loss:0.226635 acc:0.92\n",
      "Train Epoch:8[14848/60000 (25%)]\t Loss:0.174046 acc:0.95\n",
      "Train Epoch:8[15360/60000 (26%)]\t Loss:0.193031 acc:0.93\n",
      "Train Epoch:8[15872/60000 (26%)]\t Loss:0.164787 acc:0.95\n",
      "Train Epoch:8[16384/60000 (27%)]\t Loss:0.210229 acc:0.93\n",
      "Train Epoch:8[16896/60000 (28%)]\t Loss:0.178599 acc:0.94\n",
      "Train Epoch:8[17408/60000 (29%)]\t Loss:0.219464 acc:0.92\n",
      "Train Epoch:8[17920/60000 (30%)]\t Loss:0.133727 acc:0.96\n",
      "Train Epoch:8[18432/60000 (31%)]\t Loss:0.142148 acc:0.96\n",
      "Train Epoch:8[18944/60000 (32%)]\t Loss:0.157986 acc:0.96\n",
      "Train Epoch:8[19456/60000 (32%)]\t Loss:0.151240 acc:0.96\n",
      "Train Epoch:8[19968/60000 (33%)]\t Loss:0.164695 acc:0.95\n",
      "Train Epoch:8[20480/60000 (34%)]\t Loss:0.283681 acc:0.93\n",
      "Train Epoch:8[20992/60000 (35%)]\t Loss:0.150680 acc:0.96\n",
      "Train Epoch:8[21504/60000 (36%)]\t Loss:0.131425 acc:0.96\n",
      "Train Epoch:8[22016/60000 (37%)]\t Loss:0.162622 acc:0.95\n",
      "Train Epoch:8[22528/60000 (38%)]\t Loss:0.182499 acc:0.95\n",
      "Train Epoch:8[23040/60000 (38%)]\t Loss:0.127621 acc:0.96\n",
      "Train Epoch:8[23552/60000 (39%)]\t Loss:0.189459 acc:0.95\n",
      "Train Epoch:8[24064/60000 (40%)]\t Loss:0.171167 acc:0.94\n",
      "Train Epoch:8[24576/60000 (41%)]\t Loss:0.191078 acc:0.94\n",
      "Train Epoch:8[25088/60000 (42%)]\t Loss:0.192240 acc:0.95\n",
      "Train Epoch:8[25600/60000 (43%)]\t Loss:0.170374 acc:0.94\n",
      "Train Epoch:8[26112/60000 (44%)]\t Loss:0.209781 acc:0.95\n",
      "Train Epoch:8[26624/60000 (44%)]\t Loss:0.227071 acc:0.93\n",
      "Train Epoch:8[27136/60000 (45%)]\t Loss:0.199598 acc:0.95\n",
      "Train Epoch:8[27648/60000 (46%)]\t Loss:0.132812 acc:0.96\n",
      "Train Epoch:8[28160/60000 (47%)]\t Loss:0.185504 acc:0.94\n",
      "Train Epoch:8[28672/60000 (48%)]\t Loss:0.163540 acc:0.95\n",
      "Train Epoch:8[29184/60000 (49%)]\t Loss:0.172034 acc:0.95\n",
      "Train Epoch:8[29696/60000 (49%)]\t Loss:0.226141 acc:0.93\n",
      "Train Epoch:8[30208/60000 (50%)]\t Loss:0.174355 acc:0.95\n",
      "Train Epoch:8[30720/60000 (51%)]\t Loss:0.220610 acc:0.94\n",
      "Train Epoch:8[31232/60000 (52%)]\t Loss:0.262315 acc:0.91\n",
      "Train Epoch:8[31744/60000 (53%)]\t Loss:0.185437 acc:0.94\n",
      "Train Epoch:8[32256/60000 (54%)]\t Loss:0.222094 acc:0.94\n",
      "Train Epoch:8[32768/60000 (55%)]\t Loss:0.153674 acc:0.97\n",
      "Train Epoch:8[33280/60000 (55%)]\t Loss:0.184068 acc:0.95\n",
      "Train Epoch:8[33792/60000 (56%)]\t Loss:0.103870 acc:0.98\n",
      "Train Epoch:8[34304/60000 (57%)]\t Loss:0.238079 acc:0.92\n",
      "Train Epoch:8[34816/60000 (58%)]\t Loss:0.183387 acc:0.94\n",
      "Train Epoch:8[35328/60000 (59%)]\t Loss:0.137415 acc:0.96\n",
      "Train Epoch:8[35840/60000 (60%)]\t Loss:0.147917 acc:0.96\n",
      "Train Epoch:8[36352/60000 (61%)]\t Loss:0.150438 acc:0.95\n",
      "Train Epoch:8[36864/60000 (61%)]\t Loss:0.194245 acc:0.95\n",
      "Train Epoch:8[37376/60000 (62%)]\t Loss:0.215342 acc:0.94\n",
      "Train Epoch:8[37888/60000 (63%)]\t Loss:0.156896 acc:0.96\n",
      "Train Epoch:8[38400/60000 (64%)]\t Loss:0.150875 acc:0.96\n",
      "Train Epoch:8[38912/60000 (65%)]\t Loss:0.177422 acc:0.94\n",
      "Train Epoch:8[39424/60000 (66%)]\t Loss:0.173023 acc:0.95\n",
      "Train Epoch:8[39936/60000 (67%)]\t Loss:0.148929 acc:0.96\n",
      "Train Epoch:8[40448/60000 (67%)]\t Loss:0.143232 acc:0.96\n",
      "Train Epoch:8[40960/60000 (68%)]\t Loss:0.238917 acc:0.93\n",
      "Train Epoch:8[41472/60000 (69%)]\t Loss:0.179623 acc:0.95\n",
      "Train Epoch:8[41984/60000 (70%)]\t Loss:0.200293 acc:0.94\n",
      "Train Epoch:8[42496/60000 (71%)]\t Loss:0.219054 acc:0.94\n",
      "Train Epoch:8[43008/60000 (72%)]\t Loss:0.154726 acc:0.95\n",
      "Train Epoch:8[43520/60000 (73%)]\t Loss:0.169674 acc:0.95\n",
      "Train Epoch:8[44032/60000 (73%)]\t Loss:0.188438 acc:0.95\n",
      "Train Epoch:8[44544/60000 (74%)]\t Loss:0.183075 acc:0.94\n",
      "Train Epoch:8[45056/60000 (75%)]\t Loss:0.182988 acc:0.95\n",
      "Train Epoch:8[45568/60000 (76%)]\t Loss:0.238195 acc:0.92\n",
      "Train Epoch:8[46080/60000 (77%)]\t Loss:0.224555 acc:0.93\n",
      "Train Epoch:8[46592/60000 (78%)]\t Loss:0.140774 acc:0.96\n",
      "Train Epoch:8[47104/60000 (79%)]\t Loss:0.199558 acc:0.94\n",
      "Train Epoch:8[47616/60000 (79%)]\t Loss:0.148872 acc:0.96\n",
      "Train Epoch:8[48128/60000 (80%)]\t Loss:0.157132 acc:0.95\n",
      "Train Epoch:8[48640/60000 (81%)]\t Loss:0.211916 acc:0.93\n",
      "Train Epoch:8[49152/60000 (82%)]\t Loss:0.240395 acc:0.92\n",
      "Train Epoch:8[49664/60000 (83%)]\t Loss:0.176760 acc:0.95\n",
      "Train Epoch:8[50176/60000 (84%)]\t Loss:0.273012 acc:0.94\n",
      "Train Epoch:8[50688/60000 (84%)]\t Loss:0.131540 acc:0.97\n",
      "Train Epoch:8[51200/60000 (85%)]\t Loss:0.154967 acc:0.95\n",
      "Train Epoch:8[51712/60000 (86%)]\t Loss:0.211434 acc:0.93\n",
      "Train Epoch:8[52224/60000 (87%)]\t Loss:0.152768 acc:0.95\n",
      "Train Epoch:8[52736/60000 (88%)]\t Loss:0.235975 acc:0.94\n",
      "Train Epoch:8[53248/60000 (89%)]\t Loss:0.135762 acc:0.96\n",
      "Train Epoch:8[53760/60000 (90%)]\t Loss:0.162482 acc:0.96\n",
      "Train Epoch:8[54272/60000 (90%)]\t Loss:0.121825 acc:0.96\n",
      "Train Epoch:8[54784/60000 (91%)]\t Loss:0.190862 acc:0.94\n",
      "Train Epoch:8[55296/60000 (92%)]\t Loss:0.188284 acc:0.95\n",
      "Train Epoch:8[55808/60000 (93%)]\t Loss:0.140346 acc:0.96\n",
      "Train Epoch:8[56320/60000 (94%)]\t Loss:0.162148 acc:0.96\n",
      "Train Epoch:8[56832/60000 (95%)]\t Loss:0.122088 acc:0.97\n",
      "Train Epoch:8[57344/60000 (96%)]\t Loss:0.169767 acc:0.95\n",
      "Train Epoch:8[57856/60000 (96%)]\t Loss:0.095611 acc:0.97\n",
      "Train Epoch:8[58368/60000 (97%)]\t Loss:0.091080 acc:0.98\n",
      "Train Epoch:8[58880/60000 (98%)]\t Loss:0.075550 acc:0.98\n",
      "Train Epoch:8[59392/60000 (99%)]\t Loss:0.157499 acc:0.96\n",
      "Train Epoch:8[59904/60000 (100%)]\t Loss:0.245463 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:8 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:8 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:8 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:8 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:8 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:8 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:8 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:8 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:8 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:8 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:8 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:8 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:8 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:8 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:8 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:8 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:8 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:8 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:8 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:8 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:9[0/60000 (0%)]\t Loss:0.177976 acc:0.95\n",
      "Train Epoch:9[512/60000 (1%)]\t Loss:0.206610 acc:0.95\n",
      "Train Epoch:9[1024/60000 (2%)]\t Loss:0.241910 acc:0.93\n",
      "Train Epoch:9[1536/60000 (3%)]\t Loss:0.122869 acc:0.97\n",
      "Train Epoch:9[2048/60000 (3%)]\t Loss:0.118472 acc:0.96\n",
      "Train Epoch:9[2560/60000 (4%)]\t Loss:0.162686 acc:0.97\n",
      "Train Epoch:9[3072/60000 (5%)]\t Loss:0.107550 acc:0.98\n",
      "Train Epoch:9[3584/60000 (6%)]\t Loss:0.145645 acc:0.96\n",
      "Train Epoch:9[4096/60000 (7%)]\t Loss:0.159850 acc:0.95\n",
      "Train Epoch:9[4608/60000 (8%)]\t Loss:0.170428 acc:0.95\n",
      "Train Epoch:9[5120/60000 (9%)]\t Loss:0.167963 acc:0.95\n",
      "Train Epoch:9[5632/60000 (9%)]\t Loss:0.179076 acc:0.95\n",
      "Train Epoch:9[6144/60000 (10%)]\t Loss:0.143353 acc:0.96\n",
      "Train Epoch:9[6656/60000 (11%)]\t Loss:0.208663 acc:0.93\n",
      "Train Epoch:9[7168/60000 (12%)]\t Loss:0.162224 acc:0.94\n",
      "Train Epoch:9[7680/60000 (13%)]\t Loss:0.183509 acc:0.94\n",
      "Train Epoch:9[8192/60000 (14%)]\t Loss:0.201134 acc:0.94\n",
      "Train Epoch:9[8704/60000 (15%)]\t Loss:0.250558 acc:0.93\n",
      "Train Epoch:9[9216/60000 (15%)]\t Loss:0.173792 acc:0.95\n",
      "Train Epoch:9[9728/60000 (16%)]\t Loss:0.168045 acc:0.94\n",
      "Train Epoch:9[10240/60000 (17%)]\t Loss:0.157436 acc:0.95\n",
      "Train Epoch:9[10752/60000 (18%)]\t Loss:0.154850 acc:0.96\n",
      "Train Epoch:9[11264/60000 (19%)]\t Loss:0.193518 acc:0.94\n",
      "Train Epoch:9[11776/60000 (20%)]\t Loss:0.158475 acc:0.95\n",
      "Train Epoch:9[12288/60000 (20%)]\t Loss:0.246527 acc:0.94\n",
      "Train Epoch:9[12800/60000 (21%)]\t Loss:0.157501 acc:0.94\n",
      "Train Epoch:9[13312/60000 (22%)]\t Loss:0.141181 acc:0.96\n",
      "Train Epoch:9[13824/60000 (23%)]\t Loss:0.206767 acc:0.93\n",
      "Train Epoch:9[14336/60000 (24%)]\t Loss:0.200998 acc:0.93\n",
      "Train Epoch:9[14848/60000 (25%)]\t Loss:0.156590 acc:0.95\n",
      "Train Epoch:9[15360/60000 (26%)]\t Loss:0.179147 acc:0.94\n",
      "Train Epoch:9[15872/60000 (26%)]\t Loss:0.147067 acc:0.95\n",
      "Train Epoch:9[16384/60000 (27%)]\t Loss:0.196919 acc:0.94\n",
      "Train Epoch:9[16896/60000 (28%)]\t Loss:0.161809 acc:0.95\n",
      "Train Epoch:9[17408/60000 (29%)]\t Loss:0.197230 acc:0.93\n",
      "Train Epoch:9[17920/60000 (30%)]\t Loss:0.123651 acc:0.97\n",
      "Train Epoch:9[18432/60000 (31%)]\t Loss:0.124828 acc:0.97\n",
      "Train Epoch:9[18944/60000 (32%)]\t Loss:0.147804 acc:0.96\n",
      "Train Epoch:9[19456/60000 (32%)]\t Loss:0.140096 acc:0.96\n",
      "Train Epoch:9[19968/60000 (33%)]\t Loss:0.150405 acc:0.95\n",
      "Train Epoch:9[20480/60000 (34%)]\t Loss:0.270086 acc:0.94\n",
      "Train Epoch:9[20992/60000 (35%)]\t Loss:0.138140 acc:0.96\n",
      "Train Epoch:9[21504/60000 (36%)]\t Loss:0.119479 acc:0.96\n",
      "Train Epoch:9[22016/60000 (37%)]\t Loss:0.150605 acc:0.95\n",
      "Train Epoch:9[22528/60000 (38%)]\t Loss:0.170407 acc:0.95\n",
      "Train Epoch:9[23040/60000 (38%)]\t Loss:0.115332 acc:0.96\n",
      "Train Epoch:9[23552/60000 (39%)]\t Loss:0.176532 acc:0.95\n",
      "Train Epoch:9[24064/60000 (40%)]\t Loss:0.154675 acc:0.94\n",
      "Train Epoch:9[24576/60000 (41%)]\t Loss:0.171445 acc:0.95\n",
      "Train Epoch:9[25088/60000 (42%)]\t Loss:0.174285 acc:0.95\n",
      "Train Epoch:9[25600/60000 (43%)]\t Loss:0.155751 acc:0.95\n",
      "Train Epoch:9[26112/60000 (44%)]\t Loss:0.193532 acc:0.95\n",
      "Train Epoch:9[26624/60000 (44%)]\t Loss:0.208750 acc:0.94\n",
      "Train Epoch:9[27136/60000 (45%)]\t Loss:0.184588 acc:0.95\n",
      "Train Epoch:9[27648/60000 (46%)]\t Loss:0.125990 acc:0.96\n",
      "Train Epoch:9[28160/60000 (47%)]\t Loss:0.170197 acc:0.95\n",
      "Train Epoch:9[28672/60000 (48%)]\t Loss:0.149615 acc:0.96\n",
      "Train Epoch:9[29184/60000 (49%)]\t Loss:0.152525 acc:0.96\n",
      "Train Epoch:9[29696/60000 (49%)]\t Loss:0.200053 acc:0.94\n",
      "Train Epoch:9[30208/60000 (50%)]\t Loss:0.154563 acc:0.96\n",
      "Train Epoch:9[30720/60000 (51%)]\t Loss:0.202766 acc:0.94\n",
      "Train Epoch:9[31232/60000 (52%)]\t Loss:0.243073 acc:0.92\n",
      "Train Epoch:9[31744/60000 (53%)]\t Loss:0.168030 acc:0.95\n",
      "Train Epoch:9[32256/60000 (54%)]\t Loss:0.206664 acc:0.94\n",
      "Train Epoch:9[32768/60000 (55%)]\t Loss:0.137433 acc:0.97\n",
      "Train Epoch:9[33280/60000 (55%)]\t Loss:0.167657 acc:0.95\n",
      "Train Epoch:9[33792/60000 (56%)]\t Loss:0.095319 acc:0.98\n",
      "Train Epoch:9[34304/60000 (57%)]\t Loss:0.224864 acc:0.92\n",
      "Train Epoch:9[34816/60000 (58%)]\t Loss:0.169158 acc:0.95\n",
      "Train Epoch:9[35328/60000 (59%)]\t Loss:0.130850 acc:0.96\n",
      "Train Epoch:9[35840/60000 (60%)]\t Loss:0.137179 acc:0.95\n",
      "Train Epoch:9[36352/60000 (61%)]\t Loss:0.138538 acc:0.96\n",
      "Train Epoch:9[36864/60000 (61%)]\t Loss:0.177689 acc:0.95\n",
      "Train Epoch:9[37376/60000 (62%)]\t Loss:0.194483 acc:0.94\n",
      "Train Epoch:9[37888/60000 (63%)]\t Loss:0.142745 acc:0.96\n",
      "Train Epoch:9[38400/60000 (64%)]\t Loss:0.139636 acc:0.96\n",
      "Train Epoch:9[38912/60000 (65%)]\t Loss:0.169044 acc:0.94\n",
      "Train Epoch:9[39424/60000 (66%)]\t Loss:0.156211 acc:0.96\n",
      "Train Epoch:9[39936/60000 (67%)]\t Loss:0.140037 acc:0.96\n",
      "Train Epoch:9[40448/60000 (67%)]\t Loss:0.130552 acc:0.96\n",
      "Train Epoch:9[40960/60000 (68%)]\t Loss:0.220155 acc:0.93\n",
      "Train Epoch:9[41472/60000 (69%)]\t Loss:0.161467 acc:0.95\n",
      "Train Epoch:9[41984/60000 (70%)]\t Loss:0.175514 acc:0.95\n",
      "Train Epoch:9[42496/60000 (71%)]\t Loss:0.199722 acc:0.94\n",
      "Train Epoch:9[43008/60000 (72%)]\t Loss:0.142601 acc:0.95\n",
      "Train Epoch:9[43520/60000 (73%)]\t Loss:0.158418 acc:0.96\n",
      "Train Epoch:9[44032/60000 (73%)]\t Loss:0.174623 acc:0.95\n",
      "Train Epoch:9[44544/60000 (74%)]\t Loss:0.163264 acc:0.94\n",
      "Train Epoch:9[45056/60000 (75%)]\t Loss:0.167002 acc:0.95\n",
      "Train Epoch:9[45568/60000 (76%)]\t Loss:0.225193 acc:0.92\n",
      "Train Epoch:9[46080/60000 (77%)]\t Loss:0.212770 acc:0.94\n",
      "Train Epoch:9[46592/60000 (78%)]\t Loss:0.133696 acc:0.96\n",
      "Train Epoch:9[47104/60000 (79%)]\t Loss:0.182274 acc:0.94\n",
      "Train Epoch:9[47616/60000 (79%)]\t Loss:0.138785 acc:0.96\n",
      "Train Epoch:9[48128/60000 (80%)]\t Loss:0.141808 acc:0.95\n",
      "Train Epoch:9[48640/60000 (81%)]\t Loss:0.195999 acc:0.94\n",
      "Train Epoch:9[49152/60000 (82%)]\t Loss:0.218425 acc:0.93\n",
      "Train Epoch:9[49664/60000 (83%)]\t Loss:0.160112 acc:0.95\n",
      "Train Epoch:9[50176/60000 (84%)]\t Loss:0.258236 acc:0.94\n",
      "Train Epoch:9[50688/60000 (84%)]\t Loss:0.114607 acc:0.98\n",
      "Train Epoch:9[51200/60000 (85%)]\t Loss:0.143822 acc:0.95\n",
      "Train Epoch:9[51712/60000 (86%)]\t Loss:0.196492 acc:0.94\n",
      "Train Epoch:9[52224/60000 (87%)]\t Loss:0.137849 acc:0.96\n",
      "Train Epoch:9[52736/60000 (88%)]\t Loss:0.223290 acc:0.94\n",
      "Train Epoch:9[53248/60000 (89%)]\t Loss:0.123999 acc:0.97\n",
      "Train Epoch:9[53760/60000 (90%)]\t Loss:0.152888 acc:0.96\n",
      "Train Epoch:9[54272/60000 (90%)]\t Loss:0.110999 acc:0.97\n",
      "Train Epoch:9[54784/60000 (91%)]\t Loss:0.173791 acc:0.95\n",
      "Train Epoch:9[55296/60000 (92%)]\t Loss:0.174734 acc:0.95\n",
      "Train Epoch:9[55808/60000 (93%)]\t Loss:0.130590 acc:0.96\n",
      "Train Epoch:9[56320/60000 (94%)]\t Loss:0.145460 acc:0.96\n",
      "Train Epoch:9[56832/60000 (95%)]\t Loss:0.109237 acc:0.96\n",
      "Train Epoch:9[57344/60000 (96%)]\t Loss:0.159118 acc:0.95\n",
      "Train Epoch:9[57856/60000 (96%)]\t Loss:0.089299 acc:0.97\n",
      "Train Epoch:9[58368/60000 (97%)]\t Loss:0.083959 acc:0.98\n",
      "Train Epoch:9[58880/60000 (98%)]\t Loss:0.067714 acc:0.98\n",
      "Train Epoch:9[59392/60000 (99%)]\t Loss:0.145142 acc:0.97\n",
      "Train Epoch:9[59904/60000 (100%)]\t Loss:0.245203 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:9 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:9 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:9 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:9 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:9 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:9 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:9 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:9 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:9 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:9 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:9 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:9 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:9 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:9 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:9 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:9 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:9 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:9 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:9 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:9 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:10[0/60000 (0%)]\t Loss:0.166432 acc:0.96\n",
      "Train Epoch:10[512/60000 (1%)]\t Loss:0.191468 acc:0.95\n",
      "Train Epoch:10[1024/60000 (2%)]\t Loss:0.227638 acc:0.92\n",
      "Train Epoch:10[1536/60000 (3%)]\t Loss:0.112778 acc:0.97\n",
      "Train Epoch:10[2048/60000 (3%)]\t Loss:0.108144 acc:0.96\n",
      "Train Epoch:10[2560/60000 (4%)]\t Loss:0.148619 acc:0.97\n",
      "Train Epoch:10[3072/60000 (5%)]\t Loss:0.094388 acc:0.97\n",
      "Train Epoch:10[3584/60000 (6%)]\t Loss:0.129579 acc:0.96\n",
      "Train Epoch:10[4096/60000 (7%)]\t Loss:0.146965 acc:0.96\n",
      "Train Epoch:10[4608/60000 (8%)]\t Loss:0.153883 acc:0.96\n",
      "Train Epoch:10[5120/60000 (9%)]\t Loss:0.151799 acc:0.95\n",
      "Train Epoch:10[5632/60000 (9%)]\t Loss:0.170686 acc:0.96\n",
      "Train Epoch:10[6144/60000 (10%)]\t Loss:0.133782 acc:0.96\n",
      "Train Epoch:10[6656/60000 (11%)]\t Loss:0.193772 acc:0.94\n",
      "Train Epoch:10[7168/60000 (12%)]\t Loss:0.151936 acc:0.94\n",
      "Train Epoch:10[7680/60000 (13%)]\t Loss:0.170845 acc:0.94\n",
      "Train Epoch:10[8192/60000 (14%)]\t Loss:0.184137 acc:0.95\n",
      "Train Epoch:10[8704/60000 (15%)]\t Loss:0.232862 acc:0.93\n",
      "Train Epoch:10[9216/60000 (15%)]\t Loss:0.158361 acc:0.95\n",
      "Train Epoch:10[9728/60000 (16%)]\t Loss:0.151600 acc:0.95\n",
      "Train Epoch:10[10240/60000 (17%)]\t Loss:0.148750 acc:0.95\n",
      "Train Epoch:10[10752/60000 (18%)]\t Loss:0.137785 acc:0.96\n",
      "Train Epoch:10[11264/60000 (19%)]\t Loss:0.173646 acc:0.95\n",
      "Train Epoch:10[11776/60000 (20%)]\t Loss:0.144847 acc:0.96\n",
      "Train Epoch:10[12288/60000 (20%)]\t Loss:0.230497 acc:0.94\n",
      "Train Epoch:10[12800/60000 (21%)]\t Loss:0.146157 acc:0.95\n",
      "Train Epoch:10[13312/60000 (22%)]\t Loss:0.128905 acc:0.96\n",
      "Train Epoch:10[13824/60000 (23%)]\t Loss:0.187109 acc:0.93\n",
      "Train Epoch:10[14336/60000 (24%)]\t Loss:0.180396 acc:0.94\n",
      "Train Epoch:10[14848/60000 (25%)]\t Loss:0.141508 acc:0.96\n",
      "Train Epoch:10[15360/60000 (26%)]\t Loss:0.165928 acc:0.95\n",
      "Train Epoch:10[15872/60000 (26%)]\t Loss:0.132938 acc:0.96\n",
      "Train Epoch:10[16384/60000 (27%)]\t Loss:0.182404 acc:0.95\n",
      "Train Epoch:10[16896/60000 (28%)]\t Loss:0.147058 acc:0.96\n",
      "Train Epoch:10[17408/60000 (29%)]\t Loss:0.178697 acc:0.95\n",
      "Train Epoch:10[17920/60000 (30%)]\t Loss:0.116030 acc:0.97\n",
      "Train Epoch:10[18432/60000 (31%)]\t Loss:0.110258 acc:0.97\n",
      "Train Epoch:10[18944/60000 (32%)]\t Loss:0.138524 acc:0.96\n",
      "Train Epoch:10[19456/60000 (32%)]\t Loss:0.130472 acc:0.96\n",
      "Train Epoch:10[19968/60000 (33%)]\t Loss:0.137153 acc:0.95\n",
      "Train Epoch:10[20480/60000 (34%)]\t Loss:0.255424 acc:0.94\n",
      "Train Epoch:10[20992/60000 (35%)]\t Loss:0.127305 acc:0.96\n",
      "Train Epoch:10[21504/60000 (36%)]\t Loss:0.109341 acc:0.97\n",
      "Train Epoch:10[22016/60000 (37%)]\t Loss:0.139773 acc:0.95\n",
      "Train Epoch:10[22528/60000 (38%)]\t Loss:0.155011 acc:0.95\n",
      "Train Epoch:10[23040/60000 (38%)]\t Loss:0.105363 acc:0.97\n",
      "Train Epoch:10[23552/60000 (39%)]\t Loss:0.166060 acc:0.95\n",
      "Train Epoch:10[24064/60000 (40%)]\t Loss:0.142157 acc:0.94\n",
      "Train Epoch:10[24576/60000 (41%)]\t Loss:0.155861 acc:0.96\n",
      "Train Epoch:10[25088/60000 (42%)]\t Loss:0.160192 acc:0.95\n",
      "Train Epoch:10[25600/60000 (43%)]\t Loss:0.141869 acc:0.96\n",
      "Train Epoch:10[26112/60000 (44%)]\t Loss:0.175403 acc:0.95\n",
      "Train Epoch:10[26624/60000 (44%)]\t Loss:0.188828 acc:0.94\n",
      "Train Epoch:10[27136/60000 (45%)]\t Loss:0.168644 acc:0.96\n",
      "Train Epoch:10[27648/60000 (46%)]\t Loss:0.120257 acc:0.96\n",
      "Train Epoch:10[28160/60000 (47%)]\t Loss:0.160685 acc:0.95\n",
      "Train Epoch:10[28672/60000 (48%)]\t Loss:0.138981 acc:0.96\n",
      "Train Epoch:10[29184/60000 (49%)]\t Loss:0.135712 acc:0.96\n",
      "Train Epoch:10[29696/60000 (49%)]\t Loss:0.180907 acc:0.94\n",
      "Train Epoch:10[30208/60000 (50%)]\t Loss:0.135239 acc:0.96\n",
      "Train Epoch:10[30720/60000 (51%)]\t Loss:0.185919 acc:0.95\n",
      "Train Epoch:10[31232/60000 (52%)]\t Loss:0.227634 acc:0.93\n",
      "Train Epoch:10[31744/60000 (53%)]\t Loss:0.156147 acc:0.95\n",
      "Train Epoch:10[32256/60000 (54%)]\t Loss:0.197227 acc:0.94\n",
      "Train Epoch:10[32768/60000 (55%)]\t Loss:0.125629 acc:0.97\n",
      "Train Epoch:10[33280/60000 (55%)]\t Loss:0.153020 acc:0.96\n",
      "Train Epoch:10[33792/60000 (56%)]\t Loss:0.085044 acc:0.98\n",
      "Train Epoch:10[34304/60000 (57%)]\t Loss:0.207673 acc:0.94\n",
      "Train Epoch:10[34816/60000 (58%)]\t Loss:0.154045 acc:0.95\n",
      "Train Epoch:10[35328/60000 (59%)]\t Loss:0.126250 acc:0.96\n",
      "Train Epoch:10[35840/60000 (60%)]\t Loss:0.128778 acc:0.95\n",
      "Train Epoch:10[36352/60000 (61%)]\t Loss:0.126944 acc:0.96\n",
      "Train Epoch:10[36864/60000 (61%)]\t Loss:0.165370 acc:0.95\n",
      "Train Epoch:10[37376/60000 (62%)]\t Loss:0.175519 acc:0.95\n",
      "Train Epoch:10[37888/60000 (63%)]\t Loss:0.125280 acc:0.97\n",
      "Train Epoch:10[38400/60000 (64%)]\t Loss:0.125245 acc:0.96\n",
      "Train Epoch:10[38912/60000 (65%)]\t Loss:0.161434 acc:0.94\n",
      "Train Epoch:10[39424/60000 (66%)]\t Loss:0.144291 acc:0.96\n",
      "Train Epoch:10[39936/60000 (67%)]\t Loss:0.131734 acc:0.96\n",
      "Train Epoch:10[40448/60000 (67%)]\t Loss:0.122675 acc:0.96\n",
      "Train Epoch:10[40960/60000 (68%)]\t Loss:0.200441 acc:0.94\n",
      "Train Epoch:10[41472/60000 (69%)]\t Loss:0.144696 acc:0.96\n",
      "Train Epoch:10[41984/60000 (70%)]\t Loss:0.160878 acc:0.95\n",
      "Train Epoch:10[42496/60000 (71%)]\t Loss:0.179680 acc:0.95\n",
      "Train Epoch:10[43008/60000 (72%)]\t Loss:0.131727 acc:0.95\n",
      "Train Epoch:10[43520/60000 (73%)]\t Loss:0.149061 acc:0.96\n",
      "Train Epoch:10[44032/60000 (73%)]\t Loss:0.164097 acc:0.96\n",
      "Train Epoch:10[44544/60000 (74%)]\t Loss:0.145950 acc:0.95\n",
      "Train Epoch:10[45056/60000 (75%)]\t Loss:0.154014 acc:0.96\n",
      "Train Epoch:10[45568/60000 (76%)]\t Loss:0.214583 acc:0.93\n",
      "Train Epoch:10[46080/60000 (77%)]\t Loss:0.200459 acc:0.94\n",
      "Train Epoch:10[46592/60000 (78%)]\t Loss:0.124750 acc:0.96\n",
      "Train Epoch:10[47104/60000 (79%)]\t Loss:0.171952 acc:0.95\n",
      "Train Epoch:10[47616/60000 (79%)]\t Loss:0.131393 acc:0.96\n",
      "Train Epoch:10[48128/60000 (80%)]\t Loss:0.127877 acc:0.96\n",
      "Train Epoch:10[48640/60000 (81%)]\t Loss:0.186105 acc:0.94\n",
      "Train Epoch:10[49152/60000 (82%)]\t Loss:0.197260 acc:0.94\n",
      "Train Epoch:10[49664/60000 (83%)]\t Loss:0.142893 acc:0.96\n",
      "Train Epoch:10[50176/60000 (84%)]\t Loss:0.241645 acc:0.94\n",
      "Train Epoch:10[50688/60000 (84%)]\t Loss:0.103311 acc:0.98\n",
      "Train Epoch:10[51200/60000 (85%)]\t Loss:0.133155 acc:0.96\n",
      "Train Epoch:10[51712/60000 (86%)]\t Loss:0.182303 acc:0.94\n",
      "Train Epoch:10[52224/60000 (87%)]\t Loss:0.124233 acc:0.96\n",
      "Train Epoch:10[52736/60000 (88%)]\t Loss:0.213181 acc:0.94\n",
      "Train Epoch:10[53248/60000 (89%)]\t Loss:0.116173 acc:0.97\n",
      "Train Epoch:10[53760/60000 (90%)]\t Loss:0.146259 acc:0.96\n",
      "Train Epoch:10[54272/60000 (90%)]\t Loss:0.102920 acc:0.97\n",
      "Train Epoch:10[54784/60000 (91%)]\t Loss:0.161845 acc:0.95\n",
      "Train Epoch:10[55296/60000 (92%)]\t Loss:0.164087 acc:0.96\n",
      "Train Epoch:10[55808/60000 (93%)]\t Loss:0.122586 acc:0.96\n",
      "Train Epoch:10[56320/60000 (94%)]\t Loss:0.130828 acc:0.96\n",
      "Train Epoch:10[56832/60000 (95%)]\t Loss:0.099281 acc:0.97\n",
      "Train Epoch:10[57344/60000 (96%)]\t Loss:0.146323 acc:0.96\n",
      "Train Epoch:10[57856/60000 (96%)]\t Loss:0.083694 acc:0.97\n",
      "Train Epoch:10[58368/60000 (97%)]\t Loss:0.079396 acc:0.98\n",
      "Train Epoch:10[58880/60000 (98%)]\t Loss:0.061660 acc:0.98\n",
      "Train Epoch:10[59392/60000 (99%)]\t Loss:0.136725 acc:0.97\n",
      "Train Epoch:10[59904/60000 (100%)]\t Loss:0.245611 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:10 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:10 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:10 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:10 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:10 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:10 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:10 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:10 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:10 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:10 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:10 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:10 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:10 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:10 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:10 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:10 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:10 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:10 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:10 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:10 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:11[0/60000 (0%)]\t Loss:0.159438 acc:0.96\n",
      "Train Epoch:11[512/60000 (1%)]\t Loss:0.177238 acc:0.95\n",
      "Train Epoch:11[1024/60000 (2%)]\t Loss:0.212572 acc:0.94\n",
      "Train Epoch:11[1536/60000 (3%)]\t Loss:0.104695 acc:0.97\n",
      "Train Epoch:11[2048/60000 (3%)]\t Loss:0.097403 acc:0.96\n",
      "Train Epoch:11[2560/60000 (4%)]\t Loss:0.138605 acc:0.97\n",
      "Train Epoch:11[3072/60000 (5%)]\t Loss:0.085439 acc:0.98\n",
      "Train Epoch:11[3584/60000 (6%)]\t Loss:0.116713 acc:0.96\n",
      "Train Epoch:11[4096/60000 (7%)]\t Loss:0.135443 acc:0.96\n",
      "Train Epoch:11[4608/60000 (8%)]\t Loss:0.141412 acc:0.96\n",
      "Train Epoch:11[5120/60000 (9%)]\t Loss:0.135667 acc:0.96\n",
      "Train Epoch:11[5632/60000 (9%)]\t Loss:0.160797 acc:0.96\n",
      "Train Epoch:11[6144/60000 (10%)]\t Loss:0.129496 acc:0.96\n",
      "Train Epoch:11[6656/60000 (11%)]\t Loss:0.180801 acc:0.94\n",
      "Train Epoch:11[7168/60000 (12%)]\t Loss:0.144835 acc:0.95\n",
      "Train Epoch:11[7680/60000 (13%)]\t Loss:0.160388 acc:0.95\n",
      "Train Epoch:11[8192/60000 (14%)]\t Loss:0.170366 acc:0.95\n",
      "Train Epoch:11[8704/60000 (15%)]\t Loss:0.218341 acc:0.93\n",
      "Train Epoch:11[9216/60000 (15%)]\t Loss:0.149395 acc:0.96\n",
      "Train Epoch:11[9728/60000 (16%)]\t Loss:0.138100 acc:0.95\n",
      "Train Epoch:11[10240/60000 (17%)]\t Loss:0.136022 acc:0.96\n",
      "Train Epoch:11[10752/60000 (18%)]\t Loss:0.122955 acc:0.96\n",
      "Train Epoch:11[11264/60000 (19%)]\t Loss:0.155095 acc:0.96\n",
      "Train Epoch:11[11776/60000 (20%)]\t Loss:0.131135 acc:0.96\n",
      "Train Epoch:11[12288/60000 (20%)]\t Loss:0.215583 acc:0.94\n",
      "Train Epoch:11[12800/60000 (21%)]\t Loss:0.135237 acc:0.95\n",
      "Train Epoch:11[13312/60000 (22%)]\t Loss:0.119839 acc:0.96\n",
      "Train Epoch:11[13824/60000 (23%)]\t Loss:0.172354 acc:0.94\n",
      "Train Epoch:11[14336/60000 (24%)]\t Loss:0.164573 acc:0.95\n",
      "Train Epoch:11[14848/60000 (25%)]\t Loss:0.130870 acc:0.96\n",
      "Train Epoch:11[15360/60000 (26%)]\t Loss:0.154510 acc:0.95\n",
      "Train Epoch:11[15872/60000 (26%)]\t Loss:0.120845 acc:0.97\n",
      "Train Epoch:11[16384/60000 (27%)]\t Loss:0.168455 acc:0.95\n",
      "Train Epoch:11[16896/60000 (28%)]\t Loss:0.134930 acc:0.96\n",
      "Train Epoch:11[17408/60000 (29%)]\t Loss:0.166275 acc:0.95\n",
      "Train Epoch:11[17920/60000 (30%)]\t Loss:0.109525 acc:0.97\n",
      "Train Epoch:11[18432/60000 (31%)]\t Loss:0.098117 acc:0.98\n",
      "Train Epoch:11[18944/60000 (32%)]\t Loss:0.128735 acc:0.97\n",
      "Train Epoch:11[19456/60000 (32%)]\t Loss:0.122327 acc:0.96\n",
      "Train Epoch:11[19968/60000 (33%)]\t Loss:0.126648 acc:0.96\n",
      "Train Epoch:11[20480/60000 (34%)]\t Loss:0.242028 acc:0.94\n",
      "Train Epoch:11[20992/60000 (35%)]\t Loss:0.117126 acc:0.96\n",
      "Train Epoch:11[21504/60000 (36%)]\t Loss:0.101007 acc:0.97\n",
      "Train Epoch:11[22016/60000 (37%)]\t Loss:0.130994 acc:0.96\n",
      "Train Epoch:11[22528/60000 (38%)]\t Loss:0.142108 acc:0.95\n",
      "Train Epoch:11[23040/60000 (38%)]\t Loss:0.098963 acc:0.97\n",
      "Train Epoch:11[23552/60000 (39%)]\t Loss:0.156812 acc:0.95\n",
      "Train Epoch:11[24064/60000 (40%)]\t Loss:0.131124 acc:0.95\n",
      "Train Epoch:11[24576/60000 (41%)]\t Loss:0.142276 acc:0.96\n",
      "Train Epoch:11[25088/60000 (42%)]\t Loss:0.150574 acc:0.95\n",
      "Train Epoch:11[25600/60000 (43%)]\t Loss:0.131766 acc:0.96\n",
      "Train Epoch:11[26112/60000 (44%)]\t Loss:0.161384 acc:0.96\n",
      "Train Epoch:11[26624/60000 (44%)]\t Loss:0.173054 acc:0.95\n",
      "Train Epoch:11[27136/60000 (45%)]\t Loss:0.154894 acc:0.96\n",
      "Train Epoch:11[27648/60000 (46%)]\t Loss:0.113532 acc:0.96\n",
      "Train Epoch:11[28160/60000 (47%)]\t Loss:0.151677 acc:0.95\n",
      "Train Epoch:11[28672/60000 (48%)]\t Loss:0.130050 acc:0.96\n",
      "Train Epoch:11[29184/60000 (49%)]\t Loss:0.122270 acc:0.96\n",
      "Train Epoch:11[29696/60000 (49%)]\t Loss:0.167157 acc:0.95\n",
      "Train Epoch:11[30208/60000 (50%)]\t Loss:0.118913 acc:0.97\n",
      "Train Epoch:11[30720/60000 (51%)]\t Loss:0.170184 acc:0.95\n",
      "Train Epoch:11[31232/60000 (52%)]\t Loss:0.212531 acc:0.94\n",
      "Train Epoch:11[31744/60000 (53%)]\t Loss:0.145536 acc:0.96\n",
      "Train Epoch:11[32256/60000 (54%)]\t Loss:0.188254 acc:0.94\n",
      "Train Epoch:11[32768/60000 (55%)]\t Loss:0.116648 acc:0.97\n",
      "Train Epoch:11[33280/60000 (55%)]\t Loss:0.143536 acc:0.96\n",
      "Train Epoch:11[33792/60000 (56%)]\t Loss:0.077010 acc:0.98\n",
      "Train Epoch:11[34304/60000 (57%)]\t Loss:0.191117 acc:0.95\n",
      "Train Epoch:11[34816/60000 (58%)]\t Loss:0.140416 acc:0.96\n",
      "Train Epoch:11[35328/60000 (59%)]\t Loss:0.119455 acc:0.96\n",
      "Train Epoch:11[35840/60000 (60%)]\t Loss:0.120284 acc:0.96\n",
      "Train Epoch:11[36352/60000 (61%)]\t Loss:0.118086 acc:0.96\n",
      "Train Epoch:11[36864/60000 (61%)]\t Loss:0.156593 acc:0.96\n",
      "Train Epoch:11[37376/60000 (62%)]\t Loss:0.161728 acc:0.96\n",
      "Train Epoch:11[37888/60000 (63%)]\t Loss:0.109955 acc:0.97\n",
      "Train Epoch:11[38400/60000 (64%)]\t Loss:0.110910 acc:0.97\n",
      "Train Epoch:11[38912/60000 (65%)]\t Loss:0.153031 acc:0.95\n",
      "Train Epoch:11[39424/60000 (66%)]\t Loss:0.135617 acc:0.96\n",
      "Train Epoch:11[39936/60000 (67%)]\t Loss:0.124959 acc:0.97\n",
      "Train Epoch:11[40448/60000 (67%)]\t Loss:0.117800 acc:0.96\n",
      "Train Epoch:11[40960/60000 (68%)]\t Loss:0.188034 acc:0.94\n",
      "Train Epoch:11[41472/60000 (69%)]\t Loss:0.131188 acc:0.96\n",
      "Train Epoch:11[41984/60000 (70%)]\t Loss:0.154711 acc:0.96\n",
      "Train Epoch:11[42496/60000 (71%)]\t Loss:0.161388 acc:0.95\n",
      "Train Epoch:11[43008/60000 (72%)]\t Loss:0.119440 acc:0.96\n",
      "Train Epoch:11[43520/60000 (73%)]\t Loss:0.138993 acc:0.96\n",
      "Train Epoch:11[44032/60000 (73%)]\t Loss:0.153586 acc:0.96\n",
      "Train Epoch:11[44544/60000 (74%)]\t Loss:0.134136 acc:0.96\n",
      "Train Epoch:11[45056/60000 (75%)]\t Loss:0.144187 acc:0.96\n",
      "Train Epoch:11[45568/60000 (76%)]\t Loss:0.206566 acc:0.94\n",
      "Train Epoch:11[46080/60000 (77%)]\t Loss:0.191108 acc:0.94\n",
      "Train Epoch:11[46592/60000 (78%)]\t Loss:0.114588 acc:0.97\n",
      "Train Epoch:11[47104/60000 (79%)]\t Loss:0.166232 acc:0.95\n",
      "Train Epoch:11[47616/60000 (79%)]\t Loss:0.124179 acc:0.96\n",
      "Train Epoch:11[48128/60000 (80%)]\t Loss:0.117574 acc:0.96\n",
      "Train Epoch:11[48640/60000 (81%)]\t Loss:0.182548 acc:0.94\n",
      "Train Epoch:11[49152/60000 (82%)]\t Loss:0.181215 acc:0.95\n",
      "Train Epoch:11[49664/60000 (83%)]\t Loss:0.130257 acc:0.96\n",
      "Train Epoch:11[50176/60000 (84%)]\t Loss:0.227206 acc:0.95\n",
      "Train Epoch:11[50688/60000 (84%)]\t Loss:0.095679 acc:0.98\n",
      "Train Epoch:11[51200/60000 (85%)]\t Loss:0.124221 acc:0.96\n",
      "Train Epoch:11[51712/60000 (86%)]\t Loss:0.169939 acc:0.95\n",
      "Train Epoch:11[52224/60000 (87%)]\t Loss:0.111955 acc:0.96\n",
      "Train Epoch:11[52736/60000 (88%)]\t Loss:0.205216 acc:0.94\n",
      "Train Epoch:11[53248/60000 (89%)]\t Loss:0.109970 acc:0.97\n",
      "Train Epoch:11[53760/60000 (90%)]\t Loss:0.143605 acc:0.96\n",
      "Train Epoch:11[54272/60000 (90%)]\t Loss:0.098228 acc:0.97\n",
      "Train Epoch:11[54784/60000 (91%)]\t Loss:0.152466 acc:0.95\n",
      "Train Epoch:11[55296/60000 (92%)]\t Loss:0.154110 acc:0.96\n",
      "Train Epoch:11[55808/60000 (93%)]\t Loss:0.115527 acc:0.96\n",
      "Train Epoch:11[56320/60000 (94%)]\t Loss:0.119604 acc:0.97\n",
      "Train Epoch:11[56832/60000 (95%)]\t Loss:0.091901 acc:0.97\n",
      "Train Epoch:11[57344/60000 (96%)]\t Loss:0.134554 acc:0.96\n",
      "Train Epoch:11[57856/60000 (96%)]\t Loss:0.078552 acc:0.98\n",
      "Train Epoch:11[58368/60000 (97%)]\t Loss:0.075737 acc:0.98\n",
      "Train Epoch:11[58880/60000 (98%)]\t Loss:0.056309 acc:0.98\n",
      "Train Epoch:11[59392/60000 (99%)]\t Loss:0.132944 acc:0.97\n",
      "Train Epoch:11[59904/60000 (100%)]\t Loss:0.238582 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:11 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:11 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:11 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:11 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:11 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:11 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:11 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:11 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:11 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:11 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:11 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:11 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:11 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:11 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:11 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:11 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:11 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:11 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:11 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:11 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:12[0/60000 (0%)]\t Loss:0.152990 acc:0.96\n",
      "Train Epoch:12[512/60000 (1%)]\t Loss:0.166646 acc:0.95\n",
      "Train Epoch:12[1024/60000 (2%)]\t Loss:0.201893 acc:0.94\n",
      "Train Epoch:12[1536/60000 (3%)]\t Loss:0.099537 acc:0.98\n",
      "Train Epoch:12[2048/60000 (3%)]\t Loss:0.088680 acc:0.96\n",
      "Train Epoch:12[2560/60000 (4%)]\t Loss:0.131520 acc:0.97\n",
      "Train Epoch:12[3072/60000 (5%)]\t Loss:0.078680 acc:0.98\n",
      "Train Epoch:12[3584/60000 (6%)]\t Loss:0.105253 acc:0.97\n",
      "Train Epoch:12[4096/60000 (7%)]\t Loss:0.124281 acc:0.96\n",
      "Train Epoch:12[4608/60000 (8%)]\t Loss:0.129877 acc:0.96\n",
      "Train Epoch:12[5120/60000 (9%)]\t Loss:0.122119 acc:0.97\n",
      "Train Epoch:12[5632/60000 (9%)]\t Loss:0.150234 acc:0.96\n",
      "Train Epoch:12[6144/60000 (10%)]\t Loss:0.124840 acc:0.97\n",
      "Train Epoch:12[6656/60000 (11%)]\t Loss:0.167511 acc:0.95\n",
      "Train Epoch:12[7168/60000 (12%)]\t Loss:0.138251 acc:0.95\n",
      "Train Epoch:12[7680/60000 (13%)]\t Loss:0.148206 acc:0.95\n",
      "Train Epoch:12[8192/60000 (14%)]\t Loss:0.159307 acc:0.95\n",
      "Train Epoch:12[8704/60000 (15%)]\t Loss:0.203241 acc:0.94\n",
      "Train Epoch:12[9216/60000 (15%)]\t Loss:0.141943 acc:0.96\n",
      "Train Epoch:12[9728/60000 (16%)]\t Loss:0.126636 acc:0.95\n",
      "Train Epoch:12[10240/60000 (17%)]\t Loss:0.124717 acc:0.96\n",
      "Train Epoch:12[10752/60000 (18%)]\t Loss:0.111315 acc:0.97\n",
      "Train Epoch:12[11264/60000 (19%)]\t Loss:0.138679 acc:0.96\n",
      "Train Epoch:12[11776/60000 (20%)]\t Loss:0.118101 acc:0.97\n",
      "Train Epoch:12[12288/60000 (20%)]\t Loss:0.205713 acc:0.94\n",
      "Train Epoch:12[12800/60000 (21%)]\t Loss:0.126080 acc:0.95\n",
      "Train Epoch:12[13312/60000 (22%)]\t Loss:0.112803 acc:0.97\n",
      "Train Epoch:12[13824/60000 (23%)]\t Loss:0.160317 acc:0.94\n",
      "Train Epoch:12[14336/60000 (24%)]\t Loss:0.150889 acc:0.95\n",
      "Train Epoch:12[14848/60000 (25%)]\t Loss:0.122961 acc:0.96\n",
      "Train Epoch:12[15360/60000 (26%)]\t Loss:0.146019 acc:0.95\n",
      "Train Epoch:12[15872/60000 (26%)]\t Loss:0.112828 acc:0.97\n",
      "Train Epoch:12[16384/60000 (27%)]\t Loss:0.156200 acc:0.95\n",
      "Train Epoch:12[16896/60000 (28%)]\t Loss:0.124531 acc:0.96\n",
      "Train Epoch:12[17408/60000 (29%)]\t Loss:0.155112 acc:0.96\n",
      "Train Epoch:12[17920/60000 (30%)]\t Loss:0.103207 acc:0.97\n",
      "Train Epoch:12[18432/60000 (31%)]\t Loss:0.088209 acc:0.98\n",
      "Train Epoch:12[18944/60000 (32%)]\t Loss:0.120631 acc:0.97\n",
      "Train Epoch:12[19456/60000 (32%)]\t Loss:0.114084 acc:0.96\n",
      "Train Epoch:12[19968/60000 (33%)]\t Loss:0.119660 acc:0.96\n",
      "Train Epoch:12[20480/60000 (34%)]\t Loss:0.231060 acc:0.94\n",
      "Train Epoch:12[20992/60000 (35%)]\t Loss:0.108224 acc:0.96\n",
      "Train Epoch:12[21504/60000 (36%)]\t Loss:0.093745 acc:0.97\n",
      "Train Epoch:12[22016/60000 (37%)]\t Loss:0.121880 acc:0.96\n",
      "Train Epoch:12[22528/60000 (38%)]\t Loss:0.131712 acc:0.95\n",
      "Train Epoch:12[23040/60000 (38%)]\t Loss:0.093229 acc:0.97\n",
      "Train Epoch:12[23552/60000 (39%)]\t Loss:0.150421 acc:0.96\n",
      "Train Epoch:12[24064/60000 (40%)]\t Loss:0.122927 acc:0.95\n",
      "Train Epoch:12[24576/60000 (41%)]\t Loss:0.132335 acc:0.97\n",
      "Train Epoch:12[25088/60000 (42%)]\t Loss:0.143731 acc:0.96\n",
      "Train Epoch:12[25600/60000 (43%)]\t Loss:0.123738 acc:0.96\n",
      "Train Epoch:12[26112/60000 (44%)]\t Loss:0.150330 acc:0.96\n",
      "Train Epoch:12[26624/60000 (44%)]\t Loss:0.161063 acc:0.95\n",
      "Train Epoch:12[27136/60000 (45%)]\t Loss:0.142454 acc:0.96\n",
      "Train Epoch:12[27648/60000 (46%)]\t Loss:0.110075 acc:0.96\n",
      "Train Epoch:12[28160/60000 (47%)]\t Loss:0.146268 acc:0.95\n",
      "Train Epoch:12[28672/60000 (48%)]\t Loss:0.121688 acc:0.96\n",
      "Train Epoch:12[29184/60000 (49%)]\t Loss:0.110856 acc:0.97\n",
      "Train Epoch:12[29696/60000 (49%)]\t Loss:0.156564 acc:0.95\n",
      "Train Epoch:12[30208/60000 (50%)]\t Loss:0.106196 acc:0.97\n",
      "Train Epoch:12[30720/60000 (51%)]\t Loss:0.155910 acc:0.95\n",
      "Train Epoch:12[31232/60000 (52%)]\t Loss:0.199003 acc:0.95\n",
      "Train Epoch:12[31744/60000 (53%)]\t Loss:0.137653 acc:0.96\n",
      "Train Epoch:12[32256/60000 (54%)]\t Loss:0.181703 acc:0.94\n",
      "Train Epoch:12[32768/60000 (55%)]\t Loss:0.110965 acc:0.98\n",
      "Train Epoch:12[33280/60000 (55%)]\t Loss:0.138966 acc:0.97\n",
      "Train Epoch:12[33792/60000 (56%)]\t Loss:0.072884 acc:0.98\n",
      "Train Epoch:12[34304/60000 (57%)]\t Loss:0.178801 acc:0.95\n",
      "Train Epoch:12[34816/60000 (58%)]\t Loss:0.129228 acc:0.96\n",
      "Train Epoch:12[35328/60000 (59%)]\t Loss:0.113284 acc:0.97\n",
      "Train Epoch:12[35840/60000 (60%)]\t Loss:0.111918 acc:0.96\n",
      "Train Epoch:12[36352/60000 (61%)]\t Loss:0.113708 acc:0.96\n",
      "Train Epoch:12[36864/60000 (61%)]\t Loss:0.151300 acc:0.96\n",
      "Train Epoch:12[37376/60000 (62%)]\t Loss:0.151117 acc:0.96\n",
      "Train Epoch:12[37888/60000 (63%)]\t Loss:0.098840 acc:0.97\n",
      "Train Epoch:12[38400/60000 (64%)]\t Loss:0.098172 acc:0.97\n",
      "Train Epoch:12[38912/60000 (65%)]\t Loss:0.146671 acc:0.95\n",
      "Train Epoch:12[39424/60000 (66%)]\t Loss:0.130398 acc:0.96\n",
      "Train Epoch:12[39936/60000 (67%)]\t Loss:0.120090 acc:0.97\n",
      "Train Epoch:12[40448/60000 (67%)]\t Loss:0.115468 acc:0.96\n",
      "Train Epoch:12[40960/60000 (68%)]\t Loss:0.178672 acc:0.95\n",
      "Train Epoch:12[41472/60000 (69%)]\t Loss:0.121590 acc:0.97\n",
      "Train Epoch:12[41984/60000 (70%)]\t Loss:0.152389 acc:0.95\n",
      "Train Epoch:12[42496/60000 (71%)]\t Loss:0.148505 acc:0.95\n",
      "Train Epoch:12[43008/60000 (72%)]\t Loss:0.111260 acc:0.96\n",
      "Train Epoch:12[43520/60000 (73%)]\t Loss:0.129311 acc:0.97\n",
      "Train Epoch:12[44032/60000 (73%)]\t Loss:0.142156 acc:0.97\n",
      "Train Epoch:12[44544/60000 (74%)]\t Loss:0.124821 acc:0.96\n",
      "Train Epoch:12[45056/60000 (75%)]\t Loss:0.134576 acc:0.96\n",
      "Train Epoch:12[45568/60000 (76%)]\t Loss:0.202099 acc:0.94\n",
      "Train Epoch:12[46080/60000 (77%)]\t Loss:0.183537 acc:0.94\n",
      "Train Epoch:12[46592/60000 (78%)]\t Loss:0.105200 acc:0.97\n",
      "Train Epoch:12[47104/60000 (79%)]\t Loss:0.165257 acc:0.95\n",
      "Train Epoch:12[47616/60000 (79%)]\t Loss:0.117907 acc:0.97\n",
      "Train Epoch:12[48128/60000 (80%)]\t Loss:0.109952 acc:0.96\n",
      "Train Epoch:12[48640/60000 (81%)]\t Loss:0.182272 acc:0.94\n",
      "Train Epoch:12[49152/60000 (82%)]\t Loss:0.169032 acc:0.95\n",
      "Train Epoch:12[49664/60000 (83%)]\t Loss:0.120031 acc:0.97\n",
      "Train Epoch:12[50176/60000 (84%)]\t Loss:0.214999 acc:0.95\n",
      "Train Epoch:12[50688/60000 (84%)]\t Loss:0.090827 acc:0.98\n",
      "Train Epoch:12[51200/60000 (85%)]\t Loss:0.115857 acc:0.96\n",
      "Train Epoch:12[51712/60000 (86%)]\t Loss:0.157967 acc:0.96\n",
      "Train Epoch:12[52224/60000 (87%)]\t Loss:0.101415 acc:0.97\n",
      "Train Epoch:12[52736/60000 (88%)]\t Loss:0.196345 acc:0.95\n",
      "Train Epoch:12[53248/60000 (89%)]\t Loss:0.104808 acc:0.97\n",
      "Train Epoch:12[53760/60000 (90%)]\t Loss:0.140347 acc:0.96\n",
      "Train Epoch:12[54272/60000 (90%)]\t Loss:0.094942 acc:0.97\n",
      "Train Epoch:12[54784/60000 (91%)]\t Loss:0.147738 acc:0.95\n",
      "Train Epoch:12[55296/60000 (92%)]\t Loss:0.147748 acc:0.96\n",
      "Train Epoch:12[55808/60000 (93%)]\t Loss:0.109001 acc:0.96\n",
      "Train Epoch:12[56320/60000 (94%)]\t Loss:0.111703 acc:0.97\n",
      "Train Epoch:12[56832/60000 (95%)]\t Loss:0.086057 acc:0.98\n",
      "Train Epoch:12[57344/60000 (96%)]\t Loss:0.124871 acc:0.97\n",
      "Train Epoch:12[57856/60000 (96%)]\t Loss:0.073731 acc:0.98\n",
      "Train Epoch:12[58368/60000 (97%)]\t Loss:0.072061 acc:0.98\n",
      "Train Epoch:12[58880/60000 (98%)]\t Loss:0.050897 acc:0.98\n",
      "Train Epoch:12[59392/60000 (99%)]\t Loss:0.132146 acc:0.97\n",
      "Train Epoch:12[59904/60000 (100%)]\t Loss:0.227827 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:12 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:12 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:12 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:12 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:12 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:12 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:12 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:12 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:12 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:12 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:12 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:12 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:12 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:12 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:12 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:12 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:12 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:12 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:12 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:12 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:13[0/60000 (0%)]\t Loss:0.145095 acc:0.96\n",
      "Train Epoch:13[512/60000 (1%)]\t Loss:0.157760 acc:0.96\n",
      "Train Epoch:13[1024/60000 (2%)]\t Loss:0.195522 acc:0.94\n",
      "Train Epoch:13[1536/60000 (3%)]\t Loss:0.095333 acc:0.98\n",
      "Train Epoch:13[2048/60000 (3%)]\t Loss:0.082645 acc:0.97\n",
      "Train Epoch:13[2560/60000 (4%)]\t Loss:0.124828 acc:0.97\n",
      "Train Epoch:13[3072/60000 (5%)]\t Loss:0.073756 acc:0.98\n",
      "Train Epoch:13[3584/60000 (6%)]\t Loss:0.095687 acc:0.97\n",
      "Train Epoch:13[4096/60000 (7%)]\t Loss:0.114511 acc:0.97\n",
      "Train Epoch:13[4608/60000 (8%)]\t Loss:0.122045 acc:0.97\n",
      "Train Epoch:13[5120/60000 (9%)]\t Loss:0.111468 acc:0.97\n",
      "Train Epoch:13[5632/60000 (9%)]\t Loss:0.140309 acc:0.96\n",
      "Train Epoch:13[6144/60000 (10%)]\t Loss:0.115314 acc:0.97\n",
      "Train Epoch:13[6656/60000 (11%)]\t Loss:0.154986 acc:0.96\n",
      "Train Epoch:13[7168/60000 (12%)]\t Loss:0.132471 acc:0.95\n",
      "Train Epoch:13[7680/60000 (13%)]\t Loss:0.136785 acc:0.95\n",
      "Train Epoch:13[8192/60000 (14%)]\t Loss:0.150351 acc:0.95\n",
      "Train Epoch:13[8704/60000 (15%)]\t Loss:0.188510 acc:0.94\n",
      "Train Epoch:13[9216/60000 (15%)]\t Loss:0.134892 acc:0.96\n",
      "Train Epoch:13[9728/60000 (16%)]\t Loss:0.116318 acc:0.95\n",
      "Train Epoch:13[10240/60000 (17%)]\t Loss:0.115694 acc:0.96\n",
      "Train Epoch:13[10752/60000 (18%)]\t Loss:0.102128 acc:0.97\n",
      "Train Epoch:13[11264/60000 (19%)]\t Loss:0.123939 acc:0.96\n",
      "Train Epoch:13[11776/60000 (20%)]\t Loss:0.106985 acc:0.97\n",
      "Train Epoch:13[12288/60000 (20%)]\t Loss:0.196387 acc:0.94\n",
      "Train Epoch:13[12800/60000 (21%)]\t Loss:0.118168 acc:0.95\n",
      "Train Epoch:13[13312/60000 (22%)]\t Loss:0.106399 acc:0.97\n",
      "Train Epoch:13[13824/60000 (23%)]\t Loss:0.151359 acc:0.94\n",
      "Train Epoch:13[14336/60000 (24%)]\t Loss:0.139093 acc:0.96\n",
      "Train Epoch:13[14848/60000 (25%)]\t Loss:0.116278 acc:0.96\n",
      "Train Epoch:13[15360/60000 (26%)]\t Loss:0.139219 acc:0.95\n",
      "Train Epoch:13[15872/60000 (26%)]\t Loss:0.108118 acc:0.97\n",
      "Train Epoch:13[16384/60000 (27%)]\t Loss:0.147377 acc:0.95\n",
      "Train Epoch:13[16896/60000 (28%)]\t Loss:0.117038 acc:0.96\n",
      "Train Epoch:13[17408/60000 (29%)]\t Loss:0.144174 acc:0.95\n",
      "Train Epoch:13[17920/60000 (30%)]\t Loss:0.097169 acc:0.97\n",
      "Train Epoch:13[18432/60000 (31%)]\t Loss:0.080214 acc:0.98\n",
      "Train Epoch:13[18944/60000 (32%)]\t Loss:0.113364 acc:0.97\n",
      "Train Epoch:13[19456/60000 (32%)]\t Loss:0.105132 acc:0.97\n",
      "Train Epoch:13[19968/60000 (33%)]\t Loss:0.112598 acc:0.96\n",
      "Train Epoch:13[20480/60000 (34%)]\t Loss:0.222483 acc:0.95\n",
      "Train Epoch:13[20992/60000 (35%)]\t Loss:0.100769 acc:0.96\n",
      "Train Epoch:13[21504/60000 (36%)]\t Loss:0.086730 acc:0.97\n",
      "Train Epoch:13[22016/60000 (37%)]\t Loss:0.111747 acc:0.96\n",
      "Train Epoch:13[22528/60000 (38%)]\t Loss:0.122255 acc:0.96\n",
      "Train Epoch:13[23040/60000 (38%)]\t Loss:0.085511 acc:0.97\n",
      "Train Epoch:13[23552/60000 (39%)]\t Loss:0.143354 acc:0.96\n",
      "Train Epoch:13[24064/60000 (40%)]\t Loss:0.113818 acc:0.96\n",
      "Train Epoch:13[24576/60000 (41%)]\t Loss:0.124569 acc:0.97\n",
      "Train Epoch:13[25088/60000 (42%)]\t Loss:0.136642 acc:0.96\n",
      "Train Epoch:13[25600/60000 (43%)]\t Loss:0.117048 acc:0.96\n",
      "Train Epoch:13[26112/60000 (44%)]\t Loss:0.138986 acc:0.97\n",
      "Train Epoch:13[26624/60000 (44%)]\t Loss:0.149816 acc:0.95\n",
      "Train Epoch:13[27136/60000 (45%)]\t Loss:0.130876 acc:0.97\n",
      "Train Epoch:13[27648/60000 (46%)]\t Loss:0.103047 acc:0.97\n",
      "Train Epoch:13[28160/60000 (47%)]\t Loss:0.140137 acc:0.96\n",
      "Train Epoch:13[28672/60000 (48%)]\t Loss:0.114298 acc:0.96\n",
      "Train Epoch:13[29184/60000 (49%)]\t Loss:0.101647 acc:0.97\n",
      "Train Epoch:13[29696/60000 (49%)]\t Loss:0.148893 acc:0.95\n",
      "Train Epoch:13[30208/60000 (50%)]\t Loss:0.095083 acc:0.98\n",
      "Train Epoch:13[30720/60000 (51%)]\t Loss:0.142680 acc:0.96\n",
      "Train Epoch:13[31232/60000 (52%)]\t Loss:0.184089 acc:0.95\n",
      "Train Epoch:13[31744/60000 (53%)]\t Loss:0.127022 acc:0.97\n",
      "Train Epoch:13[32256/60000 (54%)]\t Loss:0.173462 acc:0.94\n",
      "Train Epoch:13[32768/60000 (55%)]\t Loss:0.106461 acc:0.98\n",
      "Train Epoch:13[33280/60000 (55%)]\t Loss:0.136858 acc:0.97\n",
      "Train Epoch:13[33792/60000 (56%)]\t Loss:0.070613 acc:0.98\n",
      "Train Epoch:13[34304/60000 (57%)]\t Loss:0.167087 acc:0.96\n",
      "Train Epoch:13[34816/60000 (58%)]\t Loss:0.121706 acc:0.96\n",
      "Train Epoch:13[35328/60000 (59%)]\t Loss:0.104520 acc:0.97\n",
      "Train Epoch:13[35840/60000 (60%)]\t Loss:0.100994 acc:0.96\n",
      "Train Epoch:13[36352/60000 (61%)]\t Loss:0.109525 acc:0.96\n",
      "Train Epoch:13[36864/60000 (61%)]\t Loss:0.147451 acc:0.96\n",
      "Train Epoch:13[37376/60000 (62%)]\t Loss:0.143306 acc:0.96\n",
      "Train Epoch:13[37888/60000 (63%)]\t Loss:0.088669 acc:0.97\n",
      "Train Epoch:13[38400/60000 (64%)]\t Loss:0.088169 acc:0.98\n",
      "Train Epoch:13[38912/60000 (65%)]\t Loss:0.140072 acc:0.95\n",
      "Train Epoch:13[39424/60000 (66%)]\t Loss:0.125206 acc:0.97\n",
      "Train Epoch:13[39936/60000 (67%)]\t Loss:0.109202 acc:0.97\n",
      "Train Epoch:13[40448/60000 (67%)]\t Loss:0.109404 acc:0.96\n",
      "Train Epoch:13[40960/60000 (68%)]\t Loss:0.169725 acc:0.95\n",
      "Train Epoch:13[41472/60000 (69%)]\t Loss:0.113129 acc:0.97\n",
      "Train Epoch:13[41984/60000 (70%)]\t Loss:0.155750 acc:0.94\n",
      "Train Epoch:13[42496/60000 (71%)]\t Loss:0.139288 acc:0.96\n",
      "Train Epoch:13[43008/60000 (72%)]\t Loss:0.104666 acc:0.96\n",
      "Train Epoch:13[43520/60000 (73%)]\t Loss:0.118993 acc:0.97\n",
      "Train Epoch:13[44032/60000 (73%)]\t Loss:0.129984 acc:0.97\n",
      "Train Epoch:13[44544/60000 (74%)]\t Loss:0.116410 acc:0.96\n",
      "Train Epoch:13[45056/60000 (75%)]\t Loss:0.124203 acc:0.96\n",
      "Train Epoch:13[45568/60000 (76%)]\t Loss:0.194570 acc:0.94\n",
      "Train Epoch:13[46080/60000 (77%)]\t Loss:0.177038 acc:0.95\n",
      "Train Epoch:13[46592/60000 (78%)]\t Loss:0.099070 acc:0.97\n",
      "Train Epoch:13[47104/60000 (79%)]\t Loss:0.166498 acc:0.95\n",
      "Train Epoch:13[47616/60000 (79%)]\t Loss:0.110695 acc:0.97\n",
      "Train Epoch:13[48128/60000 (80%)]\t Loss:0.102826 acc:0.96\n",
      "Train Epoch:13[48640/60000 (81%)]\t Loss:0.181833 acc:0.94\n",
      "Train Epoch:13[49152/60000 (82%)]\t Loss:0.161687 acc:0.95\n",
      "Train Epoch:13[49664/60000 (83%)]\t Loss:0.109016 acc:0.97\n",
      "Train Epoch:13[50176/60000 (84%)]\t Loss:0.203391 acc:0.95\n",
      "Train Epoch:13[50688/60000 (84%)]\t Loss:0.090268 acc:0.97\n",
      "Train Epoch:13[51200/60000 (85%)]\t Loss:0.109162 acc:0.96\n",
      "Train Epoch:13[51712/60000 (86%)]\t Loss:0.147010 acc:0.95\n",
      "Train Epoch:13[52224/60000 (87%)]\t Loss:0.093898 acc:0.97\n",
      "Train Epoch:13[52736/60000 (88%)]\t Loss:0.185855 acc:0.96\n",
      "Train Epoch:13[53248/60000 (89%)]\t Loss:0.096344 acc:0.97\n",
      "Train Epoch:13[53760/60000 (90%)]\t Loss:0.134933 acc:0.96\n",
      "Train Epoch:13[54272/60000 (90%)]\t Loss:0.092366 acc:0.97\n",
      "Train Epoch:13[54784/60000 (91%)]\t Loss:0.143501 acc:0.95\n",
      "Train Epoch:13[55296/60000 (92%)]\t Loss:0.141776 acc:0.96\n",
      "Train Epoch:13[55808/60000 (93%)]\t Loss:0.105960 acc:0.96\n",
      "Train Epoch:13[56320/60000 (94%)]\t Loss:0.107802 acc:0.97\n",
      "Train Epoch:13[56832/60000 (95%)]\t Loss:0.081977 acc:0.98\n",
      "Train Epoch:13[57344/60000 (96%)]\t Loss:0.116560 acc:0.97\n",
      "Train Epoch:13[57856/60000 (96%)]\t Loss:0.067840 acc:0.98\n",
      "Train Epoch:13[58368/60000 (97%)]\t Loss:0.067048 acc:0.98\n",
      "Train Epoch:13[58880/60000 (98%)]\t Loss:0.045933 acc:0.99\n",
      "Train Epoch:13[59392/60000 (99%)]\t Loss:0.132531 acc:0.97\n",
      "Train Epoch:13[59904/60000 (100%)]\t Loss:0.215718 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:13 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:13 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:13 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:13 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:13 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:13 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:13 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:13 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:13 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:13 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:13 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:13 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:13 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:13 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:13 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:13 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:13 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:13 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:13 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:13 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:14[0/60000 (0%)]\t Loss:0.137378 acc:0.97\n",
      "Train Epoch:14[512/60000 (1%)]\t Loss:0.149534 acc:0.96\n",
      "Train Epoch:14[1024/60000 (2%)]\t Loss:0.189601 acc:0.95\n",
      "Train Epoch:14[1536/60000 (3%)]\t Loss:0.090710 acc:0.98\n",
      "Train Epoch:14[2048/60000 (3%)]\t Loss:0.078156 acc:0.97\n",
      "Train Epoch:14[2560/60000 (4%)]\t Loss:0.119219 acc:0.98\n",
      "Train Epoch:14[3072/60000 (5%)]\t Loss:0.068316 acc:0.99\n",
      "Train Epoch:14[3584/60000 (6%)]\t Loss:0.087831 acc:0.97\n",
      "Train Epoch:14[4096/60000 (7%)]\t Loss:0.107716 acc:0.97\n",
      "Train Epoch:14[4608/60000 (8%)]\t Loss:0.116448 acc:0.97\n",
      "Train Epoch:14[5120/60000 (9%)]\t Loss:0.104396 acc:0.97\n",
      "Train Epoch:14[5632/60000 (9%)]\t Loss:0.131939 acc:0.96\n",
      "Train Epoch:14[6144/60000 (10%)]\t Loss:0.106991 acc:0.97\n",
      "Train Epoch:14[6656/60000 (11%)]\t Loss:0.144498 acc:0.96\n",
      "Train Epoch:14[7168/60000 (12%)]\t Loss:0.125952 acc:0.96\n",
      "Train Epoch:14[7680/60000 (13%)]\t Loss:0.126432 acc:0.96\n",
      "Train Epoch:14[8192/60000 (14%)]\t Loss:0.143923 acc:0.96\n",
      "Train Epoch:14[8704/60000 (15%)]\t Loss:0.176461 acc:0.95\n",
      "Train Epoch:14[9216/60000 (15%)]\t Loss:0.128250 acc:0.96\n",
      "Train Epoch:14[9728/60000 (16%)]\t Loss:0.109513 acc:0.96\n",
      "Train Epoch:14[10240/60000 (17%)]\t Loss:0.111725 acc:0.96\n",
      "Train Epoch:14[10752/60000 (18%)]\t Loss:0.094694 acc:0.97\n",
      "Train Epoch:14[11264/60000 (19%)]\t Loss:0.111714 acc:0.97\n",
      "Train Epoch:14[11776/60000 (20%)]\t Loss:0.097411 acc:0.97\n",
      "Train Epoch:14[12288/60000 (20%)]\t Loss:0.185388 acc:0.94\n",
      "Train Epoch:14[12800/60000 (21%)]\t Loss:0.110056 acc:0.95\n",
      "Train Epoch:14[13312/60000 (22%)]\t Loss:0.100480 acc:0.97\n",
      "Train Epoch:14[13824/60000 (23%)]\t Loss:0.144035 acc:0.95\n",
      "Train Epoch:14[14336/60000 (24%)]\t Loss:0.128454 acc:0.96\n",
      "Train Epoch:14[14848/60000 (25%)]\t Loss:0.108839 acc:0.96\n",
      "Train Epoch:14[15360/60000 (26%)]\t Loss:0.132267 acc:0.95\n",
      "Train Epoch:14[15872/60000 (26%)]\t Loss:0.103268 acc:0.97\n",
      "Train Epoch:14[16384/60000 (27%)]\t Loss:0.140423 acc:0.96\n",
      "Train Epoch:14[16896/60000 (28%)]\t Loss:0.110897 acc:0.96\n",
      "Train Epoch:14[17408/60000 (29%)]\t Loss:0.135350 acc:0.96\n",
      "Train Epoch:14[17920/60000 (30%)]\t Loss:0.091149 acc:0.97\n",
      "Train Epoch:14[18432/60000 (31%)]\t Loss:0.073697 acc:0.99\n",
      "Train Epoch:14[18944/60000 (32%)]\t Loss:0.106678 acc:0.97\n",
      "Train Epoch:14[19456/60000 (32%)]\t Loss:0.097333 acc:0.97\n",
      "Train Epoch:14[19968/60000 (33%)]\t Loss:0.106810 acc:0.96\n",
      "Train Epoch:14[20480/60000 (34%)]\t Loss:0.214425 acc:0.94\n",
      "Train Epoch:14[20992/60000 (35%)]\t Loss:0.094191 acc:0.97\n",
      "Train Epoch:14[21504/60000 (36%)]\t Loss:0.082138 acc:0.97\n",
      "Train Epoch:14[22016/60000 (37%)]\t Loss:0.102064 acc:0.96\n",
      "Train Epoch:14[22528/60000 (38%)]\t Loss:0.116593 acc:0.96\n",
      "Train Epoch:14[23040/60000 (38%)]\t Loss:0.076887 acc:0.98\n",
      "Train Epoch:14[23552/60000 (39%)]\t Loss:0.135453 acc:0.96\n",
      "Train Epoch:14[24064/60000 (40%)]\t Loss:0.103392 acc:0.96\n",
      "Train Epoch:14[24576/60000 (41%)]\t Loss:0.115979 acc:0.97\n",
      "Train Epoch:14[25088/60000 (42%)]\t Loss:0.128929 acc:0.96\n",
      "Train Epoch:14[25600/60000 (43%)]\t Loss:0.112064 acc:0.96\n",
      "Train Epoch:14[26112/60000 (44%)]\t Loss:0.130681 acc:0.97\n",
      "Train Epoch:14[26624/60000 (44%)]\t Loss:0.141824 acc:0.96\n",
      "Train Epoch:14[27136/60000 (45%)]\t Loss:0.122896 acc:0.97\n",
      "Train Epoch:14[27648/60000 (46%)]\t Loss:0.096562 acc:0.97\n",
      "Train Epoch:14[28160/60000 (47%)]\t Loss:0.131818 acc:0.96\n",
      "Train Epoch:14[28672/60000 (48%)]\t Loss:0.108044 acc:0.96\n",
      "Train Epoch:14[29184/60000 (49%)]\t Loss:0.094090 acc:0.97\n",
      "Train Epoch:14[29696/60000 (49%)]\t Loss:0.140623 acc:0.95\n",
      "Train Epoch:14[30208/60000 (50%)]\t Loss:0.086924 acc:0.98\n",
      "Train Epoch:14[30720/60000 (51%)]\t Loss:0.131566 acc:0.96\n",
      "Train Epoch:14[31232/60000 (52%)]\t Loss:0.168209 acc:0.96\n",
      "Train Epoch:14[31744/60000 (53%)]\t Loss:0.116460 acc:0.97\n",
      "Train Epoch:14[32256/60000 (54%)]\t Loss:0.162661 acc:0.94\n",
      "Train Epoch:14[32768/60000 (55%)]\t Loss:0.099980 acc:0.98\n",
      "Train Epoch:14[33280/60000 (55%)]\t Loss:0.134250 acc:0.97\n",
      "Train Epoch:14[33792/60000 (56%)]\t Loss:0.069392 acc:0.98\n",
      "Train Epoch:14[34304/60000 (57%)]\t Loss:0.161391 acc:0.96\n",
      "Train Epoch:14[34816/60000 (58%)]\t Loss:0.120092 acc:0.96\n",
      "Train Epoch:14[35328/60000 (59%)]\t Loss:0.098673 acc:0.97\n",
      "Train Epoch:14[35840/60000 (60%)]\t Loss:0.092862 acc:0.97\n",
      "Train Epoch:14[36352/60000 (61%)]\t Loss:0.107265 acc:0.97\n",
      "Train Epoch:14[36864/60000 (61%)]\t Loss:0.140814 acc:0.96\n",
      "Train Epoch:14[37376/60000 (62%)]\t Loss:0.134040 acc:0.96\n",
      "Train Epoch:14[37888/60000 (63%)]\t Loss:0.080506 acc:0.97\n",
      "Train Epoch:14[38400/60000 (64%)]\t Loss:0.082049 acc:0.98\n",
      "Train Epoch:14[38912/60000 (65%)]\t Loss:0.136185 acc:0.96\n",
      "Train Epoch:14[39424/60000 (66%)]\t Loss:0.119318 acc:0.96\n",
      "Train Epoch:14[39936/60000 (67%)]\t Loss:0.099035 acc:0.97\n",
      "Train Epoch:14[40448/60000 (67%)]\t Loss:0.102456 acc:0.96\n",
      "Train Epoch:14[40960/60000 (68%)]\t Loss:0.161141 acc:0.95\n",
      "Train Epoch:14[41472/60000 (69%)]\t Loss:0.105316 acc:0.97\n",
      "Train Epoch:14[41984/60000 (70%)]\t Loss:0.152098 acc:0.94\n",
      "Train Epoch:14[42496/60000 (71%)]\t Loss:0.132719 acc:0.96\n",
      "Train Epoch:14[43008/60000 (72%)]\t Loss:0.100256 acc:0.96\n",
      "Train Epoch:14[43520/60000 (73%)]\t Loss:0.112099 acc:0.96\n",
      "Train Epoch:14[44032/60000 (73%)]\t Loss:0.120757 acc:0.96\n",
      "Train Epoch:14[44544/60000 (74%)]\t Loss:0.108637 acc:0.96\n",
      "Train Epoch:14[45056/60000 (75%)]\t Loss:0.114035 acc:0.96\n",
      "Train Epoch:14[45568/60000 (76%)]\t Loss:0.181810 acc:0.94\n",
      "Train Epoch:14[46080/60000 (77%)]\t Loss:0.167587 acc:0.95\n",
      "Train Epoch:14[46592/60000 (78%)]\t Loss:0.093538 acc:0.98\n",
      "Train Epoch:14[47104/60000 (79%)]\t Loss:0.165250 acc:0.95\n",
      "Train Epoch:14[47616/60000 (79%)]\t Loss:0.106378 acc:0.97\n",
      "Train Epoch:14[48128/60000 (80%)]\t Loss:0.096588 acc:0.97\n",
      "Train Epoch:14[48640/60000 (81%)]\t Loss:0.181300 acc:0.94\n",
      "Train Epoch:14[49152/60000 (82%)]\t Loss:0.156101 acc:0.95\n",
      "Train Epoch:14[49664/60000 (83%)]\t Loss:0.100086 acc:0.97\n",
      "Train Epoch:14[50176/60000 (84%)]\t Loss:0.191841 acc:0.95\n",
      "Train Epoch:14[50688/60000 (84%)]\t Loss:0.085251 acc:0.97\n",
      "Train Epoch:14[51200/60000 (85%)]\t Loss:0.103665 acc:0.97\n",
      "Train Epoch:14[51712/60000 (86%)]\t Loss:0.138108 acc:0.96\n",
      "Train Epoch:14[52224/60000 (87%)]\t Loss:0.089734 acc:0.97\n",
      "Train Epoch:14[52736/60000 (88%)]\t Loss:0.176357 acc:0.96\n",
      "Train Epoch:14[53248/60000 (89%)]\t Loss:0.089233 acc:0.97\n",
      "Train Epoch:14[53760/60000 (90%)]\t Loss:0.127017 acc:0.96\n",
      "Train Epoch:14[54272/60000 (90%)]\t Loss:0.087252 acc:0.98\n",
      "Train Epoch:14[54784/60000 (91%)]\t Loss:0.137209 acc:0.95\n",
      "Train Epoch:14[55296/60000 (92%)]\t Loss:0.136588 acc:0.96\n",
      "Train Epoch:14[55808/60000 (93%)]\t Loss:0.103327 acc:0.96\n",
      "Train Epoch:14[56320/60000 (94%)]\t Loss:0.106345 acc:0.97\n",
      "Train Epoch:14[56832/60000 (95%)]\t Loss:0.078381 acc:0.98\n",
      "Train Epoch:14[57344/60000 (96%)]\t Loss:0.112335 acc:0.97\n",
      "Train Epoch:14[57856/60000 (96%)]\t Loss:0.063387 acc:0.98\n",
      "Train Epoch:14[58368/60000 (97%)]\t Loss:0.061283 acc:0.98\n",
      "Train Epoch:14[58880/60000 (98%)]\t Loss:0.041048 acc:0.99\n",
      "Train Epoch:14[59392/60000 (99%)]\t Loss:0.129053 acc:0.97\n",
      "Train Epoch:14[59904/60000 (100%)]\t Loss:0.207297 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:14 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:14 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:14 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:14 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:14 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:14 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:14 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:14 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:14 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:14 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:14 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:14 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:14 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:14 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:14 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:14 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:14 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:14 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:14 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:14 [9728/10000 (97%)]\t acc:0.96\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = SummaryWriter('logs')\n",
    "    # device = torch.device('cuda:0')\n",
    "\n",
    "    # if torch.cuda.is_available():\n",
    "    #     device = torch.device('cuda:0')\n",
    "    # else:\n",
    "    #     device = torch.device('cpu')\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    net = LeNet()  # 实例化网络\n",
    "    # data_input = Variable(torch.randn(16,1,28,28))\n",
    "    # print(net(data_input))\n",
    "    net.to(device) # 将参数送入GPU中\n",
    "\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    cost_fun = nn.CrossEntropyLoss()\n",
    "    # optim\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.95, weight_decay=1e-3)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        # train\n",
    "        train(epoch)\n",
    "        writer.add_scalar('Train/Loss', train_loss[-2].item(), epoch)\n",
    "        writer.add_scalar('Train/Acc', train_acc[-2], epoch)\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # save_state\n",
    "        # ----------------------------------------- #\n",
    "        print('===> Saving models...')\n",
    "        state = {\n",
    "            'state': net.state_dict(),\n",
    "            'epoch': epoch  # 将epoch一并保存\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('./checkpoint')\n",
    "        torch.save(state, path_model + 'Epoch-' + str(epoch) + '-Loss-'+ str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # test\n",
    "        # ----------------------------------------- #\n",
    "        test()\n",
    "    writer.close()\n",
    "\n",
    "    # ----------------------------------------- #\n",
    "    # 加载指定的weights进行预测\n",
    "    # ----------------------------------------- #\n",
    "    # predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneTensor(model_path, file_path, labely):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    img0 = cv2.imread(file_path, 0).astype(np.uint8)\n",
    "    # print(img0.shape)\n",
    "    img0 = cv2.resize(img0, (28,28))\n",
    "    img0 = img0 / 255.\n",
    "    img0 = torch.from_numpy(img0)\n",
    "\n",
    "    img = torch.as_tensor(img0, dtype=torch.float32)\n",
    "    img = img.unsqueeze(0) #在第一维度上增加一个维度，作为通道大小\n",
    "    img = Variable(torch.unsqueeze(img, dim=0).float(),).to(device) #在第一维度上增加一个维度，作为batch size大小\n",
    "    # img = img.permute(0, 3, 1, 2) # 将图像channel提到前面即 [batch size, width, height, channel]-> [batch size, channel, width, height]\n",
    "    img = img.to(device)\n",
    "    print(img.shape)\n",
    "    print('===> Loading weights : ' + model_path)\n",
    "    weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        predy = net(img)\n",
    "        # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "        # predicted, actual = classes[torch.argmax(predy[0])], classes[labely]\n",
    "        # 最终输出的预测值与真实值\n",
    "        # print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n",
    "        np.set_printoptions(suppress = True) #非科学计数法\n",
    "        # predy[0]是网络输出，predy[1]是网络中间层输出，为一个字典\n",
    "        for x, y in predy[1].items():\n",
    "            if x == 'softmax_output':\n",
    "                print(f'predicted: \"{y.cpu().numpy()}\", actual:\"{labely}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "===> Loading weights : ./checkpoint/model_14_5_GPU.pth\n",
      "predicted: \"[[0.00000249 0.00000013 0.00321754 0.00014252 0.9463915  0.04714505\n",
      "  0.00018849 0.00016619 0.00034051 0.0024056 ]]\", actual:\"9\"\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "model_path = './checkpoint/model_14_5_GPU.pth' #  ***为指定加载的权重文件名称\n",
    "# file_path = './test_images/pic_3_57585.png'\n",
    "# labely = 3\n",
    "\n",
    "# file_path = './test_images/pic_2_7140.png'\n",
    "# labely = 2\n",
    "\n",
    "# file_path = './test_images/pic_2_11796.png'\n",
    "# labely = 2\n",
    "\n",
    "# file_path = './test_images/pic_0_15066.png'\n",
    "# labely = 0\n",
    "\n",
    "# file_path = './test_images/pic_4_54348.png'\n",
    "# labely = 4\n",
    "\n",
    "# file_path = './test_images/pic_6_23534.png'\n",
    "# labely = 6\n",
    "\n",
    "# file_path = './test_images/pic_7_39306.png'\n",
    "# labely = 7\n",
    "\n",
    "file_path = './test_images/padpic_9_13429.png'\n",
    "labely = 9\n",
    "# predict()\n",
    "predictOneTensor(model_path, file_path, labely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Linear-7                  [-1, 120]          48,120\n",
      "              ReLU-8                  [-1, 120]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             ReLU-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "          Softmax-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#输出每层网络参数信息\n",
    "def variaes_show():\n",
    "    net = LeNet().to(device)\n",
    "    data_input = Variable(torch.randn(16,1,28,28)).to(device)\n",
    "    print(data_input.size())\n",
    "    net(data_input)\n",
    "    print(summary(net,(1,28,28)))\n",
    "\n",
    "variaes_show()\n",
    "\n",
    "# net = LeNet()\n",
    "# summary(net,(1,28,28),batch_size=16,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初版从模型中获取权重的方法\n",
    "# def load_weight(model_path):\n",
    "        \n",
    "#         print('===> Loading weights : ' + model_path)\n",
    "#         weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "\n",
    "#         print('type: ' + str(type(weight_dict)))\n",
    "#         print('len: ' + str(len(weight_dict)))\n",
    "\n",
    "#         for k in weight_dict.keys():\n",
    "#                 print('key: '+ k)\n",
    "\n",
    "#         # print(weight_dict['state'])\n",
    "#         # print(weight_dict['epoch'])\n",
    "#         print(\"================================\")\n",
    "\n",
    "#         for key,value in weight_dict['state'].items():\n",
    "#                 value_np = value.numpy()\n",
    "#                 if not os.path.isdir('csv'):\n",
    "#                         os.mkdir('./csv')\n",
    "#                 # np.savetxt(\"./csv/%s.csv\" %(key), value_np,  delimiter=\",\")\n",
    "#                 # pd.DataFrame(value_np).to_csv(\"./csv/%s.csv\" %(key))\n",
    "#                 # print(key, value.size())\n",
    "#                 print(key)\n",
    "#                 print('shape: '+ str(value_np.shape))\n",
    "#                 if (value_np.ndim == 4):\n",
    "#                         (n_dim, _, _, _) = value_np.shape\n",
    "#                         value_2d = value_np.reshape(n_dim,-1)\n",
    "#                         np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "#                         print(\"csv: \", value_2d.shape,'\\n')\n",
    "#                 elif (value_np.ndim == 3):\n",
    "#                         ndim, _, _ = value_np.shape\n",
    "#                         value_2d = value_np.reshape(n_dim,-1)\n",
    "#                         np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "#                         print(\"csv: \", value_2d.shape,'\\n')\n",
    "#                 # elif (value_np.ndim == 2):\n",
    "#                 #         ndim, _ = value_np.shape\n",
    "#                 #         value_2d = value_np.reshape(n_dim,-1)\n",
    "#                 #         print(value_2d.shape) \n",
    "#                 else :  \n",
    "#                         value_2d = value_np\n",
    "#                         np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "#                         print(\"csv: \", value_2d.shape,'\\n')             \n",
    "\n",
    "\n",
    "#         print(\"================================\")\n",
    "#         print(type(weight_dict['state']))\n",
    "        \n",
    "\n",
    "# state_path = './checkpoint/model_14.pth'\n",
    "# load_weight(state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Pytorch38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b956c267005580222d4281e5b83de2a0aaf8ff0a6c95725a53fb5f995e2e0f78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
