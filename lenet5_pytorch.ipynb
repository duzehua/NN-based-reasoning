{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "path_model = \"./checkpoint/\"\n",
    "batch_size = 512\n",
    "epochs = 15\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "# sampler = torch.utils.data.SubsetRandomSampler(indices=list(range(2000)))\n",
    "\n",
    "# download mnist dataset\n",
    "dataset_train = torchvision.datasets.MNIST(root='./data/',train=True,download=True,transform=transform)\n",
    "dataset_test = torchvision.datasets.MNIST(root='./data/',train=False,download=True,transform=transform)\n",
    "\n",
    "class_names = dataset_train.classes  # 获取数据集的分类信息 返回一个字典\n",
    "# load dataset\n",
    "data_train = dataloader(dataset=dataset_train,batch_size=batch_size,shuffle=False)\n",
    "data_test = dataloader(dataset=dataset_test,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "print(len(data_train))\n",
    "# for batch_idx,(data,target) in enumerate(data_test):\n",
    "#     print(\"id \",batch_idx, \"data shape\",data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()  # 切换到测试模式\n",
    "    test_correct_num = 0\n",
    "    with torch.no_grad():   # 不更新参数\n",
    "\n",
    "        for batch_idx,(data,target) in enumerate(data_test):\n",
    "            # data = data.to(device)\n",
    "            # target = target.to(device)\n",
    "            output, _ = net(data) # 正向传播得到预测值\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            test_correct_num += torch.sum(pred==target).item()\n",
    "            print(\"Test Epoch:{} [{}/{} ({:.0f}%)]\\t acc:{:.2f}\".format(epoch,batch_idx*batch_size,len(data_test.dataset),\n",
    "                                                 100. * batch_size*batch_idx/len(data_test.dataset),test_correct_num/len(data_test.dataset)))\n",
    "def train(epoch):\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(data_train):\n",
    "        # 清除grad累积值\n",
    "        optimizer.zero_grad()\n",
    "        # 读取dataloader中的数据，前半部分是tensor变量，后半部分是真实label\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward之后得到预测值\n",
    "        output, process_output_ = net(data)\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_layerout(epoch, batch_idx, process_output_)\n",
    "        # 计算loss\n",
    "        loss = cost_fun(output, target)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # 收集一组新的梯度，并使用optimizer.step()将其传播回每个网络参数\n",
    "        optimizer.step()\n",
    "        # 给出loss和acc\n",
    "        train_loss.append(loss)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        correct_num = torch.sum(pred == target).item()\n",
    "        train_acc.append(correct_num / batch_size)\n",
    "        print(\"Train Epoch:{}[{}/{} ({:.0f}%)]\\t Loss:{:.6f} acc:{:.2f}\".format(epoch, batch_idx * batch_size,\n",
    "               len(data_train.dataset),100. * batch_size * batch_idx / len(data_train.dataset), loss.item(),correct_num / batch_size))\n",
    "        \n",
    "        # MNIST一共60000个数据，batch_size为512，一共60000/512 = 118个batch\n",
    "        if (epoch == epochs - 1) & (batch_idx == len(data_train)-1):\n",
    "            save_weight(epoch, batch_idx)\n",
    "\n",
    "def save_layerout(epoch, batch_idx, process_output_):\n",
    "    cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "    # 将网络的过程结果进行保存\n",
    "    col_counter = 1\n",
    "    for key in process_output_.keys():\n",
    "\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = process_output_[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # --\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # --\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名\n",
    "        curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "        # 数据存储\n",
    "        if not os.path.isdir('layeroutput_data'):\n",
    "            os.mkdir('.\\layeroutput_data')\n",
    "        layer_output_result_path = '.\\layeroutput_data'\n",
    "        with open(layer_output_result_path + '\\\\' + curt_csv_file_name + \".csv\", \"a\",\n",
    "                    newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            data = process_output_[key].reshape(-1)\n",
    "            data_np = data.detach().numpy()  # TODO 注意确认是否存在通道问题、此处摒弃梯度信息\n",
    "            writer.writerows([data_np])\n",
    "            # writer.writerows([data_curt] for data_curt in data_np)\n",
    "            csvfile.close()\n",
    "            # --\n",
    "        col_counter += 1\n",
    "\n",
    "def save_weight(epoch, batch_idx):\n",
    "#    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "    cscfphn_str = str(epoch) + '_' + str(batch_idx) + '_'  # curt_step_curt_file_pre_head_name\n",
    "\n",
    "    # 网络参数输出\n",
    "    parm = {}\n",
    "    for name, parameters in net.named_parameters():\n",
    "        # print('网络参数输出')\n",
    "        # print(name, ':', parameters.size())\n",
    "        parm[name] = parameters.detach().numpy()  # 将tensor变量转换为np格式\n",
    "\n",
    "        # TODO 将读取出来的参数进行保存，注意确认是否存在tensor与np之间的转换通道问题\n",
    "        '''\n",
    "        文件名共分8部分：\n",
    "        epoch step index                   number        channel   length  width  value_name\n",
    "        轮数   步数  序号(按参数在网络中的顺序)  变量中数据块个数 变量通道数  变量长   变量宽  变量名称\n",
    "        '''\n",
    "    col_counter = 1\n",
    "    for key in parm.keys():\n",
    "        # 获取变量的尺寸，根据其尺寸定义前导尺寸值\n",
    "        curt_value_shape = parm[key].shape\n",
    "        curt_value_shape_len = len(curt_value_shape)\n",
    "        pre_load_len_name = ''\n",
    "        # -- 定义有信息的前导尺寸\n",
    "        for cvsl_idx in range(curt_value_shape_len):\n",
    "            pre_load_len_name = pre_load_len_name + str(curt_value_shape[cvsl_idx]) + '_'\n",
    "        # -- 将无信息的前导尺寸设置为缺省值\n",
    "        dif_curt_value_shape_len = 4 - curt_value_shape_len\n",
    "        if dif_curt_value_shape_len:\n",
    "            for dcvsl_idx in range(dif_curt_value_shape_len):\n",
    "                pre_load_len_name = '0_' + pre_load_len_name\n",
    "\n",
    "        # 获取文件名\n",
    "        curt_csv_file_name = cscfphn_str + str(col_counter) + '_' + pre_load_len_name + key\n",
    "\n",
    "        # 数据存储\n",
    "        # 创建文件对象\n",
    "        if not os.path.isdir('layer_para'):\n",
    "            os.mkdir('.\\layer_para')\n",
    "        layer_result_path = '.\\layer_para'\n",
    "        with open(layer_result_path + '\\\\' + curt_csv_file_name + \".csv\", \"a\", newline='') as csvfile:\n",
    "            # 基于文件对象构建 csv写入对象\n",
    "            writer = csv.writer(csvfile, delimiter=' ')\n",
    "            data = parm[key].reshape(-1)\n",
    "            # writer.writerows([data_curt] for data_curt in data)\n",
    "            writer.writerows([data])\n",
    "            csvfile.close()\n",
    "        # --\n",
    "        col_counter += 1 \n",
    "    \n",
    "\n",
    "def save_state():\n",
    "    print('===> Saving weights...')\n",
    "    state = {\n",
    "        'state': net.state_dict(),\n",
    "        'epoch': epoch  # 将epoch一并保存\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('./checkpoint')\n",
    "    torch.save(state, path_model + 'Epoch:' + str(epoch) + ' Loss:' + str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "def predict():\n",
    "    state_path = './checkpoint/model_14.pth' #  ***为指定加载的权重文件名称\n",
    "    print('===> Loading weights : ' + state_path)\n",
    "    weight_dict = torch.load(state_path)  # 加载最后训练出的权重\n",
    "    net.load_state_dict(weight_dict['state'])\n",
    "    # 从测试集中选取一个batch做预测\n",
    "    # pred_test = enumerate(data_test)\n",
    "    # batch_idx, (pred_data, pred_gt) = next(pred_test)\n",
    "    # output = net(pred_data)\n",
    "    # print(\"data: \", output.data)\n",
    "    # maxdata, pred = torch.max(output.data, 1) # 得到预测值,返回每一行的最大值，且返回索引\n",
    "    # print(\"maxdata: \", maxdata)\n",
    "    # print(\"ground truth: \",pred_gt)\n",
    "    # print(\"predict value: \",pred)\n",
    "    # 获取预测结果\n",
    "    classes = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    # 把tensor转成Image， 方便可视化\n",
    "    show = ToPILImage()\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "    net.eval()\n",
    "    for i in np.random.randint(0,20,size=10):\n",
    "        x, y = dataset_test[i][0], dataset_test[i][1]\n",
    "        # tensor格式数据可视化\n",
    "        show(x).show()\n",
    "        # 扩展张量维度为4维\n",
    "        x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=False).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            # 得到预测类别中最高的那一类，再把最高的这一类对应classes中的哪一类标签\n",
    "            predicted, actual = classes[torch.argmax(pred[0])], classes[y]\n",
    "            # 最终输出的预测值与真实值\n",
    "            print(f'predicted: \"{predicted}\", actual:\"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "class LeNet(nn.Module): \t\t\t\t\t# 继承于nn.Module这个父类\n",
    "    def __init__(self):\t\t\t\t\t\t# 初始化网络结构\n",
    "        super(LeNet, self).__init__()    \t# 多继承需用到super函数\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),  # 输出为6*28*28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为6*14*14\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 输出为16*10*10\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 输出为16*5*5\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # 正向传播过程\n",
    "        # x = self.block_1(x)\n",
    "        # x = x.view(-1,16*5*5)\n",
    "        # x = self.block_2(x)\n",
    "        block1_conv1_out = self.block_1[0](x)\n",
    "        block1_relu1_out = self.block_1[1](block1_conv1_out)\n",
    "        block1_maxpo1_out = self.block_1[2](block1_relu1_out)\n",
    "        block1_conv2_out = self.block_1[3](block1_maxpo1_out)\n",
    "        block1_relu2_out = self.block_1[4](block1_conv2_out)\n",
    "        block1_maxpo2_out = self.block_1[5](block1_relu2_out)\n",
    "\n",
    "        block1_maxpo2_out = block1_maxpo2_out.view(-1,16*5*5)\n",
    "\n",
    "        block2_fc1_out = self.block_2[0](block1_maxpo2_out)\n",
    "        block2_relu1_out = self.block_2[1](block2_fc1_out)\n",
    "        block2_fc2_out = self.block_2[2](block2_relu1_out)\n",
    "        block2_relu2_out = self.block_2[3](block2_fc2_out)\n",
    "        block2_fc3_out = self.block_2[4](block2_relu2_out)\n",
    "\n",
    "        softmax_output =  self.block_2[5](block2_fc3_out)\n",
    "\n",
    "        process_output = {'block1_conv1_out': block1_conv1_out,\n",
    "                          'block1_relu1_out': block1_relu1_out,\n",
    "                          'block1_maxpo1_out': block1_maxpo1_out,\n",
    "                          'block1_conv2_out': block1_conv2_out,\n",
    "                          'block1_relu2_out': block1_relu2_out,\n",
    "                          'block1_maxpo2_out': block1_maxpo2_out,\n",
    "\n",
    "                          'block2_fc1_out': block2_fc1_out,\n",
    "                          'block2_relu1_out': block2_relu1_out,\n",
    "                          'block2_fc2_out': block2_fc2_out,\n",
    "                          'block2_relu2_out': block2_relu2_out,\n",
    "                          'block2_fc3_out': block2_fc3_out,\n",
    "                          'softmax_output': softmax_output\n",
    "                        }\n",
    "\n",
    "        return block2_fc3_out, process_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0[0/60000 (0%)]\t Loss:2.330160 acc:0.13\n",
      "Train Epoch:0[512/60000 (1%)]\t Loss:2.344574 acc:0.10\n",
      "Train Epoch:0[1024/60000 (2%)]\t Loss:2.332537 acc:0.14\n",
      "Train Epoch:0[1536/60000 (3%)]\t Loss:2.319909 acc:0.13\n",
      "Train Epoch:0[2048/60000 (3%)]\t Loss:2.338782 acc:0.09\n",
      "Train Epoch:0[2560/60000 (4%)]\t Loss:2.326663 acc:0.12\n",
      "Train Epoch:0[3072/60000 (5%)]\t Loss:2.314810 acc:0.13\n",
      "Train Epoch:0[3584/60000 (6%)]\t Loss:2.321602 acc:0.14\n",
      "Train Epoch:0[4096/60000 (7%)]\t Loss:2.335610 acc:0.10\n",
      "Train Epoch:0[4608/60000 (8%)]\t Loss:2.334769 acc:0.12\n",
      "Train Epoch:0[5120/60000 (9%)]\t Loss:2.314288 acc:0.13\n",
      "Train Epoch:0[5632/60000 (9%)]\t Loss:2.305368 acc:0.14\n",
      "Train Epoch:0[6144/60000 (10%)]\t Loss:2.312869 acc:0.14\n",
      "Train Epoch:0[6656/60000 (11%)]\t Loss:2.323741 acc:0.12\n",
      "Train Epoch:0[7168/60000 (12%)]\t Loss:2.318835 acc:0.14\n",
      "Train Epoch:0[7680/60000 (13%)]\t Loss:2.315438 acc:0.14\n",
      "Train Epoch:0[8192/60000 (14%)]\t Loss:2.304026 acc:0.15\n",
      "Train Epoch:0[8704/60000 (15%)]\t Loss:2.308032 acc:0.11\n",
      "Train Epoch:0[9216/60000 (15%)]\t Loss:2.314738 acc:0.12\n",
      "Train Epoch:0[9728/60000 (16%)]\t Loss:2.294935 acc:0.19\n",
      "Train Epoch:0[10240/60000 (17%)]\t Loss:2.302626 acc:0.15\n",
      "Train Epoch:0[10752/60000 (18%)]\t Loss:2.286701 acc:0.17\n",
      "Train Epoch:0[11264/60000 (19%)]\t Loss:2.301255 acc:0.15\n",
      "Train Epoch:0[11776/60000 (20%)]\t Loss:2.289958 acc:0.16\n",
      "Train Epoch:0[12288/60000 (20%)]\t Loss:2.300585 acc:0.13\n",
      "Train Epoch:0[12800/60000 (21%)]\t Loss:2.287170 acc:0.15\n",
      "Train Epoch:0[13312/60000 (22%)]\t Loss:2.291782 acc:0.16\n",
      "Train Epoch:0[13824/60000 (23%)]\t Loss:2.293954 acc:0.15\n",
      "Train Epoch:0[14336/60000 (24%)]\t Loss:2.293627 acc:0.15\n",
      "Train Epoch:0[14848/60000 (25%)]\t Loss:2.284467 acc:0.17\n",
      "Train Epoch:0[15360/60000 (26%)]\t Loss:2.280142 acc:0.16\n",
      "Train Epoch:0[15872/60000 (26%)]\t Loss:2.290763 acc:0.16\n",
      "Train Epoch:0[16384/60000 (27%)]\t Loss:2.272584 acc:0.19\n",
      "Train Epoch:0[16896/60000 (28%)]\t Loss:2.281955 acc:0.15\n",
      "Train Epoch:0[17408/60000 (29%)]\t Loss:2.283736 acc:0.17\n",
      "Train Epoch:0[17920/60000 (30%)]\t Loss:2.269661 acc:0.18\n",
      "Train Epoch:0[18432/60000 (31%)]\t Loss:2.272777 acc:0.19\n",
      "Train Epoch:0[18944/60000 (32%)]\t Loss:2.274885 acc:0.16\n",
      "Train Epoch:0[19456/60000 (32%)]\t Loss:2.271349 acc:0.19\n",
      "Train Epoch:0[19968/60000 (33%)]\t Loss:2.275136 acc:0.18\n",
      "Train Epoch:0[20480/60000 (34%)]\t Loss:2.252542 acc:0.20\n",
      "Train Epoch:0[20992/60000 (35%)]\t Loss:2.268045 acc:0.19\n",
      "Train Epoch:0[21504/60000 (36%)]\t Loss:2.253391 acc:0.20\n",
      "Train Epoch:0[22016/60000 (37%)]\t Loss:2.259981 acc:0.22\n",
      "Train Epoch:0[22528/60000 (38%)]\t Loss:2.267017 acc:0.17\n",
      "Train Epoch:0[23040/60000 (38%)]\t Loss:2.266667 acc:0.16\n",
      "Train Epoch:0[23552/60000 (39%)]\t Loss:2.257283 acc:0.21\n",
      "Train Epoch:0[24064/60000 (40%)]\t Loss:2.253955 acc:0.21\n",
      "Train Epoch:0[24576/60000 (41%)]\t Loss:2.253973 acc:0.22\n",
      "Train Epoch:0[25088/60000 (42%)]\t Loss:2.251337 acc:0.21\n",
      "Train Epoch:0[25600/60000 (43%)]\t Loss:2.258302 acc:0.19\n",
      "Train Epoch:0[26112/60000 (44%)]\t Loss:2.248186 acc:0.25\n",
      "Train Epoch:0[26624/60000 (44%)]\t Loss:2.249657 acc:0.21\n",
      "Train Epoch:0[27136/60000 (45%)]\t Loss:2.251485 acc:0.25\n",
      "Train Epoch:0[27648/60000 (46%)]\t Loss:2.231701 acc:0.24\n",
      "Train Epoch:0[28160/60000 (47%)]\t Loss:2.233507 acc:0.24\n",
      "Train Epoch:0[28672/60000 (48%)]\t Loss:2.235555 acc:0.23\n",
      "Train Epoch:0[29184/60000 (49%)]\t Loss:2.234627 acc:0.22\n",
      "Train Epoch:0[29696/60000 (49%)]\t Loss:2.241034 acc:0.22\n",
      "Train Epoch:0[30208/60000 (50%)]\t Loss:2.238678 acc:0.26\n",
      "Train Epoch:0[30720/60000 (51%)]\t Loss:2.229838 acc:0.27\n",
      "Train Epoch:0[31232/60000 (52%)]\t Loss:2.233241 acc:0.25\n",
      "Train Epoch:0[31744/60000 (53%)]\t Loss:2.231517 acc:0.24\n",
      "Train Epoch:0[32256/60000 (54%)]\t Loss:2.231696 acc:0.26\n",
      "Train Epoch:0[32768/60000 (55%)]\t Loss:2.211521 acc:0.30\n",
      "Train Epoch:0[33280/60000 (55%)]\t Loss:2.215809 acc:0.29\n",
      "Train Epoch:0[33792/60000 (56%)]\t Loss:2.210601 acc:0.27\n",
      "Train Epoch:0[34304/60000 (57%)]\t Loss:2.210477 acc:0.27\n",
      "Train Epoch:0[34816/60000 (58%)]\t Loss:2.213786 acc:0.26\n",
      "Train Epoch:0[35328/60000 (59%)]\t Loss:2.206111 acc:0.27\n",
      "Train Epoch:0[35840/60000 (60%)]\t Loss:2.199841 acc:0.28\n",
      "Train Epoch:0[36352/60000 (61%)]\t Loss:2.207996 acc:0.23\n",
      "Train Epoch:0[36864/60000 (61%)]\t Loss:2.185120 acc:0.30\n",
      "Train Epoch:0[37376/60000 (62%)]\t Loss:2.201147 acc:0.29\n",
      "Train Epoch:0[37888/60000 (63%)]\t Loss:2.185165 acc:0.29\n",
      "Train Epoch:0[38400/60000 (64%)]\t Loss:2.197576 acc:0.26\n",
      "Train Epoch:0[38912/60000 (65%)]\t Loss:2.183630 acc:0.27\n",
      "Train Epoch:0[39424/60000 (66%)]\t Loss:2.178266 acc:0.29\n",
      "Train Epoch:0[39936/60000 (67%)]\t Loss:2.173565 acc:0.29\n",
      "Train Epoch:0[40448/60000 (67%)]\t Loss:2.172239 acc:0.30\n",
      "Train Epoch:0[40960/60000 (68%)]\t Loss:2.193538 acc:0.28\n",
      "Train Epoch:0[41472/60000 (69%)]\t Loss:2.180334 acc:0.27\n",
      "Train Epoch:0[41984/60000 (70%)]\t Loss:2.166930 acc:0.33\n",
      "Train Epoch:0[42496/60000 (71%)]\t Loss:2.158855 acc:0.30\n",
      "Train Epoch:0[43008/60000 (72%)]\t Loss:2.148386 acc:0.34\n",
      "Train Epoch:0[43520/60000 (73%)]\t Loss:2.149661 acc:0.33\n",
      "Train Epoch:0[44032/60000 (73%)]\t Loss:2.150830 acc:0.32\n",
      "Train Epoch:0[44544/60000 (74%)]\t Loss:2.154473 acc:0.31\n",
      "Train Epoch:0[45056/60000 (75%)]\t Loss:2.139656 acc:0.36\n",
      "Train Epoch:0[45568/60000 (76%)]\t Loss:2.136127 acc:0.35\n",
      "Train Epoch:0[46080/60000 (77%)]\t Loss:2.123951 acc:0.36\n",
      "Train Epoch:0[46592/60000 (78%)]\t Loss:2.118446 acc:0.36\n",
      "Train Epoch:0[47104/60000 (79%)]\t Loss:2.124383 acc:0.33\n",
      "Train Epoch:0[47616/60000 (79%)]\t Loss:2.107113 acc:0.35\n",
      "Train Epoch:0[48128/60000 (80%)]\t Loss:2.087740 acc:0.37\n",
      "Train Epoch:0[48640/60000 (81%)]\t Loss:2.099327 acc:0.36\n",
      "Train Epoch:0[49152/60000 (82%)]\t Loss:2.100780 acc:0.39\n",
      "Train Epoch:0[49664/60000 (83%)]\t Loss:2.109210 acc:0.38\n",
      "Train Epoch:0[50176/60000 (84%)]\t Loss:2.085223 acc:0.40\n",
      "Train Epoch:0[50688/60000 (84%)]\t Loss:2.067188 acc:0.43\n",
      "Train Epoch:0[51200/60000 (85%)]\t Loss:2.075215 acc:0.40\n",
      "Train Epoch:0[51712/60000 (86%)]\t Loss:2.079318 acc:0.39\n",
      "Train Epoch:0[52224/60000 (87%)]\t Loss:2.026893 acc:0.44\n",
      "Train Epoch:0[52736/60000 (88%)]\t Loss:2.047712 acc:0.42\n",
      "Train Epoch:0[53248/60000 (89%)]\t Loss:2.012476 acc:0.50\n",
      "Train Epoch:0[53760/60000 (90%)]\t Loss:2.031205 acc:0.47\n",
      "Train Epoch:0[54272/60000 (90%)]\t Loss:2.004736 acc:0.49\n",
      "Train Epoch:0[54784/60000 (91%)]\t Loss:2.002591 acc:0.49\n",
      "Train Epoch:0[55296/60000 (92%)]\t Loss:1.987371 acc:0.47\n",
      "Train Epoch:0[55808/60000 (93%)]\t Loss:1.982876 acc:0.51\n",
      "Train Epoch:0[56320/60000 (94%)]\t Loss:1.995844 acc:0.49\n",
      "Train Epoch:0[56832/60000 (95%)]\t Loss:1.988413 acc:0.50\n",
      "Train Epoch:0[57344/60000 (96%)]\t Loss:1.953387 acc:0.50\n",
      "Train Epoch:0[57856/60000 (96%)]\t Loss:1.929751 acc:0.54\n",
      "Train Epoch:0[58368/60000 (97%)]\t Loss:1.918101 acc:0.54\n",
      "Train Epoch:0[58880/60000 (98%)]\t Loss:1.886464 acc:0.55\n",
      "Train Epoch:0[59392/60000 (99%)]\t Loss:1.867565 acc:0.57\n",
      "Train Epoch:0[59904/60000 (100%)]\t Loss:1.969627 acc:0.11\n",
      "===> Saving models...\n",
      "Test Epoch:0 [0/10000 (0%)]\t acc:0.03\n",
      "Test Epoch:0 [512/10000 (5%)]\t acc:0.06\n",
      "Test Epoch:0 [1024/10000 (10%)]\t acc:0.09\n",
      "Test Epoch:0 [1536/10000 (15%)]\t acc:0.12\n",
      "Test Epoch:0 [2048/10000 (20%)]\t acc:0.14\n",
      "Test Epoch:0 [2560/10000 (26%)]\t acc:0.17\n",
      "Test Epoch:0 [3072/10000 (31%)]\t acc:0.20\n",
      "Test Epoch:0 [3584/10000 (36%)]\t acc:0.23\n",
      "Test Epoch:0 [4096/10000 (41%)]\t acc:0.26\n",
      "Test Epoch:0 [4608/10000 (46%)]\t acc:0.29\n",
      "Test Epoch:0 [5120/10000 (51%)]\t acc:0.32\n",
      "Test Epoch:0 [5632/10000 (56%)]\t acc:0.34\n",
      "Test Epoch:0 [6144/10000 (61%)]\t acc:0.37\n",
      "Test Epoch:0 [6656/10000 (67%)]\t acc:0.40\n",
      "Test Epoch:0 [7168/10000 (72%)]\t acc:0.43\n",
      "Test Epoch:0 [7680/10000 (77%)]\t acc:0.46\n",
      "Test Epoch:0 [8192/10000 (82%)]\t acc:0.48\n",
      "Test Epoch:0 [8704/10000 (87%)]\t acc:0.51\n",
      "Test Epoch:0 [9216/10000 (92%)]\t acc:0.54\n",
      "Test Epoch:0 [9728/10000 (97%)]\t acc:0.55\n",
      "Train Epoch:1[0/60000 (0%)]\t Loss:1.867176 acc:0.59\n",
      "Train Epoch:1[512/60000 (1%)]\t Loss:1.889752 acc:0.54\n",
      "Train Epoch:1[1024/60000 (2%)]\t Loss:1.883236 acc:0.56\n",
      "Train Epoch:1[1536/60000 (3%)]\t Loss:1.792792 acc:0.62\n",
      "Train Epoch:1[2048/60000 (3%)]\t Loss:1.800321 acc:0.62\n",
      "Train Epoch:1[2560/60000 (4%)]\t Loss:1.776026 acc:0.63\n",
      "Train Epoch:1[3072/60000 (5%)]\t Loss:1.792664 acc:0.61\n",
      "Train Epoch:1[3584/60000 (6%)]\t Loss:1.749271 acc:0.57\n",
      "Train Epoch:1[4096/60000 (7%)]\t Loss:1.725566 acc:0.61\n",
      "Train Epoch:1[4608/60000 (8%)]\t Loss:1.738133 acc:0.56\n",
      "Train Epoch:1[5120/60000 (9%)]\t Loss:1.672654 acc:0.66\n",
      "Train Epoch:1[5632/60000 (9%)]\t Loss:1.687642 acc:0.63\n",
      "Train Epoch:1[6144/60000 (10%)]\t Loss:1.641707 acc:0.67\n",
      "Train Epoch:1[6656/60000 (11%)]\t Loss:1.691735 acc:0.60\n",
      "Train Epoch:1[7168/60000 (12%)]\t Loss:1.723758 acc:0.59\n",
      "Train Epoch:1[7680/60000 (13%)]\t Loss:1.575713 acc:0.64\n",
      "Train Epoch:1[8192/60000 (14%)]\t Loss:1.616467 acc:0.62\n",
      "Train Epoch:1[8704/60000 (15%)]\t Loss:1.544241 acc:0.67\n",
      "Train Epoch:1[9216/60000 (15%)]\t Loss:1.524688 acc:0.67\n",
      "Train Epoch:1[9728/60000 (16%)]\t Loss:1.484055 acc:0.70\n",
      "Train Epoch:1[10240/60000 (17%)]\t Loss:1.449142 acc:0.68\n",
      "Train Epoch:1[10752/60000 (18%)]\t Loss:1.405219 acc:0.68\n",
      "Train Epoch:1[11264/60000 (19%)]\t Loss:1.439340 acc:0.66\n",
      "Train Epoch:1[11776/60000 (20%)]\t Loss:1.441516 acc:0.67\n",
      "Train Epoch:1[12288/60000 (20%)]\t Loss:1.471432 acc:0.63\n",
      "Train Epoch:1[12800/60000 (21%)]\t Loss:1.411033 acc:0.65\n",
      "Train Epoch:1[13312/60000 (22%)]\t Loss:1.335972 acc:0.69\n",
      "Train Epoch:1[13824/60000 (23%)]\t Loss:1.393626 acc:0.63\n",
      "Train Epoch:1[14336/60000 (24%)]\t Loss:1.471622 acc:0.60\n",
      "Train Epoch:1[14848/60000 (25%)]\t Loss:1.252478 acc:0.70\n",
      "Train Epoch:1[15360/60000 (26%)]\t Loss:1.240032 acc:0.66\n",
      "Train Epoch:1[15872/60000 (26%)]\t Loss:1.283548 acc:0.66\n",
      "Train Epoch:1[16384/60000 (27%)]\t Loss:1.227818 acc:0.68\n",
      "Train Epoch:1[16896/60000 (28%)]\t Loss:1.244573 acc:0.68\n",
      "Train Epoch:1[17408/60000 (29%)]\t Loss:1.255937 acc:0.67\n",
      "Train Epoch:1[17920/60000 (30%)]\t Loss:1.092764 acc:0.77\n",
      "Train Epoch:1[18432/60000 (31%)]\t Loss:1.132434 acc:0.71\n",
      "Train Epoch:1[18944/60000 (32%)]\t Loss:1.104229 acc:0.71\n",
      "Train Epoch:1[19456/60000 (32%)]\t Loss:0.990650 acc:0.77\n",
      "Train Epoch:1[19968/60000 (33%)]\t Loss:1.100234 acc:0.71\n",
      "Train Epoch:1[20480/60000 (34%)]\t Loss:1.023842 acc:0.69\n",
      "Train Epoch:1[20992/60000 (35%)]\t Loss:1.003626 acc:0.73\n",
      "Train Epoch:1[21504/60000 (36%)]\t Loss:0.882178 acc:0.79\n",
      "Train Epoch:1[22016/60000 (37%)]\t Loss:1.061365 acc:0.68\n",
      "Train Epoch:1[22528/60000 (38%)]\t Loss:0.934670 acc:0.73\n",
      "Train Epoch:1[23040/60000 (38%)]\t Loss:0.914216 acc:0.73\n",
      "Train Epoch:1[23552/60000 (39%)]\t Loss:0.945635 acc:0.75\n",
      "Train Epoch:1[24064/60000 (40%)]\t Loss:0.889677 acc:0.75\n",
      "Train Epoch:1[24576/60000 (41%)]\t Loss:0.887974 acc:0.73\n",
      "Train Epoch:1[25088/60000 (42%)]\t Loss:0.824496 acc:0.74\n",
      "Train Epoch:1[25600/60000 (43%)]\t Loss:0.772798 acc:0.79\n",
      "Train Epoch:1[26112/60000 (44%)]\t Loss:0.856683 acc:0.77\n",
      "Train Epoch:1[26624/60000 (44%)]\t Loss:0.855735 acc:0.76\n",
      "Train Epoch:1[27136/60000 (45%)]\t Loss:0.833784 acc:0.77\n",
      "Train Epoch:1[27648/60000 (46%)]\t Loss:0.688664 acc:0.79\n",
      "Train Epoch:1[28160/60000 (47%)]\t Loss:0.754291 acc:0.79\n",
      "Train Epoch:1[28672/60000 (48%)]\t Loss:0.747362 acc:0.78\n",
      "Train Epoch:1[29184/60000 (49%)]\t Loss:0.719913 acc:0.80\n",
      "Train Epoch:1[29696/60000 (49%)]\t Loss:0.941406 acc:0.71\n",
      "Train Epoch:1[30208/60000 (50%)]\t Loss:0.819405 acc:0.74\n",
      "Train Epoch:1[30720/60000 (51%)]\t Loss:0.734564 acc:0.76\n",
      "Train Epoch:1[31232/60000 (52%)]\t Loss:0.850960 acc:0.74\n",
      "Train Epoch:1[31744/60000 (53%)]\t Loss:0.747999 acc:0.77\n",
      "Train Epoch:1[32256/60000 (54%)]\t Loss:0.822714 acc:0.75\n",
      "Train Epoch:1[32768/60000 (55%)]\t Loss:0.708748 acc:0.79\n",
      "Train Epoch:1[33280/60000 (55%)]\t Loss:0.666801 acc:0.81\n",
      "Train Epoch:1[33792/60000 (56%)]\t Loss:0.517093 acc:0.84\n",
      "Train Epoch:1[34304/60000 (57%)]\t Loss:0.649435 acc:0.79\n",
      "Train Epoch:1[34816/60000 (58%)]\t Loss:0.653583 acc:0.80\n",
      "Train Epoch:1[35328/60000 (59%)]\t Loss:0.633367 acc:0.81\n",
      "Train Epoch:1[35840/60000 (60%)]\t Loss:0.588905 acc:0.82\n",
      "Train Epoch:1[36352/60000 (61%)]\t Loss:0.601525 acc:0.80\n",
      "Train Epoch:1[36864/60000 (61%)]\t Loss:0.649028 acc:0.80\n",
      "Train Epoch:1[37376/60000 (62%)]\t Loss:0.678463 acc:0.76\n",
      "Train Epoch:1[37888/60000 (63%)]\t Loss:0.601407 acc:0.81\n",
      "Train Epoch:1[38400/60000 (64%)]\t Loss:0.561151 acc:0.81\n",
      "Train Epoch:1[38912/60000 (65%)]\t Loss:0.559225 acc:0.82\n",
      "Train Epoch:1[39424/60000 (66%)]\t Loss:0.675480 acc:0.78\n",
      "Train Epoch:1[39936/60000 (67%)]\t Loss:0.524715 acc:0.81\n",
      "Train Epoch:1[40448/60000 (67%)]\t Loss:0.520931 acc:0.85\n",
      "Train Epoch:1[40960/60000 (68%)]\t Loss:0.673182 acc:0.78\n",
      "Train Epoch:1[41472/60000 (69%)]\t Loss:0.572906 acc:0.83\n",
      "Train Epoch:1[41984/60000 (70%)]\t Loss:0.763824 acc:0.76\n",
      "Train Epoch:1[42496/60000 (71%)]\t Loss:0.615967 acc:0.82\n",
      "Train Epoch:1[43008/60000 (72%)]\t Loss:0.499528 acc:0.85\n",
      "Train Epoch:1[43520/60000 (73%)]\t Loss:0.518420 acc:0.83\n",
      "Train Epoch:1[44032/60000 (73%)]\t Loss:0.657598 acc:0.80\n",
      "Train Epoch:1[44544/60000 (74%)]\t Loss:0.536252 acc:0.83\n",
      "Train Epoch:1[45056/60000 (75%)]\t Loss:0.533024 acc:0.84\n",
      "Train Epoch:1[45568/60000 (76%)]\t Loss:0.537306 acc:0.84\n",
      "Train Epoch:1[46080/60000 (77%)]\t Loss:0.546494 acc:0.82\n",
      "Train Epoch:1[46592/60000 (78%)]\t Loss:0.488756 acc:0.85\n",
      "Train Epoch:1[47104/60000 (79%)]\t Loss:0.536262 acc:0.84\n",
      "Train Epoch:1[47616/60000 (79%)]\t Loss:0.503728 acc:0.85\n",
      "Train Epoch:1[48128/60000 (80%)]\t Loss:0.460621 acc:0.85\n",
      "Train Epoch:1[48640/60000 (81%)]\t Loss:0.563054 acc:0.82\n",
      "Train Epoch:1[49152/60000 (82%)]\t Loss:0.599182 acc:0.82\n",
      "Train Epoch:1[49664/60000 (83%)]\t Loss:0.568863 acc:0.80\n",
      "Train Epoch:1[50176/60000 (84%)]\t Loss:0.616136 acc:0.81\n",
      "Train Epoch:1[50688/60000 (84%)]\t Loss:0.453916 acc:0.85\n",
      "Train Epoch:1[51200/60000 (85%)]\t Loss:0.453350 acc:0.86\n",
      "Train Epoch:1[51712/60000 (86%)]\t Loss:0.586991 acc:0.82\n",
      "Train Epoch:1[52224/60000 (87%)]\t Loss:0.448053 acc:0.88\n",
      "Train Epoch:1[52736/60000 (88%)]\t Loss:0.687023 acc:0.80\n",
      "Train Epoch:1[53248/60000 (89%)]\t Loss:0.434890 acc:0.87\n",
      "Train Epoch:1[53760/60000 (90%)]\t Loss:0.470765 acc:0.84\n",
      "Train Epoch:1[54272/60000 (90%)]\t Loss:0.432977 acc:0.87\n",
      "Train Epoch:1[54784/60000 (91%)]\t Loss:0.488945 acc:0.84\n",
      "Train Epoch:1[55296/60000 (92%)]\t Loss:0.451895 acc:0.87\n",
      "Train Epoch:1[55808/60000 (93%)]\t Loss:0.406259 acc:0.87\n",
      "Train Epoch:1[56320/60000 (94%)]\t Loss:0.418691 acc:0.86\n",
      "Train Epoch:1[56832/60000 (95%)]\t Loss:0.519757 acc:0.82\n",
      "Train Epoch:1[57344/60000 (96%)]\t Loss:0.468636 acc:0.86\n",
      "Train Epoch:1[57856/60000 (96%)]\t Loss:0.333123 acc:0.91\n",
      "Train Epoch:1[58368/60000 (97%)]\t Loss:0.364645 acc:0.91\n",
      "Train Epoch:1[58880/60000 (98%)]\t Loss:0.351311 acc:0.90\n",
      "Train Epoch:1[59392/60000 (99%)]\t Loss:0.368247 acc:0.90\n",
      "Train Epoch:1[59904/60000 (100%)]\t Loss:0.565616 acc:0.15\n",
      "===> Saving models...\n",
      "Test Epoch:1 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:1 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:1 [1024/10000 (10%)]\t acc:0.13\n",
      "Test Epoch:1 [1536/10000 (15%)]\t acc:0.18\n",
      "Test Epoch:1 [2048/10000 (20%)]\t acc:0.22\n",
      "Test Epoch:1 [2560/10000 (26%)]\t acc:0.26\n",
      "Test Epoch:1 [3072/10000 (31%)]\t acc:0.31\n",
      "Test Epoch:1 [3584/10000 (36%)]\t acc:0.35\n",
      "Test Epoch:1 [4096/10000 (41%)]\t acc:0.40\n",
      "Test Epoch:1 [4608/10000 (46%)]\t acc:0.44\n",
      "Test Epoch:1 [5120/10000 (51%)]\t acc:0.49\n",
      "Test Epoch:1 [5632/10000 (56%)]\t acc:0.53\n",
      "Test Epoch:1 [6144/10000 (61%)]\t acc:0.57\n",
      "Test Epoch:1 [6656/10000 (67%)]\t acc:0.62\n",
      "Test Epoch:1 [7168/10000 (72%)]\t acc:0.66\n",
      "Test Epoch:1 [7680/10000 (77%)]\t acc:0.71\n",
      "Test Epoch:1 [8192/10000 (82%)]\t acc:0.75\n",
      "Test Epoch:1 [8704/10000 (87%)]\t acc:0.79\n",
      "Test Epoch:1 [9216/10000 (92%)]\t acc:0.83\n",
      "Test Epoch:1 [9728/10000 (97%)]\t acc:0.86\n",
      "Train Epoch:2[0/60000 (0%)]\t Loss:0.455526 acc:0.86\n",
      "Train Epoch:2[512/60000 (1%)]\t Loss:0.515406 acc:0.84\n",
      "Train Epoch:2[1024/60000 (2%)]\t Loss:0.557065 acc:0.85\n",
      "Train Epoch:2[1536/60000 (3%)]\t Loss:0.373275 acc:0.90\n",
      "Train Epoch:2[2048/60000 (3%)]\t Loss:0.409612 acc:0.88\n",
      "Train Epoch:2[2560/60000 (4%)]\t Loss:0.452837 acc:0.84\n",
      "Train Epoch:2[3072/60000 (5%)]\t Loss:0.443450 acc:0.85\n",
      "Train Epoch:2[3584/60000 (6%)]\t Loss:0.451251 acc:0.84\n",
      "Train Epoch:2[4096/60000 (7%)]\t Loss:0.408488 acc:0.86\n",
      "Train Epoch:2[4608/60000 (8%)]\t Loss:0.467829 acc:0.87\n",
      "Train Epoch:2[5120/60000 (9%)]\t Loss:0.468764 acc:0.88\n",
      "Train Epoch:2[5632/60000 (9%)]\t Loss:0.429256 acc:0.87\n",
      "Train Epoch:2[6144/60000 (10%)]\t Loss:0.367354 acc:0.88\n",
      "Train Epoch:2[6656/60000 (11%)]\t Loss:0.467409 acc:0.84\n",
      "Train Epoch:2[7168/60000 (12%)]\t Loss:0.462911 acc:0.88\n",
      "Train Epoch:2[7680/60000 (13%)]\t Loss:0.432405 acc:0.88\n",
      "Train Epoch:2[8192/60000 (14%)]\t Loss:0.509902 acc:0.85\n",
      "Train Epoch:2[8704/60000 (15%)]\t Loss:0.514025 acc:0.86\n",
      "Train Epoch:2[9216/60000 (15%)]\t Loss:0.420568 acc:0.88\n",
      "Train Epoch:2[9728/60000 (16%)]\t Loss:0.445432 acc:0.88\n",
      "Train Epoch:2[10240/60000 (17%)]\t Loss:0.327392 acc:0.89\n",
      "Train Epoch:2[10752/60000 (18%)]\t Loss:0.395990 acc:0.85\n",
      "Train Epoch:2[11264/60000 (19%)]\t Loss:0.484110 acc:0.86\n",
      "Train Epoch:2[11776/60000 (20%)]\t Loss:0.424508 acc:0.85\n",
      "Train Epoch:2[12288/60000 (20%)]\t Loss:0.579983 acc:0.84\n",
      "Train Epoch:2[12800/60000 (21%)]\t Loss:0.512766 acc:0.85\n",
      "Train Epoch:2[13312/60000 (22%)]\t Loss:0.365097 acc:0.90\n",
      "Train Epoch:2[13824/60000 (23%)]\t Loss:0.542917 acc:0.84\n",
      "Train Epoch:2[14336/60000 (24%)]\t Loss:0.619241 acc:0.79\n",
      "Train Epoch:2[14848/60000 (25%)]\t Loss:0.399903 acc:0.89\n",
      "Train Epoch:2[15360/60000 (26%)]\t Loss:0.382818 acc:0.90\n",
      "Train Epoch:2[15872/60000 (26%)]\t Loss:0.413096 acc:0.86\n",
      "Train Epoch:2[16384/60000 (27%)]\t Loss:0.431094 acc:0.88\n",
      "Train Epoch:2[16896/60000 (28%)]\t Loss:0.468230 acc:0.84\n",
      "Train Epoch:2[17408/60000 (29%)]\t Loss:0.517273 acc:0.84\n",
      "Train Epoch:2[17920/60000 (30%)]\t Loss:0.333618 acc:0.90\n",
      "Train Epoch:2[18432/60000 (31%)]\t Loss:0.377913 acc:0.89\n",
      "Train Epoch:2[18944/60000 (32%)]\t Loss:0.387994 acc:0.87\n",
      "Train Epoch:2[19456/60000 (32%)]\t Loss:0.331154 acc:0.90\n",
      "Train Epoch:2[19968/60000 (33%)]\t Loss:0.405584 acc:0.88\n",
      "Train Epoch:2[20480/60000 (34%)]\t Loss:0.478914 acc:0.85\n",
      "Train Epoch:2[20992/60000 (35%)]\t Loss:0.368893 acc:0.90\n",
      "Train Epoch:2[21504/60000 (36%)]\t Loss:0.345888 acc:0.91\n",
      "Train Epoch:2[22016/60000 (37%)]\t Loss:0.392448 acc:0.88\n",
      "Train Epoch:2[22528/60000 (38%)]\t Loss:0.375767 acc:0.87\n",
      "Train Epoch:2[23040/60000 (38%)]\t Loss:0.372908 acc:0.88\n",
      "Train Epoch:2[23552/60000 (39%)]\t Loss:0.436488 acc:0.86\n",
      "Train Epoch:2[24064/60000 (40%)]\t Loss:0.408524 acc:0.87\n",
      "Train Epoch:2[24576/60000 (41%)]\t Loss:0.426781 acc:0.86\n",
      "Train Epoch:2[25088/60000 (42%)]\t Loss:0.330413 acc:0.89\n",
      "Train Epoch:2[25600/60000 (43%)]\t Loss:0.329643 acc:0.89\n",
      "Train Epoch:2[26112/60000 (44%)]\t Loss:0.432121 acc:0.88\n",
      "Train Epoch:2[26624/60000 (44%)]\t Loss:0.441982 acc:0.87\n",
      "Train Epoch:2[27136/60000 (45%)]\t Loss:0.456211 acc:0.88\n",
      "Train Epoch:2[27648/60000 (46%)]\t Loss:0.333858 acc:0.89\n",
      "Train Epoch:2[28160/60000 (47%)]\t Loss:0.430153 acc:0.87\n",
      "Train Epoch:2[28672/60000 (48%)]\t Loss:0.345413 acc:0.90\n",
      "Train Epoch:2[29184/60000 (49%)]\t Loss:0.377565 acc:0.89\n",
      "Train Epoch:2[29696/60000 (49%)]\t Loss:0.489548 acc:0.84\n",
      "Train Epoch:2[30208/60000 (50%)]\t Loss:0.386101 acc:0.88\n",
      "Train Epoch:2[30720/60000 (51%)]\t Loss:0.432992 acc:0.87\n",
      "Train Epoch:2[31232/60000 (52%)]\t Loss:0.536084 acc:0.83\n",
      "Train Epoch:2[31744/60000 (53%)]\t Loss:0.397937 acc:0.87\n",
      "Train Epoch:2[32256/60000 (54%)]\t Loss:0.440551 acc:0.86\n",
      "Train Epoch:2[32768/60000 (55%)]\t Loss:0.387624 acc:0.88\n",
      "Train Epoch:2[33280/60000 (55%)]\t Loss:0.377927 acc:0.89\n",
      "Train Epoch:2[33792/60000 (56%)]\t Loss:0.252954 acc:0.94\n",
      "Train Epoch:2[34304/60000 (57%)]\t Loss:0.398584 acc:0.87\n",
      "Train Epoch:2[34816/60000 (58%)]\t Loss:0.350358 acc:0.90\n",
      "Train Epoch:2[35328/60000 (59%)]\t Loss:0.320005 acc:0.89\n",
      "Train Epoch:2[35840/60000 (60%)]\t Loss:0.293720 acc:0.91\n",
      "Train Epoch:2[36352/60000 (61%)]\t Loss:0.324844 acc:0.91\n",
      "Train Epoch:2[36864/60000 (61%)]\t Loss:0.392489 acc:0.88\n",
      "Train Epoch:2[37376/60000 (62%)]\t Loss:0.408849 acc:0.86\n",
      "Train Epoch:2[37888/60000 (63%)]\t Loss:0.357918 acc:0.90\n",
      "Train Epoch:2[38400/60000 (64%)]\t Loss:0.322830 acc:0.90\n",
      "Train Epoch:2[38912/60000 (65%)]\t Loss:0.336836 acc:0.91\n",
      "Train Epoch:2[39424/60000 (66%)]\t Loss:0.411616 acc:0.88\n",
      "Train Epoch:2[39936/60000 (67%)]\t Loss:0.342809 acc:0.88\n",
      "Train Epoch:2[40448/60000 (67%)]\t Loss:0.303474 acc:0.90\n",
      "Train Epoch:2[40960/60000 (68%)]\t Loss:0.415335 acc:0.89\n",
      "Train Epoch:2[41472/60000 (69%)]\t Loss:0.341715 acc:0.90\n",
      "Train Epoch:2[41984/60000 (70%)]\t Loss:0.483944 acc:0.84\n",
      "Train Epoch:2[42496/60000 (71%)]\t Loss:0.410401 acc:0.88\n",
      "Train Epoch:2[43008/60000 (72%)]\t Loss:0.293419 acc:0.91\n",
      "Train Epoch:2[43520/60000 (73%)]\t Loss:0.350936 acc:0.90\n",
      "Train Epoch:2[44032/60000 (73%)]\t Loss:0.416700 acc:0.87\n",
      "Train Epoch:2[44544/60000 (74%)]\t Loss:0.350240 acc:0.90\n",
      "Train Epoch:2[45056/60000 (75%)]\t Loss:0.351611 acc:0.91\n",
      "Train Epoch:2[45568/60000 (76%)]\t Loss:0.367263 acc:0.89\n",
      "Train Epoch:2[46080/60000 (77%)]\t Loss:0.343173 acc:0.90\n",
      "Train Epoch:2[46592/60000 (78%)]\t Loss:0.286823 acc:0.91\n",
      "Train Epoch:2[47104/60000 (79%)]\t Loss:0.345460 acc:0.90\n",
      "Train Epoch:2[47616/60000 (79%)]\t Loss:0.287483 acc:0.92\n",
      "Train Epoch:2[48128/60000 (80%)]\t Loss:0.301340 acc:0.90\n",
      "Train Epoch:2[48640/60000 (81%)]\t Loss:0.378437 acc:0.89\n",
      "Train Epoch:2[49152/60000 (82%)]\t Loss:0.390544 acc:0.89\n",
      "Train Epoch:2[49664/60000 (83%)]\t Loss:0.387284 acc:0.89\n",
      "Train Epoch:2[50176/60000 (84%)]\t Loss:0.452717 acc:0.89\n",
      "Train Epoch:2[50688/60000 (84%)]\t Loss:0.317618 acc:0.89\n",
      "Train Epoch:2[51200/60000 (85%)]\t Loss:0.299098 acc:0.91\n",
      "Train Epoch:2[51712/60000 (86%)]\t Loss:0.393178 acc:0.88\n",
      "Train Epoch:2[52224/60000 (87%)]\t Loss:0.294742 acc:0.92\n",
      "Train Epoch:2[52736/60000 (88%)]\t Loss:0.450772 acc:0.87\n",
      "Train Epoch:2[53248/60000 (89%)]\t Loss:0.272587 acc:0.92\n",
      "Train Epoch:2[53760/60000 (90%)]\t Loss:0.316869 acc:0.90\n",
      "Train Epoch:2[54272/60000 (90%)]\t Loss:0.275208 acc:0.91\n",
      "Train Epoch:2[54784/60000 (91%)]\t Loss:0.348649 acc:0.88\n",
      "Train Epoch:2[55296/60000 (92%)]\t Loss:0.278713 acc:0.92\n",
      "Train Epoch:2[55808/60000 (93%)]\t Loss:0.258923 acc:0.92\n",
      "Train Epoch:2[56320/60000 (94%)]\t Loss:0.272637 acc:0.91\n",
      "Train Epoch:2[56832/60000 (95%)]\t Loss:0.301311 acc:0.91\n",
      "Train Epoch:2[57344/60000 (96%)]\t Loss:0.315615 acc:0.91\n",
      "Train Epoch:2[57856/60000 (96%)]\t Loss:0.204421 acc:0.94\n",
      "Train Epoch:2[58368/60000 (97%)]\t Loss:0.207498 acc:0.95\n",
      "Train Epoch:2[58880/60000 (98%)]\t Loss:0.204181 acc:0.94\n",
      "Train Epoch:2[59392/60000 (99%)]\t Loss:0.226073 acc:0.94\n",
      "Train Epoch:2[59904/60000 (100%)]\t Loss:0.396783 acc:0.17\n",
      "===> Saving models...\n",
      "Test Epoch:2 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:2 [512/10000 (5%)]\t acc:0.09\n",
      "Test Epoch:2 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:2 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:2 [2048/10000 (20%)]\t acc:0.23\n",
      "Test Epoch:2 [2560/10000 (26%)]\t acc:0.28\n",
      "Test Epoch:2 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:2 [3584/10000 (36%)]\t acc:0.37\n",
      "Test Epoch:2 [4096/10000 (41%)]\t acc:0.42\n",
      "Test Epoch:2 [4608/10000 (46%)]\t acc:0.47\n",
      "Test Epoch:2 [5120/10000 (51%)]\t acc:0.51\n",
      "Test Epoch:2 [5632/10000 (56%)]\t acc:0.56\n",
      "Test Epoch:2 [6144/10000 (61%)]\t acc:0.61\n",
      "Test Epoch:2 [6656/10000 (67%)]\t acc:0.65\n",
      "Test Epoch:2 [7168/10000 (72%)]\t acc:0.70\n",
      "Test Epoch:2 [7680/10000 (77%)]\t acc:0.75\n",
      "Test Epoch:2 [8192/10000 (82%)]\t acc:0.79\n",
      "Test Epoch:2 [8704/10000 (87%)]\t acc:0.84\n",
      "Test Epoch:2 [9216/10000 (92%)]\t acc:0.89\n",
      "Test Epoch:2 [9728/10000 (97%)]\t acc:0.91\n",
      "Train Epoch:3[0/60000 (0%)]\t Loss:0.314071 acc:0.90\n",
      "Train Epoch:3[512/60000 (1%)]\t Loss:0.345192 acc:0.89\n",
      "Train Epoch:3[1024/60000 (2%)]\t Loss:0.434161 acc:0.88\n",
      "Train Epoch:3[1536/60000 (3%)]\t Loss:0.251664 acc:0.94\n",
      "Train Epoch:3[2048/60000 (3%)]\t Loss:0.295116 acc:0.91\n",
      "Train Epoch:3[2560/60000 (4%)]\t Loss:0.290766 acc:0.91\n",
      "Train Epoch:3[3072/60000 (5%)]\t Loss:0.263002 acc:0.92\n",
      "Train Epoch:3[3584/60000 (6%)]\t Loss:0.283423 acc:0.92\n",
      "Train Epoch:3[4096/60000 (7%)]\t Loss:0.316584 acc:0.89\n",
      "Train Epoch:3[4608/60000 (8%)]\t Loss:0.336830 acc:0.90\n",
      "Train Epoch:3[5120/60000 (9%)]\t Loss:0.354845 acc:0.89\n",
      "Train Epoch:3[5632/60000 (9%)]\t Loss:0.301739 acc:0.90\n",
      "Train Epoch:3[6144/60000 (10%)]\t Loss:0.241847 acc:0.92\n",
      "Train Epoch:3[6656/60000 (11%)]\t Loss:0.342126 acc:0.89\n",
      "Train Epoch:3[7168/60000 (12%)]\t Loss:0.326326 acc:0.90\n",
      "Train Epoch:3[7680/60000 (13%)]\t Loss:0.297436 acc:0.92\n",
      "Train Epoch:3[8192/60000 (14%)]\t Loss:0.350614 acc:0.90\n",
      "Train Epoch:3[8704/60000 (15%)]\t Loss:0.425836 acc:0.88\n",
      "Train Epoch:3[9216/60000 (15%)]\t Loss:0.295705 acc:0.91\n",
      "Train Epoch:3[9728/60000 (16%)]\t Loss:0.316254 acc:0.91\n",
      "Train Epoch:3[10240/60000 (17%)]\t Loss:0.268669 acc:0.91\n",
      "Train Epoch:3[10752/60000 (18%)]\t Loss:0.296294 acc:0.93\n",
      "Train Epoch:3[11264/60000 (19%)]\t Loss:0.364109 acc:0.88\n",
      "Train Epoch:3[11776/60000 (20%)]\t Loss:0.297622 acc:0.90\n",
      "Train Epoch:3[12288/60000 (20%)]\t Loss:0.396865 acc:0.88\n",
      "Train Epoch:3[12800/60000 (21%)]\t Loss:0.334853 acc:0.89\n",
      "Train Epoch:3[13312/60000 (22%)]\t Loss:0.276597 acc:0.92\n",
      "Train Epoch:3[13824/60000 (23%)]\t Loss:0.386873 acc:0.88\n",
      "Train Epoch:3[14336/60000 (24%)]\t Loss:0.450017 acc:0.86\n",
      "Train Epoch:3[14848/60000 (25%)]\t Loss:0.299979 acc:0.91\n",
      "Train Epoch:3[15360/60000 (26%)]\t Loss:0.301525 acc:0.90\n",
      "Train Epoch:3[15872/60000 (26%)]\t Loss:0.303502 acc:0.91\n",
      "Train Epoch:3[16384/60000 (27%)]\t Loss:0.322946 acc:0.90\n",
      "Train Epoch:3[16896/60000 (28%)]\t Loss:0.323397 acc:0.90\n",
      "Train Epoch:3[17408/60000 (29%)]\t Loss:0.367643 acc:0.88\n",
      "Train Epoch:3[17920/60000 (30%)]\t Loss:0.228314 acc:0.93\n",
      "Train Epoch:3[18432/60000 (31%)]\t Loss:0.266381 acc:0.92\n",
      "Train Epoch:3[18944/60000 (32%)]\t Loss:0.282033 acc:0.91\n",
      "Train Epoch:3[19456/60000 (32%)]\t Loss:0.236250 acc:0.93\n",
      "Train Epoch:3[19968/60000 (33%)]\t Loss:0.294977 acc:0.92\n",
      "Train Epoch:3[20480/60000 (34%)]\t Loss:0.431213 acc:0.88\n",
      "Train Epoch:3[20992/60000 (35%)]\t Loss:0.256922 acc:0.93\n",
      "Train Epoch:3[21504/60000 (36%)]\t Loss:0.233675 acc:0.94\n",
      "Train Epoch:3[22016/60000 (37%)]\t Loss:0.250007 acc:0.93\n",
      "Train Epoch:3[22528/60000 (38%)]\t Loss:0.271034 acc:0.92\n",
      "Train Epoch:3[23040/60000 (38%)]\t Loss:0.229895 acc:0.92\n",
      "Train Epoch:3[23552/60000 (39%)]\t Loss:0.309001 acc:0.90\n",
      "Train Epoch:3[24064/60000 (40%)]\t Loss:0.296271 acc:0.91\n",
      "Train Epoch:3[24576/60000 (41%)]\t Loss:0.337942 acc:0.90\n",
      "Train Epoch:3[25088/60000 (42%)]\t Loss:0.242721 acc:0.92\n",
      "Train Epoch:3[25600/60000 (43%)]\t Loss:0.240942 acc:0.92\n",
      "Train Epoch:3[26112/60000 (44%)]\t Loss:0.319811 acc:0.90\n",
      "Train Epoch:3[26624/60000 (44%)]\t Loss:0.347483 acc:0.90\n",
      "Train Epoch:3[27136/60000 (45%)]\t Loss:0.337877 acc:0.90\n",
      "Train Epoch:3[27648/60000 (46%)]\t Loss:0.227442 acc:0.92\n",
      "Train Epoch:3[28160/60000 (47%)]\t Loss:0.317796 acc:0.90\n",
      "Train Epoch:3[28672/60000 (48%)]\t Loss:0.248907 acc:0.93\n",
      "Train Epoch:3[29184/60000 (49%)]\t Loss:0.263131 acc:0.93\n",
      "Train Epoch:3[29696/60000 (49%)]\t Loss:0.367751 acc:0.90\n",
      "Train Epoch:3[30208/60000 (50%)]\t Loss:0.286936 acc:0.91\n",
      "Train Epoch:3[30720/60000 (51%)]\t Loss:0.348748 acc:0.91\n",
      "Train Epoch:3[31232/60000 (52%)]\t Loss:0.399724 acc:0.87\n",
      "Train Epoch:3[31744/60000 (53%)]\t Loss:0.295507 acc:0.90\n",
      "Train Epoch:3[32256/60000 (54%)]\t Loss:0.323577 acc:0.90\n",
      "Train Epoch:3[32768/60000 (55%)]\t Loss:0.255504 acc:0.95\n",
      "Train Epoch:3[33280/60000 (55%)]\t Loss:0.266895 acc:0.92\n",
      "Train Epoch:3[33792/60000 (56%)]\t Loss:0.171258 acc:0.96\n",
      "Train Epoch:3[34304/60000 (57%)]\t Loss:0.310546 acc:0.90\n",
      "Train Epoch:3[34816/60000 (58%)]\t Loss:0.264673 acc:0.92\n",
      "Train Epoch:3[35328/60000 (59%)]\t Loss:0.233057 acc:0.93\n",
      "Train Epoch:3[35840/60000 (60%)]\t Loss:0.211136 acc:0.93\n",
      "Train Epoch:3[36352/60000 (61%)]\t Loss:0.249031 acc:0.92\n",
      "Train Epoch:3[36864/60000 (61%)]\t Loss:0.282335 acc:0.90\n",
      "Train Epoch:3[37376/60000 (62%)]\t Loss:0.316867 acc:0.91\n",
      "Train Epoch:3[37888/60000 (63%)]\t Loss:0.261329 acc:0.91\n",
      "Train Epoch:3[38400/60000 (64%)]\t Loss:0.237357 acc:0.93\n",
      "Train Epoch:3[38912/60000 (65%)]\t Loss:0.271691 acc:0.92\n",
      "Train Epoch:3[39424/60000 (66%)]\t Loss:0.313657 acc:0.91\n",
      "Train Epoch:3[39936/60000 (67%)]\t Loss:0.250232 acc:0.92\n",
      "Train Epoch:3[40448/60000 (67%)]\t Loss:0.232582 acc:0.92\n",
      "Train Epoch:3[40960/60000 (68%)]\t Loss:0.325403 acc:0.91\n",
      "Train Epoch:3[41472/60000 (69%)]\t Loss:0.254716 acc:0.92\n",
      "Train Epoch:3[41984/60000 (70%)]\t Loss:0.372138 acc:0.88\n",
      "Train Epoch:3[42496/60000 (71%)]\t Loss:0.323605 acc:0.92\n",
      "Train Epoch:3[43008/60000 (72%)]\t Loss:0.217308 acc:0.93\n",
      "Train Epoch:3[43520/60000 (73%)]\t Loss:0.264486 acc:0.92\n",
      "Train Epoch:3[44032/60000 (73%)]\t Loss:0.330988 acc:0.89\n",
      "Train Epoch:3[44544/60000 (74%)]\t Loss:0.293059 acc:0.91\n",
      "Train Epoch:3[45056/60000 (75%)]\t Loss:0.279277 acc:0.92\n",
      "Train Epoch:3[45568/60000 (76%)]\t Loss:0.303089 acc:0.91\n",
      "Train Epoch:3[46080/60000 (77%)]\t Loss:0.297954 acc:0.91\n",
      "Train Epoch:3[46592/60000 (78%)]\t Loss:0.235081 acc:0.92\n",
      "Train Epoch:3[47104/60000 (79%)]\t Loss:0.283581 acc:0.91\n",
      "Train Epoch:3[47616/60000 (79%)]\t Loss:0.231760 acc:0.93\n",
      "Train Epoch:3[48128/60000 (80%)]\t Loss:0.226513 acc:0.93\n",
      "Train Epoch:3[48640/60000 (81%)]\t Loss:0.296195 acc:0.91\n",
      "Train Epoch:3[49152/60000 (82%)]\t Loss:0.307039 acc:0.91\n",
      "Train Epoch:3[49664/60000 (83%)]\t Loss:0.284207 acc:0.91\n",
      "Train Epoch:3[50176/60000 (84%)]\t Loss:0.386617 acc:0.90\n",
      "Train Epoch:3[50688/60000 (84%)]\t Loss:0.250473 acc:0.92\n",
      "Train Epoch:3[51200/60000 (85%)]\t Loss:0.235401 acc:0.92\n",
      "Train Epoch:3[51712/60000 (86%)]\t Loss:0.317839 acc:0.90\n",
      "Train Epoch:3[52224/60000 (87%)]\t Loss:0.236494 acc:0.93\n",
      "Train Epoch:3[52736/60000 (88%)]\t Loss:0.352722 acc:0.90\n",
      "Train Epoch:3[53248/60000 (89%)]\t Loss:0.224722 acc:0.94\n",
      "Train Epoch:3[53760/60000 (90%)]\t Loss:0.265236 acc:0.93\n",
      "Train Epoch:3[54272/60000 (90%)]\t Loss:0.208694 acc:0.94\n",
      "Train Epoch:3[54784/60000 (91%)]\t Loss:0.275319 acc:0.91\n",
      "Train Epoch:3[55296/60000 (92%)]\t Loss:0.223644 acc:0.93\n",
      "Train Epoch:3[55808/60000 (93%)]\t Loss:0.199389 acc:0.94\n",
      "Train Epoch:3[56320/60000 (94%)]\t Loss:0.213881 acc:0.94\n",
      "Train Epoch:3[56832/60000 (95%)]\t Loss:0.213749 acc:0.94\n",
      "Train Epoch:3[57344/60000 (96%)]\t Loss:0.254739 acc:0.91\n",
      "Train Epoch:3[57856/60000 (96%)]\t Loss:0.157473 acc:0.95\n",
      "Train Epoch:3[58368/60000 (97%)]\t Loss:0.162973 acc:0.96\n",
      "Train Epoch:3[58880/60000 (98%)]\t Loss:0.143227 acc:0.96\n",
      "Train Epoch:3[59392/60000 (99%)]\t Loss:0.176477 acc:0.96\n",
      "Train Epoch:3[59904/60000 (100%)]\t Loss:0.293588 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:3 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:3 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:3 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:3 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:3 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:3 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:3 [3072/10000 (31%)]\t acc:0.33\n",
      "Test Epoch:3 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:3 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:3 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:3 [5120/10000 (51%)]\t acc:0.52\n",
      "Test Epoch:3 [5632/10000 (56%)]\t acc:0.57\n",
      "Test Epoch:3 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:3 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:3 [7168/10000 (72%)]\t acc:0.71\n",
      "Test Epoch:3 [7680/10000 (77%)]\t acc:0.76\n",
      "Test Epoch:3 [8192/10000 (82%)]\t acc:0.81\n",
      "Test Epoch:3 [8704/10000 (87%)]\t acc:0.86\n",
      "Test Epoch:3 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:3 [9728/10000 (97%)]\t acc:0.93\n",
      "Train Epoch:4[0/60000 (0%)]\t Loss:0.254693 acc:0.93\n",
      "Train Epoch:4[512/60000 (1%)]\t Loss:0.273749 acc:0.92\n",
      "Train Epoch:4[1024/60000 (2%)]\t Loss:0.344845 acc:0.90\n",
      "Train Epoch:4[1536/60000 (3%)]\t Loss:0.191442 acc:0.95\n",
      "Train Epoch:4[2048/60000 (3%)]\t Loss:0.225651 acc:0.94\n",
      "Train Epoch:4[2560/60000 (4%)]\t Loss:0.240695 acc:0.93\n",
      "Train Epoch:4[3072/60000 (5%)]\t Loss:0.200233 acc:0.93\n",
      "Train Epoch:4[3584/60000 (6%)]\t Loss:0.207689 acc:0.95\n",
      "Train Epoch:4[4096/60000 (7%)]\t Loss:0.229524 acc:0.93\n",
      "Train Epoch:4[4608/60000 (8%)]\t Loss:0.258397 acc:0.92\n",
      "Train Epoch:4[5120/60000 (9%)]\t Loss:0.269832 acc:0.91\n",
      "Train Epoch:4[5632/60000 (9%)]\t Loss:0.225452 acc:0.93\n",
      "Train Epoch:4[6144/60000 (10%)]\t Loss:0.189167 acc:0.94\n",
      "Train Epoch:4[6656/60000 (11%)]\t Loss:0.277151 acc:0.91\n",
      "Train Epoch:4[7168/60000 (12%)]\t Loss:0.270839 acc:0.91\n",
      "Train Epoch:4[7680/60000 (13%)]\t Loss:0.249828 acc:0.92\n",
      "Train Epoch:4[8192/60000 (14%)]\t Loss:0.294543 acc:0.92\n",
      "Train Epoch:4[8704/60000 (15%)]\t Loss:0.346740 acc:0.89\n",
      "Train Epoch:4[9216/60000 (15%)]\t Loss:0.233854 acc:0.92\n",
      "Train Epoch:4[9728/60000 (16%)]\t Loss:0.236511 acc:0.93\n",
      "Train Epoch:4[10240/60000 (17%)]\t Loss:0.219188 acc:0.93\n",
      "Train Epoch:4[10752/60000 (18%)]\t Loss:0.229813 acc:0.94\n",
      "Train Epoch:4[11264/60000 (19%)]\t Loss:0.290910 acc:0.91\n",
      "Train Epoch:4[11776/60000 (20%)]\t Loss:0.238243 acc:0.92\n",
      "Train Epoch:4[12288/60000 (20%)]\t Loss:0.331216 acc:0.89\n",
      "Train Epoch:4[12800/60000 (21%)]\t Loss:0.259252 acc:0.92\n",
      "Train Epoch:4[13312/60000 (22%)]\t Loss:0.217760 acc:0.94\n",
      "Train Epoch:4[13824/60000 (23%)]\t Loss:0.303922 acc:0.89\n",
      "Train Epoch:4[14336/60000 (24%)]\t Loss:0.372796 acc:0.88\n",
      "Train Epoch:4[14848/60000 (25%)]\t Loss:0.238074 acc:0.93\n",
      "Train Epoch:4[15360/60000 (26%)]\t Loss:0.246705 acc:0.92\n",
      "Train Epoch:4[15872/60000 (26%)]\t Loss:0.222963 acc:0.93\n",
      "Train Epoch:4[16384/60000 (27%)]\t Loss:0.263021 acc:0.92\n",
      "Train Epoch:4[16896/60000 (28%)]\t Loss:0.235432 acc:0.93\n",
      "Train Epoch:4[17408/60000 (29%)]\t Loss:0.282073 acc:0.92\n",
      "Train Epoch:4[17920/60000 (30%)]\t Loss:0.186274 acc:0.95\n",
      "Train Epoch:4[18432/60000 (31%)]\t Loss:0.212052 acc:0.94\n",
      "Train Epoch:4[18944/60000 (32%)]\t Loss:0.234218 acc:0.92\n",
      "Train Epoch:4[19456/60000 (32%)]\t Loss:0.187997 acc:0.95\n",
      "Train Epoch:4[19968/60000 (33%)]\t Loss:0.226409 acc:0.94\n",
      "Train Epoch:4[20480/60000 (34%)]\t Loss:0.349148 acc:0.91\n",
      "Train Epoch:4[20992/60000 (35%)]\t Loss:0.206367 acc:0.95\n",
      "Train Epoch:4[21504/60000 (36%)]\t Loss:0.186496 acc:0.95\n",
      "Train Epoch:4[22016/60000 (37%)]\t Loss:0.204576 acc:0.94\n",
      "Train Epoch:4[22528/60000 (38%)]\t Loss:0.214381 acc:0.92\n",
      "Train Epoch:4[23040/60000 (38%)]\t Loss:0.182542 acc:0.94\n",
      "Train Epoch:4[23552/60000 (39%)]\t Loss:0.250205 acc:0.92\n",
      "Train Epoch:4[24064/60000 (40%)]\t Loss:0.239131 acc:0.91\n",
      "Train Epoch:4[24576/60000 (41%)]\t Loss:0.288019 acc:0.93\n",
      "Train Epoch:4[25088/60000 (42%)]\t Loss:0.206693 acc:0.93\n",
      "Train Epoch:4[25600/60000 (43%)]\t Loss:0.203487 acc:0.94\n",
      "Train Epoch:4[26112/60000 (44%)]\t Loss:0.273257 acc:0.92\n",
      "Train Epoch:4[26624/60000 (44%)]\t Loss:0.280550 acc:0.92\n",
      "Train Epoch:4[27136/60000 (45%)]\t Loss:0.271609 acc:0.92\n",
      "Train Epoch:4[27648/60000 (46%)]\t Loss:0.185231 acc:0.94\n",
      "Train Epoch:4[28160/60000 (47%)]\t Loss:0.274054 acc:0.92\n",
      "Train Epoch:4[28672/60000 (48%)]\t Loss:0.204889 acc:0.95\n",
      "Train Epoch:4[29184/60000 (49%)]\t Loss:0.212072 acc:0.94\n",
      "Train Epoch:4[29696/60000 (49%)]\t Loss:0.303183 acc:0.91\n",
      "Train Epoch:4[30208/60000 (50%)]\t Loss:0.234310 acc:0.93\n",
      "Train Epoch:4[30720/60000 (51%)]\t Loss:0.293686 acc:0.92\n",
      "Train Epoch:4[31232/60000 (52%)]\t Loss:0.332509 acc:0.90\n",
      "Train Epoch:4[31744/60000 (53%)]\t Loss:0.235612 acc:0.92\n",
      "Train Epoch:4[32256/60000 (54%)]\t Loss:0.271926 acc:0.92\n",
      "Train Epoch:4[32768/60000 (55%)]\t Loss:0.210721 acc:0.95\n",
      "Train Epoch:4[33280/60000 (55%)]\t Loss:0.231126 acc:0.93\n",
      "Train Epoch:4[33792/60000 (56%)]\t Loss:0.139025 acc:0.97\n",
      "Train Epoch:4[34304/60000 (57%)]\t Loss:0.266438 acc:0.91\n",
      "Train Epoch:4[34816/60000 (58%)]\t Loss:0.220527 acc:0.94\n",
      "Train Epoch:4[35328/60000 (59%)]\t Loss:0.185850 acc:0.96\n",
      "Train Epoch:4[35840/60000 (60%)]\t Loss:0.171768 acc:0.95\n",
      "Train Epoch:4[36352/60000 (61%)]\t Loss:0.201446 acc:0.94\n",
      "Train Epoch:4[36864/60000 (61%)]\t Loss:0.236755 acc:0.91\n",
      "Train Epoch:4[37376/60000 (62%)]\t Loss:0.270120 acc:0.92\n",
      "Train Epoch:4[37888/60000 (63%)]\t Loss:0.211320 acc:0.92\n",
      "Train Epoch:4[38400/60000 (64%)]\t Loss:0.197358 acc:0.94\n",
      "Train Epoch:4[38912/60000 (65%)]\t Loss:0.231079 acc:0.93\n",
      "Train Epoch:4[39424/60000 (66%)]\t Loss:0.255574 acc:0.93\n",
      "Train Epoch:4[39936/60000 (67%)]\t Loss:0.206955 acc:0.95\n",
      "Train Epoch:4[40448/60000 (67%)]\t Loss:0.196330 acc:0.93\n",
      "Train Epoch:4[40960/60000 (68%)]\t Loss:0.280706 acc:0.93\n",
      "Train Epoch:4[41472/60000 (69%)]\t Loss:0.210392 acc:0.93\n",
      "Train Epoch:4[41984/60000 (70%)]\t Loss:0.310325 acc:0.90\n",
      "Train Epoch:4[42496/60000 (71%)]\t Loss:0.276280 acc:0.93\n",
      "Train Epoch:4[43008/60000 (72%)]\t Loss:0.180856 acc:0.94\n",
      "Train Epoch:4[43520/60000 (73%)]\t Loss:0.225717 acc:0.93\n",
      "Train Epoch:4[44032/60000 (73%)]\t Loss:0.283586 acc:0.90\n",
      "Train Epoch:4[44544/60000 (74%)]\t Loss:0.249681 acc:0.93\n",
      "Train Epoch:4[45056/60000 (75%)]\t Loss:0.237022 acc:0.93\n",
      "Train Epoch:4[45568/60000 (76%)]\t Loss:0.268574 acc:0.92\n",
      "Train Epoch:4[46080/60000 (77%)]\t Loss:0.262061 acc:0.92\n",
      "Train Epoch:4[46592/60000 (78%)]\t Loss:0.197894 acc:0.93\n",
      "Train Epoch:4[47104/60000 (79%)]\t Loss:0.251340 acc:0.93\n",
      "Train Epoch:4[47616/60000 (79%)]\t Loss:0.194317 acc:0.95\n",
      "Train Epoch:4[48128/60000 (80%)]\t Loss:0.187823 acc:0.94\n",
      "Train Epoch:4[48640/60000 (81%)]\t Loss:0.260596 acc:0.91\n",
      "Train Epoch:4[49152/60000 (82%)]\t Loss:0.265895 acc:0.92\n",
      "Train Epoch:4[49664/60000 (83%)]\t Loss:0.232767 acc:0.92\n",
      "Train Epoch:4[50176/60000 (84%)]\t Loss:0.342654 acc:0.91\n",
      "Train Epoch:4[50688/60000 (84%)]\t Loss:0.207310 acc:0.94\n",
      "Train Epoch:4[51200/60000 (85%)]\t Loss:0.192171 acc:0.94\n",
      "Train Epoch:4[51712/60000 (86%)]\t Loss:0.271232 acc:0.92\n",
      "Train Epoch:4[52224/60000 (87%)]\t Loss:0.197012 acc:0.95\n",
      "Train Epoch:4[52736/60000 (88%)]\t Loss:0.304224 acc:0.92\n",
      "Train Epoch:4[53248/60000 (89%)]\t Loss:0.189826 acc:0.95\n",
      "Train Epoch:4[53760/60000 (90%)]\t Loss:0.235261 acc:0.93\n",
      "Train Epoch:4[54272/60000 (90%)]\t Loss:0.174477 acc:0.95\n",
      "Train Epoch:4[54784/60000 (91%)]\t Loss:0.240456 acc:0.92\n",
      "Train Epoch:4[55296/60000 (92%)]\t Loss:0.192902 acc:0.94\n",
      "Train Epoch:4[55808/60000 (93%)]\t Loss:0.165637 acc:0.95\n",
      "Train Epoch:4[56320/60000 (94%)]\t Loss:0.185136 acc:0.95\n",
      "Train Epoch:4[56832/60000 (95%)]\t Loss:0.170552 acc:0.95\n",
      "Train Epoch:4[57344/60000 (96%)]\t Loss:0.211105 acc:0.93\n",
      "Train Epoch:4[57856/60000 (96%)]\t Loss:0.130409 acc:0.96\n",
      "Train Epoch:4[58368/60000 (97%)]\t Loss:0.131523 acc:0.97\n",
      "Train Epoch:4[58880/60000 (98%)]\t Loss:0.110061 acc:0.97\n",
      "Train Epoch:4[59392/60000 (99%)]\t Loss:0.149788 acc:0.97\n",
      "Train Epoch:4[59904/60000 (100%)]\t Loss:0.263911 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:4 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:4 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:4 [1024/10000 (10%)]\t acc:0.14\n",
      "Test Epoch:4 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:4 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:4 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:4 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:4 [3584/10000 (36%)]\t acc:0.38\n",
      "Test Epoch:4 [4096/10000 (41%)]\t acc:0.43\n",
      "Test Epoch:4 [4608/10000 (46%)]\t acc:0.48\n",
      "Test Epoch:4 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:4 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:4 [6144/10000 (61%)]\t acc:0.62\n",
      "Test Epoch:4 [6656/10000 (67%)]\t acc:0.67\n",
      "Test Epoch:4 [7168/10000 (72%)]\t acc:0.72\n",
      "Test Epoch:4 [7680/10000 (77%)]\t acc:0.77\n",
      "Test Epoch:4 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:4 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:4 [9216/10000 (92%)]\t acc:0.91\n",
      "Test Epoch:4 [9728/10000 (97%)]\t acc:0.94\n",
      "Train Epoch:5[0/60000 (0%)]\t Loss:0.221437 acc:0.94\n",
      "Train Epoch:5[512/60000 (1%)]\t Loss:0.237573 acc:0.93\n",
      "Train Epoch:5[1024/60000 (2%)]\t Loss:0.299647 acc:0.92\n",
      "Train Epoch:5[1536/60000 (3%)]\t Loss:0.158876 acc:0.96\n",
      "Train Epoch:5[2048/60000 (3%)]\t Loss:0.179487 acc:0.94\n",
      "Train Epoch:5[2560/60000 (4%)]\t Loss:0.208745 acc:0.94\n",
      "Train Epoch:5[3072/60000 (5%)]\t Loss:0.168907 acc:0.94\n",
      "Train Epoch:5[3584/60000 (6%)]\t Loss:0.172697 acc:0.96\n",
      "Train Epoch:5[4096/60000 (7%)]\t Loss:0.195051 acc:0.94\n",
      "Train Epoch:5[4608/60000 (8%)]\t Loss:0.218753 acc:0.93\n",
      "Train Epoch:5[5120/60000 (9%)]\t Loss:0.222413 acc:0.92\n",
      "Train Epoch:5[5632/60000 (9%)]\t Loss:0.192544 acc:0.95\n",
      "Train Epoch:5[6144/60000 (10%)]\t Loss:0.162715 acc:0.96\n",
      "Train Epoch:5[6656/60000 (11%)]\t Loss:0.237648 acc:0.93\n",
      "Train Epoch:5[7168/60000 (12%)]\t Loss:0.228070 acc:0.93\n",
      "Train Epoch:5[7680/60000 (13%)]\t Loss:0.221200 acc:0.93\n",
      "Train Epoch:5[8192/60000 (14%)]\t Loss:0.258928 acc:0.92\n",
      "Train Epoch:5[8704/60000 (15%)]\t Loss:0.306223 acc:0.91\n",
      "Train Epoch:5[9216/60000 (15%)]\t Loss:0.204890 acc:0.94\n",
      "Train Epoch:5[9728/60000 (16%)]\t Loss:0.201705 acc:0.94\n",
      "Train Epoch:5[10240/60000 (17%)]\t Loss:0.190468 acc:0.94\n",
      "Train Epoch:5[10752/60000 (18%)]\t Loss:0.197426 acc:0.94\n",
      "Train Epoch:5[11264/60000 (19%)]\t Loss:0.247857 acc:0.92\n",
      "Train Epoch:5[11776/60000 (20%)]\t Loss:0.199455 acc:0.93\n",
      "Train Epoch:5[12288/60000 (20%)]\t Loss:0.284931 acc:0.92\n",
      "Train Epoch:5[12800/60000 (21%)]\t Loss:0.215305 acc:0.93\n",
      "Train Epoch:5[13312/60000 (22%)]\t Loss:0.184768 acc:0.95\n",
      "Train Epoch:5[13824/60000 (23%)]\t Loss:0.255736 acc:0.91\n",
      "Train Epoch:5[14336/60000 (24%)]\t Loss:0.315243 acc:0.89\n",
      "Train Epoch:5[14848/60000 (25%)]\t Loss:0.204728 acc:0.94\n",
      "Train Epoch:5[15360/60000 (26%)]\t Loss:0.216998 acc:0.93\n",
      "Train Epoch:5[15872/60000 (26%)]\t Loss:0.182668 acc:0.95\n",
      "Train Epoch:5[16384/60000 (27%)]\t Loss:0.226786 acc:0.93\n",
      "Train Epoch:5[16896/60000 (28%)]\t Loss:0.191984 acc:0.95\n",
      "Train Epoch:5[17408/60000 (29%)]\t Loss:0.236002 acc:0.93\n",
      "Train Epoch:5[17920/60000 (30%)]\t Loss:0.164424 acc:0.96\n",
      "Train Epoch:5[18432/60000 (31%)]\t Loss:0.180046 acc:0.95\n",
      "Train Epoch:5[18944/60000 (32%)]\t Loss:0.204556 acc:0.93\n",
      "Train Epoch:5[19456/60000 (32%)]\t Loss:0.165276 acc:0.96\n",
      "Train Epoch:5[19968/60000 (33%)]\t Loss:0.195888 acc:0.94\n",
      "Train Epoch:5[20480/60000 (34%)]\t Loss:0.304715 acc:0.92\n",
      "Train Epoch:5[20992/60000 (35%)]\t Loss:0.179738 acc:0.95\n",
      "Train Epoch:5[21504/60000 (36%)]\t Loss:0.155577 acc:0.96\n",
      "Train Epoch:5[22016/60000 (37%)]\t Loss:0.178192 acc:0.95\n",
      "Train Epoch:5[22528/60000 (38%)]\t Loss:0.183775 acc:0.93\n",
      "Train Epoch:5[23040/60000 (38%)]\t Loss:0.157274 acc:0.95\n",
      "Train Epoch:5[23552/60000 (39%)]\t Loss:0.214390 acc:0.93\n",
      "Train Epoch:5[24064/60000 (40%)]\t Loss:0.208134 acc:0.92\n",
      "Train Epoch:5[24576/60000 (41%)]\t Loss:0.252814 acc:0.93\n",
      "Train Epoch:5[25088/60000 (42%)]\t Loss:0.189705 acc:0.94\n",
      "Train Epoch:5[25600/60000 (43%)]\t Loss:0.182002 acc:0.95\n",
      "Train Epoch:5[26112/60000 (44%)]\t Loss:0.239934 acc:0.93\n",
      "Train Epoch:5[26624/60000 (44%)]\t Loss:0.240994 acc:0.92\n",
      "Train Epoch:5[27136/60000 (45%)]\t Loss:0.238196 acc:0.93\n",
      "Train Epoch:5[27648/60000 (46%)]\t Loss:0.161109 acc:0.94\n",
      "Train Epoch:5[28160/60000 (47%)]\t Loss:0.242604 acc:0.93\n",
      "Train Epoch:5[28672/60000 (48%)]\t Loss:0.174328 acc:0.96\n",
      "Train Epoch:5[29184/60000 (49%)]\t Loss:0.185831 acc:0.95\n",
      "Train Epoch:5[29696/60000 (49%)]\t Loss:0.267921 acc:0.91\n",
      "Train Epoch:5[30208/60000 (50%)]\t Loss:0.195439 acc:0.94\n",
      "Train Epoch:5[30720/60000 (51%)]\t Loss:0.252862 acc:0.93\n",
      "Train Epoch:5[31232/60000 (52%)]\t Loss:0.286072 acc:0.91\n",
      "Train Epoch:5[31744/60000 (53%)]\t Loss:0.195249 acc:0.95\n",
      "Train Epoch:5[32256/60000 (54%)]\t Loss:0.231033 acc:0.93\n",
      "Train Epoch:5[32768/60000 (55%)]\t Loss:0.182164 acc:0.96\n",
      "Train Epoch:5[33280/60000 (55%)]\t Loss:0.208662 acc:0.94\n",
      "Train Epoch:5[33792/60000 (56%)]\t Loss:0.117434 acc:0.97\n",
      "Train Epoch:5[34304/60000 (57%)]\t Loss:0.244157 acc:0.92\n",
      "Train Epoch:5[34816/60000 (58%)]\t Loss:0.190861 acc:0.95\n",
      "Train Epoch:5[35328/60000 (59%)]\t Loss:0.160155 acc:0.96\n",
      "Train Epoch:5[35840/60000 (60%)]\t Loss:0.150355 acc:0.96\n",
      "Train Epoch:5[36352/60000 (61%)]\t Loss:0.178389 acc:0.94\n",
      "Train Epoch:5[36864/60000 (61%)]\t Loss:0.208247 acc:0.93\n",
      "Train Epoch:5[37376/60000 (62%)]\t Loss:0.234905 acc:0.93\n",
      "Train Epoch:5[37888/60000 (63%)]\t Loss:0.174923 acc:0.95\n",
      "Train Epoch:5[38400/60000 (64%)]\t Loss:0.169062 acc:0.95\n",
      "Train Epoch:5[38912/60000 (65%)]\t Loss:0.202938 acc:0.93\n",
      "Train Epoch:5[39424/60000 (66%)]\t Loss:0.213899 acc:0.94\n",
      "Train Epoch:5[39936/60000 (67%)]\t Loss:0.175959 acc:0.96\n",
      "Train Epoch:5[40448/60000 (67%)]\t Loss:0.170900 acc:0.94\n",
      "Train Epoch:5[40960/60000 (68%)]\t Loss:0.248532 acc:0.93\n",
      "Train Epoch:5[41472/60000 (69%)]\t Loss:0.179942 acc:0.94\n",
      "Train Epoch:5[41984/60000 (70%)]\t Loss:0.264369 acc:0.92\n",
      "Train Epoch:5[42496/60000 (71%)]\t Loss:0.242275 acc:0.93\n",
      "Train Epoch:5[43008/60000 (72%)]\t Loss:0.160944 acc:0.95\n",
      "Train Epoch:5[43520/60000 (73%)]\t Loss:0.196083 acc:0.94\n",
      "Train Epoch:5[44032/60000 (73%)]\t Loss:0.243570 acc:0.92\n",
      "Train Epoch:5[44544/60000 (74%)]\t Loss:0.212194 acc:0.93\n",
      "Train Epoch:5[45056/60000 (75%)]\t Loss:0.202008 acc:0.94\n",
      "Train Epoch:5[45568/60000 (76%)]\t Loss:0.235688 acc:0.93\n",
      "Train Epoch:5[46080/60000 (77%)]\t Loss:0.236053 acc:0.93\n",
      "Train Epoch:5[46592/60000 (78%)]\t Loss:0.174997 acc:0.94\n",
      "Train Epoch:5[47104/60000 (79%)]\t Loss:0.230019 acc:0.93\n",
      "Train Epoch:5[47616/60000 (79%)]\t Loss:0.168789 acc:0.96\n",
      "Train Epoch:5[48128/60000 (80%)]\t Loss:0.156200 acc:0.95\n",
      "Train Epoch:5[48640/60000 (81%)]\t Loss:0.236802 acc:0.92\n",
      "Train Epoch:5[49152/60000 (82%)]\t Loss:0.237366 acc:0.93\n",
      "Train Epoch:5[49664/60000 (83%)]\t Loss:0.195693 acc:0.94\n",
      "Train Epoch:5[50176/60000 (84%)]\t Loss:0.310239 acc:0.92\n",
      "Train Epoch:5[50688/60000 (84%)]\t Loss:0.169602 acc:0.94\n",
      "Train Epoch:5[51200/60000 (85%)]\t Loss:0.158074 acc:0.95\n",
      "Train Epoch:5[51712/60000 (86%)]\t Loss:0.235219 acc:0.93\n",
      "Train Epoch:5[52224/60000 (87%)]\t Loss:0.164834 acc:0.95\n",
      "Train Epoch:5[52736/60000 (88%)]\t Loss:0.268687 acc:0.92\n",
      "Train Epoch:5[53248/60000 (89%)]\t Loss:0.163684 acc:0.94\n",
      "Train Epoch:5[53760/60000 (90%)]\t Loss:0.217558 acc:0.94\n",
      "Train Epoch:5[54272/60000 (90%)]\t Loss:0.151437 acc:0.96\n",
      "Train Epoch:5[54784/60000 (91%)]\t Loss:0.211248 acc:0.93\n",
      "Train Epoch:5[55296/60000 (92%)]\t Loss:0.170237 acc:0.95\n",
      "Train Epoch:5[55808/60000 (93%)]\t Loss:0.145290 acc:0.95\n",
      "Train Epoch:5[56320/60000 (94%)]\t Loss:0.160736 acc:0.95\n",
      "Train Epoch:5[56832/60000 (95%)]\t Loss:0.141044 acc:0.96\n",
      "Train Epoch:5[57344/60000 (96%)]\t Loss:0.179190 acc:0.95\n",
      "Train Epoch:5[57856/60000 (96%)]\t Loss:0.112538 acc:0.96\n",
      "Train Epoch:5[58368/60000 (97%)]\t Loss:0.113415 acc:0.97\n",
      "Train Epoch:5[58880/60000 (98%)]\t Loss:0.088813 acc:0.98\n",
      "Train Epoch:5[59392/60000 (99%)]\t Loss:0.136927 acc:0.97\n",
      "Train Epoch:5[59904/60000 (100%)]\t Loss:0.257411 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:5 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:5 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:5 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:5 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:5 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:5 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:5 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:5 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:5 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:5 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:5 [5120/10000 (51%)]\t acc:0.53\n",
      "Test Epoch:5 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:5 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:5 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:5 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:5 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:5 [8192/10000 (82%)]\t acc:0.82\n",
      "Test Epoch:5 [8704/10000 (87%)]\t acc:0.87\n",
      "Test Epoch:5 [9216/10000 (92%)]\t acc:0.92\n",
      "Test Epoch:5 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:6[0/60000 (0%)]\t Loss:0.197746 acc:0.94\n",
      "Train Epoch:6[512/60000 (1%)]\t Loss:0.209851 acc:0.94\n",
      "Train Epoch:6[1024/60000 (2%)]\t Loss:0.265834 acc:0.92\n",
      "Train Epoch:6[1536/60000 (3%)]\t Loss:0.132498 acc:0.97\n",
      "Train Epoch:6[2048/60000 (3%)]\t Loss:0.144706 acc:0.96\n",
      "Train Epoch:6[2560/60000 (4%)]\t Loss:0.181742 acc:0.95\n",
      "Train Epoch:6[3072/60000 (5%)]\t Loss:0.146308 acc:0.95\n",
      "Train Epoch:6[3584/60000 (6%)]\t Loss:0.147159 acc:0.96\n",
      "Train Epoch:6[4096/60000 (7%)]\t Loss:0.170328 acc:0.95\n",
      "Train Epoch:6[4608/60000 (8%)]\t Loss:0.189249 acc:0.95\n",
      "Train Epoch:6[5120/60000 (9%)]\t Loss:0.191116 acc:0.94\n",
      "Train Epoch:6[5632/60000 (9%)]\t Loss:0.170857 acc:0.95\n",
      "Train Epoch:6[6144/60000 (10%)]\t Loss:0.146801 acc:0.96\n",
      "Train Epoch:6[6656/60000 (11%)]\t Loss:0.212101 acc:0.94\n",
      "Train Epoch:6[7168/60000 (12%)]\t Loss:0.196545 acc:0.94\n",
      "Train Epoch:6[7680/60000 (13%)]\t Loss:0.197782 acc:0.94\n",
      "Train Epoch:6[8192/60000 (14%)]\t Loss:0.229692 acc:0.92\n",
      "Train Epoch:6[8704/60000 (15%)]\t Loss:0.271363 acc:0.92\n",
      "Train Epoch:6[9216/60000 (15%)]\t Loss:0.184361 acc:0.95\n",
      "Train Epoch:6[9728/60000 (16%)]\t Loss:0.179251 acc:0.95\n",
      "Train Epoch:6[10240/60000 (17%)]\t Loss:0.168397 acc:0.95\n",
      "Train Epoch:6[10752/60000 (18%)]\t Loss:0.173988 acc:0.95\n",
      "Train Epoch:6[11264/60000 (19%)]\t Loss:0.213524 acc:0.94\n",
      "Train Epoch:6[11776/60000 (20%)]\t Loss:0.167405 acc:0.94\n",
      "Train Epoch:6[12288/60000 (20%)]\t Loss:0.253363 acc:0.92\n",
      "Train Epoch:6[12800/60000 (21%)]\t Loss:0.185559 acc:0.94\n",
      "Train Epoch:6[13312/60000 (22%)]\t Loss:0.161650 acc:0.95\n",
      "Train Epoch:6[13824/60000 (23%)]\t Loss:0.221557 acc:0.92\n",
      "Train Epoch:6[14336/60000 (24%)]\t Loss:0.269251 acc:0.90\n",
      "Train Epoch:6[14848/60000 (25%)]\t Loss:0.179605 acc:0.95\n",
      "Train Epoch:6[15360/60000 (26%)]\t Loss:0.193489 acc:0.94\n",
      "Train Epoch:6[15872/60000 (26%)]\t Loss:0.159666 acc:0.95\n",
      "Train Epoch:6[16384/60000 (27%)]\t Loss:0.195267 acc:0.94\n",
      "Train Epoch:6[16896/60000 (28%)]\t Loss:0.166308 acc:0.95\n",
      "Train Epoch:6[17408/60000 (29%)]\t Loss:0.203124 acc:0.94\n",
      "Train Epoch:6[17920/60000 (30%)]\t Loss:0.145386 acc:0.96\n",
      "Train Epoch:6[18432/60000 (31%)]\t Loss:0.153517 acc:0.96\n",
      "Train Epoch:6[18944/60000 (32%)]\t Loss:0.178039 acc:0.94\n",
      "Train Epoch:6[19456/60000 (32%)]\t Loss:0.154096 acc:0.96\n",
      "Train Epoch:6[19968/60000 (33%)]\t Loss:0.177572 acc:0.95\n",
      "Train Epoch:6[20480/60000 (34%)]\t Loss:0.272891 acc:0.93\n",
      "Train Epoch:6[20992/60000 (35%)]\t Loss:0.161562 acc:0.96\n",
      "Train Epoch:6[21504/60000 (36%)]\t Loss:0.134024 acc:0.96\n",
      "Train Epoch:6[22016/60000 (37%)]\t Loss:0.160076 acc:0.95\n",
      "Train Epoch:6[22528/60000 (38%)]\t Loss:0.165723 acc:0.94\n",
      "Train Epoch:6[23040/60000 (38%)]\t Loss:0.135025 acc:0.96\n",
      "Train Epoch:6[23552/60000 (39%)]\t Loss:0.188340 acc:0.94\n",
      "Train Epoch:6[24064/60000 (40%)]\t Loss:0.183853 acc:0.93\n",
      "Train Epoch:6[24576/60000 (41%)]\t Loss:0.226526 acc:0.94\n",
      "Train Epoch:6[25088/60000 (42%)]\t Loss:0.172999 acc:0.95\n",
      "Train Epoch:6[25600/60000 (43%)]\t Loss:0.162944 acc:0.96\n",
      "Train Epoch:6[26112/60000 (44%)]\t Loss:0.212751 acc:0.93\n",
      "Train Epoch:6[26624/60000 (44%)]\t Loss:0.208886 acc:0.94\n",
      "Train Epoch:6[27136/60000 (45%)]\t Loss:0.210914 acc:0.94\n",
      "Train Epoch:6[27648/60000 (46%)]\t Loss:0.142204 acc:0.95\n",
      "Train Epoch:6[28160/60000 (47%)]\t Loss:0.219614 acc:0.94\n",
      "Train Epoch:6[28672/60000 (48%)]\t Loss:0.150849 acc:0.96\n",
      "Train Epoch:6[29184/60000 (49%)]\t Loss:0.169183 acc:0.95\n",
      "Train Epoch:6[29696/60000 (49%)]\t Loss:0.244234 acc:0.92\n",
      "Train Epoch:6[30208/60000 (50%)]\t Loss:0.164762 acc:0.95\n",
      "Train Epoch:6[30720/60000 (51%)]\t Loss:0.219485 acc:0.94\n",
      "Train Epoch:6[31232/60000 (52%)]\t Loss:0.250881 acc:0.93\n",
      "Train Epoch:6[31744/60000 (53%)]\t Loss:0.166176 acc:0.95\n",
      "Train Epoch:6[32256/60000 (54%)]\t Loss:0.199679 acc:0.94\n",
      "Train Epoch:6[32768/60000 (55%)]\t Loss:0.159346 acc:0.96\n",
      "Train Epoch:6[33280/60000 (55%)]\t Loss:0.186746 acc:0.95\n",
      "Train Epoch:6[33792/60000 (56%)]\t Loss:0.101241 acc:0.98\n",
      "Train Epoch:6[34304/60000 (57%)]\t Loss:0.228315 acc:0.92\n",
      "Train Epoch:6[34816/60000 (58%)]\t Loss:0.164488 acc:0.95\n",
      "Train Epoch:6[35328/60000 (59%)]\t Loss:0.144789 acc:0.97\n",
      "Train Epoch:6[35840/60000 (60%)]\t Loss:0.135872 acc:0.96\n",
      "Train Epoch:6[36352/60000 (61%)]\t Loss:0.162100 acc:0.95\n",
      "Train Epoch:6[36864/60000 (61%)]\t Loss:0.188102 acc:0.94\n",
      "Train Epoch:6[37376/60000 (62%)]\t Loss:0.207506 acc:0.94\n",
      "Train Epoch:6[37888/60000 (63%)]\t Loss:0.149097 acc:0.96\n",
      "Train Epoch:6[38400/60000 (64%)]\t Loss:0.148478 acc:0.95\n",
      "Train Epoch:6[38912/60000 (65%)]\t Loss:0.182711 acc:0.94\n",
      "Train Epoch:6[39424/60000 (66%)]\t Loss:0.182815 acc:0.95\n",
      "Train Epoch:6[39936/60000 (67%)]\t Loss:0.154203 acc:0.96\n",
      "Train Epoch:6[40448/60000 (67%)]\t Loss:0.152759 acc:0.95\n",
      "Train Epoch:6[40960/60000 (68%)]\t Loss:0.225627 acc:0.93\n",
      "Train Epoch:6[41472/60000 (69%)]\t Loss:0.157135 acc:0.95\n",
      "Train Epoch:6[41984/60000 (70%)]\t Loss:0.228289 acc:0.93\n",
      "Train Epoch:6[42496/60000 (71%)]\t Loss:0.216851 acc:0.95\n",
      "Train Epoch:6[43008/60000 (72%)]\t Loss:0.145052 acc:0.96\n",
      "Train Epoch:6[43520/60000 (73%)]\t Loss:0.173406 acc:0.95\n",
      "Train Epoch:6[44032/60000 (73%)]\t Loss:0.211925 acc:0.94\n",
      "Train Epoch:6[44544/60000 (74%)]\t Loss:0.187195 acc:0.94\n",
      "Train Epoch:6[45056/60000 (75%)]\t Loss:0.177038 acc:0.95\n",
      "Train Epoch:6[45568/60000 (76%)]\t Loss:0.208543 acc:0.94\n",
      "Train Epoch:6[46080/60000 (77%)]\t Loss:0.218276 acc:0.93\n",
      "Train Epoch:6[46592/60000 (78%)]\t Loss:0.157956 acc:0.95\n",
      "Train Epoch:6[47104/60000 (79%)]\t Loss:0.214871 acc:0.94\n",
      "Train Epoch:6[47616/60000 (79%)]\t Loss:0.147138 acc:0.96\n",
      "Train Epoch:6[48128/60000 (80%)]\t Loss:0.131857 acc:0.95\n",
      "Train Epoch:6[48640/60000 (81%)]\t Loss:0.217709 acc:0.93\n",
      "Train Epoch:6[49152/60000 (82%)]\t Loss:0.214581 acc:0.94\n",
      "Train Epoch:6[49664/60000 (83%)]\t Loss:0.174358 acc:0.95\n",
      "Train Epoch:6[50176/60000 (84%)]\t Loss:0.283799 acc:0.93\n",
      "Train Epoch:6[50688/60000 (84%)]\t Loss:0.144005 acc:0.95\n",
      "Train Epoch:6[51200/60000 (85%)]\t Loss:0.135768 acc:0.96\n",
      "Train Epoch:6[51712/60000 (86%)]\t Loss:0.207266 acc:0.94\n",
      "Train Epoch:6[52224/60000 (87%)]\t Loss:0.141179 acc:0.96\n",
      "Train Epoch:6[52736/60000 (88%)]\t Loss:0.239996 acc:0.94\n",
      "Train Epoch:6[53248/60000 (89%)]\t Loss:0.146185 acc:0.95\n",
      "Train Epoch:6[53760/60000 (90%)]\t Loss:0.201821 acc:0.94\n",
      "Train Epoch:6[54272/60000 (90%)]\t Loss:0.134956 acc:0.96\n",
      "Train Epoch:6[54784/60000 (91%)]\t Loss:0.190765 acc:0.92\n",
      "Train Epoch:6[55296/60000 (92%)]\t Loss:0.154772 acc:0.96\n",
      "Train Epoch:6[55808/60000 (93%)]\t Loss:0.132891 acc:0.96\n",
      "Train Epoch:6[56320/60000 (94%)]\t Loss:0.140393 acc:0.95\n",
      "Train Epoch:6[56832/60000 (95%)]\t Loss:0.119011 acc:0.96\n",
      "Train Epoch:6[57344/60000 (96%)]\t Loss:0.153662 acc:0.96\n",
      "Train Epoch:6[57856/60000 (96%)]\t Loss:0.096826 acc:0.97\n",
      "Train Epoch:6[58368/60000 (97%)]\t Loss:0.096636 acc:0.98\n",
      "Train Epoch:6[58880/60000 (98%)]\t Loss:0.074921 acc:0.98\n",
      "Train Epoch:6[59392/60000 (99%)]\t Loss:0.129171 acc:0.97\n",
      "Train Epoch:6[59904/60000 (100%)]\t Loss:0.244049 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:6 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:6 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:6 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:6 [1536/10000 (15%)]\t acc:0.19\n",
      "Test Epoch:6 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:6 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:6 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:6 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:6 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:6 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:6 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:6 [5632/10000 (56%)]\t acc:0.58\n",
      "Test Epoch:6 [6144/10000 (61%)]\t acc:0.63\n",
      "Test Epoch:6 [6656/10000 (67%)]\t acc:0.68\n",
      "Test Epoch:6 [7168/10000 (72%)]\t acc:0.73\n",
      "Test Epoch:6 [7680/10000 (77%)]\t acc:0.78\n",
      "Test Epoch:6 [8192/10000 (82%)]\t acc:0.83\n",
      "Test Epoch:6 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:6 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:6 [9728/10000 (97%)]\t acc:0.95\n",
      "Train Epoch:7[0/60000 (0%)]\t Loss:0.180058 acc:0.96\n",
      "Train Epoch:7[512/60000 (1%)]\t Loss:0.188210 acc:0.95\n",
      "Train Epoch:7[1024/60000 (2%)]\t Loss:0.243525 acc:0.92\n",
      "Train Epoch:7[1536/60000 (3%)]\t Loss:0.115367 acc:0.97\n",
      "Train Epoch:7[2048/60000 (3%)]\t Loss:0.120199 acc:0.96\n",
      "Train Epoch:7[2560/60000 (4%)]\t Loss:0.159044 acc:0.96\n",
      "Train Epoch:7[3072/60000 (5%)]\t Loss:0.126172 acc:0.96\n",
      "Train Epoch:7[3584/60000 (6%)]\t Loss:0.125564 acc:0.97\n",
      "Train Epoch:7[4096/60000 (7%)]\t Loss:0.151565 acc:0.96\n",
      "Train Epoch:7[4608/60000 (8%)]\t Loss:0.166255 acc:0.96\n",
      "Train Epoch:7[5120/60000 (9%)]\t Loss:0.169486 acc:0.95\n",
      "Train Epoch:7[5632/60000 (9%)]\t Loss:0.152527 acc:0.96\n",
      "Train Epoch:7[6144/60000 (10%)]\t Loss:0.132549 acc:0.96\n",
      "Train Epoch:7[6656/60000 (11%)]\t Loss:0.193919 acc:0.95\n",
      "Train Epoch:7[7168/60000 (12%)]\t Loss:0.171958 acc:0.95\n",
      "Train Epoch:7[7680/60000 (13%)]\t Loss:0.178079 acc:0.95\n",
      "Train Epoch:7[8192/60000 (14%)]\t Loss:0.206051 acc:0.93\n",
      "Train Epoch:7[8704/60000 (15%)]\t Loss:0.248112 acc:0.92\n",
      "Train Epoch:7[9216/60000 (15%)]\t Loss:0.168798 acc:0.95\n",
      "Train Epoch:7[9728/60000 (16%)]\t Loss:0.162475 acc:0.95\n",
      "Train Epoch:7[10240/60000 (17%)]\t Loss:0.153186 acc:0.96\n",
      "Train Epoch:7[10752/60000 (18%)]\t Loss:0.157673 acc:0.96\n",
      "Train Epoch:7[11264/60000 (19%)]\t Loss:0.185675 acc:0.95\n",
      "Train Epoch:7[11776/60000 (20%)]\t Loss:0.141731 acc:0.95\n",
      "Train Epoch:7[12288/60000 (20%)]\t Loss:0.226612 acc:0.93\n",
      "Train Epoch:7[12800/60000 (21%)]\t Loss:0.162371 acc:0.95\n",
      "Train Epoch:7[13312/60000 (22%)]\t Loss:0.141782 acc:0.96\n",
      "Train Epoch:7[13824/60000 (23%)]\t Loss:0.194621 acc:0.93\n",
      "Train Epoch:7[14336/60000 (24%)]\t Loss:0.233582 acc:0.92\n",
      "Train Epoch:7[14848/60000 (25%)]\t Loss:0.160084 acc:0.96\n",
      "Train Epoch:7[15360/60000 (26%)]\t Loss:0.175380 acc:0.95\n",
      "Train Epoch:7[15872/60000 (26%)]\t Loss:0.145030 acc:0.96\n",
      "Train Epoch:7[16384/60000 (27%)]\t Loss:0.171224 acc:0.95\n",
      "Train Epoch:7[16896/60000 (28%)]\t Loss:0.149559 acc:0.96\n",
      "Train Epoch:7[17408/60000 (29%)]\t Loss:0.180248 acc:0.95\n",
      "Train Epoch:7[17920/60000 (30%)]\t Loss:0.130243 acc:0.96\n",
      "Train Epoch:7[18432/60000 (31%)]\t Loss:0.129097 acc:0.97\n",
      "Train Epoch:7[18944/60000 (32%)]\t Loss:0.154019 acc:0.95\n",
      "Train Epoch:7[19456/60000 (32%)]\t Loss:0.142512 acc:0.96\n",
      "Train Epoch:7[19968/60000 (33%)]\t Loss:0.159784 acc:0.95\n",
      "Train Epoch:7[20480/60000 (34%)]\t Loss:0.247091 acc:0.94\n",
      "Train Epoch:7[20992/60000 (35%)]\t Loss:0.147955 acc:0.96\n",
      "Train Epoch:7[21504/60000 (36%)]\t Loss:0.120305 acc:0.97\n",
      "Train Epoch:7[22016/60000 (37%)]\t Loss:0.147350 acc:0.95\n",
      "Train Epoch:7[22528/60000 (38%)]\t Loss:0.153515 acc:0.94\n",
      "Train Epoch:7[23040/60000 (38%)]\t Loss:0.115853 acc:0.96\n",
      "Train Epoch:7[23552/60000 (39%)]\t Loss:0.167921 acc:0.95\n",
      "Train Epoch:7[24064/60000 (40%)]\t Loss:0.159272 acc:0.94\n",
      "Train Epoch:7[24576/60000 (41%)]\t Loss:0.204165 acc:0.94\n",
      "Train Epoch:7[25088/60000 (42%)]\t Loss:0.158225 acc:0.95\n",
      "Train Epoch:7[25600/60000 (43%)]\t Loss:0.148244 acc:0.96\n",
      "Train Epoch:7[26112/60000 (44%)]\t Loss:0.193090 acc:0.94\n",
      "Train Epoch:7[26624/60000 (44%)]\t Loss:0.183725 acc:0.95\n",
      "Train Epoch:7[27136/60000 (45%)]\t Loss:0.187168 acc:0.95\n",
      "Train Epoch:7[27648/60000 (46%)]\t Loss:0.128046 acc:0.96\n",
      "Train Epoch:7[28160/60000 (47%)]\t Loss:0.197584 acc:0.94\n",
      "Train Epoch:7[28672/60000 (48%)]\t Loss:0.133460 acc:0.96\n",
      "Train Epoch:7[29184/60000 (49%)]\t Loss:0.151266 acc:0.96\n",
      "Train Epoch:7[29696/60000 (49%)]\t Loss:0.220134 acc:0.92\n",
      "Train Epoch:7[30208/60000 (50%)]\t Loss:0.142776 acc:0.96\n",
      "Train Epoch:7[30720/60000 (51%)]\t Loss:0.192268 acc:0.94\n",
      "Train Epoch:7[31232/60000 (52%)]\t Loss:0.226186 acc:0.94\n",
      "Train Epoch:7[31744/60000 (53%)]\t Loss:0.146841 acc:0.96\n",
      "Train Epoch:7[32256/60000 (54%)]\t Loss:0.179568 acc:0.95\n",
      "Train Epoch:7[32768/60000 (55%)]\t Loss:0.138787 acc:0.97\n",
      "Train Epoch:7[33280/60000 (55%)]\t Loss:0.168849 acc:0.95\n",
      "Train Epoch:7[33792/60000 (56%)]\t Loss:0.090034 acc:0.98\n",
      "Train Epoch:7[34304/60000 (57%)]\t Loss:0.210561 acc:0.93\n",
      "Train Epoch:7[34816/60000 (58%)]\t Loss:0.143653 acc:0.96\n",
      "Train Epoch:7[35328/60000 (59%)]\t Loss:0.134818 acc:0.97\n",
      "Train Epoch:7[35840/60000 (60%)]\t Loss:0.125593 acc:0.96\n",
      "Train Epoch:7[36352/60000 (61%)]\t Loss:0.149358 acc:0.95\n",
      "Train Epoch:7[36864/60000 (61%)]\t Loss:0.174889 acc:0.94\n",
      "Train Epoch:7[37376/60000 (62%)]\t Loss:0.184984 acc:0.95\n",
      "Train Epoch:7[37888/60000 (63%)]\t Loss:0.126139 acc:0.96\n",
      "Train Epoch:7[38400/60000 (64%)]\t Loss:0.129999 acc:0.96\n",
      "Train Epoch:7[38912/60000 (65%)]\t Loss:0.163541 acc:0.95\n",
      "Train Epoch:7[39424/60000 (66%)]\t Loss:0.160615 acc:0.95\n",
      "Train Epoch:7[39936/60000 (67%)]\t Loss:0.135162 acc:0.96\n",
      "Train Epoch:7[40448/60000 (67%)]\t Loss:0.138046 acc:0.95\n",
      "Train Epoch:7[40960/60000 (68%)]\t Loss:0.211012 acc:0.94\n",
      "Train Epoch:7[41472/60000 (69%)]\t Loss:0.141646 acc:0.96\n",
      "Train Epoch:7[41984/60000 (70%)]\t Loss:0.202828 acc:0.93\n",
      "Train Epoch:7[42496/60000 (71%)]\t Loss:0.196662 acc:0.95\n",
      "Train Epoch:7[43008/60000 (72%)]\t Loss:0.130163 acc:0.96\n",
      "Train Epoch:7[43520/60000 (73%)]\t Loss:0.153121 acc:0.95\n",
      "Train Epoch:7[44032/60000 (73%)]\t Loss:0.186237 acc:0.95\n",
      "Train Epoch:7[44544/60000 (74%)]\t Loss:0.168419 acc:0.94\n",
      "Train Epoch:7[45056/60000 (75%)]\t Loss:0.158509 acc:0.95\n",
      "Train Epoch:7[45568/60000 (76%)]\t Loss:0.189098 acc:0.95\n",
      "Train Epoch:7[46080/60000 (77%)]\t Loss:0.204103 acc:0.94\n",
      "Train Epoch:7[46592/60000 (78%)]\t Loss:0.140942 acc:0.96\n",
      "Train Epoch:7[47104/60000 (79%)]\t Loss:0.204136 acc:0.94\n",
      "Train Epoch:7[47616/60000 (79%)]\t Loss:0.130372 acc:0.97\n",
      "Train Epoch:7[48128/60000 (80%)]\t Loss:0.111988 acc:0.96\n",
      "Train Epoch:7[48640/60000 (81%)]\t Loss:0.202232 acc:0.94\n",
      "Train Epoch:7[49152/60000 (82%)]\t Loss:0.199132 acc:0.94\n",
      "Train Epoch:7[49664/60000 (83%)]\t Loss:0.158544 acc:0.96\n",
      "Train Epoch:7[50176/60000 (84%)]\t Loss:0.258232 acc:0.94\n",
      "Train Epoch:7[50688/60000 (84%)]\t Loss:0.125175 acc:0.95\n",
      "Train Epoch:7[51200/60000 (85%)]\t Loss:0.121100 acc:0.97\n",
      "Train Epoch:7[51712/60000 (86%)]\t Loss:0.183821 acc:0.94\n",
      "Train Epoch:7[52224/60000 (87%)]\t Loss:0.123203 acc:0.96\n",
      "Train Epoch:7[52736/60000 (88%)]\t Loss:0.214704 acc:0.95\n",
      "Train Epoch:7[53248/60000 (89%)]\t Loss:0.134857 acc:0.95\n",
      "Train Epoch:7[53760/60000 (90%)]\t Loss:0.183800 acc:0.94\n",
      "Train Epoch:7[54272/60000 (90%)]\t Loss:0.120715 acc:0.97\n",
      "Train Epoch:7[54784/60000 (91%)]\t Loss:0.172259 acc:0.93\n",
      "Train Epoch:7[55296/60000 (92%)]\t Loss:0.144127 acc:0.96\n",
      "Train Epoch:7[55808/60000 (93%)]\t Loss:0.124391 acc:0.96\n",
      "Train Epoch:7[56320/60000 (94%)]\t Loss:0.125942 acc:0.96\n",
      "Train Epoch:7[56832/60000 (95%)]\t Loss:0.104304 acc:0.97\n",
      "Train Epoch:7[57344/60000 (96%)]\t Loss:0.136087 acc:0.96\n",
      "Train Epoch:7[57856/60000 (96%)]\t Loss:0.086065 acc:0.97\n",
      "Train Epoch:7[58368/60000 (97%)]\t Loss:0.081981 acc:0.98\n",
      "Train Epoch:7[58880/60000 (98%)]\t Loss:0.064603 acc:0.98\n",
      "Train Epoch:7[59392/60000 (99%)]\t Loss:0.123624 acc:0.97\n",
      "Train Epoch:7[59904/60000 (100%)]\t Loss:0.227798 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:7 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:7 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:7 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:7 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:7 [2048/10000 (20%)]\t acc:0.24\n",
      "Test Epoch:7 [2560/10000 (26%)]\t acc:0.29\n",
      "Test Epoch:7 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:7 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:7 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:7 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:7 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:7 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:7 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:7 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:7 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:7 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:7 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:7 [8704/10000 (87%)]\t acc:0.88\n",
      "Test Epoch:7 [9216/10000 (92%)]\t acc:0.93\n",
      "Test Epoch:7 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:8[0/60000 (0%)]\t Loss:0.165751 acc:0.96\n",
      "Train Epoch:8[512/60000 (1%)]\t Loss:0.170343 acc:0.95\n",
      "Train Epoch:8[1024/60000 (2%)]\t Loss:0.226057 acc:0.93\n",
      "Train Epoch:8[1536/60000 (3%)]\t Loss:0.103162 acc:0.97\n",
      "Train Epoch:8[2048/60000 (3%)]\t Loss:0.104264 acc:0.97\n",
      "Train Epoch:8[2560/60000 (4%)]\t Loss:0.143691 acc:0.96\n",
      "Train Epoch:8[3072/60000 (5%)]\t Loss:0.110592 acc:0.97\n",
      "Train Epoch:8[3584/60000 (6%)]\t Loss:0.108890 acc:0.97\n",
      "Train Epoch:8[4096/60000 (7%)]\t Loss:0.137107 acc:0.96\n",
      "Train Epoch:8[4608/60000 (8%)]\t Loss:0.149845 acc:0.96\n",
      "Train Epoch:8[5120/60000 (9%)]\t Loss:0.153283 acc:0.95\n",
      "Train Epoch:8[5632/60000 (9%)]\t Loss:0.141140 acc:0.96\n",
      "Train Epoch:8[6144/60000 (10%)]\t Loss:0.122365 acc:0.96\n",
      "Train Epoch:8[6656/60000 (11%)]\t Loss:0.180718 acc:0.95\n",
      "Train Epoch:8[7168/60000 (12%)]\t Loss:0.152999 acc:0.95\n",
      "Train Epoch:8[7680/60000 (13%)]\t Loss:0.161991 acc:0.95\n",
      "Train Epoch:8[8192/60000 (14%)]\t Loss:0.186603 acc:0.94\n",
      "Train Epoch:8[8704/60000 (15%)]\t Loss:0.230134 acc:0.92\n",
      "Train Epoch:8[9216/60000 (15%)]\t Loss:0.152235 acc:0.95\n",
      "Train Epoch:8[9728/60000 (16%)]\t Loss:0.149156 acc:0.95\n",
      "Train Epoch:8[10240/60000 (17%)]\t Loss:0.141156 acc:0.96\n",
      "Train Epoch:8[10752/60000 (18%)]\t Loss:0.145666 acc:0.96\n",
      "Train Epoch:8[11264/60000 (19%)]\t Loss:0.167563 acc:0.95\n",
      "Train Epoch:8[11776/60000 (20%)]\t Loss:0.124533 acc:0.96\n",
      "Train Epoch:8[12288/60000 (20%)]\t Loss:0.204043 acc:0.94\n",
      "Train Epoch:8[12800/60000 (21%)]\t Loss:0.146600 acc:0.95\n",
      "Train Epoch:8[13312/60000 (22%)]\t Loss:0.126546 acc:0.97\n",
      "Train Epoch:8[13824/60000 (23%)]\t Loss:0.174229 acc:0.94\n",
      "Train Epoch:8[14336/60000 (24%)]\t Loss:0.204621 acc:0.93\n",
      "Train Epoch:8[14848/60000 (25%)]\t Loss:0.142756 acc:0.96\n",
      "Train Epoch:8[15360/60000 (26%)]\t Loss:0.160073 acc:0.95\n",
      "Train Epoch:8[15872/60000 (26%)]\t Loss:0.134151 acc:0.96\n",
      "Train Epoch:8[16384/60000 (27%)]\t Loss:0.152611 acc:0.95\n",
      "Train Epoch:8[16896/60000 (28%)]\t Loss:0.137648 acc:0.96\n",
      "Train Epoch:8[17408/60000 (29%)]\t Loss:0.165751 acc:0.95\n",
      "Train Epoch:8[17920/60000 (30%)]\t Loss:0.120218 acc:0.96\n",
      "Train Epoch:8[18432/60000 (31%)]\t Loss:0.110765 acc:0.97\n",
      "Train Epoch:8[18944/60000 (32%)]\t Loss:0.136016 acc:0.96\n",
      "Train Epoch:8[19456/60000 (32%)]\t Loss:0.131385 acc:0.96\n",
      "Train Epoch:8[19968/60000 (33%)]\t Loss:0.143641 acc:0.95\n",
      "Train Epoch:8[20480/60000 (34%)]\t Loss:0.226286 acc:0.95\n",
      "Train Epoch:8[20992/60000 (35%)]\t Loss:0.136279 acc:0.96\n",
      "Train Epoch:8[21504/60000 (36%)]\t Loss:0.111523 acc:0.97\n",
      "Train Epoch:8[22016/60000 (37%)]\t Loss:0.137187 acc:0.96\n",
      "Train Epoch:8[22528/60000 (38%)]\t Loss:0.145225 acc:0.95\n",
      "Train Epoch:8[23040/60000 (38%)]\t Loss:0.100746 acc:0.97\n",
      "Train Epoch:8[23552/60000 (39%)]\t Loss:0.151271 acc:0.96\n",
      "Train Epoch:8[24064/60000 (40%)]\t Loss:0.136537 acc:0.95\n",
      "Train Epoch:8[24576/60000 (41%)]\t Loss:0.183254 acc:0.95\n",
      "Train Epoch:8[25088/60000 (42%)]\t Loss:0.144149 acc:0.96\n",
      "Train Epoch:8[25600/60000 (43%)]\t Loss:0.136601 acc:0.96\n",
      "Train Epoch:8[26112/60000 (44%)]\t Loss:0.178801 acc:0.94\n",
      "Train Epoch:8[26624/60000 (44%)]\t Loss:0.165194 acc:0.95\n",
      "Train Epoch:8[27136/60000 (45%)]\t Loss:0.170093 acc:0.95\n",
      "Train Epoch:8[27648/60000 (46%)]\t Loss:0.118761 acc:0.96\n",
      "Train Epoch:8[28160/60000 (47%)]\t Loss:0.180372 acc:0.95\n",
      "Train Epoch:8[28672/60000 (48%)]\t Loss:0.121247 acc:0.96\n",
      "Train Epoch:8[29184/60000 (49%)]\t Loss:0.136840 acc:0.96\n",
      "Train Epoch:8[29696/60000 (49%)]\t Loss:0.201961 acc:0.93\n",
      "Train Epoch:8[30208/60000 (50%)]\t Loss:0.124911 acc:0.96\n",
      "Train Epoch:8[30720/60000 (51%)]\t Loss:0.170319 acc:0.94\n",
      "Train Epoch:8[31232/60000 (52%)]\t Loss:0.206148 acc:0.94\n",
      "Train Epoch:8[31744/60000 (53%)]\t Loss:0.134002 acc:0.96\n",
      "Train Epoch:8[32256/60000 (54%)]\t Loss:0.166141 acc:0.95\n",
      "Train Epoch:8[32768/60000 (55%)]\t Loss:0.123958 acc:0.97\n",
      "Train Epoch:8[33280/60000 (55%)]\t Loss:0.155287 acc:0.95\n",
      "Train Epoch:8[33792/60000 (56%)]\t Loss:0.081813 acc:0.98\n",
      "Train Epoch:8[34304/60000 (57%)]\t Loss:0.192085 acc:0.94\n",
      "Train Epoch:8[34816/60000 (58%)]\t Loss:0.127585 acc:0.96\n",
      "Train Epoch:8[35328/60000 (59%)]\t Loss:0.126050 acc:0.97\n",
      "Train Epoch:8[35840/60000 (60%)]\t Loss:0.116416 acc:0.96\n",
      "Train Epoch:8[36352/60000 (61%)]\t Loss:0.138933 acc:0.95\n",
      "Train Epoch:8[36864/60000 (61%)]\t Loss:0.166218 acc:0.95\n",
      "Train Epoch:8[37376/60000 (62%)]\t Loss:0.168862 acc:0.95\n",
      "Train Epoch:8[37888/60000 (63%)]\t Loss:0.108305 acc:0.96\n",
      "Train Epoch:8[38400/60000 (64%)]\t Loss:0.116848 acc:0.96\n",
      "Train Epoch:8[38912/60000 (65%)]\t Loss:0.149027 acc:0.96\n",
      "Train Epoch:8[39424/60000 (66%)]\t Loss:0.143720 acc:0.96\n",
      "Train Epoch:8[39936/60000 (67%)]\t Loss:0.117765 acc:0.96\n",
      "Train Epoch:8[40448/60000 (67%)]\t Loss:0.124259 acc:0.95\n",
      "Train Epoch:8[40960/60000 (68%)]\t Loss:0.194850 acc:0.94\n",
      "Train Epoch:8[41472/60000 (69%)]\t Loss:0.129220 acc:0.96\n",
      "Train Epoch:8[41984/60000 (70%)]\t Loss:0.185308 acc:0.93\n",
      "Train Epoch:8[42496/60000 (71%)]\t Loss:0.182745 acc:0.95\n",
      "Train Epoch:8[43008/60000 (72%)]\t Loss:0.119660 acc:0.96\n",
      "Train Epoch:8[43520/60000 (73%)]\t Loss:0.138119 acc:0.96\n",
      "Train Epoch:8[44032/60000 (73%)]\t Loss:0.166805 acc:0.95\n",
      "Train Epoch:8[44544/60000 (74%)]\t Loss:0.153307 acc:0.95\n",
      "Train Epoch:8[45056/60000 (75%)]\t Loss:0.143379 acc:0.96\n",
      "Train Epoch:8[45568/60000 (76%)]\t Loss:0.173980 acc:0.95\n",
      "Train Epoch:8[46080/60000 (77%)]\t Loss:0.189147 acc:0.94\n",
      "Train Epoch:8[46592/60000 (78%)]\t Loss:0.127141 acc:0.96\n",
      "Train Epoch:8[47104/60000 (79%)]\t Loss:0.192547 acc:0.94\n",
      "Train Epoch:8[47616/60000 (79%)]\t Loss:0.118418 acc:0.97\n",
      "Train Epoch:8[48128/60000 (80%)]\t Loss:0.097034 acc:0.96\n",
      "Train Epoch:8[48640/60000 (81%)]\t Loss:0.190293 acc:0.95\n",
      "Train Epoch:8[49152/60000 (82%)]\t Loss:0.188818 acc:0.94\n",
      "Train Epoch:8[49664/60000 (83%)]\t Loss:0.145356 acc:0.96\n",
      "Train Epoch:8[50176/60000 (84%)]\t Loss:0.236057 acc:0.94\n",
      "Train Epoch:8[50688/60000 (84%)]\t Loss:0.112664 acc:0.96\n",
      "Train Epoch:8[51200/60000 (85%)]\t Loss:0.111471 acc:0.97\n",
      "Train Epoch:8[51712/60000 (86%)]\t Loss:0.166665 acc:0.95\n",
      "Train Epoch:8[52224/60000 (87%)]\t Loss:0.110317 acc:0.97\n",
      "Train Epoch:8[52736/60000 (88%)]\t Loss:0.195549 acc:0.95\n",
      "Train Epoch:8[53248/60000 (89%)]\t Loss:0.125452 acc:0.96\n",
      "Train Epoch:8[53760/60000 (90%)]\t Loss:0.167415 acc:0.95\n",
      "Train Epoch:8[54272/60000 (90%)]\t Loss:0.110267 acc:0.97\n",
      "Train Epoch:8[54784/60000 (91%)]\t Loss:0.155650 acc:0.94\n",
      "Train Epoch:8[55296/60000 (92%)]\t Loss:0.136020 acc:0.96\n",
      "Train Epoch:8[55808/60000 (93%)]\t Loss:0.117597 acc:0.97\n",
      "Train Epoch:8[56320/60000 (94%)]\t Loss:0.116333 acc:0.96\n",
      "Train Epoch:8[56832/60000 (95%)]\t Loss:0.093001 acc:0.97\n",
      "Train Epoch:8[57344/60000 (96%)]\t Loss:0.123403 acc:0.97\n",
      "Train Epoch:8[57856/60000 (96%)]\t Loss:0.078857 acc:0.97\n",
      "Train Epoch:8[58368/60000 (97%)]\t Loss:0.071806 acc:0.99\n",
      "Train Epoch:8[58880/60000 (98%)]\t Loss:0.056755 acc:0.99\n",
      "Train Epoch:8[59392/60000 (99%)]\t Loss:0.117761 acc:0.97\n",
      "Train Epoch:8[59904/60000 (100%)]\t Loss:0.222213 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:8 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:8 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:8 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:8 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:8 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:8 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:8 [3072/10000 (31%)]\t acc:0.34\n",
      "Test Epoch:8 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:8 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:8 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:8 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:8 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:8 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:8 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:8 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:8 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:8 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:8 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:8 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:8 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:9[0/60000 (0%)]\t Loss:0.154570 acc:0.96\n",
      "Train Epoch:9[512/60000 (1%)]\t Loss:0.155736 acc:0.96\n",
      "Train Epoch:9[1024/60000 (2%)]\t Loss:0.210865 acc:0.93\n",
      "Train Epoch:9[1536/60000 (3%)]\t Loss:0.093679 acc:0.98\n",
      "Train Epoch:9[2048/60000 (3%)]\t Loss:0.092626 acc:0.97\n",
      "Train Epoch:9[2560/60000 (4%)]\t Loss:0.132226 acc:0.97\n",
      "Train Epoch:9[3072/60000 (5%)]\t Loss:0.098448 acc:0.97\n",
      "Train Epoch:9[3584/60000 (6%)]\t Loss:0.097595 acc:0.97\n",
      "Train Epoch:9[4096/60000 (7%)]\t Loss:0.129218 acc:0.97\n",
      "Train Epoch:9[4608/60000 (8%)]\t Loss:0.139974 acc:0.96\n",
      "Train Epoch:9[5120/60000 (9%)]\t Loss:0.141771 acc:0.96\n",
      "Train Epoch:9[5632/60000 (9%)]\t Loss:0.133049 acc:0.96\n",
      "Train Epoch:9[6144/60000 (10%)]\t Loss:0.117798 acc:0.96\n",
      "Train Epoch:9[6656/60000 (11%)]\t Loss:0.170511 acc:0.95\n",
      "Train Epoch:9[7168/60000 (12%)]\t Loss:0.139927 acc:0.96\n",
      "Train Epoch:9[7680/60000 (13%)]\t Loss:0.150776 acc:0.95\n",
      "Train Epoch:9[8192/60000 (14%)]\t Loss:0.172421 acc:0.94\n",
      "Train Epoch:9[8704/60000 (15%)]\t Loss:0.215207 acc:0.93\n",
      "Train Epoch:9[9216/60000 (15%)]\t Loss:0.140398 acc:0.95\n",
      "Train Epoch:9[9728/60000 (16%)]\t Loss:0.137625 acc:0.95\n",
      "Train Epoch:9[10240/60000 (17%)]\t Loss:0.128982 acc:0.96\n",
      "Train Epoch:9[10752/60000 (18%)]\t Loss:0.136202 acc:0.96\n",
      "Train Epoch:9[11264/60000 (19%)]\t Loss:0.153761 acc:0.96\n",
      "Train Epoch:9[11776/60000 (20%)]\t Loss:0.111786 acc:0.96\n",
      "Train Epoch:9[12288/60000 (20%)]\t Loss:0.185462 acc:0.95\n",
      "Train Epoch:9[12800/60000 (21%)]\t Loss:0.135506 acc:0.96\n",
      "Train Epoch:9[13312/60000 (22%)]\t Loss:0.113995 acc:0.97\n",
      "Train Epoch:9[13824/60000 (23%)]\t Loss:0.158189 acc:0.95\n",
      "Train Epoch:9[14336/60000 (24%)]\t Loss:0.182576 acc:0.93\n",
      "Train Epoch:9[14848/60000 (25%)]\t Loss:0.128741 acc:0.96\n",
      "Train Epoch:9[15360/60000 (26%)]\t Loss:0.145858 acc:0.96\n",
      "Train Epoch:9[15872/60000 (26%)]\t Loss:0.124721 acc:0.96\n",
      "Train Epoch:9[16384/60000 (27%)]\t Loss:0.137229 acc:0.96\n",
      "Train Epoch:9[16896/60000 (28%)]\t Loss:0.128250 acc:0.96\n",
      "Train Epoch:9[17408/60000 (29%)]\t Loss:0.153126 acc:0.96\n",
      "Train Epoch:9[17920/60000 (30%)]\t Loss:0.113385 acc:0.96\n",
      "Train Epoch:9[18432/60000 (31%)]\t Loss:0.097123 acc:0.97\n",
      "Train Epoch:9[18944/60000 (32%)]\t Loss:0.123843 acc:0.96\n",
      "Train Epoch:9[19456/60000 (32%)]\t Loss:0.121713 acc:0.96\n",
      "Train Epoch:9[19968/60000 (33%)]\t Loss:0.129489 acc:0.96\n",
      "Train Epoch:9[20480/60000 (34%)]\t Loss:0.211174 acc:0.95\n",
      "Train Epoch:9[20992/60000 (35%)]\t Loss:0.125402 acc:0.96\n",
      "Train Epoch:9[21504/60000 (36%)]\t Loss:0.105338 acc:0.97\n",
      "Train Epoch:9[22016/60000 (37%)]\t Loss:0.128410 acc:0.96\n",
      "Train Epoch:9[22528/60000 (38%)]\t Loss:0.138099 acc:0.95\n",
      "Train Epoch:9[23040/60000 (38%)]\t Loss:0.089348 acc:0.97\n",
      "Train Epoch:9[23552/60000 (39%)]\t Loss:0.139154 acc:0.96\n",
      "Train Epoch:9[24064/60000 (40%)]\t Loss:0.119586 acc:0.97\n",
      "Train Epoch:9[24576/60000 (41%)]\t Loss:0.167512 acc:0.95\n",
      "Train Epoch:9[25088/60000 (42%)]\t Loss:0.130464 acc:0.96\n",
      "Train Epoch:9[25600/60000 (43%)]\t Loss:0.126487 acc:0.96\n",
      "Train Epoch:9[26112/60000 (44%)]\t Loss:0.166877 acc:0.94\n",
      "Train Epoch:9[26624/60000 (44%)]\t Loss:0.149813 acc:0.96\n",
      "Train Epoch:9[27136/60000 (45%)]\t Loss:0.156588 acc:0.95\n",
      "Train Epoch:9[27648/60000 (46%)]\t Loss:0.111949 acc:0.96\n",
      "Train Epoch:9[28160/60000 (47%)]\t Loss:0.167236 acc:0.95\n",
      "Train Epoch:9[28672/60000 (48%)]\t Loss:0.114096 acc:0.96\n",
      "Train Epoch:9[29184/60000 (49%)]\t Loss:0.125431 acc:0.96\n",
      "Train Epoch:9[29696/60000 (49%)]\t Loss:0.186776 acc:0.94\n",
      "Train Epoch:9[30208/60000 (50%)]\t Loss:0.111209 acc:0.96\n",
      "Train Epoch:9[30720/60000 (51%)]\t Loss:0.153190 acc:0.96\n",
      "Train Epoch:9[31232/60000 (52%)]\t Loss:0.189397 acc:0.95\n",
      "Train Epoch:9[31744/60000 (53%)]\t Loss:0.123663 acc:0.96\n",
      "Train Epoch:9[32256/60000 (54%)]\t Loss:0.155618 acc:0.95\n",
      "Train Epoch:9[32768/60000 (55%)]\t Loss:0.112743 acc:0.97\n",
      "Train Epoch:9[33280/60000 (55%)]\t Loss:0.143506 acc:0.96\n",
      "Train Epoch:9[33792/60000 (56%)]\t Loss:0.075300 acc:0.98\n",
      "Train Epoch:9[34304/60000 (57%)]\t Loss:0.174021 acc:0.94\n",
      "Train Epoch:9[34816/60000 (58%)]\t Loss:0.116390 acc:0.97\n",
      "Train Epoch:9[35328/60000 (59%)]\t Loss:0.119446 acc:0.96\n",
      "Train Epoch:9[35840/60000 (60%)]\t Loss:0.106836 acc:0.96\n",
      "Train Epoch:9[36352/60000 (61%)]\t Loss:0.130105 acc:0.96\n",
      "Train Epoch:9[36864/60000 (61%)]\t Loss:0.158653 acc:0.95\n",
      "Train Epoch:9[37376/60000 (62%)]\t Loss:0.157366 acc:0.95\n",
      "Train Epoch:9[37888/60000 (63%)]\t Loss:0.096598 acc:0.97\n",
      "Train Epoch:9[38400/60000 (64%)]\t Loss:0.107580 acc:0.96\n",
      "Train Epoch:9[38912/60000 (65%)]\t Loss:0.136535 acc:0.96\n",
      "Train Epoch:9[39424/60000 (66%)]\t Loss:0.130507 acc:0.96\n",
      "Train Epoch:9[39936/60000 (67%)]\t Loss:0.102173 acc:0.97\n",
      "Train Epoch:9[40448/60000 (67%)]\t Loss:0.112521 acc:0.96\n",
      "Train Epoch:9[40960/60000 (68%)]\t Loss:0.178904 acc:0.94\n",
      "Train Epoch:9[41472/60000 (69%)]\t Loss:0.117946 acc:0.96\n",
      "Train Epoch:9[41984/60000 (70%)]\t Loss:0.170614 acc:0.94\n",
      "Train Epoch:9[42496/60000 (71%)]\t Loss:0.172572 acc:0.96\n",
      "Train Epoch:9[43008/60000 (72%)]\t Loss:0.112109 acc:0.96\n",
      "Train Epoch:9[43520/60000 (73%)]\t Loss:0.125116 acc:0.96\n",
      "Train Epoch:9[44032/60000 (73%)]\t Loss:0.153399 acc:0.95\n",
      "Train Epoch:9[44544/60000 (74%)]\t Loss:0.142077 acc:0.96\n",
      "Train Epoch:9[45056/60000 (75%)]\t Loss:0.131437 acc:0.96\n",
      "Train Epoch:9[45568/60000 (76%)]\t Loss:0.161753 acc:0.95\n",
      "Train Epoch:9[46080/60000 (77%)]\t Loss:0.175981 acc:0.95\n",
      "Train Epoch:9[46592/60000 (78%)]\t Loss:0.116407 acc:0.97\n",
      "Train Epoch:9[47104/60000 (79%)]\t Loss:0.178166 acc:0.94\n",
      "Train Epoch:9[47616/60000 (79%)]\t Loss:0.110094 acc:0.97\n",
      "Train Epoch:9[48128/60000 (80%)]\t Loss:0.085922 acc:0.97\n",
      "Train Epoch:9[48640/60000 (81%)]\t Loss:0.181203 acc:0.95\n",
      "Train Epoch:9[49152/60000 (82%)]\t Loss:0.180919 acc:0.94\n",
      "Train Epoch:9[49664/60000 (83%)]\t Loss:0.136126 acc:0.97\n",
      "Train Epoch:9[50176/60000 (84%)]\t Loss:0.215530 acc:0.95\n",
      "Train Epoch:9[50688/60000 (84%)]\t Loss:0.101214 acc:0.97\n",
      "Train Epoch:9[51200/60000 (85%)]\t Loss:0.104272 acc:0.97\n",
      "Train Epoch:9[51712/60000 (86%)]\t Loss:0.154417 acc:0.95\n",
      "Train Epoch:9[52224/60000 (87%)]\t Loss:0.101491 acc:0.97\n",
      "Train Epoch:9[52736/60000 (88%)]\t Loss:0.180174 acc:0.96\n",
      "Train Epoch:9[53248/60000 (89%)]\t Loss:0.118066 acc:0.96\n",
      "Train Epoch:9[53760/60000 (90%)]\t Loss:0.155501 acc:0.96\n",
      "Train Epoch:9[54272/60000 (90%)]\t Loss:0.101375 acc:0.98\n",
      "Train Epoch:9[54784/60000 (91%)]\t Loss:0.141350 acc:0.94\n",
      "Train Epoch:9[55296/60000 (92%)]\t Loss:0.129572 acc:0.96\n",
      "Train Epoch:9[55808/60000 (93%)]\t Loss:0.111542 acc:0.97\n",
      "Train Epoch:9[56320/60000 (94%)]\t Loss:0.108986 acc:0.97\n",
      "Train Epoch:9[56832/60000 (95%)]\t Loss:0.083650 acc:0.97\n",
      "Train Epoch:9[57344/60000 (96%)]\t Loss:0.114352 acc:0.96\n",
      "Train Epoch:9[57856/60000 (96%)]\t Loss:0.074706 acc:0.98\n",
      "Train Epoch:9[58368/60000 (97%)]\t Loss:0.065308 acc:0.99\n",
      "Train Epoch:9[58880/60000 (98%)]\t Loss:0.051109 acc:0.99\n",
      "Train Epoch:9[59392/60000 (99%)]\t Loss:0.112533 acc:0.98\n",
      "Train Epoch:9[59904/60000 (100%)]\t Loss:0.221967 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:9 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:9 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:9 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:9 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:9 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:9 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:9 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:9 [3584/10000 (36%)]\t acc:0.39\n",
      "Test Epoch:9 [4096/10000 (41%)]\t acc:0.44\n",
      "Test Epoch:9 [4608/10000 (46%)]\t acc:0.49\n",
      "Test Epoch:9 [5120/10000 (51%)]\t acc:0.54\n",
      "Test Epoch:9 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:9 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:9 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:9 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:9 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:9 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:9 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:9 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:9 [9728/10000 (97%)]\t acc:0.96\n",
      "Train Epoch:10[0/60000 (0%)]\t Loss:0.146277 acc:0.96\n",
      "Train Epoch:10[512/60000 (1%)]\t Loss:0.142310 acc:0.96\n",
      "Train Epoch:10[1024/60000 (2%)]\t Loss:0.195941 acc:0.94\n",
      "Train Epoch:10[1536/60000 (3%)]\t Loss:0.086832 acc:0.98\n",
      "Train Epoch:10[2048/60000 (3%)]\t Loss:0.084459 acc:0.98\n",
      "Train Epoch:10[2560/60000 (4%)]\t Loss:0.125791 acc:0.97\n",
      "Train Epoch:10[3072/60000 (5%)]\t Loss:0.088791 acc:0.97\n",
      "Train Epoch:10[3584/60000 (6%)]\t Loss:0.088692 acc:0.97\n",
      "Train Epoch:10[4096/60000 (7%)]\t Loss:0.122748 acc:0.97\n",
      "Train Epoch:10[4608/60000 (8%)]\t Loss:0.134215 acc:0.96\n",
      "Train Epoch:10[5120/60000 (9%)]\t Loss:0.133321 acc:0.96\n",
      "Train Epoch:10[5632/60000 (9%)]\t Loss:0.126833 acc:0.96\n",
      "Train Epoch:10[6144/60000 (10%)]\t Loss:0.116791 acc:0.97\n",
      "Train Epoch:10[6656/60000 (11%)]\t Loss:0.163163 acc:0.96\n",
      "Train Epoch:10[7168/60000 (12%)]\t Loss:0.130377 acc:0.96\n",
      "Train Epoch:10[7680/60000 (13%)]\t Loss:0.140888 acc:0.96\n",
      "Train Epoch:10[8192/60000 (14%)]\t Loss:0.162717 acc:0.95\n",
      "Train Epoch:10[8704/60000 (15%)]\t Loss:0.203455 acc:0.94\n",
      "Train Epoch:10[9216/60000 (15%)]\t Loss:0.132019 acc:0.96\n",
      "Train Epoch:10[9728/60000 (16%)]\t Loss:0.126504 acc:0.95\n",
      "Train Epoch:10[10240/60000 (17%)]\t Loss:0.119172 acc:0.96\n",
      "Train Epoch:10[10752/60000 (18%)]\t Loss:0.128087 acc:0.96\n",
      "Train Epoch:10[11264/60000 (19%)]\t Loss:0.143202 acc:0.96\n",
      "Train Epoch:10[11776/60000 (20%)]\t Loss:0.102479 acc:0.96\n",
      "Train Epoch:10[12288/60000 (20%)]\t Loss:0.169496 acc:0.95\n",
      "Train Epoch:10[12800/60000 (21%)]\t Loss:0.127249 acc:0.96\n",
      "Train Epoch:10[13312/60000 (22%)]\t Loss:0.105145 acc:0.98\n",
      "Train Epoch:10[13824/60000 (23%)]\t Loss:0.145240 acc:0.96\n",
      "Train Epoch:10[14336/60000 (24%)]\t Loss:0.166731 acc:0.93\n",
      "Train Epoch:10[14848/60000 (25%)]\t Loss:0.117524 acc:0.96\n",
      "Train Epoch:10[15360/60000 (26%)]\t Loss:0.133035 acc:0.96\n",
      "Train Epoch:10[15872/60000 (26%)]\t Loss:0.117577 acc:0.96\n",
      "Train Epoch:10[16384/60000 (27%)]\t Loss:0.125223 acc:0.96\n",
      "Train Epoch:10[16896/60000 (28%)]\t Loss:0.118464 acc:0.97\n",
      "Train Epoch:10[17408/60000 (29%)]\t Loss:0.142745 acc:0.96\n",
      "Train Epoch:10[17920/60000 (30%)]\t Loss:0.108076 acc:0.96\n",
      "Train Epoch:10[18432/60000 (31%)]\t Loss:0.086547 acc:0.97\n",
      "Train Epoch:10[18944/60000 (32%)]\t Loss:0.115426 acc:0.96\n",
      "Train Epoch:10[19456/60000 (32%)]\t Loss:0.115402 acc:0.96\n",
      "Train Epoch:10[19968/60000 (33%)]\t Loss:0.118746 acc:0.96\n",
      "Train Epoch:10[20480/60000 (34%)]\t Loss:0.199268 acc:0.96\n",
      "Train Epoch:10[20992/60000 (35%)]\t Loss:0.115118 acc:0.97\n",
      "Train Epoch:10[21504/60000 (36%)]\t Loss:0.099953 acc:0.97\n",
      "Train Epoch:10[22016/60000 (37%)]\t Loss:0.120147 acc:0.96\n",
      "Train Epoch:10[22528/60000 (38%)]\t Loss:0.130154 acc:0.95\n",
      "Train Epoch:10[23040/60000 (38%)]\t Loss:0.080245 acc:0.98\n",
      "Train Epoch:10[23552/60000 (39%)]\t Loss:0.129861 acc:0.97\n",
      "Train Epoch:10[24064/60000 (40%)]\t Loss:0.106728 acc:0.97\n",
      "Train Epoch:10[24576/60000 (41%)]\t Loss:0.154499 acc:0.96\n",
      "Train Epoch:10[25088/60000 (42%)]\t Loss:0.118998 acc:0.97\n",
      "Train Epoch:10[25600/60000 (43%)]\t Loss:0.117480 acc:0.96\n",
      "Train Epoch:10[26112/60000 (44%)]\t Loss:0.156142 acc:0.95\n",
      "Train Epoch:10[26624/60000 (44%)]\t Loss:0.136643 acc:0.96\n",
      "Train Epoch:10[27136/60000 (45%)]\t Loss:0.143440 acc:0.96\n",
      "Train Epoch:10[27648/60000 (46%)]\t Loss:0.106391 acc:0.96\n",
      "Train Epoch:10[28160/60000 (47%)]\t Loss:0.156568 acc:0.96\n",
      "Train Epoch:10[28672/60000 (48%)]\t Loss:0.107080 acc:0.97\n",
      "Train Epoch:10[29184/60000 (49%)]\t Loss:0.117092 acc:0.97\n",
      "Train Epoch:10[29696/60000 (49%)]\t Loss:0.177283 acc:0.94\n",
      "Train Epoch:10[30208/60000 (50%)]\t Loss:0.101573 acc:0.97\n",
      "Train Epoch:10[30720/60000 (51%)]\t Loss:0.137900 acc:0.96\n",
      "Train Epoch:10[31232/60000 (52%)]\t Loss:0.173696 acc:0.95\n",
      "Train Epoch:10[31744/60000 (53%)]\t Loss:0.114633 acc:0.96\n",
      "Train Epoch:10[32256/60000 (54%)]\t Loss:0.146085 acc:0.95\n",
      "Train Epoch:10[32768/60000 (55%)]\t Loss:0.104485 acc:0.97\n",
      "Train Epoch:10[33280/60000 (55%)]\t Loss:0.134414 acc:0.96\n",
      "Train Epoch:10[33792/60000 (56%)]\t Loss:0.070058 acc:0.98\n",
      "Train Epoch:10[34304/60000 (57%)]\t Loss:0.161270 acc:0.95\n",
      "Train Epoch:10[34816/60000 (58%)]\t Loss:0.109382 acc:0.97\n",
      "Train Epoch:10[35328/60000 (59%)]\t Loss:0.114242 acc:0.97\n",
      "Train Epoch:10[35840/60000 (60%)]\t Loss:0.098022 acc:0.96\n",
      "Train Epoch:10[36352/60000 (61%)]\t Loss:0.122848 acc:0.96\n",
      "Train Epoch:10[36864/60000 (61%)]\t Loss:0.150539 acc:0.95\n",
      "Train Epoch:10[37376/60000 (62%)]\t Loss:0.148963 acc:0.96\n",
      "Train Epoch:10[37888/60000 (63%)]\t Loss:0.087491 acc:0.97\n",
      "Train Epoch:10[38400/60000 (64%)]\t Loss:0.102329 acc:0.97\n",
      "Train Epoch:10[38912/60000 (65%)]\t Loss:0.127523 acc:0.96\n",
      "Train Epoch:10[39424/60000 (66%)]\t Loss:0.122406 acc:0.96\n",
      "Train Epoch:10[39936/60000 (67%)]\t Loss:0.092010 acc:0.97\n",
      "Train Epoch:10[40448/60000 (67%)]\t Loss:0.101158 acc:0.96\n",
      "Train Epoch:10[40960/60000 (68%)]\t Loss:0.166039 acc:0.95\n",
      "Train Epoch:10[41472/60000 (69%)]\t Loss:0.109174 acc:0.97\n",
      "Train Epoch:10[41984/60000 (70%)]\t Loss:0.157903 acc:0.94\n",
      "Train Epoch:10[42496/60000 (71%)]\t Loss:0.164292 acc:0.96\n",
      "Train Epoch:10[43008/60000 (72%)]\t Loss:0.105500 acc:0.96\n",
      "Train Epoch:10[43520/60000 (73%)]\t Loss:0.114986 acc:0.97\n",
      "Train Epoch:10[44032/60000 (73%)]\t Loss:0.144795 acc:0.95\n",
      "Train Epoch:10[44544/60000 (74%)]\t Loss:0.134020 acc:0.96\n",
      "Train Epoch:10[45056/60000 (75%)]\t Loss:0.122536 acc:0.96\n",
      "Train Epoch:10[45568/60000 (76%)]\t Loss:0.152271 acc:0.96\n",
      "Train Epoch:10[46080/60000 (77%)]\t Loss:0.166191 acc:0.95\n",
      "Train Epoch:10[46592/60000 (78%)]\t Loss:0.109472 acc:0.97\n",
      "Train Epoch:10[47104/60000 (79%)]\t Loss:0.165212 acc:0.94\n",
      "Train Epoch:10[47616/60000 (79%)]\t Loss:0.103996 acc:0.97\n",
      "Train Epoch:10[48128/60000 (80%)]\t Loss:0.078415 acc:0.97\n",
      "Train Epoch:10[48640/60000 (81%)]\t Loss:0.175034 acc:0.95\n",
      "Train Epoch:10[49152/60000 (82%)]\t Loss:0.175808 acc:0.94\n",
      "Train Epoch:10[49664/60000 (83%)]\t Loss:0.130533 acc:0.97\n",
      "Train Epoch:10[50176/60000 (84%)]\t Loss:0.198877 acc:0.95\n",
      "Train Epoch:10[50688/60000 (84%)]\t Loss:0.092949 acc:0.97\n",
      "Train Epoch:10[51200/60000 (85%)]\t Loss:0.098300 acc:0.97\n",
      "Train Epoch:10[51712/60000 (86%)]\t Loss:0.144833 acc:0.96\n",
      "Train Epoch:10[52224/60000 (87%)]\t Loss:0.094222 acc:0.97\n",
      "Train Epoch:10[52736/60000 (88%)]\t Loss:0.169743 acc:0.96\n",
      "Train Epoch:10[53248/60000 (89%)]\t Loss:0.111225 acc:0.96\n",
      "Train Epoch:10[53760/60000 (90%)]\t Loss:0.146680 acc:0.96\n",
      "Train Epoch:10[54272/60000 (90%)]\t Loss:0.095047 acc:0.98\n",
      "Train Epoch:10[54784/60000 (91%)]\t Loss:0.131235 acc:0.95\n",
      "Train Epoch:10[55296/60000 (92%)]\t Loss:0.123870 acc:0.96\n",
      "Train Epoch:10[55808/60000 (93%)]\t Loss:0.106753 acc:0.97\n",
      "Train Epoch:10[56320/60000 (94%)]\t Loss:0.101785 acc:0.96\n",
      "Train Epoch:10[56832/60000 (95%)]\t Loss:0.076289 acc:0.97\n",
      "Train Epoch:10[57344/60000 (96%)]\t Loss:0.107854 acc:0.96\n",
      "Train Epoch:10[57856/60000 (96%)]\t Loss:0.071190 acc:0.98\n",
      "Train Epoch:10[58368/60000 (97%)]\t Loss:0.061419 acc:0.99\n",
      "Train Epoch:10[58880/60000 (98%)]\t Loss:0.046488 acc:0.99\n",
      "Train Epoch:10[59392/60000 (99%)]\t Loss:0.108918 acc:0.98\n",
      "Train Epoch:10[59904/60000 (100%)]\t Loss:0.224729 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:10 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:10 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:10 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:10 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:10 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:10 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:10 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:10 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:10 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:10 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:10 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:10 [5632/10000 (56%)]\t acc:0.59\n",
      "Test Epoch:10 [6144/10000 (61%)]\t acc:0.64\n",
      "Test Epoch:10 [6656/10000 (67%)]\t acc:0.69\n",
      "Test Epoch:10 [7168/10000 (72%)]\t acc:0.74\n",
      "Test Epoch:10 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:10 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:10 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:10 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:10 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:11[0/60000 (0%)]\t Loss:0.140017 acc:0.96\n",
      "Train Epoch:11[512/60000 (1%)]\t Loss:0.132702 acc:0.96\n",
      "Train Epoch:11[1024/60000 (2%)]\t Loss:0.183811 acc:0.94\n",
      "Train Epoch:11[1536/60000 (3%)]\t Loss:0.081060 acc:0.98\n",
      "Train Epoch:11[2048/60000 (3%)]\t Loss:0.077223 acc:0.98\n",
      "Train Epoch:11[2560/60000 (4%)]\t Loss:0.120855 acc:0.97\n",
      "Train Epoch:11[3072/60000 (5%)]\t Loss:0.079519 acc:0.97\n",
      "Train Epoch:11[3584/60000 (6%)]\t Loss:0.080381 acc:0.97\n",
      "Train Epoch:11[4096/60000 (7%)]\t Loss:0.116445 acc:0.97\n",
      "Train Epoch:11[4608/60000 (8%)]\t Loss:0.130252 acc:0.96\n",
      "Train Epoch:11[5120/60000 (9%)]\t Loss:0.125420 acc:0.96\n",
      "Train Epoch:11[5632/60000 (9%)]\t Loss:0.122327 acc:0.96\n",
      "Train Epoch:11[6144/60000 (10%)]\t Loss:0.118494 acc:0.97\n",
      "Train Epoch:11[6656/60000 (11%)]\t Loss:0.158256 acc:0.96\n",
      "Train Epoch:11[7168/60000 (12%)]\t Loss:0.123223 acc:0.96\n",
      "Train Epoch:11[7680/60000 (13%)]\t Loss:0.132897 acc:0.96\n",
      "Train Epoch:11[8192/60000 (14%)]\t Loss:0.154414 acc:0.95\n",
      "Train Epoch:11[8704/60000 (15%)]\t Loss:0.192154 acc:0.95\n",
      "Train Epoch:11[9216/60000 (15%)]\t Loss:0.126161 acc:0.96\n",
      "Train Epoch:11[9728/60000 (16%)]\t Loss:0.117212 acc:0.96\n",
      "Train Epoch:11[10240/60000 (17%)]\t Loss:0.109114 acc:0.97\n",
      "Train Epoch:11[10752/60000 (18%)]\t Loss:0.120686 acc:0.96\n",
      "Train Epoch:11[11264/60000 (19%)]\t Loss:0.133057 acc:0.96\n",
      "Train Epoch:11[11776/60000 (20%)]\t Loss:0.094264 acc:0.97\n",
      "Train Epoch:11[12288/60000 (20%)]\t Loss:0.153020 acc:0.96\n",
      "Train Epoch:11[12800/60000 (21%)]\t Loss:0.119237 acc:0.96\n",
      "Train Epoch:11[13312/60000 (22%)]\t Loss:0.098207 acc:0.98\n",
      "Train Epoch:11[13824/60000 (23%)]\t Loss:0.136587 acc:0.96\n",
      "Train Epoch:11[14336/60000 (24%)]\t Loss:0.157069 acc:0.93\n",
      "Train Epoch:11[14848/60000 (25%)]\t Loss:0.109085 acc:0.96\n",
      "Train Epoch:11[15360/60000 (26%)]\t Loss:0.123078 acc:0.96\n",
      "Train Epoch:11[15872/60000 (26%)]\t Loss:0.111533 acc:0.97\n",
      "Train Epoch:11[16384/60000 (27%)]\t Loss:0.116744 acc:0.96\n",
      "Train Epoch:11[16896/60000 (28%)]\t Loss:0.111374 acc:0.97\n",
      "Train Epoch:11[17408/60000 (29%)]\t Loss:0.132882 acc:0.96\n",
      "Train Epoch:11[17920/60000 (30%)]\t Loss:0.102701 acc:0.96\n",
      "Train Epoch:11[18432/60000 (31%)]\t Loss:0.077431 acc:0.98\n",
      "Train Epoch:11[18944/60000 (32%)]\t Loss:0.108658 acc:0.97\n",
      "Train Epoch:11[19456/60000 (32%)]\t Loss:0.110712 acc:0.96\n",
      "Train Epoch:11[19968/60000 (33%)]\t Loss:0.110400 acc:0.97\n",
      "Train Epoch:11[20480/60000 (34%)]\t Loss:0.189545 acc:0.96\n",
      "Train Epoch:11[20992/60000 (35%)]\t Loss:0.107941 acc:0.97\n",
      "Train Epoch:11[21504/60000 (36%)]\t Loss:0.094891 acc:0.97\n",
      "Train Epoch:11[22016/60000 (37%)]\t Loss:0.112183 acc:0.96\n",
      "Train Epoch:11[22528/60000 (38%)]\t Loss:0.120209 acc:0.96\n",
      "Train Epoch:11[23040/60000 (38%)]\t Loss:0.072897 acc:0.98\n",
      "Train Epoch:11[23552/60000 (39%)]\t Loss:0.122287 acc:0.97\n",
      "Train Epoch:11[24064/60000 (40%)]\t Loss:0.096979 acc:0.97\n",
      "Train Epoch:11[24576/60000 (41%)]\t Loss:0.144547 acc:0.96\n",
      "Train Epoch:11[25088/60000 (42%)]\t Loss:0.109843 acc:0.97\n",
      "Train Epoch:11[25600/60000 (43%)]\t Loss:0.110384 acc:0.97\n",
      "Train Epoch:11[26112/60000 (44%)]\t Loss:0.146900 acc:0.96\n",
      "Train Epoch:11[26624/60000 (44%)]\t Loss:0.126418 acc:0.96\n",
      "Train Epoch:11[27136/60000 (45%)]\t Loss:0.132999 acc:0.97\n",
      "Train Epoch:11[27648/60000 (46%)]\t Loss:0.101576 acc:0.96\n",
      "Train Epoch:11[28160/60000 (47%)]\t Loss:0.148461 acc:0.96\n",
      "Train Epoch:11[28672/60000 (48%)]\t Loss:0.101383 acc:0.97\n",
      "Train Epoch:11[29184/60000 (49%)]\t Loss:0.109487 acc:0.97\n",
      "Train Epoch:11[29696/60000 (49%)]\t Loss:0.171269 acc:0.95\n",
      "Train Epoch:11[30208/60000 (50%)]\t Loss:0.094327 acc:0.97\n",
      "Train Epoch:11[30720/60000 (51%)]\t Loss:0.126323 acc:0.96\n",
      "Train Epoch:11[31232/60000 (52%)]\t Loss:0.160278 acc:0.96\n",
      "Train Epoch:11[31744/60000 (53%)]\t Loss:0.106534 acc:0.96\n",
      "Train Epoch:11[32256/60000 (54%)]\t Loss:0.136792 acc:0.95\n",
      "Train Epoch:11[32768/60000 (55%)]\t Loss:0.097238 acc:0.97\n",
      "Train Epoch:11[33280/60000 (55%)]\t Loss:0.126575 acc:0.96\n",
      "Train Epoch:11[33792/60000 (56%)]\t Loss:0.066682 acc:0.98\n",
      "Train Epoch:11[34304/60000 (57%)]\t Loss:0.151423 acc:0.96\n",
      "Train Epoch:11[34816/60000 (58%)]\t Loss:0.104413 acc:0.96\n",
      "Train Epoch:11[35328/60000 (59%)]\t Loss:0.109434 acc:0.97\n",
      "Train Epoch:11[35840/60000 (60%)]\t Loss:0.091860 acc:0.97\n",
      "Train Epoch:11[36352/60000 (61%)]\t Loss:0.116801 acc:0.96\n",
      "Train Epoch:11[36864/60000 (61%)]\t Loss:0.142562 acc:0.95\n",
      "Train Epoch:11[37376/60000 (62%)]\t Loss:0.142461 acc:0.96\n",
      "Train Epoch:11[37888/60000 (63%)]\t Loss:0.081220 acc:0.98\n",
      "Train Epoch:11[38400/60000 (64%)]\t Loss:0.097966 acc:0.97\n",
      "Train Epoch:11[38912/60000 (65%)]\t Loss:0.122805 acc:0.96\n",
      "Train Epoch:11[39424/60000 (66%)]\t Loss:0.116020 acc:0.96\n",
      "Train Epoch:11[39936/60000 (67%)]\t Loss:0.082224 acc:0.97\n",
      "Train Epoch:11[40448/60000 (67%)]\t Loss:0.091943 acc:0.97\n",
      "Train Epoch:11[40960/60000 (68%)]\t Loss:0.155128 acc:0.95\n",
      "Train Epoch:11[41472/60000 (69%)]\t Loss:0.101647 acc:0.97\n",
      "Train Epoch:11[41984/60000 (70%)]\t Loss:0.144073 acc:0.95\n",
      "Train Epoch:11[42496/60000 (71%)]\t Loss:0.157422 acc:0.96\n",
      "Train Epoch:11[43008/60000 (72%)]\t Loss:0.100064 acc:0.96\n",
      "Train Epoch:11[43520/60000 (73%)]\t Loss:0.106377 acc:0.97\n",
      "Train Epoch:11[44032/60000 (73%)]\t Loss:0.138880 acc:0.95\n",
      "Train Epoch:11[44544/60000 (74%)]\t Loss:0.127339 acc:0.96\n",
      "Train Epoch:11[45056/60000 (75%)]\t Loss:0.114741 acc:0.96\n",
      "Train Epoch:11[45568/60000 (76%)]\t Loss:0.145477 acc:0.96\n",
      "Train Epoch:11[46080/60000 (77%)]\t Loss:0.158634 acc:0.95\n",
      "Train Epoch:11[46592/60000 (78%)]\t Loss:0.103450 acc:0.97\n",
      "Train Epoch:11[47104/60000 (79%)]\t Loss:0.153018 acc:0.95\n",
      "Train Epoch:11[47616/60000 (79%)]\t Loss:0.099155 acc:0.97\n",
      "Train Epoch:11[48128/60000 (80%)]\t Loss:0.072388 acc:0.97\n",
      "Train Epoch:11[48640/60000 (81%)]\t Loss:0.169707 acc:0.95\n",
      "Train Epoch:11[49152/60000 (82%)]\t Loss:0.169174 acc:0.94\n",
      "Train Epoch:11[49664/60000 (83%)]\t Loss:0.126005 acc:0.97\n",
      "Train Epoch:11[50176/60000 (84%)]\t Loss:0.185831 acc:0.95\n",
      "Train Epoch:11[50688/60000 (84%)]\t Loss:0.086543 acc:0.98\n",
      "Train Epoch:11[51200/60000 (85%)]\t Loss:0.093616 acc:0.98\n",
      "Train Epoch:11[51712/60000 (86%)]\t Loss:0.137685 acc:0.96\n",
      "Train Epoch:11[52224/60000 (87%)]\t Loss:0.088872 acc:0.97\n",
      "Train Epoch:11[52736/60000 (88%)]\t Loss:0.161228 acc:0.96\n",
      "Train Epoch:11[53248/60000 (89%)]\t Loss:0.105306 acc:0.96\n",
      "Train Epoch:11[53760/60000 (90%)]\t Loss:0.139156 acc:0.97\n",
      "Train Epoch:11[54272/60000 (90%)]\t Loss:0.089087 acc:0.98\n",
      "Train Epoch:11[54784/60000 (91%)]\t Loss:0.124195 acc:0.95\n",
      "Train Epoch:11[55296/60000 (92%)]\t Loss:0.117773 acc:0.97\n",
      "Train Epoch:11[55808/60000 (93%)]\t Loss:0.101966 acc:0.97\n",
      "Train Epoch:11[56320/60000 (94%)]\t Loss:0.094584 acc:0.96\n",
      "Train Epoch:11[56832/60000 (95%)]\t Loss:0.071181 acc:0.98\n",
      "Train Epoch:11[57344/60000 (96%)]\t Loss:0.103985 acc:0.97\n",
      "Train Epoch:11[57856/60000 (96%)]\t Loss:0.068381 acc:0.98\n",
      "Train Epoch:11[58368/60000 (97%)]\t Loss:0.059131 acc:0.99\n",
      "Train Epoch:11[58880/60000 (98%)]\t Loss:0.042439 acc:0.99\n",
      "Train Epoch:11[59392/60000 (99%)]\t Loss:0.104984 acc:0.98\n",
      "Train Epoch:11[59904/60000 (100%)]\t Loss:0.225139 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:11 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:11 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:11 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:11 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:11 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:11 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:11 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:11 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:11 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:11 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:11 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:11 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:11 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:11 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:11 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:11 [7680/10000 (77%)]\t acc:0.79\n",
      "Test Epoch:11 [8192/10000 (82%)]\t acc:0.84\n",
      "Test Epoch:11 [8704/10000 (87%)]\t acc:0.89\n",
      "Test Epoch:11 [9216/10000 (92%)]\t acc:0.94\n",
      "Test Epoch:11 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:12[0/60000 (0%)]\t Loss:0.134048 acc:0.97\n",
      "Train Epoch:12[512/60000 (1%)]\t Loss:0.123701 acc:0.97\n",
      "Train Epoch:12[1024/60000 (2%)]\t Loss:0.171318 acc:0.95\n",
      "Train Epoch:12[1536/60000 (3%)]\t Loss:0.076848 acc:0.98\n",
      "Train Epoch:12[2048/60000 (3%)]\t Loss:0.071176 acc:0.98\n",
      "Train Epoch:12[2560/60000 (4%)]\t Loss:0.117405 acc:0.97\n",
      "Train Epoch:12[3072/60000 (5%)]\t Loss:0.072112 acc:0.98\n",
      "Train Epoch:12[3584/60000 (6%)]\t Loss:0.072308 acc:0.98\n",
      "Train Epoch:12[4096/60000 (7%)]\t Loss:0.108429 acc:0.97\n",
      "Train Epoch:12[4608/60000 (8%)]\t Loss:0.122860 acc:0.96\n",
      "Train Epoch:12[5120/60000 (9%)]\t Loss:0.115615 acc:0.96\n",
      "Train Epoch:12[5632/60000 (9%)]\t Loss:0.118063 acc:0.97\n",
      "Train Epoch:12[6144/60000 (10%)]\t Loss:0.117674 acc:0.97\n",
      "Train Epoch:12[6656/60000 (11%)]\t Loss:0.154071 acc:0.97\n",
      "Train Epoch:12[7168/60000 (12%)]\t Loss:0.117095 acc:0.96\n",
      "Train Epoch:12[7680/60000 (13%)]\t Loss:0.126104 acc:0.96\n",
      "Train Epoch:12[8192/60000 (14%)]\t Loss:0.148059 acc:0.95\n",
      "Train Epoch:12[8704/60000 (15%)]\t Loss:0.180571 acc:0.95\n",
      "Train Epoch:12[9216/60000 (15%)]\t Loss:0.119719 acc:0.96\n",
      "Train Epoch:12[9728/60000 (16%)]\t Loss:0.106794 acc:0.96\n",
      "Train Epoch:12[10240/60000 (17%)]\t Loss:0.098911 acc:0.97\n",
      "Train Epoch:12[10752/60000 (18%)]\t Loss:0.112005 acc:0.97\n",
      "Train Epoch:12[11264/60000 (19%)]\t Loss:0.121822 acc:0.96\n",
      "Train Epoch:12[11776/60000 (20%)]\t Loss:0.087293 acc:0.97\n",
      "Train Epoch:12[12288/60000 (20%)]\t Loss:0.136292 acc:0.96\n",
      "Train Epoch:12[12800/60000 (21%)]\t Loss:0.112733 acc:0.96\n",
      "Train Epoch:12[13312/60000 (22%)]\t Loss:0.092126 acc:0.98\n",
      "Train Epoch:12[13824/60000 (23%)]\t Loss:0.130093 acc:0.96\n",
      "Train Epoch:12[14336/60000 (24%)]\t Loss:0.150246 acc:0.94\n",
      "Train Epoch:12[14848/60000 (25%)]\t Loss:0.101559 acc:0.96\n",
      "Train Epoch:12[15360/60000 (26%)]\t Loss:0.113962 acc:0.96\n",
      "Train Epoch:12[15872/60000 (26%)]\t Loss:0.107234 acc:0.96\n",
      "Train Epoch:12[16384/60000 (27%)]\t Loss:0.110822 acc:0.96\n",
      "Train Epoch:12[16896/60000 (28%)]\t Loss:0.106508 acc:0.97\n",
      "Train Epoch:12[17408/60000 (29%)]\t Loss:0.126092 acc:0.96\n",
      "Train Epoch:12[17920/60000 (30%)]\t Loss:0.096626 acc:0.97\n",
      "Train Epoch:12[18432/60000 (31%)]\t Loss:0.068788 acc:0.99\n",
      "Train Epoch:12[18944/60000 (32%)]\t Loss:0.102149 acc:0.97\n",
      "Train Epoch:12[19456/60000 (32%)]\t Loss:0.103180 acc:0.96\n",
      "Train Epoch:12[19968/60000 (33%)]\t Loss:0.100976 acc:0.97\n",
      "Train Epoch:12[20480/60000 (34%)]\t Loss:0.179989 acc:0.96\n",
      "Train Epoch:12[20992/60000 (35%)]\t Loss:0.102119 acc:0.97\n",
      "Train Epoch:12[21504/60000 (36%)]\t Loss:0.089916 acc:0.97\n",
      "Train Epoch:12[22016/60000 (37%)]\t Loss:0.105394 acc:0.97\n",
      "Train Epoch:12[22528/60000 (38%)]\t Loss:0.111289 acc:0.96\n",
      "Train Epoch:12[23040/60000 (38%)]\t Loss:0.067344 acc:0.98\n",
      "Train Epoch:12[23552/60000 (39%)]\t Loss:0.116647 acc:0.97\n",
      "Train Epoch:12[24064/60000 (40%)]\t Loss:0.087044 acc:0.97\n",
      "Train Epoch:12[24576/60000 (41%)]\t Loss:0.136262 acc:0.96\n",
      "Train Epoch:12[25088/60000 (42%)]\t Loss:0.102108 acc:0.97\n",
      "Train Epoch:12[25600/60000 (43%)]\t Loss:0.104877 acc:0.97\n",
      "Train Epoch:12[26112/60000 (44%)]\t Loss:0.137625 acc:0.96\n",
      "Train Epoch:12[26624/60000 (44%)]\t Loss:0.117824 acc:0.96\n",
      "Train Epoch:12[27136/60000 (45%)]\t Loss:0.123068 acc:0.97\n",
      "Train Epoch:12[27648/60000 (46%)]\t Loss:0.095582 acc:0.96\n",
      "Train Epoch:12[28160/60000 (47%)]\t Loss:0.140155 acc:0.96\n",
      "Train Epoch:12[28672/60000 (48%)]\t Loss:0.096941 acc:0.97\n",
      "Train Epoch:12[29184/60000 (49%)]\t Loss:0.103003 acc:0.97\n",
      "Train Epoch:12[29696/60000 (49%)]\t Loss:0.167357 acc:0.95\n",
      "Train Epoch:12[30208/60000 (50%)]\t Loss:0.088923 acc:0.98\n",
      "Train Epoch:12[30720/60000 (51%)]\t Loss:0.118673 acc:0.97\n",
      "Train Epoch:12[31232/60000 (52%)]\t Loss:0.150375 acc:0.96\n",
      "Train Epoch:12[31744/60000 (53%)]\t Loss:0.099722 acc:0.96\n",
      "Train Epoch:12[32256/60000 (54%)]\t Loss:0.128614 acc:0.96\n",
      "Train Epoch:12[32768/60000 (55%)]\t Loss:0.090695 acc:0.97\n",
      "Train Epoch:12[33280/60000 (55%)]\t Loss:0.119195 acc:0.96\n",
      "Train Epoch:12[33792/60000 (56%)]\t Loss:0.063555 acc:0.98\n",
      "Train Epoch:12[34304/60000 (57%)]\t Loss:0.142712 acc:0.96\n",
      "Train Epoch:12[34816/60000 (58%)]\t Loss:0.101827 acc:0.96\n",
      "Train Epoch:12[35328/60000 (59%)]\t Loss:0.104422 acc:0.97\n",
      "Train Epoch:12[35840/60000 (60%)]\t Loss:0.086747 acc:0.98\n",
      "Train Epoch:12[36352/60000 (61%)]\t Loss:0.112307 acc:0.97\n",
      "Train Epoch:12[36864/60000 (61%)]\t Loss:0.135345 acc:0.95\n",
      "Train Epoch:12[37376/60000 (62%)]\t Loss:0.137290 acc:0.96\n",
      "Train Epoch:12[37888/60000 (63%)]\t Loss:0.077778 acc:0.98\n",
      "Train Epoch:12[38400/60000 (64%)]\t Loss:0.094147 acc:0.98\n",
      "Train Epoch:12[38912/60000 (65%)]\t Loss:0.121594 acc:0.96\n",
      "Train Epoch:12[39424/60000 (66%)]\t Loss:0.111471 acc:0.96\n",
      "Train Epoch:12[39936/60000 (67%)]\t Loss:0.073839 acc:0.98\n",
      "Train Epoch:12[40448/60000 (67%)]\t Loss:0.085191 acc:0.97\n",
      "Train Epoch:12[40960/60000 (68%)]\t Loss:0.145295 acc:0.95\n",
      "Train Epoch:12[41472/60000 (69%)]\t Loss:0.094511 acc:0.97\n",
      "Train Epoch:12[41984/60000 (70%)]\t Loss:0.129485 acc:0.96\n",
      "Train Epoch:12[42496/60000 (71%)]\t Loss:0.149558 acc:0.96\n",
      "Train Epoch:12[43008/60000 (72%)]\t Loss:0.095338 acc:0.97\n",
      "Train Epoch:12[43520/60000 (73%)]\t Loss:0.098955 acc:0.97\n",
      "Train Epoch:12[44032/60000 (73%)]\t Loss:0.134967 acc:0.96\n",
      "Train Epoch:12[44544/60000 (74%)]\t Loss:0.122154 acc:0.96\n",
      "Train Epoch:12[45056/60000 (75%)]\t Loss:0.109032 acc:0.96\n",
      "Train Epoch:12[45568/60000 (76%)]\t Loss:0.142321 acc:0.96\n",
      "Train Epoch:12[46080/60000 (77%)]\t Loss:0.153868 acc:0.95\n",
      "Train Epoch:12[46592/60000 (78%)]\t Loss:0.098843 acc:0.96\n",
      "Train Epoch:12[47104/60000 (79%)]\t Loss:0.143843 acc:0.95\n",
      "Train Epoch:12[47616/60000 (79%)]\t Loss:0.094272 acc:0.97\n",
      "Train Epoch:12[48128/60000 (80%)]\t Loss:0.067049 acc:0.98\n",
      "Train Epoch:12[48640/60000 (81%)]\t Loss:0.163031 acc:0.95\n",
      "Train Epoch:12[49152/60000 (82%)]\t Loss:0.163048 acc:0.95\n",
      "Train Epoch:12[49664/60000 (83%)]\t Loss:0.120873 acc:0.97\n",
      "Train Epoch:12[50176/60000 (84%)]\t Loss:0.174667 acc:0.96\n",
      "Train Epoch:12[50688/60000 (84%)]\t Loss:0.079324 acc:0.98\n",
      "Train Epoch:12[51200/60000 (85%)]\t Loss:0.088339 acc:0.97\n",
      "Train Epoch:12[51712/60000 (86%)]\t Loss:0.131818 acc:0.96\n",
      "Train Epoch:12[52224/60000 (87%)]\t Loss:0.083582 acc:0.98\n",
      "Train Epoch:12[52736/60000 (88%)]\t Loss:0.155413 acc:0.96\n",
      "Train Epoch:12[53248/60000 (89%)]\t Loss:0.100973 acc:0.96\n",
      "Train Epoch:12[53760/60000 (90%)]\t Loss:0.133293 acc:0.97\n",
      "Train Epoch:12[54272/60000 (90%)]\t Loss:0.082833 acc:0.98\n",
      "Train Epoch:12[54784/60000 (91%)]\t Loss:0.117415 acc:0.95\n",
      "Train Epoch:12[55296/60000 (92%)]\t Loss:0.111821 acc:0.97\n",
      "Train Epoch:12[55808/60000 (93%)]\t Loss:0.095625 acc:0.97\n",
      "Train Epoch:12[56320/60000 (94%)]\t Loss:0.087503 acc:0.97\n",
      "Train Epoch:12[56832/60000 (95%)]\t Loss:0.066948 acc:0.98\n",
      "Train Epoch:12[57344/60000 (96%)]\t Loss:0.100844 acc:0.96\n",
      "Train Epoch:12[57856/60000 (96%)]\t Loss:0.066293 acc:0.98\n",
      "Train Epoch:12[58368/60000 (97%)]\t Loss:0.058774 acc:0.99\n",
      "Train Epoch:12[58880/60000 (98%)]\t Loss:0.039245 acc:0.99\n",
      "Train Epoch:12[59392/60000 (99%)]\t Loss:0.101981 acc:0.98\n",
      "Train Epoch:12[59904/60000 (100%)]\t Loss:0.224610 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:12 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:12 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:12 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:12 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:12 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:12 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:12 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:12 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:12 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:12 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:12 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:12 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:12 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:12 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:12 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:12 [7680/10000 (77%)]\t acc:0.80\n",
      "Test Epoch:12 [8192/10000 (82%)]\t acc:0.85\n",
      "Test Epoch:12 [8704/10000 (87%)]\t acc:0.90\n",
      "Test Epoch:12 [9216/10000 (92%)]\t acc:0.95\n",
      "Test Epoch:12 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:13[0/60000 (0%)]\t Loss:0.128523 acc:0.96\n",
      "Train Epoch:13[512/60000 (1%)]\t Loss:0.116003 acc:0.97\n",
      "Train Epoch:13[1024/60000 (2%)]\t Loss:0.160394 acc:0.95\n",
      "Train Epoch:13[1536/60000 (3%)]\t Loss:0.073021 acc:0.98\n",
      "Train Epoch:13[2048/60000 (3%)]\t Loss:0.065512 acc:0.98\n",
      "Train Epoch:13[2560/60000 (4%)]\t Loss:0.115409 acc:0.97\n",
      "Train Epoch:13[3072/60000 (5%)]\t Loss:0.065591 acc:0.98\n",
      "Train Epoch:13[3584/60000 (6%)]\t Loss:0.064799 acc:0.98\n",
      "Train Epoch:13[4096/60000 (7%)]\t Loss:0.099159 acc:0.97\n",
      "Train Epoch:13[4608/60000 (8%)]\t Loss:0.116308 acc:0.96\n",
      "Train Epoch:13[5120/60000 (9%)]\t Loss:0.104250 acc:0.97\n",
      "Train Epoch:13[5632/60000 (9%)]\t Loss:0.112054 acc:0.97\n",
      "Train Epoch:13[6144/60000 (10%)]\t Loss:0.111807 acc:0.97\n",
      "Train Epoch:13[6656/60000 (11%)]\t Loss:0.149043 acc:0.96\n",
      "Train Epoch:13[7168/60000 (12%)]\t Loss:0.113000 acc:0.95\n",
      "Train Epoch:13[7680/60000 (13%)]\t Loss:0.120625 acc:0.96\n",
      "Train Epoch:13[8192/60000 (14%)]\t Loss:0.143213 acc:0.95\n",
      "Train Epoch:13[8704/60000 (15%)]\t Loss:0.170372 acc:0.95\n",
      "Train Epoch:13[9216/60000 (15%)]\t Loss:0.115386 acc:0.97\n",
      "Train Epoch:13[9728/60000 (16%)]\t Loss:0.097465 acc:0.96\n",
      "Train Epoch:13[10240/60000 (17%)]\t Loss:0.089018 acc:0.98\n",
      "Train Epoch:13[10752/60000 (18%)]\t Loss:0.102468 acc:0.97\n",
      "Train Epoch:13[11264/60000 (19%)]\t Loss:0.109955 acc:0.96\n",
      "Train Epoch:13[11776/60000 (20%)]\t Loss:0.080738 acc:0.97\n",
      "Train Epoch:13[12288/60000 (20%)]\t Loss:0.120643 acc:0.96\n",
      "Train Epoch:13[12800/60000 (21%)]\t Loss:0.105126 acc:0.97\n",
      "Train Epoch:13[13312/60000 (22%)]\t Loss:0.086227 acc:0.98\n",
      "Train Epoch:13[13824/60000 (23%)]\t Loss:0.123165 acc:0.96\n",
      "Train Epoch:13[14336/60000 (24%)]\t Loss:0.144917 acc:0.94\n",
      "Train Epoch:13[14848/60000 (25%)]\t Loss:0.095803 acc:0.96\n",
      "Train Epoch:13[15360/60000 (26%)]\t Loss:0.107342 acc:0.97\n",
      "Train Epoch:13[15872/60000 (26%)]\t Loss:0.103301 acc:0.96\n",
      "Train Epoch:13[16384/60000 (27%)]\t Loss:0.105865 acc:0.96\n",
      "Train Epoch:13[16896/60000 (28%)]\t Loss:0.103904 acc:0.97\n",
      "Train Epoch:13[17408/60000 (29%)]\t Loss:0.121288 acc:0.96\n",
      "Train Epoch:13[17920/60000 (30%)]\t Loss:0.091953 acc:0.97\n",
      "Train Epoch:13[18432/60000 (31%)]\t Loss:0.061764 acc:0.99\n",
      "Train Epoch:13[18944/60000 (32%)]\t Loss:0.095953 acc:0.97\n",
      "Train Epoch:13[19456/60000 (32%)]\t Loss:0.094468 acc:0.97\n",
      "Train Epoch:13[19968/60000 (33%)]\t Loss:0.092675 acc:0.97\n",
      "Train Epoch:13[20480/60000 (34%)]\t Loss:0.168560 acc:0.96\n",
      "Train Epoch:13[20992/60000 (35%)]\t Loss:0.096605 acc:0.97\n",
      "Train Epoch:13[21504/60000 (36%)]\t Loss:0.085619 acc:0.97\n",
      "Train Epoch:13[22016/60000 (37%)]\t Loss:0.099899 acc:0.97\n",
      "Train Epoch:13[22528/60000 (38%)]\t Loss:0.103129 acc:0.96\n",
      "Train Epoch:13[23040/60000 (38%)]\t Loss:0.063647 acc:0.98\n",
      "Train Epoch:13[23552/60000 (39%)]\t Loss:0.112460 acc:0.97\n",
      "Train Epoch:13[24064/60000 (40%)]\t Loss:0.079263 acc:0.97\n",
      "Train Epoch:13[24576/60000 (41%)]\t Loss:0.129686 acc:0.96\n",
      "Train Epoch:13[25088/60000 (42%)]\t Loss:0.097268 acc:0.97\n",
      "Train Epoch:13[25600/60000 (43%)]\t Loss:0.101749 acc:0.97\n",
      "Train Epoch:13[26112/60000 (44%)]\t Loss:0.130410 acc:0.96\n",
      "Train Epoch:13[26624/60000 (44%)]\t Loss:0.111148 acc:0.96\n",
      "Train Epoch:13[27136/60000 (45%)]\t Loss:0.116958 acc:0.97\n",
      "Train Epoch:13[27648/60000 (46%)]\t Loss:0.088637 acc:0.96\n",
      "Train Epoch:13[28160/60000 (47%)]\t Loss:0.130991 acc:0.96\n",
      "Train Epoch:13[28672/60000 (48%)]\t Loss:0.090615 acc:0.97\n",
      "Train Epoch:13[29184/60000 (49%)]\t Loss:0.096260 acc:0.98\n",
      "Train Epoch:13[29696/60000 (49%)]\t Loss:0.163672 acc:0.94\n",
      "Train Epoch:13[30208/60000 (50%)]\t Loss:0.084774 acc:0.98\n",
      "Train Epoch:13[30720/60000 (51%)]\t Loss:0.113662 acc:0.97\n",
      "Train Epoch:13[31232/60000 (52%)]\t Loss:0.144462 acc:0.96\n",
      "Train Epoch:13[31744/60000 (53%)]\t Loss:0.094354 acc:0.97\n",
      "Train Epoch:13[32256/60000 (54%)]\t Loss:0.121642 acc:0.96\n",
      "Train Epoch:13[32768/60000 (55%)]\t Loss:0.084589 acc:0.98\n",
      "Train Epoch:13[33280/60000 (55%)]\t Loss:0.113034 acc:0.97\n",
      "Train Epoch:13[33792/60000 (56%)]\t Loss:0.060170 acc:0.98\n",
      "Train Epoch:13[34304/60000 (57%)]\t Loss:0.136406 acc:0.96\n",
      "Train Epoch:13[34816/60000 (58%)]\t Loss:0.098838 acc:0.96\n",
      "Train Epoch:13[35328/60000 (59%)]\t Loss:0.099395 acc:0.97\n",
      "Train Epoch:13[35840/60000 (60%)]\t Loss:0.083258 acc:0.98\n",
      "Train Epoch:13[36352/60000 (61%)]\t Loss:0.108195 acc:0.97\n",
      "Train Epoch:13[36864/60000 (61%)]\t Loss:0.127766 acc:0.95\n",
      "Train Epoch:13[37376/60000 (62%)]\t Loss:0.130256 acc:0.96\n",
      "Train Epoch:13[37888/60000 (63%)]\t Loss:0.074919 acc:0.98\n",
      "Train Epoch:13[38400/60000 (64%)]\t Loss:0.091244 acc:0.97\n",
      "Train Epoch:13[38912/60000 (65%)]\t Loss:0.120113 acc:0.96\n",
      "Train Epoch:13[39424/60000 (66%)]\t Loss:0.107571 acc:0.97\n",
      "Train Epoch:13[39936/60000 (67%)]\t Loss:0.066996 acc:0.98\n",
      "Train Epoch:13[40448/60000 (67%)]\t Loss:0.079956 acc:0.97\n",
      "Train Epoch:13[40960/60000 (68%)]\t Loss:0.137594 acc:0.95\n",
      "Train Epoch:13[41472/60000 (69%)]\t Loss:0.088957 acc:0.97\n",
      "Train Epoch:13[41984/60000 (70%)]\t Loss:0.116062 acc:0.96\n",
      "Train Epoch:13[42496/60000 (71%)]\t Loss:0.139573 acc:0.96\n",
      "Train Epoch:13[43008/60000 (72%)]\t Loss:0.089302 acc:0.97\n",
      "Train Epoch:13[43520/60000 (73%)]\t Loss:0.092366 acc:0.97\n",
      "Train Epoch:13[44032/60000 (73%)]\t Loss:0.129803 acc:0.96\n",
      "Train Epoch:13[44544/60000 (74%)]\t Loss:0.115909 acc:0.96\n",
      "Train Epoch:13[45056/60000 (75%)]\t Loss:0.104007 acc:0.97\n",
      "Train Epoch:13[45568/60000 (76%)]\t Loss:0.140179 acc:0.96\n",
      "Train Epoch:13[46080/60000 (77%)]\t Loss:0.148241 acc:0.95\n",
      "Train Epoch:13[46592/60000 (78%)]\t Loss:0.094921 acc:0.96\n",
      "Train Epoch:13[47104/60000 (79%)]\t Loss:0.137304 acc:0.96\n",
      "Train Epoch:13[47616/60000 (79%)]\t Loss:0.089807 acc:0.97\n",
      "Train Epoch:13[48128/60000 (80%)]\t Loss:0.062884 acc:0.98\n",
      "Train Epoch:13[48640/60000 (81%)]\t Loss:0.155714 acc:0.95\n",
      "Train Epoch:13[49152/60000 (82%)]\t Loss:0.154706 acc:0.95\n",
      "Train Epoch:13[49664/60000 (83%)]\t Loss:0.113421 acc:0.97\n",
      "Train Epoch:13[50176/60000 (84%)]\t Loss:0.164447 acc:0.96\n",
      "Train Epoch:13[50688/60000 (84%)]\t Loss:0.071253 acc:0.98\n",
      "Train Epoch:13[51200/60000 (85%)]\t Loss:0.082348 acc:0.97\n",
      "Train Epoch:13[51712/60000 (86%)]\t Loss:0.125288 acc:0.96\n",
      "Train Epoch:13[52224/60000 (87%)]\t Loss:0.077510 acc:0.98\n",
      "Train Epoch:13[52736/60000 (88%)]\t Loss:0.151052 acc:0.96\n",
      "Train Epoch:13[53248/60000 (89%)]\t Loss:0.096411 acc:0.96\n",
      "Train Epoch:13[53760/60000 (90%)]\t Loss:0.128658 acc:0.97\n",
      "Train Epoch:13[54272/60000 (90%)]\t Loss:0.077223 acc:0.98\n",
      "Train Epoch:13[54784/60000 (91%)]\t Loss:0.112069 acc:0.96\n",
      "Train Epoch:13[55296/60000 (92%)]\t Loss:0.107276 acc:0.97\n",
      "Train Epoch:13[55808/60000 (93%)]\t Loss:0.090287 acc:0.97\n",
      "Train Epoch:13[56320/60000 (94%)]\t Loss:0.078584 acc:0.97\n",
      "Train Epoch:13[56832/60000 (95%)]\t Loss:0.063863 acc:0.98\n",
      "Train Epoch:13[57344/60000 (96%)]\t Loss:0.096043 acc:0.97\n",
      "Train Epoch:13[57856/60000 (96%)]\t Loss:0.062906 acc:0.98\n",
      "Train Epoch:13[58368/60000 (97%)]\t Loss:0.057858 acc:0.99\n",
      "Train Epoch:13[58880/60000 (98%)]\t Loss:0.035810 acc:0.99\n",
      "Train Epoch:13[59392/60000 (99%)]\t Loss:0.099894 acc:0.98\n",
      "Train Epoch:13[59904/60000 (100%)]\t Loss:0.218540 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:13 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:13 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:13 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:13 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:13 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:13 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:13 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:13 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:13 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:13 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:13 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:13 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:13 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:13 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:13 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:13 [7680/10000 (77%)]\t acc:0.80\n",
      "Test Epoch:13 [8192/10000 (82%)]\t acc:0.85\n",
      "Test Epoch:13 [8704/10000 (87%)]\t acc:0.90\n",
      "Test Epoch:13 [9216/10000 (92%)]\t acc:0.95\n",
      "Test Epoch:13 [9728/10000 (97%)]\t acc:0.97\n",
      "Train Epoch:14[0/60000 (0%)]\t Loss:0.124053 acc:0.96\n",
      "Train Epoch:14[512/60000 (1%)]\t Loss:0.110676 acc:0.97\n",
      "Train Epoch:14[1024/60000 (2%)]\t Loss:0.151690 acc:0.95\n",
      "Train Epoch:14[1536/60000 (3%)]\t Loss:0.068921 acc:0.98\n",
      "Train Epoch:14[2048/60000 (3%)]\t Loss:0.059669 acc:0.99\n",
      "Train Epoch:14[2560/60000 (4%)]\t Loss:0.111951 acc:0.97\n",
      "Train Epoch:14[3072/60000 (5%)]\t Loss:0.060391 acc:0.98\n",
      "Train Epoch:14[3584/60000 (6%)]\t Loss:0.058236 acc:0.98\n",
      "Train Epoch:14[4096/60000 (7%)]\t Loss:0.090515 acc:0.97\n",
      "Train Epoch:14[4608/60000 (8%)]\t Loss:0.107658 acc:0.96\n",
      "Train Epoch:14[5120/60000 (9%)]\t Loss:0.093340 acc:0.97\n",
      "Train Epoch:14[5632/60000 (9%)]\t Loss:0.104997 acc:0.97\n",
      "Train Epoch:14[6144/60000 (10%)]\t Loss:0.102298 acc:0.97\n",
      "Train Epoch:14[6656/60000 (11%)]\t Loss:0.142456 acc:0.96\n",
      "Train Epoch:14[7168/60000 (12%)]\t Loss:0.107498 acc:0.96\n",
      "Train Epoch:14[7680/60000 (13%)]\t Loss:0.114379 acc:0.96\n",
      "Train Epoch:14[8192/60000 (14%)]\t Loss:0.137318 acc:0.95\n",
      "Train Epoch:14[8704/60000 (15%)]\t Loss:0.160466 acc:0.96\n",
      "Train Epoch:14[9216/60000 (15%)]\t Loss:0.111136 acc:0.97\n",
      "Train Epoch:14[9728/60000 (16%)]\t Loss:0.089715 acc:0.96\n",
      "Train Epoch:14[10240/60000 (17%)]\t Loss:0.080240 acc:0.98\n",
      "Train Epoch:14[10752/60000 (18%)]\t Loss:0.094122 acc:0.97\n",
      "Train Epoch:14[11264/60000 (19%)]\t Loss:0.096947 acc:0.96\n",
      "Train Epoch:14[11776/60000 (20%)]\t Loss:0.075281 acc:0.98\n",
      "Train Epoch:14[12288/60000 (20%)]\t Loss:0.108350 acc:0.96\n",
      "Train Epoch:14[12800/60000 (21%)]\t Loss:0.096383 acc:0.97\n",
      "Train Epoch:14[13312/60000 (22%)]\t Loss:0.080358 acc:0.98\n",
      "Train Epoch:14[13824/60000 (23%)]\t Loss:0.115704 acc:0.96\n",
      "Train Epoch:14[14336/60000 (24%)]\t Loss:0.136579 acc:0.94\n",
      "Train Epoch:14[14848/60000 (25%)]\t Loss:0.090045 acc:0.97\n",
      "Train Epoch:14[15360/60000 (26%)]\t Loss:0.101137 acc:0.97\n",
      "Train Epoch:14[15872/60000 (26%)]\t Loss:0.099207 acc:0.97\n",
      "Train Epoch:14[16384/60000 (27%)]\t Loss:0.100840 acc:0.97\n",
      "Train Epoch:14[16896/60000 (28%)]\t Loss:0.101357 acc:0.97\n",
      "Train Epoch:14[17408/60000 (29%)]\t Loss:0.117275 acc:0.96\n",
      "Train Epoch:14[17920/60000 (30%)]\t Loss:0.088635 acc:0.97\n",
      "Train Epoch:14[18432/60000 (31%)]\t Loss:0.055779 acc:0.99\n",
      "Train Epoch:14[18944/60000 (32%)]\t Loss:0.090420 acc:0.97\n",
      "Train Epoch:14[19456/60000 (32%)]\t Loss:0.084230 acc:0.97\n",
      "Train Epoch:14[19968/60000 (33%)]\t Loss:0.085468 acc:0.97\n",
      "Train Epoch:14[20480/60000 (34%)]\t Loss:0.157422 acc:0.96\n",
      "Train Epoch:14[20992/60000 (35%)]\t Loss:0.091032 acc:0.97\n",
      "Train Epoch:14[21504/60000 (36%)]\t Loss:0.081374 acc:0.97\n",
      "Train Epoch:14[22016/60000 (37%)]\t Loss:0.095960 acc:0.97\n",
      "Train Epoch:14[22528/60000 (38%)]\t Loss:0.096184 acc:0.96\n",
      "Train Epoch:14[23040/60000 (38%)]\t Loss:0.059427 acc:0.98\n",
      "Train Epoch:14[23552/60000 (39%)]\t Loss:0.107140 acc:0.97\n",
      "Train Epoch:14[24064/60000 (40%)]\t Loss:0.073372 acc:0.98\n",
      "Train Epoch:14[24576/60000 (41%)]\t Loss:0.123360 acc:0.96\n",
      "Train Epoch:14[25088/60000 (42%)]\t Loss:0.093212 acc:0.97\n",
      "Train Epoch:14[25600/60000 (43%)]\t Loss:0.100385 acc:0.97\n",
      "Train Epoch:14[26112/60000 (44%)]\t Loss:0.124388 acc:0.96\n",
      "Train Epoch:14[26624/60000 (44%)]\t Loss:0.106405 acc:0.96\n",
      "Train Epoch:14[27136/60000 (45%)]\t Loss:0.113337 acc:0.97\n",
      "Train Epoch:14[27648/60000 (46%)]\t Loss:0.081299 acc:0.97\n",
      "Train Epoch:14[28160/60000 (47%)]\t Loss:0.119880 acc:0.96\n",
      "Train Epoch:14[28672/60000 (48%)]\t Loss:0.083832 acc:0.97\n",
      "Train Epoch:14[29184/60000 (49%)]\t Loss:0.088997 acc:0.98\n",
      "Train Epoch:14[29696/60000 (49%)]\t Loss:0.154593 acc:0.95\n",
      "Train Epoch:14[30208/60000 (50%)]\t Loss:0.080293 acc:0.98\n",
      "Train Epoch:14[30720/60000 (51%)]\t Loss:0.109451 acc:0.97\n",
      "Train Epoch:14[31232/60000 (52%)]\t Loss:0.140900 acc:0.96\n",
      "Train Epoch:14[31744/60000 (53%)]\t Loss:0.089798 acc:0.97\n",
      "Train Epoch:14[32256/60000 (54%)]\t Loss:0.116884 acc:0.96\n",
      "Train Epoch:14[32768/60000 (55%)]\t Loss:0.079119 acc:0.98\n",
      "Train Epoch:14[33280/60000 (55%)]\t Loss:0.108052 acc:0.97\n",
      "Train Epoch:14[33792/60000 (56%)]\t Loss:0.055782 acc:0.98\n",
      "Train Epoch:14[34304/60000 (57%)]\t Loss:0.130321 acc:0.96\n",
      "Train Epoch:14[34816/60000 (58%)]\t Loss:0.093532 acc:0.97\n",
      "Train Epoch:14[35328/60000 (59%)]\t Loss:0.093680 acc:0.98\n",
      "Train Epoch:14[35840/60000 (60%)]\t Loss:0.080705 acc:0.98\n",
      "Train Epoch:14[36352/60000 (61%)]\t Loss:0.103074 acc:0.97\n",
      "Train Epoch:14[36864/60000 (61%)]\t Loss:0.121630 acc:0.96\n",
      "Train Epoch:14[37376/60000 (62%)]\t Loss:0.122420 acc:0.96\n",
      "Train Epoch:14[37888/60000 (63%)]\t Loss:0.071588 acc:0.98\n",
      "Train Epoch:14[38400/60000 (64%)]\t Loss:0.087371 acc:0.97\n",
      "Train Epoch:14[38912/60000 (65%)]\t Loss:0.116379 acc:0.97\n",
      "Train Epoch:14[39424/60000 (66%)]\t Loss:0.102265 acc:0.96\n",
      "Train Epoch:14[39936/60000 (67%)]\t Loss:0.061638 acc:0.99\n",
      "Train Epoch:14[40448/60000 (67%)]\t Loss:0.075738 acc:0.97\n",
      "Train Epoch:14[40960/60000 (68%)]\t Loss:0.131028 acc:0.95\n",
      "Train Epoch:14[41472/60000 (69%)]\t Loss:0.084361 acc:0.97\n",
      "Train Epoch:14[41984/60000 (70%)]\t Loss:0.104475 acc:0.96\n",
      "Train Epoch:14[42496/60000 (71%)]\t Loss:0.128695 acc:0.97\n",
      "Train Epoch:14[43008/60000 (72%)]\t Loss:0.083149 acc:0.97\n",
      "Train Epoch:14[43520/60000 (73%)]\t Loss:0.086252 acc:0.97\n",
      "Train Epoch:14[44032/60000 (73%)]\t Loss:0.123502 acc:0.96\n",
      "Train Epoch:14[44544/60000 (74%)]\t Loss:0.106945 acc:0.96\n",
      "Train Epoch:14[45056/60000 (75%)]\t Loss:0.098514 acc:0.97\n",
      "Train Epoch:14[45568/60000 (76%)]\t Loss:0.135968 acc:0.96\n",
      "Train Epoch:14[46080/60000 (77%)]\t Loss:0.142456 acc:0.96\n",
      "Train Epoch:14[46592/60000 (78%)]\t Loss:0.091975 acc:0.96\n",
      "Train Epoch:14[47104/60000 (79%)]\t Loss:0.131724 acc:0.96\n",
      "Train Epoch:14[47616/60000 (79%)]\t Loss:0.085449 acc:0.98\n",
      "Train Epoch:14[48128/60000 (80%)]\t Loss:0.059516 acc:0.98\n",
      "Train Epoch:14[48640/60000 (81%)]\t Loss:0.148382 acc:0.95\n",
      "Train Epoch:14[49152/60000 (82%)]\t Loss:0.146668 acc:0.95\n",
      "Train Epoch:14[49664/60000 (83%)]\t Loss:0.106708 acc:0.97\n",
      "Train Epoch:14[50176/60000 (84%)]\t Loss:0.155643 acc:0.96\n",
      "Train Epoch:14[50688/60000 (84%)]\t Loss:0.063727 acc:0.99\n",
      "Train Epoch:14[51200/60000 (85%)]\t Loss:0.076572 acc:0.97\n",
      "Train Epoch:14[51712/60000 (86%)]\t Loss:0.117903 acc:0.96\n",
      "Train Epoch:14[52224/60000 (87%)]\t Loss:0.071287 acc:0.98\n",
      "Train Epoch:14[52736/60000 (88%)]\t Loss:0.146900 acc:0.97\n",
      "Train Epoch:14[53248/60000 (89%)]\t Loss:0.092658 acc:0.96\n",
      "Train Epoch:14[53760/60000 (90%)]\t Loss:0.123076 acc:0.97\n",
      "Train Epoch:14[54272/60000 (90%)]\t Loss:0.072119 acc:0.98\n",
      "Train Epoch:14[54784/60000 (91%)]\t Loss:0.107052 acc:0.96\n",
      "Train Epoch:14[55296/60000 (92%)]\t Loss:0.103631 acc:0.97\n",
      "Train Epoch:14[55808/60000 (93%)]\t Loss:0.085936 acc:0.97\n",
      "Train Epoch:14[56320/60000 (94%)]\t Loss:0.071350 acc:0.97\n",
      "Train Epoch:14[56832/60000 (95%)]\t Loss:0.061599 acc:0.98\n",
      "Train Epoch:14[57344/60000 (96%)]\t Loss:0.091553 acc:0.97\n",
      "Train Epoch:14[57856/60000 (96%)]\t Loss:0.059519 acc:0.98\n",
      "Train Epoch:14[58368/60000 (97%)]\t Loss:0.056487 acc:0.99\n",
      "Train Epoch:14[58880/60000 (98%)]\t Loss:0.032450 acc:0.99\n",
      "Train Epoch:14[59392/60000 (99%)]\t Loss:0.097940 acc:0.98\n",
      "Train Epoch:14[59904/60000 (100%)]\t Loss:0.209701 acc:0.18\n",
      "===> Saving models...\n",
      "Test Epoch:14 [0/10000 (0%)]\t acc:0.05\n",
      "Test Epoch:14 [512/10000 (5%)]\t acc:0.10\n",
      "Test Epoch:14 [1024/10000 (10%)]\t acc:0.15\n",
      "Test Epoch:14 [1536/10000 (15%)]\t acc:0.20\n",
      "Test Epoch:14 [2048/10000 (20%)]\t acc:0.25\n",
      "Test Epoch:14 [2560/10000 (26%)]\t acc:0.30\n",
      "Test Epoch:14 [3072/10000 (31%)]\t acc:0.35\n",
      "Test Epoch:14 [3584/10000 (36%)]\t acc:0.40\n",
      "Test Epoch:14 [4096/10000 (41%)]\t acc:0.45\n",
      "Test Epoch:14 [4608/10000 (46%)]\t acc:0.50\n",
      "Test Epoch:14 [5120/10000 (51%)]\t acc:0.55\n",
      "Test Epoch:14 [5632/10000 (56%)]\t acc:0.60\n",
      "Test Epoch:14 [6144/10000 (61%)]\t acc:0.65\n",
      "Test Epoch:14 [6656/10000 (67%)]\t acc:0.70\n",
      "Test Epoch:14 [7168/10000 (72%)]\t acc:0.75\n",
      "Test Epoch:14 [7680/10000 (77%)]\t acc:0.80\n",
      "Test Epoch:14 [8192/10000 (82%)]\t acc:0.85\n",
      "Test Epoch:14 [8704/10000 (87%)]\t acc:0.90\n",
      "Test Epoch:14 [9216/10000 (92%)]\t acc:0.95\n",
      "Test Epoch:14 [9728/10000 (97%)]\t acc:0.97\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = SummaryWriter('logs')\n",
    "    # device = torch.device('cuda:0')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    net = LeNet()  # 实例化网络\n",
    "    # data_input = Variable(torch.randn(16,1,28,28))\n",
    "    # print(net(data_input))\n",
    "    net.to(device) # 将参数送入GPU中\n",
    "\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    cost_fun = nn.CrossEntropyLoss()\n",
    "    # optim\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.95, weight_decay=1e-3)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        # train\n",
    "        train(epoch)\n",
    "        writer.add_scalar('Train/Loss', train_loss[-2].item(), epoch)\n",
    "        writer.add_scalar('Train/Acc', train_acc[-2], epoch)\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # save_state\n",
    "        # ----------------------------------------- #\n",
    "        print('===> Saving models...')\n",
    "        state = {\n",
    "            'state': net.state_dict(),\n",
    "            'epoch': epoch  # 将epoch一并保存\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('./checkpoint')\n",
    "        torch.save(state, path_model + 'Epoch-' + str(epoch) + '-Loss-'+ str(train_loss[-1].item()) + '.pth')\n",
    "\n",
    "        # ----------------------------------------- #\n",
    "        # test\n",
    "        # ----------------------------------------- #\n",
    "        test()\n",
    "    writer.close()\n",
    "\n",
    "    # ----------------------------------------- #\n",
    "    # 加载指定的weights进行预测\n",
    "    # ----------------------------------------- #\n",
    "    # predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading weights : ./checkpoint/model_14.pth\n",
      "predicted: \"0\", actual:\"0\"\n",
      "predicted: \"9\", actual:\"9\"\n",
      "predicted: \"7\", actual:\"7\"\n",
      "predicted: \"9\", actual:\"9\"\n",
      "predicted: \"0\", actual:\"0\"\n",
      "predicted: \"1\", actual:\"1\"\n",
      "predicted: \"4\", actual:\"4\"\n",
      "predicted: \"0\", actual:\"0\"\n",
      "predicted: \"9\", actual:\"9\"\n",
      "predicted: \"0\", actual:\"0\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "net = LeNet()\n",
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Linear-7                  [-1, 120]          48,120\n",
      "              ReLU-8                  [-1, 120]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             ReLU-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "          Softmax-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#输出每层网络参数信息\n",
    "def variaes_show():\n",
    "    net = LeNet()\n",
    "    data_input = Variable(torch.randn(16,1,28,28))\n",
    "    print(data_input.size())\n",
    "    net(data_input)\n",
    "    print(summary(net,(1,28,28)))\n",
    "\n",
    "variaes_show()\n",
    "\n",
    "# net = LeNet()\n",
    "# summary(net,(1,28,28),batch_size=16,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading weights : ./checkpoint/model_14.pth\n",
      "type: <class 'dict'>\n",
      "len: 2\n",
      "key: state\n",
      "key: epoch\n",
      "================================\n",
      "block_1.0.weight\n",
      "shape: (6, 1, 5, 5)\n",
      "csv:  (6, 25) \n",
      "\n",
      "block_1.0.bias\n",
      "shape: (6,)\n",
      "csv:  (6,) \n",
      "\n",
      "block_1.3.weight\n",
      "shape: (16, 6, 5, 5)\n",
      "csv:  (16, 150) \n",
      "\n",
      "block_1.3.bias\n",
      "shape: (16,)\n",
      "csv:  (16,) \n",
      "\n",
      "block_2.0.weight\n",
      "shape: (120, 400)\n",
      "csv:  (120, 400) \n",
      "\n",
      "block_2.0.bias\n",
      "shape: (120,)\n",
      "csv:  (120,) \n",
      "\n",
      "block_2.2.weight\n",
      "shape: (84, 120)\n",
      "csv:  (84, 120) \n",
      "\n",
      "block_2.2.bias\n",
      "shape: (84,)\n",
      "csv:  (84,) \n",
      "\n",
      "block_2.4.weight\n",
      "shape: (10, 84)\n",
      "csv:  (10, 84) \n",
      "\n",
      "block_2.4.bias\n",
      "shape: (10,)\n",
      "csv:  (10,) \n",
      "\n",
      "================================\n",
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "def load_weight(model_path):\n",
    "        \n",
    "        print('===> Loading weights : ' + model_path)\n",
    "        weight_dict = torch.load(model_path)  # 加载最后训练出的权重\n",
    "\n",
    "        print('type: ' + str(type(weight_dict)))\n",
    "        print('len: ' + str(len(weight_dict)))\n",
    "\n",
    "        for k in weight_dict.keys():\n",
    "                print('key: '+ k)\n",
    "\n",
    "        # print(weight_dict['state'])\n",
    "        # print(weight_dict['epoch'])\n",
    "        print(\"================================\")\n",
    "\n",
    "        for key,value in weight_dict['state'].items():\n",
    "                value_np = value.numpy()\n",
    "                if not os.path.isdir('csv'):\n",
    "                        os.mkdir('./csv')\n",
    "                # np.savetxt(\"./csv/%s.csv\" %(key), value_np,  delimiter=\",\")\n",
    "                # pd.DataFrame(value_np).to_csv(\"./csv/%s.csv\" %(key))\n",
    "                # print(key, value.size())\n",
    "                print(key)\n",
    "                print('shape: '+ str(value_np.shape))\n",
    "                if (value_np.ndim == 4):\n",
    "                        (n_dim, _, _, _) = value_np.shape\n",
    "                        value_2d = value_np.reshape(n_dim,-1)\n",
    "                        np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "                        print(\"csv: \", value_2d.shape,'\\n')\n",
    "                elif (value_np.ndim == 3):\n",
    "                        ndim, _, _ = value_np.shape\n",
    "                        value_2d = value_np.reshape(n_dim,-1)\n",
    "                        np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "                        print(\"csv: \", value_2d.shape,'\\n')\n",
    "                # elif (value_np.ndim == 2):\n",
    "                #         ndim, _ = value_np.shape\n",
    "                #         value_2d = value_np.reshape(n_dim,-1)\n",
    "                #         print(value_2d.shape) \n",
    "                else :  \n",
    "                        value_2d = value_np\n",
    "                        np.savetxt(\"./csv/%s.csv\" %(key), value_2d,  delimiter=\",\")\n",
    "                        print(\"csv: \", value_2d.shape,'\\n')             \n",
    "\n",
    "\n",
    "        print(\"================================\")\n",
    "        print(type(weight_dict['state']))\n",
    "        \n",
    "\n",
    "state_path = './checkpoint/model_14.pth'\n",
    "load_weight(state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab0de5f2c42c334a270ce520738908c8f1964f7214e5cf9b2725bca46514c63e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
